[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Slack Tips for Better Team Management\n\n\n\nproductivity\n\ntools\n\n\n\n\n\n\n\n\n\nJun 30, 2025\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nKeyboard shortcuts on Mac\n\n\n\nsetup\n\nmacos\n\nshortcuts\n\nproductivity\n\nkeyboard-shortcuts\n\nworkflow\n\n\n\nKeyboard shortcuts on mac\n\n\n\n\n\nJun 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series Forecasting - Comparing MLP and Transformer Models\n\n\n\nML\n\ntime-series\n\nforecasting\n\ndeep-learning\n\ntransformers\n\npytorch\n\n\n\n\n\n\n\n\n\nMay 30, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nCharacter-Level Attention Mechanism for Name Generation\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMay 30, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nObject detection\n\n\n\nML\n\ncomputer-vision\n\nobject-detection\n\ndeep-learning\n\nneural-networks\n\nyolo\n\npytorch\n\n\n\n\n\n\n\n\n\nMay 30, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAttention in Sequence to Sequence\n\n\n\nML\n\nattention-mechanism\n\nsequence-to-sequence\n\ndeep-learning\n\nneural-networks\n\ntransformers\n\nnlp\n\npytorch\n\n\n\n\n\n\n\n\n\nMay 30, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nCharacter-Level RNN for Name Generation\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMay 30, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Distribution Analysis - Mean vs Standard Deviation\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMixture of Experts\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLogo\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJan 2, 2024\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Neural Process\n\n\n\nML\n\n\n\n\n\n\n\n\n\nDec 28, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nUsing a neural network as a covariance function\n\n\n\nML\n\n\n\n\n\n\n\n\n\nDec 22, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Transformers\n\n\n\nML\n\ntransformers\n\nattention-mechanism\n\ndeep-learning\n\nneural-networks\n\nnlp\n\nsequence-modeling\n\npytorch\n\n\n\n\n\n\n\n\n\nDec 21, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nNaive implementation of Strassen’s algorithm\n\n\n\nML\n\n\n\n\n\n\n\n\n\nDec 20, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nYouTube video to transcript using openAI whisper and summary using OLLama\n\n\n\nML\n\n\n\n\n\n\n\n\n\nDec 18, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nReinforcement Learning\n\n\n\nML\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSuper Resolution using U-Net like architecture\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nTrees using NetworkX\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nPositional Encoding\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Active Learning with Disagreement (BALD)\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nGradient wrt input for a simple model for adversarial attacks\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nPINN\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSIREN paper implementation\n\n\n\nML\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSIREN paper\n\n\n\nML\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nHeteroskedastic and Homoskedastic MLPs in PyTorch for regression\n\n\n\nML\n\n\n\n\n\n\n\n\n\nApr 10, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nTensorboard\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Connections in PyTorch\n\n\n\nML\n\n\n\n\n\n\n\n\n\nMar 18, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAutoML PyTorch\n\n\n\nML\n\nautoml\n\nneural-architecture-search\n\nhyperparameter-optimization\n\nautomated-machine-learning\n\npytorch\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nStacking (Meta Learning)\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 22, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nStacking (Ensemble Learning)\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate Taylor Series\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nComparing GP libraries\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 6, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Singular Value Decomposition with Visualizations\n\n\n\nML\n\nlinear-algebra\n\nmatrix-decomposition\n\ndimensionality-reduction\n\nvisualization\n\njax\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nConformal Prediction\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJan 19, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nVSCode Settings and Tips\n\n\n\nML\n\nvscode\n\n\n\n\n\n\n\n\n\nJan 17, 2023\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nBinomial and Poisson distribution\n\n\n\nML\n\n\n\n\n\n\n\n\n\nNov 20, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSome useful tidibts in sympy\n\n\n\nML\n\n\n\nSome useful tidibts in sympy\n\n\n\n\n\nNov 9, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAutoencoders in JAX\n\n\n\nML\n\n\n\nA programming introduction to Autoencoders in JAX\n\n\n\n\n\nNov 4, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nCalibration\n\n\n\nml\n\n\n\nProbability Calibration\n\n\n\n\n\nOct 27, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-output Gaussian Process\n\n\n\nml\n\n\n\nMulti-output Gaussian Process\n\n\n\n\n\nOct 25, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\nAudio Filtering\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 24, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nCoordinate descent failure example\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 21, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nPyro Conditioning\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 20, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression using Pyro\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 17, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilstic PCA using PyTorch distributions\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 17, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nDrawing graphical models\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 15, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nGMM\n\n\n\nML\n\nmixture-models\n\nclustering\n\nexpectation-maximization\n\nprobabilistic-models\n\nunsupervised-learning\n\n\n\n\n\n\n\n\n\nFeb 14, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression using PyTorch distributions\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 14, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nVariational inference\n\n\n\nML\n\nvariational-inference\n\nbayesian\n\napproximate-inference\n\nprobabilistic-models\n\noptimization\n\n\n\n\n\n\n\n\n\nFeb 12, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMaximum A-Posteriori (MAP) for parameters of univariate and multivariate normal distribution in PyTorch\n\n\n\nML\n\nPyTorch\n\n\n\n\n\n\n\n\n\nFeb 11, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix as transformation and interpreting low rank matrix\n\n\n\nML\n\nLA\n\n\n\n\n\n\n\n\n\nFeb 11, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMaximum Likelihood Estimation (MLE) for parameters of univariate and multivariate normal distribution in PyTorch\n\n\n\nML\n\nPyTorch\n\n\n\n\n\n\n\n\n\nFeb 9, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAutograd in JAX and PyTorch\n\n\n\nML\n\nJAX\n\nPyTorch\n\n\n\n\n\n\n\n\n\nFeb 9, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nCoin Toss (MLE, MAP, Fully Bayesian) in TF Probability\n\n\n\nML\n\nTFP\n\nTF\n\n\n\n\n\n\n\n\n\nFeb 7, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression in TF Probability using JointDistributionCoroutineAutoBatched\n\n\n\nML\n\nTFP\n\nTF\n\n\n\n\n\n\n\n\n\nFeb 5, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSimple Directed Graphical Models in TF Probability\n\n\n\nML\n\nTFP\n\nTF\n\n\n\n\n\n\n\n\n\nFeb 5, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSampling from univariate and multivariate normal distributions using Box-Muller transform\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 4, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding KL-Divergence\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJan 29, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression in Tensorflow Probability\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJan 28, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nTesting out some distributions in Tensorflow Probability\n\n\n\nML\n\n\n\n\n\n\n\n\n\nJan 26, 2022\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Gaussian Process regression parameters using mini-batch stochastic gradient descent\n\n\n\nML\n\n\n\nHow to learn the parameters of a GP\n\n\n\n\n\nSep 3, 2021\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression from scratch in Julia\n\n\n\nML\n\n\n\n\n\n\n\n\n\nSep 1, 2021\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilistic Programming in Pyro\n\n\n\nML\n\n\n\n\n\n\n\n\n\nAug 20, 2021\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nBlurring an image selectively using Affinity Photo\n\n\n\nsetup\n\n\n\nBlurring an image selectively using Affinity Photo\n\n\n\n\n\nJun 19, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nAudio filters\n\n\n\nsignal-processing\n\naudio\n\nfiltering\n\ndigital-signal-processing\n\npython\n\nscipy\n\n\n\nAudio filtering techniques and applications\n\n\n\n\n\nJun 18, 2021\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nRunning Python scripts on server over ssh and getting back content\n\n\n\nsetup\n\npython\n\nssh\n\nremote-development\n\nnetworking\n\nterminal\n\n\n\nRunning Python scripts on server over ssh and getting back content\n\n\n\n\n\nJun 17, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nSome of my shortcuts on the iPad\n\n\n\nsetup\n\nipad\n\nshortcuts\n\nautomation\n\nproductivity\n\nios\n\n\n\nSome of my shortcuts on the iPad\n\n\n\n\n\nJun 16, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMy iPad Setup\n\n\n\nsetup\n\nipad\n\nmobile-development\n\nproductivity\n\nios\n\n\n\nMy iPad computing setup\n\n\n\n\n\nJun 14, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMy Mac Setup\n\n\n\nsetup\n\nmacos\n\ndevelopment-environment\n\nproductivity\n\ntools\n\n\n\nMy Mac Setup\n\n\n\n\n\nJun 12, 2021\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nGAN\n\n\n\nML\n\ndeep-learning\n\ngenerative-models\n\nadversarial-networks\n\nneural-networks\n\nkeras\n\ntensorflow\n\n\n\nImplementation and visualization of Generative Adversarial Networks\n\n\n\n\n\nMay 31, 2021\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Kernels in Gaussian Processes Regression\n\n\n\nML\n\n\n\nUsing GPy and some interactive visualisations for understanding GPR and applying on a real world data set\n\n\n\n\n\nJun 26, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSampling from common distributions\n\n\n\nML\n\n\n\nFrom the ground up!\n\n\n\n\n\nApr 16, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Gaussian Process regression parameters using gradient descent\n\n\n\nML\n\n\n\nHow to learn the parameters of a GP\n\n\n\n\n\nMar 29, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nActive Learning with Bayesian Linear Regression\n\n\n\nML\n\n\n\nA programming introduction to Active Learning with Bayesian Linear Regression.\n\n\n\n\n\nMar 28, 2020\n\n\nZeel Patel & Nipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSome experiments in Gaussian Processes Regression\n\n\n\nML\n\n\n\nUsing GPy and some interactive visualisations for understanding GPR and applying on a real world data set\n\n\n\n\n\nMar 26, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSome Neural Network Classification\n\n\n\nML\n\n\n\nA programming introduction to NNs.\n\n\n\n\n\nMar 8, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks from scratch\n\n\n\nML\n\n\n\nSimple scripts for downloading weather data\n\n\n\n\n\nMar 2, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLearning neural network for XOR\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 28, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Linear Regression\n\n\n\nML\n\nbayesian\n\nlinear-regression\n\nuncertainty-quantification\n\nprobabilistic-models\n\nstatistics\n\n\n\nA programming introduction to Bayesian Linear Regression.\n\n\n\n\n\nFeb 20, 2020\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAn Example Markdown Post\n\n\n\nmarkdown\n\n\n\nA minimal example of using markdown with fastpages.\n\n\n\n\n\nJan 14, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nGaussian Processes\n\n\n\nML\n\ngaussian-processes\n\nbayesian\n\nuncertainty-quantification\n\nprobabilistic-models\n\nkernel-methods\n\n\n\nAn interactive exploration of Gaussian processes.\n\n\n\n\n\nAug 20, 2019\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nPlacement-Preparation-2018-1-HashMap\n\n\n\nacademia\n\n\n\nHashMaps for programming interviews\n\n\n\n\n\nAug 18, 2018\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising Electricity Access Over Space and Time\n\n\n\nsustainability\n\n\n\nHow is the world changing over the years!\n\n\n\n\n\nJun 26, 2018\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMapping location of air quality sensing in India\n\n\n\nair quality\n\n\n\nAQ sensing in India\n\n\n\n\n\nJun 21, 2018\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nActive Learning\n\n\n\nML\n\n\n\nA programming introduction to query by committee strategy for active learning\n\n\n\n\n\nJun 16, 2018\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nSignal denoising using RNNs in PyTorch\n\n\n\nML\n\n\n\nDenoising\n\n\n\n\n\nJan 13, 2018\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nCS Ph.D. lessons to my younger self\n\n\n\nacademia\n\n\n\nSome personal reflections..\n\n\n\n\n\nJan 7, 2018\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks for Collaborative Filtering\n\n\n\nML\n\n\n\nNeural networks to learn the embeddings! and how to combine them\n\n\n\n\n\nDec 29, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nRecommend keras\n\n\n\nML\n\nrecommendation-systems\n\ncollaborative-filtering\n\ndeep-learning\n\nneural-networks\n\nkeras\n\ntensorflow\n\n\n\n\n\n\n\n\n\nDec 18, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAdagrad based matrix factorization\n\n\n\nML\n\n\n\nAdagrad optimizer for matrix factorisation\n\n\n\n\n\nAug 13, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regression adagrad vs gd\n\n\n\nML\n\noptimization\n\ngradient-descent\n\nadagrad\n\nlinear-regression\n\nalgorithms\n\n\n\n\n\n\n\n\n\nAug 12, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nFifty ggplot python 1\n\n\n\nvisualization\n\ndata-visualization\n\nggplot\n\nplotnine\n\npython\n\ndata-analysis\n\n\n\n\n\n\n\n\n\nAug 2, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regression with prior (using gradient descent)\n\n\n\nML\n\n\n\nWhat if we start from some prior!\n\n\n\n\n\nJun 15, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nData exploration using widgets in Matplotlib\n\n\n\nvisualisation\n\n\n\nExploring data in Matplotlib\n\n\n\n\n\nJun 14, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nConstrained Non-negative matrix factorisation using CVXPY\n\n\n\nML\n\n\n\nConstrained NMF using CVXPY!\n\n\n\n\n\nApr 21, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nOut of Tensor factorisation\n\n\n\nML\n\n\n\nOut of tensor factorisation\n\n\n\n\n\nApr 20, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nOut of matrix non-negative matrix factorisation\n\n\n\nML\n\n\n\nWhat if we to predict for entries not within the matrix?!\n\n\n\n\n\nApr 19, 2017\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nMCMC coins\n\n\n\nML\n\nbayesian\n\nmcmc\n\nmonte-carlo\n\nprobabilistic-models\n\nparameter-estimation\n\n\n\n\n\n\n\n\n\nJul 1, 2014\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nLatexify Matplotlib\n\n\n\nvisualisation\n\n\n\nTowards amazing plots in research papers!\n\n\n\n\n\nJun 2, 2014\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nProgramatically understanding Expectation Maximization\n\n\n\nML\n\n\n\nMaximize based on what you know, re-estimate!\n\n\n\n\n\nJun 1, 2014\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nDTW\n\n\n\nML\n\ntime-series\n\ndynamic-time-warping\n\nsequence-alignment\n\nalgorithms\n\ndistance-metrics\n\n\n\n\n\n\n\n\n\nMay 1, 2014\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nGibbs sampling\n\n\n\nML\n\nbayesian\n\nmcmc\n\ngibbs-sampling\n\nprobabilistic-models\n\nsampling-methods\n\n\n\n\n\n\n\n\n\nMay 1, 2014\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nDenoising\n\n\n\nML\n\nsignal-processing\n\ndenoising\n\nimage-processing\n\nfeature-extraction\n\n\n\n\n\n\n\n\n\nSep 1, 2013\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nHMM Simulation for Continuous HMM\n\n\n\nML\n\n\n\nSimulating a continuous HMM\n\n\n\n\n\nJul 1, 2013\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nHMM simulate\n\n\n\nML\n\nhidden-markov-models\n\nsequence-modeling\n\nprobabilistic-models\n\ntime-series\n\nsimulation\n\n\n\n\n\n\n\n\n\nJun 1, 2013\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nAggregation timeseries\n\n\n\ntime-series\n\ndata-aggregation\n\ndata-analysis\n\npandas\n\nvisualization\n\n\n\n\n\n\n\n\n\nMay 1, 2013\n\n\nNipun Batra\n\n\n\n\n\n\n\n\n\n\n\n\nDownloading weather data\n\n\n\nvisualisation\n\n\n\nSimple scripts for downloading weather data\n\n\n\n\n\nApr 1, 2013\n\n\nNipun Batra\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2014-07-01-mcmc_coins.html",
    "href": "posts/2014-07-01-mcmc_coins.html",
    "title": "MCMC coins",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- bayesian- mcmc- monte-carlo- probabilistic-models- parameter-estimationdate: ’2014-07-01’output-file: 2014-07-01-mcmc_coins.htmltitle: MCMC coinstoc: true—\nIn the previous post, I had discussed regarding the EM algorithm from a programmer’s perspective. That blog post sparked an interesting discussion on Twitter which has led to the current post.\n\ntwitter: https://twitter.com/nipun_batra/status/460286604796383233\n\nThus, I started to investiage how good would MCMC methods perform in comparison to EM.\n\nProblem statement\nFor a detailed understanding, refer to the previous post. In short, the problem is as follows.\nYou have two coins - A and B. Both of them have their own biases (probability of obtaining a head (or a tail )). We pick a coin at random and toss it up 10 times. We repeat this procedure 5 times, totaling in 5 observation sets of 10 observations each. However, we are not told which coin was tossed. So, looking at the data and some rough initial guess about the respective coin biases, can we tell something about the likely biases? Let us work it up using PyMC.\n\n\nCustomary imports\n\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport seaborn as sns\n%matplotlib inline\n\n\n\nObservations\nWe use 1 for Heads and 0 for tails.\n\n# 5 observation sets of 10 observations each\nobservations = np.array([[1,0,0,0,1,1,0,1,0,1],\n                         [1,1,1,1,0,1,1,1,1,1],\n                         [1,0,1,1,1,1,1,0,1,1],\n                         [1,0,1,0,0,0,1,1,0,0],\n                         [0,1,1,1,0,1,1,1,0,1]])\nobservations_flattened = observations.flatten()\n\n\n\nNumber of heads in each obervation set\n\nn_heads_array = np.sum(observations, axis=1)\nplt.bar(range(len(n_heads_array)),n_heads_array.tolist());\nplt.title(\"Number of heads vs Observation set\")\nplt.xlabel(\"Observation set\")\nplt.ylabel(\"#Heads observed\");\n\n\n\n\n\n\n\n\n\n\nGround truth\nThe true sequence of coin tosses which was hidden from us. True indicated coin A and False indicates coin B.\n\n# Ground truth\ncoins_id = np.array([False,True,True,False,True])\n\nNumber of observation sets and number of observations in each set. This allows us to modify data easily (as opposed to hard coding stuff).\n\nn_observation_sets = observations.shape[0]\nn_observation_per_set = observations.shape[1]\n\n\n\nModel for the problem statement\nWe pick up a simple prior on the bias of coin A.\n\\(\\theta_a\\) ~ \\(\\beta(h_a,t_a)\\)\nSimilarly, for coin B.\n\\(\\theta_b\\) ~ \\(\\beta(h_b,t_b)\\)\nFor any given observation set, we assign equal probability to it coming from coin A or B.\n\\(coin choice\\) ~ DiscreteUniform(0,1)\nThus, if coin choice is known, then the associated bias term is fixed.\n\\(\\theta\\) = \\(\\theta_a\\) if \\(coin choice\\) =1 else \\(\\theta_b\\)\nLike, we did in the previous post, we use Binomial distribution with the bias as \\(\\theta\\). For each observation set, we calculate the number of heads observed and model it as our observed variable obs.\n\\(obs\\) = Binomial(n_tosses_per_observation_set, p = \\(\\theta\\) )\nLet us draw this model using daft.\n\nimport daft\n\npgm = daft.PGM([3.6, 2.7], origin=[1, 0.65])\npgm.add_node(daft.Node(\"theta_a\", r\"$\\theta_a$\", 4, 3, aspect=1.8))\npgm.add_node(daft.Node(\"theta_b\", r\"$\\theta_b$\", 3, 3, aspect=1.2))\npgm.add_node(daft.Node(\"theta\", r\"$\\theta$\", 3.5, 2, aspect=1.8))\npgm.add_node(daft.Node(\"coin_choice\", r\"coin_choice\", 2, 2, aspect=1.8))\npgm.add_node(daft.Node(\"obs\", r\"obs\", 3.5, 1, aspect=1.2, observed=True))\npgm.add_edge(\"theta_a\", \"theta\")\npgm.add_edge(\"theta_b\", \"theta\")\npgm.add_edge(\"coin_choice\", \"theta\")\npgm.add_edge(\"theta\", \"obs\")\npgm.render();\n\n\n\n\n\n\n\n\nThe following segment codes the above model.\n\n# Prior on coin A (For now we choose 2 H, 2 T)\ntheta_a = pm.Beta('theta_a',2,2)\n\n# Prior on coin B (For now we choose 2 H, 2 T)\ntheta_b = pm.Beta('theta_b',2,2)\n\n# Choosing either A or B \ncoin_choice_array = pm.DiscreteUniform('coin_choice',0,1, size = n_observation_sets)\n\n# Creating a theta (theta_a if A is tossed or theta_b if B is tossed)\n@pm.deterministic\ndef theta(theta_a = theta_a, theta_b=theta_b, coin_choice_array=coin_choice_array):\n    #print coin_choice_array\n    out = np.zeros(n_observation_sets)\n    for i, coin_choice in enumerate(coin_choice_array):\n        if coin_choice:\n            out[i] = theta_a\n        else:\n            out[i] = theta_b                   \n    return out\n\nLet us examine how theta would be related to coin choice and other variables we have defined.\n\ntheta_a.value\n\narray(0.46192564399429575)\n\n\n\ntheta_b.value\n\narray(0.5918506713420255)\n\n\n\ncoin_choice_array.value\n\narray([1, 1, 0, 0, 1])\n\n\n\ntheta.value\n\narray([ 0.46192564,  0.46192564,  0.59185067,  0.59185067,  0.46192564])\n\n\nSo, whenever we see coin A, we put it’s bias in theta and likewise if we observe coin B. Now, let us create a model for our observations which is binomial as discussed above.\n\nobservation_model = pm.Binomial(\"obs\", n=n_observation_per_set, p=theta, value = n_heads_array, observed=True)\nmodel = pm.Model([observation_model, theta_a, theta_b, coin_choice_array])\n\nLet us view a few samples from the observation_model which returns the number of heads in 5 sets of 10 tosses.\n\nobservation_model.random()\n\narray([4, 4, 7, 2, 6])\n\n\n\nobservation_model.random()\n\narray([4, 4, 7, 5, 2])\n\n\n\nmcmc = pm.MCMC(model)\nmcmc.sample(40000, 10000, 1)\n\n [-----------------100%-----------------] 40000 of 40000 complete in 7.8 sec\n\n\nLet us have a look at our posteriors for \\(\\theta_a\\) and \\(\\theta_b\\)\n\nplt.hist(mcmc.trace('theta_a')[:], bins=20,alpha=0.7,label = r\"$\\theta_a$\");\nplt.hist(mcmc.trace('theta_b')[:], bins=20,alpha=0.4,label= r\"$\\theta_b$\");\nplt.legend();\n\n\n\n\n\n\n\n\nLooks like both \\(\\theta_a\\) and \\(\\theta_b\\) peak around the same value. But, wasn’t it expected? We gave both of them the same priors. This was also the case when we initialed EM with same values for both \\(\\theta_a\\) and \\(\\theta_b\\). So, let us add some informative priors an see how we do. Like in EM experiment, we knew that one of the coin was more biased than the other. So, let us make that the case and rerun the experiment.\n\n\nMore informative priors\n\n# Prior on coin A (more likely to have heads)\ntheta_a = pm.Beta('theta_a',4,2)\n\n# Prior on coin B (more likely to have tails)\ntheta_b = pm.Beta('theta_b',2,4)\n\n# Choosing either A or B (for 5 observations)\ncoin_choice_array = pm.DiscreteUniform('coin_choice',0,1, size = 5)\n\n# Creating a theta (theta_a if A is tossed or theta_b if B is tossed)\n@pm.deterministic\ndef theta(theta_a = theta_a, theta_b=theta_b, coin_choice_array=coin_choice_array):\n    #print coin_choice_array\n    out = np.zeros(n_observation_sets)\n    for i, coin_choice in enumerate(coin_choice_array):\n        if coin_choice:\n            out[i] = theta_a\n        else:\n            out[i] = theta_b                   \n    return out\n\n\nobservation_model = pm.Binomial(\"obs\", n=10, p=theta, value = n_heads_array, observed=True)\nmodel = pm.Model([observation_model, theta_a, theta_b, coin_choice_array])\n\n\nmcmc = pm.MCMC(model)\nmcmc.sample(40000, 10000, 1)\n\n [-----------------100%-----------------] 40000 of 40000 complete in 8.0 sec\n\n\n\nplt.hist(mcmc.trace('theta_a')[:], bins=20,alpha=0.7,label = r\"$\\theta_a$\");\nplt.hist(mcmc.trace('theta_b')[:], bins=20,alpha=0.4,label= r\"$\\theta_b$\");\nplt.legend();\n\n\n\n\n\n\n\n\nQuiet a clear distinction now! \\(\\theta_a\\) seems to peak around 0.8 and \\(\\theta_b\\) around 0.5. This matches our results from EM. However, unlike EM, we have much more than point estimates.\nFeel free to leave your comments and suggestions by."
  },
  {
    "objectID": "posts/2022-02-15-draw-graphical-models.html",
    "href": "posts/2022-02-15-draw-graphical-models.html",
    "title": "Drawing graphical models",
    "section": "",
    "text": "from wand.image import Image as WImage\nfrom wand.color import Color\nimg = WImage(filename='../pgm/coin-toss.pdf', resolution=300)\nimg.crop(0, 400, 2480, 1500)\nimg\n\n\n\n\n\n\n\n\n\n%cat ../pgm/coin-toss.tex\n\n\\documentclass[a4paper]{article}\n\\usepackage{caption}\n\\usepackage{subcaption}\n\\usepackage{tikz}\n\\usetikzlibrary{bayesnet}\n\\usepackage{booktabs}\n\n\n\\setlength{\\tabcolsep}{12pt}\n\\begin{document}\n    \n    \\begin{figure}[ht]\n        \\begin{center}\n            \\begin{tabular}{@{}cccc@{}}\n                \\toprule\n                \n                $x_N$ explicit & Plate Notation & Hyperparameters on $\\mu$ & Factor\\\\  \\midrule\n                &                &            &              \\\\\n                \\begin{tikzpicture}\n                    \n                    \n                    \\node[obs]                               (x1) {$x_1$};\n                    \\node[const, right=0.5cm of x1]                               (dots) {$\\cdots$};\n                    \\node[obs, right=0.5cm of dots]                               (xn) {$x_N$};\n                    \\node[latent, above=of dots] (mu) {$\\mathbf{\\mu}$};\n                    \n                    \n                    \\edge {mu} {x1,dots,xn} ; %\n                    \n                \\end{tikzpicture}&\n                \\begin{tikzpicture}\n                    \n                    \n                    \\node[obs]                               (xn) {$x_n$};\n                    \\node[latent, above=of xn] (mu) {$\\mathbf{\\mu}$};\n                    \n                    \\plate{}{(xn)}{$n = 1, \\cdots, N$};\n                    \n                    \n                    \\edge {mu} {xn} ; %\n                    \n                \\end{tikzpicture} &\n                \n                \\begin{tikzpicture}\n                    \n                    \n                    \\node[obs]                               (xn) {$x_n$};\n                    \\node[latent, above=of xn] (mu) {$\\mathbf{\\mu}$};\n                    \\node[const, right=0.5cm of mu] (beta) {$\\mathbf{\\beta}$};\n                    \\node[const, left=0.5cm of mu] (alpha) {$\\mathbf{\\alpha}$};\n                    \n                    \\plate{}{(xn)}{$n = 1, \\cdots, N$};\n                    \n                    \n                    \\edge {mu} {xn} ; %\n                    \\edge {alpha,beta} {mu} ; %\n                    \n                    \n                \\end{tikzpicture}\n            &   \n            \\begin{tikzpicture}\n                \n                \n                \\node[obs]                               (xn) {$x_n$};\n                \\node[latent, above=of xn] (mu) {$\\mathbf{\\mu}$};\n                \\factor[above=of xn] {y-f} {left:${Ber}$} {} {} ; %\n                \\node[const, above=1 of mu, xshift=0.5cm] (beta) {$\\mathbf{\\beta}$};\n                \\node[const, above=1 of mu, xshift=-0.5cm] (alpha) {$\\mathbf{\\alpha}$};\n                \\factor[above=of mu] {mu-f} {left:${Beta}$} {} {} ; %\n                \\plate{}{(xn)}{$n = 1, \\cdots, N$};\n                \n                \n                \n                \\edge {mu} {xn} ; %\n                \\edge {alpha,beta} {mu-f} ; %\n                \\edge  {mu-f}{mu} ; %\n                \n                \n            \\end{tikzpicture}\n            \n                \n            \\end{tabular}\n            \n        \\end{center}\n        \\caption{Graphical models for a repeated Bernoulli experiment.}\n    \\end{figure}\n\n    \n\\end{document}\n\n\nReferences\n\nhttps://mml-book.github.io/book/mml-book.pdf Figure 8.10"
  },
  {
    "objectID": "posts/auto-pytorch.html",
    "href": "posts/auto-pytorch.html",
    "title": "AutoML PyTorch",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- automl- neural-architecture-search- hyperparameter-optimization- automated-machine-learning- pytorchdate: ’2023-02-25’output-file: auto-pytorch.htmltitle: AutoML PyTorchtoc: true—\nIn this post, we look at AutoPyTorch, a framework for automated machine learning.\nimport os\nimport tempfile as tmp\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\n\nimport sklearn.datasets\nimport sklearn.model_selection\n\nos.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['OPENBLAS_NUM_THREADS'] = '1'\nos.environ['MKL_NUM_THREADS'] = '1'\n\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom autoPyTorch.api.tabular_regression import TabularRegressionTask\nX, y = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    X,\n    y,\n    random_state=1,\n)\n\n# Obtain training and validation data\nX_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(\n    X_train,\n    y_train,\n    random_state=1,\n)\nX_train.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nbp\ns1\ns2\ns3\ns4\ns5\ns6\n\n\n\n\n52\n-0.052738\n-0.044642\n-0.009439\n-0.005671\n0.039710\n0.044719\n0.026550\n-0.002592\n-0.018118\n-0.013504\n\n\n121\n0.063504\n-0.044642\n0.017506\n0.021872\n0.008063\n0.021546\n-0.036038\n0.034309\n0.019908\n0.011349\n\n\n170\n0.023546\n0.050680\n-0.020218\n-0.036656\n-0.013953\n-0.015092\n0.059685\n-0.039493\n-0.096433\n-0.017646\n\n\n287\n0.045341\n-0.044642\n-0.006206\n-0.015999\n0.125019\n0.125198\n0.019187\n0.034309\n0.032433\n-0.005220\n\n\n397\n0.052606\n-0.044642\n-0.004050\n-0.030918\n-0.046975\n-0.058307\n-0.013948\n-0.025840\n0.036056\n0.023775\ny_train.head()\n\n52      59.0\n121    173.0\n170     47.0\n287    219.0\n397    198.0\nName: target, dtype: float64\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nrf = RandomForestRegressor(random_state=1)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred_rf))\n\n62.77500577100372\npred_df = pd.DataFrame({\"rf\": y_pred_rf, \"true\": y_test})\npred_df.head()\n\n\n\n\n\n\n\n\nrf\ntrue\n\n\n\n\n246\n140.76\n78.0\n\n\n425\n109.89\n152.0\n\n\n293\n161.93\n200.0\n\n\n31\n70.81\n59.0\n\n\n359\n150.91\n311.0\n# Use validation dataset to find best hyperparameters for RF\nrf = RandomForestRegressor(random_state=1)\nhyperparameters = {\"n_estimators\": [10, 100, 1000], \"max_depth\": [1, 5, 10]}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_search = GridSearchCV(rf, hyperparameters, cv=5, scoring=\"neg_root_mean_squared_error\")\ngrid_search.fit(X_valid, y_valid)\n\ngrid_search.best_params_\n\n\n{'max_depth': 5, 'n_estimators': 100}\n# Train the RF model using the best hyperparameters on train + validation data\n\nrf = RandomForestRegressor(**grid_search.best_params_, random_state=1)\n# Combine train and validation data\nX_train_overall = pd.concat([X_train, X_valid])\ny_train_overall = pd.concat([y_train, y_valid])\nrf.fit(X_train_overall, y_train_overall)\ny_pred_rf = rf.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred_rf))\n\n61.69476644955032\napi = TabularRegressionTask()\n\n# Do an api search without any memory limit but use only MLPs\n\napi.search(\n    X_train=X_train_overall,\n    y_train=y_train_overall,\n    X_test=X_test.copy(),\n    y_test=y_test.copy(),\n    optimize_metric='r2',\n    total_walltime_limit=80,\n    func_eval_time_limit_secs=10,\n    dataset_name=\"Diabetes\",\n    memory_limit=None,\n    enable_traditional_pipeline=True,\n    )\n\n&lt;autoPyTorch.api.tabular_regression.TabularRegressionTask at 0x1945be6d0&gt;\ny_pred = api.predict(X_test)\nscore = api.score(y_pred, y_test)\nprint(score)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\n{'r2': 0.3026643977627368}\n\n\n60.33987680300709\n# Print statistics from search\nprint(api.sprint_statistics())\n\nautoPyTorch results:\n    Dataset name: Diabetes\n    Optimisation Metric: r2\n    Best validation score: 0.4352600925944532\n    Number of target algorithm runs: 13\n    Number of successful target algorithm runs: 10\n    Number of crashed target algorithm runs: 2\n    Number of target algorithms that exceeded the time limit: 1\n    Number of target algorithms that exceeded the memory limit: 0\napi.get_models_with_weights()[0]\n\n(0.62,\n MyTraditionalTabularRegressionPipeline(config='random_forest',\n                                        dataset_properties={'categorical_columns': [],\n                                                            'categories': [],\n                                                            'input_shape': (10,),\n                                                            'is_small_preprocess': True,\n                                                            'issigned': True,\n                                                            'issparse': False,\n                                                            'numerical_columns': [0,\n                                                                                  1,\n                                                                                  2,\n                                                                                  3,\n                                                                                  4,\n                                                                                  5,\n                                                                                  6,\n                                                                                  7,\n                                                                                  8,\n                                                                                  9],\n                                                            'output_shape': 1,\n                                                            'output_type': 'continuous',\n                                                            'target_type': 'tabular_regression',\n                                                            'task_type': 'tabular_regression'},\n                                        init_params={'instance': None},\n                                        random_state=RandomState(MT19937) at 0x194150240))\napi.get_models_with_weights()[1]\n\n(0.18,\n ________________________________________\n    TabularRegressionPipeline\n ________________________________________\n 0-) imputer: \n    SimpleImputer\n \n 1-) variance_threshold: \n    VarianceThreshold\n \n 2-) coalescer: \n    NoCoalescer\n \n 3-) encoder: \n    NoEncoder\n \n 4-) scaler: \n    StandardScaler\n \n 5-) feature_preprocessor: \n    NoFeaturePreprocessor\n \n 6-) tabular_transformer: \n    TabularColumnTransformer\n \n 7-) preprocessing: \n    EarlyPreprocessing\n \n 8-) network_embedding: \n    autoPyTorch.pipeline NoEmbedding\n \n 9-) network_backbone: \n    autoPyTorch.pipeline ShapedMLPBackbone\n \n 10-) network_head: \n    autoPyTorch.pipeline FullyConnectedHead\n \n 11-) network: \n    Sequential ({'random_state': RandomState(MT19937) at 0x19465E140, '_fit_requirements': [FitRequirement(name='network_head', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False), FitRequirement(name='network_backbone', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False), FitRequirement(name='network_embedding', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'device': device(type='cpu'), 'network': Sequential(\n   (0): _NoEmbedding()\n   (1): Sequential(\n     (0): Linear(in_features=10, out_features=200, bias=True)\n     (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (2): ReLU()\n     (3): Linear(in_features=200, out_features=200, bias=True)\n     (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (5): ReLU()\n     (6): Linear(in_features=200, out_features=200, bias=True)\n     (7): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (8): ReLU()\n     (9): Linear(in_features=200, out_features=200, bias=True)\n     (10): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (11): ReLU()\n     (12): Linear(in_features=200, out_features=200, bias=True)\n   )\n   (2): Sequential(\n     (0): Flatten(start_dim=1, end_dim=-1)\n     (1): Linear(in_features=200, out_features=128, bias=True)\n     (2): ReLU()\n     (3): Linear(in_features=128, out_features=1, bias=True)\n   )\n ), 'final_activation': None, 'is_fitted_': True})\n \n 12-) network_init: \n    XavierInit\n \n 13-) optimizer: \n    Adam ({'random_state': RandomState(MT19937) at 0x19465E140, '_fit_requirements': [FitRequirement(name='network', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'optimizer': Adam (\n Parameter Group 0\n     amsgrad: False\n     betas: (0.9, 0.9)\n     capturable: False\n     eps: 1e-08\n     foreach: None\n     lr: 0.01\n     maximize: False\n     weight_decay: 0.0\n ), 'lr': 0.01, 'beta1': 0.9, 'beta2': 0.9, 'weight_decay': 0.0})\n \n 14-) lr_scheduler: \n    ReduceLROnPlateau\n \n 15-) data_loader: \n    DataLoader\n \n 16-) trainer: \n    autoPyTorch.pipeline Standard Trainer\n \n ________________________________________)\napi.get_models_with_weights()[2]\n\n(0.16,\n MyTraditionalTabularRegressionPipeline(config='svm',\n                                        dataset_properties={'categorical_columns': [],\n                                                            'categories': [],\n                                                            'input_shape': (10,),\n                                                            'is_small_preprocess': True,\n                                                            'issigned': True,\n                                                            'issparse': False,\n                                                            'numerical_columns': [0,\n                                                                                  1,\n                                                                                  2,\n                                                                                  3,\n                                                                                  4,\n                                                                                  5,\n                                                                                  6,\n                                                                                  7,\n                                                                                  8,\n                                                                                  9],\n                                                            'output_shape': 1,\n                                                            'output_type': 'continuous',\n                                                            'target_type': 'tabular_regression',\n                                                            'task_type': 'tabular_regression'},\n                                        init_params={'instance': None},\n                                        random_state=RandomState(MT19937) at 0x194711B40))\nWhat if we fit only NNs?\napi2 = TabularRegressionTask(seed=2, ensemble_size=0)\n\napi2.search(\n    X_train=X_train,\n    y_train=y_train,\n    X_test=X_test.copy(),\n    y_test=y_test.copy(),\n    optimize_metric='r2',\n    total_walltime_limit=40,\n    func_eval_time_limit_secs=10,\n    dataset_name=\"Diabetes\",\n    memory_limit=None,\n    enable_traditional_pipeline=False,\n    )\n\n[WARNING] [2023-02-27 18:29:06,260:Client-autoPyTorch.automl_common.common.utils.backend] Directory /var/folders/1x/wmgn24mn1bbd2vgbqlk98tbc0000gn/T/autoPyTorch_tmp_70d9fdb4-b69e-11ed-b5ea-3c7d0a00e5d9/.autoPyTorch/ensembles does not exist\n[ERROR] [2023-02-27 18:29:06,261:Client-AutoPyTorch:Diabetes:2] No valid ensemble was created. Please check the logfile for errors. Default to the best individual estimator:[(2, 2, 5.555555555555555)]\nNoneType: None\n\n\n&lt;autoPyTorch.api.tabular_regression.TabularRegressionTask at 0x194d3f160&gt;\ny_pred2 = api2.predict(X_test)\nscore2 = api2.score(y_pred2, y_test)\nscore2\n\n{'r2': -0.37656772470491995}\nnp.sqrt(mean_squared_error(y_test, y_pred2))\n\n84.77782906691597\nOkay, it seems we are worse than the random forest. Let’s see what happened.\napi2.get_models_with_weights()[0]\n\n(1.0,\n ________________________________________\n    TabularRegressionPipeline\n ________________________________________\n 0-) imputer: \n    SimpleImputer\n \n 1-) variance_threshold: \n    VarianceThreshold\n \n 2-) coalescer: \n    NoCoalescer\n \n 3-) encoder: \n    NoEncoder\n \n 4-) scaler: \n    StandardScaler\n \n 5-) feature_preprocessor: \n    NoFeaturePreprocessor\n \n 6-) tabular_transformer: \n    TabularColumnTransformer\n \n 7-) preprocessing: \n    EarlyPreprocessing\n \n 8-) network_embedding: \n    autoPyTorch.pipeline NoEmbedding\n \n 9-) network_backbone: \n    autoPyTorch.pipeline ShapedMLPBackbone\n \n 10-) network_head: \n    autoPyTorch.pipeline FullyConnectedHead\n \n 11-) network: \n    Sequential ({'random_state': RandomState(MT19937) at 0x194711A40, '_fit_requirements': [FitRequirement(name='network_head', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False), FitRequirement(name='network_backbone', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False), FitRequirement(name='network_embedding', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'device': device(type='cpu'), 'network': Sequential(\n   (0): _NoEmbedding()\n   (1): Sequential(\n     (0): Linear(in_features=10, out_features=200, bias=True)\n     (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (2): ReLU()\n     (3): Linear(in_features=200, out_features=200, bias=True)\n     (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (5): ReLU()\n     (6): Linear(in_features=200, out_features=200, bias=True)\n     (7): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (8): ReLU()\n     (9): Linear(in_features=200, out_features=200, bias=True)\n     (10): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (11): ReLU()\n     (12): Linear(in_features=200, out_features=200, bias=True)\n   )\n   (2): Sequential(\n     (0): Flatten(start_dim=1, end_dim=-1)\n     (1): Linear(in_features=200, out_features=128, bias=True)\n     (2): ReLU()\n     (3): Linear(in_features=128, out_features=1, bias=True)\n   )\n ), 'final_activation': None, 'is_fitted_': True})\n \n 12-) network_init: \n    XavierInit\n \n 13-) optimizer: \n    Adam ({'random_state': RandomState(MT19937) at 0x194711A40, '_fit_requirements': [FitRequirement(name='network', supported_types=(&lt;class 'torch.nn.modules.module.Module'&gt;,), user_defined=False, dataset_property=False)], '_cs_updates': {}, 'optimizer': Adam (\n Parameter Group 0\n     amsgrad: False\n     betas: (0.9, 0.9)\n     capturable: False\n     eps: 1e-08\n     foreach: None\n     lr: 0.01\n     maximize: False\n     weight_decay: 0.0\n ), 'lr': 0.01, 'beta1': 0.9, 'beta2': 0.9, 'weight_decay': 0.0})\n \n 14-) lr_scheduler: \n    ReduceLROnPlateau\n \n 15-) data_loader: \n    DataLoader\n \n 16-) trainer: \n    autoPyTorch.pipeline Standard Trainer\n \n ________________________________________)\nimport torch\nX_train_torch = torch.from_numpy(X_train.values).float()\ny_train_torch = torch.from_numpy(y_train.values).float()\nX_val_torch = torch.from_numpy(X_valid.values).float()\ny_val_torch = torch.from_numpy(y_valid.values).float()\nX_test_torch = torch.from_numpy(X_test.values).float()\ny_test_torch = torch.from_numpy(y_test.values).float()\n# Build a simple MLP in PyTorch, train on training data and optimize on validation data\n\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass Net(nn.Module):\n    def __init__(self, l1 = 64, l2 = 64, l3 = 64, l2_reg = 0.0):\n        super(Net, self).__init__()\n        self.l2_reg = l2_reg\n        self.fc1 = nn.Linear(10, l1)\n        self.fc2 = nn.Linear(l1, l2)\n        self.fc3 = nn.Linear(l2, l3)\n        self.fc4 = nn.Linear(l3, 1)\n\n    def forward(self, x):\n        # Add a residual connection\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n    \n\nnet = Net()\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\n\n\ntrain_losses = []\nval_losses = []\ntest_losses = []\n\n\nfor epoch in range(1000):  # loop over the dataset multiple times and store the train, test loss\n    optimizer.zero_grad()\n    outputs = net(X_train_torch)\n    loss = criterion(outputs, y_train_torch)\n    # Add L2 regularization\n    for param in net.parameters():\n        loss += net.l2_reg * torch.norm(param)\n    loss.backward()\n    optimizer.step()\n\n    train_losses.append(np.sqrt(loss.item()))\n    val_losses.append(np.sqrt(criterion(net(X_val_torch), y_val_torch).item()))\n    test_losses.append(np.sqrt(criterion(net(X_test_torch), y_test_torch).item()))\n            \nprint('Finished Training')\n\nFinished Training\nplt.plot(train_losses, label=\"Train\")\nplt.plot(test_losses, label=\"Test\")\nplt.plot(val_losses, label=\"Val\")\nplt.legend()\nwith torch.no_grad():\n    outputs = net(X_test_torch)\n    loss = criterion(outputs, y_test_torch)\n    print(f\"Test loss: {np.sqrt(loss.item())}\")\n    outputs = net(X_train_torch)    \n    loss = criterion(outputs, y_train_torch)\n    print(f\"Train loss: {np.sqrt(loss.item())}\")\n    print(\"\")\n\nTest loss: 72.43299031475574\nTrain loss: 79.2251754050993\n# Fit the NN model using scaled y values\n# Using sklearn's StandardScaler to scale the y values\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ny_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1))\ny_train_scaled = torch.from_numpy(y_train_scaled).float()\ny_test_scaled = scaler.transform(y_test.values.reshape(-1, 1))\ny_test_scaled = torch.from_numpy(y_test_scaled).float()\ny_valid_scaled = scaler.transform(y_valid.values.reshape(-1, 1))\ny_valid_scaled = torch.from_numpy(y_valid_scaled).float()\n\nnet = Net()\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=0.01)\n\ntrain_losses = []\nval_losses = []\ntest_losses = []\n\n\nfor epoch in range(4000):  # loop over the dataset multiple times and store the train, test loss\n    optimizer.zero_grad()\n    outputs = net(X_train_torch)\n    loss = criterion(outputs, y_train_scaled)\n    # Add L2 regularization\n    for param in net.parameters():\n        loss += net.l2_reg * torch.norm(param)\n    loss.backward()\n    optimizer.step()\n\n    train_losses.append(np.sqrt(loss.item()))\n\n            \nprint('Finished Training')\n\n\nFinished Training\nplt.plot(train_losses, label=\"Train\")\n# Predict the scaled y values and inverse transform them to get the original y values\n\nwith torch.no_grad():\n    outputs = net(X_test_torch)\n# Inverse transform the scaled y values to get the original y values\n\ny_pred = scaler.inverse_transform(outputs.numpy())\ny_pred = y_pred.reshape(-1)\nprint(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n\nTest RMSE: 82.79070717489064\npd.DataFrame({\"y_test\": y_test, \"y_pred\": y_pred}).plot.scatter(x=\"y_test\", y=\"y_pred\")\n# At this point it seems our model is worse than RF, Auto model containing Catboost etc. Let us optimize our NN\n# I will use Ray Tune to optimize the hyperparameters\n\nimport ray\nfrom ray import tune\nfrom ray.tune import CLIReporter\nfrom ray.tune.schedulers import ASHAScheduler\n\ndef train_mlp(config):\n    net = Net(config[\"l1\"], config[\"l2\"], config[\"l3\"], config[\"l2_reg\"])\n    \n    criterion = nn.MSELoss()\n    \n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n    for epoch in range(1000):  # loop over the dataset multiple times and store the train, test loss\n        optimizer.zero_grad()\n        outputs = net(X_train_torch)\n        loss = criterion(outputs, y_train_scaled)\n        # Add l2 regularization to loss\n        l2_reg = torch.tensor(0.)\n        for param in net.parameters():\n            l2_reg += torch.norm(param)\n        loss += config[\"l2_reg\"] * l2_reg\n        loss.backward()\n        optimizer.step()\n    with torch.no_grad():\n        outputs = net(X_val_torch)\n        # Inverse transform the scaled y values to get the original y values\n        y_pred = scaler.inverse_transform(outputs.numpy())\n        loss = np.sqrt(mean_squared_error(y_valid, y_pred))\n        return {\"loss\": loss, \"status\": \"ok\"}\nray.shutdown()\n\nray.init()\nscheduler = ASHAScheduler(\n    metric=\"loss\",\n    mode=\"min\",\n    max_t=100,\n    grace_period=1,\n    reduction_factor=2)\n\nreporter = CLIReporter(\n    parameter_columns=[\"l1\", \"l2\", \"l3\", \"lr\", \"l2_reg\"],\n    metric_columns=[\"loss\", \"training_iteration\"])\n\nanalysis = tune.run(\n    train_mlp,\n    resources_per_trial={\"cpu\": 1},\n    config={\n        \"l1\": tune.choice([2, 4, 16, 32, 64, 128, 256]),\n        \"l2\": tune.choice([2, 4, 16, 32, 64, 128, 256]),\n        \"l3\": tune.choice([2, 4, 16, 32, 64, 128, 256]),\n        \"l2_reg\": tune.loguniform(1e-4, 1.0),\n        \"lr\": tune.loguniform(1e-4, 1.0),\n    },\n    num_samples=50,\n    scheduler=scheduler,\n    progress_reporter=reporter)\n\n\n\n  Trial Progress\n  \n\n\n\nTrial name\ndate\ndone\nepisodes_total\nexperiment_id\nhostname\niterations_since_restore\nloss\nnode_ip\npid\nstatus\ntime_since_restore\ntime_this_iter_s\ntime_total_s\ntimestamp\ntimesteps_since_restore\ntimesteps_total\ntraining_iteration\ntrial_id\nwarmup_time\n\n\n\n\ntrain_mlp_c8d42_00000\n2023-02-28_10-08-51\nTrue\n\n684a45c7048544b384d756bd20117055\nNipuns-iMac-8.local\n1\n76.2275\n127.0.0.1\n99588\nok\n2.44738\n2.44738\n2.44738\n1677559131\n0\n\n1\nc8d42_00000\n0.00341606\n\n\ntrain_mlp_c8d42_00001\n2023-02-28_10-08-59\nTrue\n\n23a98dd3be3d4ad2abbc0a44970bd41b\nNipuns-iMac-8.local\n1\n76.2183\n127.0.0.1\n99594\nok\n4.5987\n4.5987\n4.5987\n1677559139\n0\n\n1\nc8d42_00001\n0.00891805\n\n\ntrain_mlp_c8d42_00002\n2023-02-28_10-08-58\nTrue\n\nf1614c13b37a4966adb785c911a54c11\nNipuns-iMac-8.local\n1\n76.2261\n127.0.0.1\n99595\nok\n2.89705\n2.89705\n2.89705\n1677559138\n0\n\n1\nc8d42_00002\n0.0356119\n\n\ntrain_mlp_c8d42_00003\n2023-02-28_10-08-57\nTrue\n\ne9475ee5dd1f4d1289ef144d1a7879ad\nNipuns-iMac-8.local\n1\n51.6545\n127.0.0.1\n99596\nok\n2.83387\n2.83387\n2.83387\n1677559137\n0\n\n1\nc8d42_00003\n0.00670218\n\n\ntrain_mlp_c8d42_00004\n2023-02-28_10-08-57\nTrue\n\n97bdec82d1ec44069bc84210c4a6a18e\nNipuns-iMac-8.local\n1\n65.3017\n127.0.0.1\n99597\nok\n2.6755\n2.6755\n2.6755\n1677559137\n0\n\n1\nc8d42_00004\n0.00920701\n\n\ntrain_mlp_c8d42_00005\n2023-02-28_10-08-59\nTrue\n\n3db458192e6944118049623bfe3128a4\nNipuns-iMac-8.local\n1\n76.1747\n127.0.0.1\n99598\nok\n4.36245\n4.36245\n4.36245\n1677559139\n0\n\n1\nc8d42_00005\n0.00544381\n\n\ntrain_mlp_c8d42_00006\n2023-02-28_10-08-59\nTrue\n\n6b794ba131304c9e841b2d671a1a4693\nNipuns-iMac-8.local\n1\n76.2181\n127.0.0.1\n99601\nok\n4.51009\n4.51009\n4.51009\n1677559139\n0\n\n1\nc8d42_00006\n0.00939798\n\n\ntrain_mlp_c8d42_00007\n2023-02-28_10-09-06\nTrue\n\n38d637c01fcb43d3be8db783cb837ea2\nNipuns-iMac-8.local\n1\n76.7874\n127.0.0.1\n99602\nok\n11.1744\n11.1744\n11.1744\n1677559146\n0\n\n1\nc8d42_00007\n0.012325\n\n\ntrain_mlp_c8d42_00008\n2023-02-28_10-09-00\nTrue\n\na15c3445ce1e4ffeba2eabf9098820f2\nNipuns-iMac-8.local\n1\n76.1934\n127.0.0.1\n99604\nok\n4.98043\n4.98043\n4.98043\n1677559140\n0\n\n1\nc8d42_00008\n0.010926\n\n\ntrain_mlp_c8d42_00009\n2023-02-28_10-09-00\nTrue\n\n9de7e974434443f6a12e1dbc614a8582\nNipuns-iMac-8.local\n1\n68.2169\n127.0.0.1\n99612\nok\n5.00434\n5.00434\n5.00434\n1677559140\n0\n\n1\nc8d42_00009\n0.00496888\n\n\ntrain_mlp_c8d42_00010\n2023-02-28_10-09-00\nTrue\n\nd7fa3bf71c4d44dd90e2988c0e59687a\nNipuns-iMac-8.local\n1\n76.2198\n127.0.0.1\n99613\nok\n5.70828\n5.70828\n5.70828\n1677559140\n0\n\n1\nc8d42_00010\n0.00938773\n\n\ntrain_mlp_c8d42_00011\n2023-02-28_10-09-03\nTrue\n\n6e08564fbc6d4f5c9bea59429a196a5e\nNipuns-iMac-8.local\n1\n52.2075\n127.0.0.1\n99614\nok\n8.02228\n8.02228\n8.02228\n1677559143\n0\n\n1\nc8d42_00011\n0.00922298\n\n\ntrain_mlp_c8d42_00012\n2023-02-28_10-08-59\nTrue\n\n98349fab3a1b4027bc14d3ce239251fd\nNipuns-iMac-8.local\n1\n76.1125\n127.0.0.1\n99615\nok\n4.87773\n4.87773\n4.87773\n1677559139\n0\n\n1\nc8d42_00012\n0.00547719\n\n\ntrain_mlp_c8d42_00013\n2023-02-28_10-08-58\nTrue\n\n6356d7d5564f49ac84f1f5221bccaa3e\nNipuns-iMac-8.local\n1\n76.2163\n127.0.0.1\n99616\nok\n3.31126\n3.31126\n3.31126\n1677559138\n0\n\n1\nc8d42_00013\n0.0112782\n\n\ntrain_mlp_c8d42_00014\n2023-02-28_10-09-00\nTrue\n\ne4c8bef4a7e246c19960353c87f60541\nNipuns-iMac-8.local\n1\n76.2002\n127.0.0.1\n99617\nok\n5.44697\n5.44697\n5.44697\n1677559140\n0\n\n1\nc8d42_00014\n0.0142629\n\n\ntrain_mlp_c8d42_00015\n2023-02-28_10-09-01\nTrue\n\nf91e68c1ff9a486f9f74c54403e236f4\nNipuns-iMac-8.local\n1\n51.5808\n127.0.0.1\n99618\nok\n5.94224\n5.94224\n5.94224\n1677559141\n0\n\n1\nc8d42_00015\n0.00973487\n\n\ntrain_mlp_c8d42_00016\n2023-02-28_10-08-59\nTrue\n\n684a45c7048544b384d756bd20117055\nNipuns-iMac-8.local\n1\n85.4019\n127.0.0.1\n99588\nok\n4.64298\n4.64298\n4.64298\n1677559139\n0\n\n1\nc8d42_00016\n0.00341606\n\n\ntrain_mlp_c8d42_00017\n2023-02-28_10-09-01\nTrue\n\n97bdec82d1ec44069bc84210c4a6a18e\nNipuns-iMac-8.local\n1\n76.2217\n127.0.0.1\n99597\nok\n3.26168\n3.26168\n3.26168\n1677559141\n0\n\n1\nc8d42_00017\n0.00920701\n\n\ntrain_mlp_c8d42_00018\n2023-02-28_10-09-00\nTrue\n\ne9475ee5dd1f4d1289ef144d1a7879ad\nNipuns-iMac-8.local\n1\n52.4798\n127.0.0.1\n99596\nok\n2.94631\n2.94631\n2.94631\n1677559140\n0\n\n1\nc8d42_00018\n0.00670218\n\n\ntrain_mlp_c8d42_00019\n2023-02-28_10-09-10\nTrue\n\nf1614c13b37a4966adb785c911a54c11\nNipuns-iMac-8.local\n1\n51.5559\n127.0.0.1\n99595\nok\n12.1603\n12.1603\n12.1603\n1677559150\n0\n\n1\nc8d42_00019\n0.0356119\n\n\ntrain_mlp_c8d42_00020\n2023-02-28_10-09-04\nTrue\n\n6356d7d5564f49ac84f1f5221bccaa3e\nNipuns-iMac-8.local\n1\n54.8401\n127.0.0.1\n99616\nok\n5.67631\n5.67631\n5.67631\n1677559144\n0\n\n1\nc8d42_00020\n0.0112782\n\n\ntrain_mlp_c8d42_00021\n2023-02-28_10-09-03\nTrue\n\n3db458192e6944118049623bfe3128a4\nNipuns-iMac-8.local\n1\n80.9971\n127.0.0.1\n99598\nok\n4.02288\n4.02288\n4.02288\n1677559143\n0\n\n1\nc8d42_00021\n0.00544381\n\n\ntrain_mlp_c8d42_00022\n2023-02-28_10-09-04\nTrue\n\n6b794ba131304c9e841b2d671a1a4693\nNipuns-iMac-8.local\n1\n62.7729\n127.0.0.1\n99601\nok\n5.19184\n5.19184\n5.19184\n1677559144\n0\n\n1\nc8d42_00022\n0.00939798\n\n\ntrain_mlp_c8d42_00023\n2023-02-28_10-09-03\nTrue\n\n23a98dd3be3d4ad2abbc0a44970bd41b\nNipuns-iMac-8.local\n1\n52.487\n127.0.0.1\n99594\nok\n3.83576\n3.83576\n3.83576\n1677559143\n0\n\n1\nc8d42_00023\n0.00891805\n\n\ntrain_mlp_c8d42_00024\n2023-02-28_10-09-09\nTrue\n\n684a45c7048544b384d756bd20117055\nNipuns-iMac-8.local\n1\n76.1853\n127.0.0.1\n99588\nok\n10.1193\n10.1193\n10.1193\n1677559149\n0\n\n1\nc8d42_00024\n0.00341606\n\n\ntrain_mlp_c8d42_00025\n2023-02-28_10-09-04\nTrue\n\n98349fab3a1b4027bc14d3ce239251fd\nNipuns-iMac-8.local\n1\n76.2173\n127.0.0.1\n99615\nok\n4.14031\n4.14031\n4.14031\n1677559144\n0\n\n1\nc8d42_00025\n0.00547719\n\n\ntrain_mlp_c8d42_00026\n2023-02-28_10-09-06\nTrue\n\na15c3445ce1e4ffeba2eabf9098820f2\nNipuns-iMac-8.local\n1\n68.3927\n127.0.0.1\n99604\nok\n6.18441\n6.18441\n6.18441\n1677559146\n0\n\n1\nc8d42_00026\n0.010926\n\n\ntrain_mlp_c8d42_00027\n2023-02-28_10-09-03\nTrue\n\n9de7e974434443f6a12e1dbc614a8582\nNipuns-iMac-8.local\n1\n76.218\n127.0.0.1\n99612\nok\n3.01754\n3.01754\n3.01754\n1677559143\n0\n\n1\nc8d42_00027\n0.00496888\n\n\ntrain_mlp_c8d42_00028\n2023-02-28_10-09-06\nTrue\n\ne4c8bef4a7e246c19960353c87f60541\nNipuns-iMac-8.local\n1\n66.4336\n127.0.0.1\n99617\nok\n5.79445\n5.79445\n5.79445\n1677559146\n0\n\n1\nc8d42_00028\n0.0142629\n\n\ntrain_mlp_c8d42_00029\n2023-02-28_10-09-03\nTrue\n\nd7fa3bf71c4d44dd90e2988c0e59687a\nNipuns-iMac-8.local\n1\n76.2164\n127.0.0.1\n99613\nok\n2.94911\n2.94911\n2.94911\n1677559143\n0\n\n1\nc8d42_00029\n0.00938773\n\n\ntrain_mlp_c8d42_00030\n2023-02-28_10-09-05\nTrue\n\ne9475ee5dd1f4d1289ef144d1a7879ad\nNipuns-iMac-8.local\n1\n75.2123\n127.0.0.1\n99596\nok\n4.99429\n4.99429\n4.99429\n1677559145\n0\n\n1\nc8d42_00030\n0.00670218\n\n\ntrain_mlp_c8d42_00031\n2023-02-28_10-09-06\nTrue\n\nf91e68c1ff9a486f9f74c54403e236f4\nNipuns-iMac-8.local\n1\n51.925\n127.0.0.1\n99618\nok\n4.96918\n4.96918\n4.96918\n1677559146\n0\n\n1\nc8d42_00031\n0.00973487\n\n\ntrain_mlp_c8d42_00032\n2023-02-28_10-09-04\nTrue\n\n97bdec82d1ec44069bc84210c4a6a18e\nNipuns-iMac-8.local\n1\n76.4117\n127.0.0.1\n99597\nok\n3.24968\n3.24968\n3.24968\n1677559144\n0\n\n1\nc8d42_00032\n0.00920701\n\n\ntrain_mlp_c8d42_00033\n2023-02-28_10-09-08\nTrue\n\n6e08564fbc6d4f5c9bea59429a196a5e\nNipuns-iMac-8.local\n1\n70.9285\n127.0.0.1\n99614\nok\n5.80603\n5.80603\n5.80603\n1677559148\n0\n\n1\nc8d42_00033\n0.00922298\n\n\ntrain_mlp_c8d42_00034\n2023-02-28_10-09-08\nTrue\n\n9de7e974434443f6a12e1dbc614a8582\nNipuns-iMac-8.local\n1\n51.9675\n127.0.0.1\n99612\nok\n5.20552\n5.20552\n5.20552\n1677559148\n0\n\n1\nc8d42_00034\n0.00496888\n\n\ntrain_mlp_c8d42_00035\n2023-02-28_10-09-07\nTrue\n\n3db458192e6944118049623bfe3128a4\nNipuns-iMac-8.local\n1\n76.1776\n127.0.0.1\n99598\nok\n3.86612\n3.86612\n3.86612\n1677559147\n0\n\n1\nc8d42_00035\n0.00544381\n\n\ntrain_mlp_c8d42_00036\n2023-02-28_10-09-07\nTrue\n\n23a98dd3be3d4ad2abbc0a44970bd41b\nNipuns-iMac-8.local\n1\n76.2167\n127.0.0.1\n99594\nok\n3.56161\n3.56161\n3.56161\n1677559147\n0\n\n1\nc8d42_00036\n0.00891805\n\n\ntrain_mlp_c8d42_00037\n2023-02-28_10-09-07\nTrue\n\nd7fa3bf71c4d44dd90e2988c0e59687a\nNipuns-iMac-8.local\n1\n51.8721\n127.0.0.1\n99613\nok\n4.08222\n4.08222\n4.08222\n1677559147\n0\n\n1\nc8d42_00037\n0.00938773\n\n\ntrain_mlp_c8d42_00038\n2023-02-28_10-09-10\nTrue\n\n98349fab3a1b4027bc14d3ce239251fd\nNipuns-iMac-8.local\n1\n76.2166\n127.0.0.1\n99615\nok\n6.54892\n6.54892\n6.54892\n1677559150\n0\n\n1\nc8d42_00038\n0.00547719\n\n\ntrain_mlp_c8d42_00039\n2023-02-28_10-09-07\nTrue\n\n6356d7d5564f49ac84f1f5221bccaa3e\nNipuns-iMac-8.local\n1\n71.0616\n127.0.0.1\n99616\nok\n3.14067\n3.14067\n3.14067\n1677559147\n0\n\n1\nc8d42_00039\n0.0112782\n\n\ntrain_mlp_c8d42_00040\n2023-02-28_10-09-07\nTrue\n\n97bdec82d1ec44069bc84210c4a6a18e\nNipuns-iMac-8.local\n1\n78.2332\n127.0.0.1\n99597\nok\n3.1038\n3.1038\n3.1038\n1677559147\n0\n\n1\nc8d42_00040\n0.00920701\n\n\ntrain_mlp_c8d42_00041\n2023-02-28_10-09-09\nTrue\n\n6b794ba131304c9e841b2d671a1a4693\nNipuns-iMac-8.local\n1\n76.2681\n127.0.0.1\n99601\nok\n4.69843\n4.69843\n4.69843\n1677559149\n0\n\n1\nc8d42_00041\n0.00939798\n\n\ntrain_mlp_c8d42_00042\n2023-02-28_10-09-09\nTrue\n\ne9475ee5dd1f4d1289ef144d1a7879ad\nNipuns-iMac-8.local\n1\n64.8587\n127.0.0.1\n99596\nok\n3.2481\n3.2481\n3.2481\n1677559149\n0\n\n1\nc8d42_00042\n0.00670218\n\n\ntrain_mlp_c8d42_00043\n2023-02-28_10-09-09\nTrue\n\nf91e68c1ff9a486f9f74c54403e236f4\nNipuns-iMac-8.local\n1\n76.2166\n127.0.0.1\n99618\nok\n2.99345\n2.99345\n2.99345\n1677559149\n0\n\n1\nc8d42_00043\n0.00973487\n\n\ntrain_mlp_c8d42_00044\n2023-02-28_10-09-09\nTrue\n\n38d637c01fcb43d3be8db783cb837ea2\nNipuns-iMac-8.local\n1\n76.2244\n127.0.0.1\n99602\nok\n3.30911\n3.30911\n3.30911\n1677559149\n0\n\n1\nc8d42_00044\n0.012325\n\n\ntrain_mlp_c8d42_00045\n2023-02-28_10-09-10\nTrue\n\na15c3445ce1e4ffeba2eabf9098820f2\nNipuns-iMac-8.local\n1\n51.9337\n127.0.0.1\n99604\nok\n3.84642\n3.84642\n3.84642\n1677559150\n0\n\n1\nc8d42_00045\n0.010926\n\n\ntrain_mlp_c8d42_00046\n2023-02-28_10-09-10\nTrue\n\ne4c8bef4a7e246c19960353c87f60541\nNipuns-iMac-8.local\n1\n76.2167\n127.0.0.1\n99617\nok\n3.67529\n3.67529\n3.67529\n1677559150\n0\n\n1\nc8d42_00046\n0.0142629\n\n\ntrain_mlp_c8d42_00047\n2023-02-28_10-09-09\nTrue\n\n23a98dd3be3d4ad2abbc0a44970bd41b\nNipuns-iMac-8.local\n1\n73.6947\n127.0.0.1\n99594\nok\n2.20929\n2.20929\n2.20929\n1677559149\n0\n\n1\nc8d42_00047\n0.00891805\n\n\ntrain_mlp_c8d42_00048\n2023-02-28_10-09-09\nTrue\n\n6356d7d5564f49ac84f1f5221bccaa3e\nNipuns-iMac-8.local\n1\n76.2164\n127.0.0.1\n99616\nok\n2.29378\n2.29378\n2.29378\n1677559149\n0\n\n1\nc8d42_00048\n0.0112782\n\n\ntrain_mlp_c8d42_00049\n2023-02-28_10-09-09\nTrue\n\n3db458192e6944118049623bfe3128a4\nNipuns-iMac-8.local\n1\n60.3637\n127.0.0.1\n99598\nok\n2.2852\n2.2852\n2.2852\n1677559149\n0\n\n1\nc8d42_00049\n0.00544381\n\n\n\n\n\n\n\n\n2023-02-28 10:09:11,027 INFO tune.py:762 -- Total run time: 26.09 seconds (25.84 seconds for the tuning loop).\n# Print the table for all the trials\ndf = analysis.results_df\n\n# Sort the table by loss\ndf.sort_values(by=\"loss\", inplace=True)\n\n# Show only loss, config/l1, config/l2, config/l3, config/lr, training_iteration\ndf[[\"loss\", \"config/l1\", \"config/l2\", \"config/l3\", \"config/lr\", \"config/l2_reg\"]]\n\n\n\n\n\n\n\n\nloss\nconfig/l1\nconfig/l2\nconfig/l3\nconfig/lr\nconfig/l2_reg\n\n\ntrial_id\n\n\n\n\n\n\n\n\n\n\nc8d42_00019\n51.555930\n256\n256\n128\n0.000125\n0.027615\n\n\nc8d42_00015\n51.580817\n4\n64\n256\n0.003980\n0.015450\n\n\nc8d42_00003\n51.654479\n2\n64\n4\n0.000991\n0.015054\n\n\nc8d42_00037\n51.872128\n128\n32\n32\n0.000114\n0.005181\n\n\nc8d42_00031\n51.925027\n128\n64\n32\n0.000103\n0.001919\n\n\nc8d42_00045\n51.933658\n64\n256\n16\n0.000139\n0.000221\n\n\nc8d42_00034\n51.967532\n2\n128\n128\n0.000371\n0.000860\n\n\nc8d42_00011\n52.207469\n16\n256\n128\n0.000134\n0.001002\n\n\nc8d42_00018\n52.479806\n2\n16\n4\n0.002317\n0.000166\n\n\nc8d42_00023\n52.486995\n64\n64\n16\n0.000214\n0.025084\n\n\nc8d42_00020\n54.840118\n2\n128\n128\n0.001178\n0.001264\n\n\nc8d42_00049\n60.363672\n4\n128\n16\n0.003238\n0.000639\n\n\nc8d42_00022\n62.772853\n256\n4\n64\n0.000419\n0.000484\n\n\nc8d42_00042\n64.858708\n128\n32\n2\n0.001164\n0.000313\n\n\nc8d42_00004\n65.301650\n4\n2\n32\n0.071916\n0.000168\n\n\nc8d42_00028\n66.433568\n128\n64\n128\n0.013376\n0.002368\n\n\nc8d42_00009\n68.216911\n32\n256\n2\n0.000931\n0.001888\n\n\nc8d42_00026\n68.392660\n2\n256\n64\n0.025460\n0.000803\n\n\nc8d42_00033\n70.928476\n2\n256\n64\n0.016914\n0.000214\n\n\nc8d42_00039\n71.061583\n16\n4\n64\n0.007347\n0.000135\n\n\nc8d42_00047\n73.694689\n4\n2\n32\n0.000104\n0.001308\n\n\nc8d42_00030\n75.212274\n16\n256\n2\n0.004354\n0.000746\n\n\nc8d42_00012\n76.112538\n128\n128\n4\n0.226784\n0.140003\n\n\nc8d42_00005\n76.174661\n4\n4\n256\n0.086190\n0.563438\n\n\nc8d42_00035\n76.177571\n64\n4\n128\n0.166371\n0.330122\n\n\nc8d42_00024\n76.185294\n32\n256\n256\n0.159865\n0.671139\n\n\nc8d42_00008\n76.193428\n256\n32\n16\n0.113514\n0.062898\n\n\nc8d42_00014\n76.200245\n32\n128\n128\n0.561836\n0.000226\n\n\nc8d42_00013\n76.216345\n64\n16\n64\n0.000173\n0.194086\n\n\nc8d42_00048\n76.216390\n64\n16\n64\n0.301651\n0.000141\n\n\nc8d42_00029\n76.216436\n16\n2\n2\n0.085926\n0.000206\n\n\nc8d42_00038\n76.216618\n16\n256\n256\n0.005644\n0.210313\n\n\nc8d42_00043\n76.216619\n64\n16\n64\n0.000284\n0.433444\n\n\nc8d42_00046\n76.216670\n256\n64\n2\n0.000617\n0.181541\n\n\nc8d42_00036\n76.216674\n2\n64\n64\n0.680740\n0.005030\n\n\nc8d42_00025\n76.217288\n16\n128\n16\n0.002700\n0.051269\n\n\nc8d42_00027\n76.218050\n2\n4\n32\n0.001925\n0.194493\n\n\nc8d42_00006\n76.218069\n256\n2\n64\n0.003326\n0.233648\n\n\nc8d42_00001\n76.218267\n2\n16\n256\n0.122404\n0.001683\n\n\nc8d42_00010\n76.219815\n128\n128\n64\n0.006478\n0.178694\n\n\nc8d42_00017\n76.221708\n32\n32\n16\n0.004100\n0.520138\n\n\nc8d42_00044\n76.224417\n256\n2\n2\n0.019401\n0.077370\n\n\nc8d42_00002\n76.226116\n16\n2\n64\n0.000326\n0.028026\n\n\nc8d42_00000\n76.227517\n4\n16\n128\n0.020000\n0.307903\n\n\nc8d42_00041\n76.268058\n256\n32\n64\n0.045152\n0.252533\n\n\nc8d42_00032\n76.411740\n32\n32\n2\n0.541939\n0.193151\n\n\nc8d42_00007\n76.787387\n256\n256\n2\n0.616285\n0.114236\n\n\nc8d42_00040\n78.233233\n64\n4\n16\n0.164726\n0.000119\n\n\nc8d42_00021\n80.997064\n128\n16\n32\n0.001292\n0.002832\n\n\nc8d42_00016\n85.401864\n32\n16\n256\n0.055791\n0.000965\n# Print the best hyperparameters\n\nanalysis.get_best_config(metric=\"loss\", mode=\"min\")\n\n{'l1': 256,\n 'l2': 256,\n 'l3': 128,\n 'l2_reg': 0.027614886800457164,\n 'lr': 0.00012453571993239395}\n# Perform the final test on the test set\n\nbest_config = analysis.get_best_config(metric=\"loss\", mode=\"min\")\n\n# Use the best hyperparameters to train the model\nnet = Net(best_config[\"l1\"], best_config[\"l2\"], best_config[\"l3\"], best_config[\"l2_reg\"])\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=best_config[\"lr\"])\nfor epoch in range(1000):  # loop over the dataset multiple times and store the train, test loss\n    optimizer.zero_grad()\n    outputs = net(X_train_torch)\n    loss = criterion(outputs, y_train_scaled)\n    # Add L2 regularization\n    for param in net.parameters():\n        loss += net.l2_reg * torch.norm(param)\n\n    \n    loss.backward()\n    optimizer.step()\n\nwith torch.no_grad():\n    outputs = net(X_test_torch)\n    # Inverse transform the scaled y values to get the original y values\n    y_pred = scaler.inverse_transform(outputs.numpy())\n    loss = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(f\"Test RMSE: {loss}\")\n    print(\"\")\n    \n\nTest RMSE: 54.06271747689579\npd.DataFrame({\"y_test\": y_test, \"y_pred\": y_pred.reshape(-1)})\n\n\n\n\n\n\n\n\ny_test\ny_pred\n\n\n\n\n246\n78.0\n107.765800\n\n\n425\n152.0\n110.693916\n\n\n293\n200.0\n175.535324\n\n\n31\n59.0\n82.328522\n\n\n359\n311.0\n176.440598\n\n\n...\n...\n...\n\n\n117\n281.0\n246.310699\n\n\n139\n281.0\n245.451309\n\n\n218\n214.0\n118.843346\n\n\n93\n96.0\n77.727440\n\n\n420\n146.0\n134.773529\n\n\n\n\n111 rows × 2 columns\n# Thus far it seems even with hyperparameter tuning we are unable to match the performance of ensemble models. \n\n# Get the top 5 configurations\n\ndf[['loss', 'config/l1', 'config/l2', 'config/l3', 'config/lr', 'config/l2_reg']].head(5)\n\n\n\n\n\n\n\n\nloss\nconfig/l1\nconfig/l2\nconfig/l3\nconfig/lr\nconfig/l2_reg\n\n\ntrial_id\n\n\n\n\n\n\n\n\n\n\nc8d42_00019\n51.555930\n256\n256\n128\n0.000125\n0.027615\n\n\nc8d42_00015\n51.580817\n4\n64\n256\n0.003980\n0.015450\n\n\nc8d42_00003\n51.654479\n2\n64\n4\n0.000991\n0.015054\n\n\nc8d42_00037\n51.872128\n128\n32\n32\n0.000114\n0.005181\n\n\nc8d42_00031\n51.925027\n128\n64\n32\n0.000103\n0.001919\nconfig_list_of_dicts = df[['config/l1', 'config/l2', 'config/l3', 'config/lr', 'config/l2_reg']].head(5).to_dict('records')\n\n# Train an ensemble of 5 models using the top 5 configurations\n\nensemble = []\nfor config in config_list_of_dicts:\n    net = Net(config[\"config/l1\"], config[\"config/l2\"], config[\"config/l3\"], config[\"config/l2_reg\"])\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=config[\"config/lr\"])\n    for epoch in range(2000):  # loop over the dataset multiple times and store the train, test loss\n        optimizer.zero_grad()\n        outputs = net(X_train_torch)\n        loss = criterion(outputs, y_train_scaled)\n        # Add L2 regularization\n        for param in net.parameters():\n            loss += net.l2_reg * torch.norm(param)\n        loss.backward()\n        optimizer.step()\n    ensemble.append(net)\n# Get the predictions from the ensemble\n\nensemble_preds = []\nfor net in ensemble:\n    with torch.no_grad():\n        outputs = net(X_test_torch)\n        # Scale the predictions back to the original scale\n        outputs = scaler.inverse_transform(outputs.numpy())\n        ensemble_preds.append(outputs)\n    \nensemble_preds = np.array(ensemble_preds)\n\n# Get the mean of the predictions\n\nensemble_preds_mean = ensemble_preds.mean(axis=0)\n\n# Get the RMSE of the ensemble\n\ncriterion = nn.MSELoss()\nloss = criterion(torch.tensor(ensemble_preds_mean), y_test_torch)\nprint(f\"Test loss: {np.sqrt(loss.item())}\")\n\nTest loss: 83.04458927945727"
  },
  {
    "objectID": "posts/auto-pytorch.html#inputs-to-meta-learning-model",
    "href": "posts/auto-pytorch.html#inputs-to-meta-learning-model",
    "title": "AutoML PyTorch",
    "section": "Inputs to Meta Learning model",
    "text": "Inputs to Meta Learning model\n\nData inputs\n\nInput vector: X is of shape N, D where N is the number of samples and D is the number of features\nOutput vector: y is of shape N, 1\n\n\n\nEncoder inputs\n\nContext vector: Containing C vectors of concatenated (X, y) pairs from the training set. Thus, shape of context vector is (C, D + 1)"
  },
  {
    "objectID": "posts/auto-pytorch.html#encoder-internals",
    "href": "posts/auto-pytorch.html#encoder-internals",
    "title": "AutoML PyTorch",
    "section": "### Encoder internals",
    "text": "### Encoder internals\n\nEncoding: Encoder is a neural network that takes in the context vector and outputs a vector of shape (C, E) where E is the encoding size"
  },
  {
    "objectID": "posts/auto-pytorch.html#encoder-outputs",
    "href": "posts/auto-pytorch.html#encoder-outputs",
    "title": "AutoML PyTorch",
    "section": "### Encoder outputs",
    "text": "### Encoder outputs\n\nEncoder summary: A vector of shape (E, ) that is the mean of the encoding"
  },
  {
    "objectID": "posts/auto-pytorch.html#decoder-inputs",
    "href": "posts/auto-pytorch.html#decoder-inputs",
    "title": "AutoML PyTorch",
    "section": "### Decoder inputs",
    "text": "### Decoder inputs\n\nQuery vector: Containing Q vectors of X from test set. Thus, shape of query vector is (Q, D)\nIt also takes the encoder summary as input of size (E, ). But, we make Q copies of the encoder summary and concatenate it with the query vector to get a vector of shape (Q, E + D)"
  },
  {
    "objectID": "posts/auto-pytorch.html#decoder-outputs",
    "href": "posts/auto-pytorch.html#decoder-outputs",
    "title": "AutoML PyTorch",
    "section": "### Decoder outputs",
    "text": "### Decoder outputs\n\nDecoding: Decoder is a neural network that takes in the query vector and encoder summary and outputs a vector of shape (Q, 1)\n\n\nD = X_train_torch.shape[1]\n\n\n# Building the encoder \n# Takes as input the number of features, the number of nodes in 3 hidden layers, and the L2 regularization parameter\n\nclass Encoder(nn.Module):\n    def __init__(self, n_features = D+1, l1_size=32, l2_size=32, E = 32, l2_reg=0.0):\n        super(Encoder, self).__init__()\n        self.l1 = nn.Linear(n_features, l1_size)\n        self.l2 = nn.Linear(l1_size, l2_size)\n        self.l3 = nn.Linear(l2_size, E)\n        self.l2_reg = l2_reg\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.relu(self.l1(x))\n        x = self.relu(self.l2(x))\n        x = self.relu(self.l3(x))\n        return x\n\n\n# Create C context vectors and pass them through the encoder\n\nC = 5\nQ = 2\nencoder = Encoder(E=32)\n\n# Create the context vectors input\nC_idx = np.random.choice(X_train_torch.shape[0], C, replace=False)\nC_idx = torch.tensor(C_idx)\n\n# Get the Q query vectors\nall_idx = np.arange(X_train_torch.shape[0])\nQ_idx = np.random.choice(np.setdiff1d(all_idx, C_idx), Q, replace=False)\nQ_idx = torch.tensor(Q_idx)\n\nC_idx, Q_idx\n\n(tensor([108,  26,  25, 210, 151]), tensor([156, 230]))\n\n\n\nX_train_torch[C_idx], y_train_scaled[C_idx], y_train_torch[C_idx]\n\n(tensor([[-0.0019, -0.0446,  0.0542, -0.0665,  0.0727,  0.0566, -0.0434,  0.0849,\n           0.0845,  0.0486],\n         [ 0.0817,  0.0507,  0.0013,  0.0356,  0.1264,  0.0911,  0.0192,  0.0343,\n           0.0845, -0.0301],\n         [ 0.0126, -0.0446,  0.0067, -0.0562, -0.0759, -0.0664, -0.0213, -0.0376,\n          -0.0181, -0.0922],\n         [ 0.0272, -0.0446,  0.0067,  0.0356,  0.0796,  0.0707,  0.0155,  0.0343,\n           0.0407,  0.0113],\n         [-0.0709,  0.0507, -0.0752, -0.0401, -0.0511, -0.0151, -0.0397, -0.0026,\n          -0.0964, -0.0342]]),\n tensor([[ 0.4966],\n         [ 0.5471],\n         [ 0.3704],\n         [-1.0812],\n         [-1.2327]]),\n tensor([192., 196., 182.,  67.,  55.]))\n\n\n\ncontext_input = torch.cat((X_train_torch[C_idx], y_train_scaled[C_idx].reshape(-1, 1)), axis=1)\npd.DataFrame(context_input)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n-0.001882\n-0.044642\n0.054152\n-0.066495\n0.072732\n0.056619\n-0.043401\n0.084863\n0.084495\n0.048628\n0.496595\n\n\n1\n0.081666\n0.050680\n0.001339\n0.035644\n0.126395\n0.091065\n0.019187\n0.034309\n0.084495\n-0.030072\n0.547084\n\n\n2\n0.012648\n-0.044642\n0.006728\n-0.056166\n-0.075870\n-0.066449\n-0.021311\n-0.037648\n-0.018118\n-0.092204\n0.370372\n\n\n3\n0.027178\n-0.044642\n0.006728\n0.035644\n0.079612\n0.070710\n0.015505\n0.034309\n0.040672\n0.011349\n-1.081190\n\n\n4\n-0.070900\n0.050680\n-0.075186\n-0.040099\n-0.051103\n-0.015092\n-0.039719\n-0.002592\n-0.096433\n-0.034215\n-1.232658\n\n\n\n\n\n\n\n\nencoder(context_input).shape\n\ntorch.Size([5, 32])\n\n\n\nencoder(context_input).mean(axis=0).shape\n\ntorch.Size([32])\n\n\n\n# Now we will build the decoder\n\nclass Decoder(nn.Module):\n    def __init__(self, E=32, l1_size=32, l2_size=32, l2_reg=0.0):\n        super(Decoder, self).__init__()\n        self.l1 = nn.Linear(E, l1_size)\n        self.l2 = nn.Linear(l1_size, l2_size)\n        self.l3 = nn.Linear(l2_size, 1)\n        self.l2_reg = l2_reg\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.relu(self.l1(x))\n        x = self.relu(self.l2(x))\n        x = self.relu(self.l3(x))\n        return x\n\n\n# Pass Q query vectors and the context vectors through the decoder\n\ndecoder = Decoder(E =32 + D)\nmean_context = encoder(context_input).mean(axis=0)\n# Repeat the mean context vector Q times\nmean_context = mean_context.repeat(Q, 1)\nmean_context.shape\n\ntorch.Size([2, 32])\n\n\n\nquery = X_train_torch[Q_idx]\nquery.shape\n\ntorch.Size([2, 10])\n\n\n\ninput_decoder = torch.cat((query, mean_context), axis=1)\ninput_decoder.shape\n\ntorch.Size([2, 42])\n\n\n\ndecoder(input_decoder).shape\n\ntorch.Size([2, 1])\n\n\n\n# Building a meta learning class\n\nclass Meta(nn.Module):\n    def __init__(self, D = X_train_torch.shape[1], E = 32,  C = 10, Q = 2, l1_size=32, l2_size=32, l2_reg=0.0):\n        super(Meta, self).__init__()\n        self.encoder = Encoder(D + 1, l1_size, l2_size, E, l2_reg)\n        self.decoder = Decoder(E + D, l1_size, l2_size, l2_reg)\n        self.D = D\n        self.E = E\n        self.C = C\n        self.Q = Q\n        self.l2_reg = l2_reg\n\n    def forward(self, context_input, query):\n        mean_context = self.encoder(context_input).mean(axis=0)\n        # Repeat the mean context vector Q times\n        mean_context = mean_context.repeat(self.Q, 1)\n        input_decoder = torch.cat((query, mean_context), axis=1)\n        return self.decoder(input_decoder)\n\n\nm = Meta()\nm(context_input, query)\n\ntensor([[0.],\n        [0.]], grad_fn=&lt;ReluBackward0&gt;)\n\n\n\n# Create a function to get the context and query vectors\n\ndef get_context_query(X, y, C, Q):\n    C_idx = np.random.choice(X.shape[0], C, replace=False)\n    C_idx = torch.tensor(C_idx)\n    all_idx = np.arange(X.shape[0])\n    Q_idx = np.random.choice(np.setdiff1d(all_idx, C_idx), Q, replace=False)\n    Q_idx = torch.tensor(Q_idx)\n    context_input = torch.cat((X[C_idx], y[C_idx].reshape(-1, 1)), axis=1)\n    query = X[Q_idx]\n    return context_input, query, y[Q_idx]\n\n\nget_context_query(X_train_torch, y_train_torch, 10, 2)\n\n(tensor([[-6.0003e-02, -4.4642e-02,  1.3387e-03, -2.9771e-02, -7.0728e-03,\n          -2.1669e-02,  1.1824e-02, -2.5923e-03,  3.1815e-02, -5.4925e-02,\n           2.5800e+02],\n         [ 3.0811e-02, -4.4642e-02, -5.0396e-02, -2.2277e-03, -4.4223e-02,\n          -8.9935e-02,  1.1859e-01, -7.6395e-02, -1.8118e-02,  3.0644e-03,\n           8.7000e+01],\n         [ 6.7136e-02, -4.4642e-02,  3.4944e-03,  3.5644e-02,  4.9341e-02,\n           3.1254e-02,  7.0730e-02, -3.9493e-02, -6.0925e-04,  1.9633e-02,\n           7.3000e+01],\n         [ 1.2648e-02, -4.4642e-02,  6.7278e-03, -5.6166e-02, -7.5870e-02,\n          -6.6449e-02, -2.1311e-02, -3.7648e-02, -1.8118e-02, -9.2204e-02,\n           1.8200e+02],\n         [-6.3635e-02,  5.0680e-02, -7.9497e-02, -5.6706e-03, -7.1743e-02,\n          -6.6449e-02, -1.0266e-02, -3.9493e-02, -1.8118e-02, -5.4925e-02,\n           1.0100e+02],\n         [-1.8820e-03, -4.4642e-02, -6.6563e-02,  1.2151e-03, -2.9449e-03,\n           3.0702e-03,  1.1824e-02, -2.5923e-03, -2.0289e-02, -2.5930e-02,\n           7.9000e+01],\n         [-5.6370e-02, -4.4642e-02, -7.4108e-02, -5.0428e-02, -2.4960e-02,\n          -4.7034e-02,  9.2820e-02, -7.6395e-02, -6.1177e-02, -4.6641e-02,\n           4.8000e+01],\n         [-7.0900e-02,  5.0680e-02, -7.5186e-02, -4.0099e-02, -5.1103e-02,\n          -1.5092e-02, -3.9719e-02, -2.5923e-03, -9.6433e-02, -3.4215e-02,\n           5.5000e+01],\n         [ 3.8076e-02,  5.0680e-02, -2.9918e-02, -4.0099e-02, -3.3216e-02,\n          -2.4174e-02, -1.0266e-02, -2.5923e-03, -1.2908e-02,  3.0644e-03,\n           1.6000e+02],\n         [ 3.4443e-02,  5.0680e-02,  1.2529e-01,  2.8758e-02, -5.3855e-02,\n          -1.2900e-02, -1.0231e-01,  1.0811e-01,  2.7149e-04,  2.7917e-02,\n           3.4100e+02]]),\n tensor([[ 0.0163, -0.0446,  0.0175, -0.0229,  0.0603,  0.0444,  0.0302, -0.0026,\n           0.0372, -0.0011],\n         [-0.0418, -0.0446,  0.0477,  0.0597,  0.1278,  0.1280, -0.0250,  0.1081,\n           0.0639,  0.0403]]),\n tensor([128., 258.]))\n\n\n\n# Training loop\n\ntrain_loss = []\nval_losses = []\ntest_losses = []\nfor i in range(2000):\n    context_input, query, y_query = get_context_query(X_train_torch, y_train_scaled, 10, 2)\n    y_pred = m(context_input, query)\n    loss = criterion(y_pred, y_query)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    train_loss.append(loss.item())\n    if i % 100 == 0:\n        print(f\"Epoch {i} - Train loss: {loss.item()}\")\n\n\nEpoch 0 - Train loss: 0.2789093554019928\nEpoch 100 - Train loss: 1.1788500547409058\nEpoch 200 - Train loss: 0.6084457039833069\nEpoch 300 - Train loss: 0.6604040265083313\nEpoch 400 - Train loss: 0.6397659778594971\nEpoch 500 - Train loss: 0.18253237009048462\nEpoch 600 - Train loss: 0.4401477575302124\nEpoch 700 - Train loss: 0.19387057423591614\nEpoch 800 - Train loss: 1.3166064023971558\nEpoch 900 - Train loss: 0.4808962345123291\nEpoch 1000 - Train loss: 0.2843365967273712\nEpoch 1100 - Train loss: 0.35177987813949585\nEpoch 1200 - Train loss: 1.1539983749389648\nEpoch 1300 - Train loss: 2.0983378887176514\nEpoch 1400 - Train loss: 3.325526237487793\nEpoch 1500 - Train loss: 0.38105207681655884\nEpoch 1600 - Train loss: 0.16427072882652283\nEpoch 1700 - Train loss: 1.9909170866012573\nEpoch 1800 - Train loss: 0.03792643919587135\nEpoch 1900 - Train loss: 2.758319854736328\n\n\n\nplt.plot(train_loss)\n\n\n\n\n\n\n\n\n\ncontext_input, _, _ = get_context_query(X_train_torch, y_train_torch, 10, query.shape[0])\ncontext_input.shape\n\ntorch.Size([10, 11])\n\n\n\nX_test_torch.shape\n\ntorch.Size([111, 10])\n\n\n\nquery.shape\n\ntorch.Size([2, 10])\n\n\n\ncontext_input.shape\n\ntorch.Size([10, 11])\n\n\n\n# Use whole of the test set as the query set\nquery = X_test_torch\ny_query = y_test_torch\n\n# get context from the training set\ncontext_input, _, _ = get_context_query(X_train_torch, y_train_scaled, 10, query.shape[0])\n\n\nm = Meta(C=10, Q=query.shape[0])\n\ny_pred = m(context_input, query)\n\n# Use inverse transform to get the original values\n\ny_pred = scaler.inverse_transform(y_pred.detach().numpy())\nprint(f\"Test loss: {np.sqrt(mean_squared_error(y_query, y_pred))}\")\n\nTest loss: 75.22261810302734\n\n\n\npd.DataFrame({\"y_pred\": y_pred.reshape(-1), \"y_query\": y_query})\n\n\n\n\n\n\n\n\ny_pred\ny_query\n\n\n\n\n0\n169.061569\n78.0\n\n\n1\n168.179596\n152.0\n\n\n2\n168.527161\n200.0\n\n\n3\n168.452423\n59.0\n\n\n4\n168.826492\n311.0\n\n\n...\n...\n...\n\n\n106\n169.100494\n281.0\n\n\n107\n168.457611\n281.0\n\n\n108\n169.019516\n214.0\n\n\n109\n168.639725\n96.0\n\n\n110\n169.026901\n146.0\n\n\n\n\n111 rows × 2 columns"
  },
  {
    "objectID": "posts/2020-03-28-active_learning_with_bayesian_linear_regression.html",
    "href": "posts/2020-03-28-active_learning_with_bayesian_linear_regression.html",
    "title": "Active Learning with Bayesian Linear Regression",
    "section": "",
    "text": "A quick wrap-up for Bayesian Linear Regression (BLR)\nWe have a feature matrix \\(X\\) and a target vector \\(Y\\). We want to obtain \\(\\theta\\) vector in such a way that the error \\(\\epsilon\\) for the following equation is minimum.\n\\[\\begin{equation}\nY = X^T\\theta + \\epsilon\n\\end{equation}\\] Prior PDF for \\(\\theta\\) is,\n\\[\\begin{equation}\np(\\theta) \\sim \\mathcal{N}(M_0, S_0)\n\\end{equation}\\]\nWhere \\(S_0\\) is prior covariance matrix, and \\(M_0\\) is prior mean.\nPosterier PDF can be given as,\n\\[\\begin{equation}\np(\\theta|X,Y) \\sim \\mathcal{N}(\\theta | M_n, S_n) \\\\\nS_n = (S_0^{-1} + \\sigma_{mle}^{-2}X^TX) \\\\\nM_n = S_n(S_0^{-1}M_0+\\sigma_{mle}^{-2}X^TY)\n\\end{equation}\\]\nMaximum likelihood estimation of \\(\\sigma\\) can be calculated as,\n\\[\\begin{equation}\n\\theta_{mle} = (X^TX)^{-1}X^TY \\\\\n\\sigma_{mle} = ||Y - X^T\\theta_{mle}||\n\\end{equation}\\]\nFinally, predicted mean \\(\\hat{Y}_{mean}\\) and predicted covariance matrix \\(\\hat{Y}_{cov}\\) can be given as,\n\\[\\begin{equation}\n\\hat{Y} \\sim \\mathcal{N}(\\hat{Y}_{mean}, \\hat{Y}_{cov}) \\\\\n\\hat{Y}_{mean} = XM_n \\\\\n\\hat{Y}_{cov} = X^TS_nX\n\\end{equation}\\]\nNow, let’s put everything together and write a class for Bayesian Linear Regression.\n\n\nCreating scikit-learn like class with fit predict methods for BLR\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib import rc\nimport warnings\nwarnings.filterwarnings('ignore')\nseed = 0 # random seed for train_test_split\n\n\nclass BLR():\n  def __init__(self,S0, M0): # M0 -&gt; prior mean, S0 -&gt; prior covariance matrix\n    self.S0 = S0\n    self.M0 = M0\n\n  def fit(self,x,y, return_self = False):\n    self.x = x\n    self.y = y\n\n    # Maximum likelihood estimation for sigma parameter\n    theta_mle = np.linalg.pinv(x.T@x)@(x.T@y)\n    sigma_2_mle = np.linalg.norm(y - x@theta_mle)**2\n    sigma_mle = np.sqrt(sigma_2_mle)\n\n    # Calculating predicted mean and covariance matrix for theta\n    self.SN = np.linalg.pinv(np.linalg.pinv(self.S0) + (sigma_mle**-2)*x.T@x)\n    self.MN = self.SN@(np.linalg.pinv(self.S0)@self.M0 + (sigma_mle**-2)*(x.T@y).squeeze())\n\n    # Calculating predicted mean and covariance matrix for data\n    self.pred_var = x@self.SN@x.T\n    self.y_hat_map = x@self.MN\n    if return_self:\n      return (self.y_hat_map, self.pred_var)\n    \n  def predict(self, x):\n    self.pred_var = x@self.SN@x.T\n    self.y_hat_map = x@self.MN\n    return (self.y_hat_map, self.pred_var)\n\n  def plot(self, s=1): # s -&gt; size of dots for scatter plot\n    individual_var = self.pred_var.diagonal()\n    plt.figure()\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.plot(self.x[:,1], self.y_hat_map, color='black', label='model')\n    plt.fill_between(self.x[:,1], self.y_hat_map-individual_var, self.y_hat_map+individual_var, alpha=0.4, color='black', label='uncertainty')\n    plt.scatter(self.x[:,1], self.y, label='actual data',s=s)\n    plt.title('MAE is '+str(np.mean(np.abs(self.y - self.y_hat_map))))\n    plt.legend()\n\n\n\nCreating & visualizing dataset\nTo start with, let’s create a random dataset with degree 3 polynomial function with some added noise.\n\\[\\begin{equation}\nY = (5X^3 - 4X^2 + 3X - 2) + \\mathcal{N}(0,1)\n\\end{equation}\\]\n\nnp.random.seed(seed)\nX_init = np.linspace(-1, 1, 1000)\nnoise = np.random.randn(1000, )\nY = (5 * X_init**3 - 4 * X_init**2 + 3 * X_init - 2) + noise\n\nWe’ll try to fit a degree 5 polynomial function to our data.\n\nX = PolynomialFeatures(degree=5, include_bias=True).fit_transform(X_init.reshape(-1,1))\nN_features = X.shape[1]\n\n\nplt.scatter(X[:,1], Y, s=0.5, label = 'data points')\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLearning a BLR model on the entire data\nWe’ll take \\(M_0\\) (prior mean) as zero vector initially, assuming that we do not have any prior knowledge about \\(M_0\\). We’re taking \\(S_0\\) (prior covariance) as the identity matrix, assuming that all coefficients are completely independent of each other.\n\nS0 = np.eye(N_features)\nM0 = np.zeros((N_features, ))\nmodel = BLR(S0, M0)\n\n\nmodel.fit(X, Y)\n\n\n\nVisualising the fit\n\nmodel.plot(s=0.5)\n\n\n\n\n\n\n\n\nThis doesn’t look like a good fit, right? Let’s set the prior closer to the real values and visualize the fit again.\n\n\nVisualising the fit after changing the prior\n\nnp.random.seed(seed)\nS0 = np.eye(N_features)\nM0 = np.array([-2, 3, -4, 5, 0, 0]) + np.random.randn(N_features, )\nmodel = BLR(S0, M0)\n\n\nmodel.fit(X, Y)\nmodel.plot(s=0.5)\n\n\n\n\n\n\n\n\nHmm, better. Now let’s see how it fits after reducing the noise and setting the prior mean to zero vector again.\n\n\nVisualising the fit after reducing the noise\n\nnp.random.seed(seed)\nX_init = np.linspace(-1, 1, 1000)\nnoise = np.random.randn(1000, ) * 0.5\nY = (5 * X_init**3 - 4 * X_init**2 + 3 * X_init - 2) + noise\n\n\nS0 = np.eye(N_features)\nM0 = np.zeros((N_features, ))\nmodel = BLR(S0, M0)\n\n\nmodel.fit(X, Y)\nmodel.plot(s=0.5)\n\n\n\n\n\n\n\n\nWhen the noise was high, the model tended to align with the prior. After keeping the prior closer to the original coefficients, the model was improved as expected. From the last plot, we can say that as noise reduces from the data, the impact of the prior reduces, and the model tries to fit the data more precisely. Therefore, we can say that when data is too noisy or insufficient, a wisely chosen prior can produce a precise fit.\n\n\nIntuition to Active Learning (Uncertainty Sampling) with an example\nLet’s take the case where we want to train a machine learning model to classify if a person is infected with COVID-19 or not, but the testing facilities for the same are not available so widely. We may have very few amounts of data for detected positive and detected negative patients. Now, we want our model to be highly confident or least uncertain about its results; otherwise, it may create havoc for wrongly classified patients, but, our bottleneck is labeled data. Thanks to active learning techniques, we can overcome this problem smartly. How?\nWe train our model with existing data and test it on all the suspected patients’ data. Let’s say we have an uncertainty measure or confidence level about each tested data point (distance from the decision boundary in case of SVM, variance in case of Gaussian processes, or Bayesian Linear Regression). We can choose a patient for which our model is least certain, and send him to COVID-19 testing facilities (assuming that we can send only one patient at a time). Now, we can include his data to the train set and test the model on everyone else. By following the same procedure repeatedly, we can increase the size of our train data and confidence of the model without sending everyone randomly for testing.\nThis method is called Uncertainty Sampling in Active Learning. Now let’s formally define Active Learning. From Wikipedia,\nActive learning is a special case of machine learning in which a learning algorithm can interactively query a user (or some other information source) to label new data points with the desired outputs.\nNow, we’ll go through the active learning procedure step by step.\n\n\nTrain set, test set, and pool. What is what?\nThe train set includes labeled data points. The pool includes potential data points to query for a label, and the test set includes labeled data points to check the performance of our model. Here, we cannot actually do a query to anyone, so we assume that we do not have labels for the pool while training, and after each iteration, we include a data point from the pool set to the train set for which our model has the highest uncertainty.\nSo, the algorithm can be represented as the following,\n\nTrain the model with the train set.\nTest the performance on the test set (This should keep improving).\n\nTest the model with the pool.\nQuery for the most uncertain datapoint from the pool.\nAdd that datapoint into the train set.\nRepeat step 1 to step 5 for \\(K\\) iterations (\\(K\\) ranges from \\(0\\) to the pool size).\n\n\n\nCreating initial train set, test set, and pool\nLet’s take half of the dataset as the test set, and from another half, we will start with some points as the train set and remaining as the pool. Let’s start with 2 data points as the train set.\n\nnp.random.seed(seed)\nX_init = np.linspace(-1, 1, 1000)\nX = PolynomialFeatures(degree=5, include_bias=True).fit_transform(X_init.reshape(-1,1))\nnoise = np.random.randn(1000, ) * 0.5\nY = (5 * X_init**3 - 4 * X_init**2 + 3 * X_init - 2) + noise\n\n\ntrain_pool_X, test_X, train_pool_Y, test_Y = train_test_split(X, Y, test_size = 0.5, random_state=seed)\ntrain_X, pool_X, train_Y, pool_Y = train_test_split(train_pool_X, train_pool_Y, train_size=2, random_state=seed)\n\nVisualizing train, test and pool.\n\nplt.scatter(test_X[:,1], test_Y, label='test set',color='r', s=2)\nplt.scatter(train_X[:,1], train_Y, label='train set',marker='s',color='k', s=50)\nplt.scatter(pool_X[:,1], pool_Y, label='pool',color='b', s=2)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLet’s initialize a few dictionaries to keep track of each iteration.\n\ntrain_X_iter = {} # to store train points at each iteration\ntrain_Y_iter = {} # to store corresponding labels to the train set at each iteration\nmodels = {} # to store the models at each iteration\nestimations = {} # to store the estimations on the test set at each iteration\ntest_mae_error = {} # to store MAE(Mean Absolute Error) at each iteration\n\n\n\nTraining & testing initial learner on train set (Iteration 0)\nNow we will train the model for the initial train set, which is iteration 0.\n\ntrain_X_iter[0] = train_X\ntrain_Y_iter[0] = train_Y\n\n\nS0 = np.eye(N_features)\nM0 = np.zeros((N_features, ))\nmodels[0] = BLR(S0, M0)\n\n\nmodels[0].fit(train_X_iter[0], train_Y_iter[0])\n\nCreating a plot method to visualize train, test and pool with estimations and uncertainty.\n\ndef plot(ax, model, init_title=''):\n  # Plotting the pool\n  ax.scatter(pool_X[:,1], pool_Y, label='pool',s=1,color='r',alpha=0.4)\n  \n  # Plotting the test data\n  ax.scatter(test_X[:,1], test_Y, label='test data',s=1, color='b', alpha=0.4)\n  \n  # Combining the test & the pool\n  test_pool_X, test_pool_Y = np.append(test_X,pool_X, axis=0), np.append(test_Y,pool_Y)\n  \n  # Sorting test_pool for plotting\n  sorted_inds = np.argsort(test_pool_X[:,1])\n  test_pool_X, test_pool_Y = test_pool_X[sorted_inds], test_pool_Y[sorted_inds]\n  \n  # Plotting test_pool with uncertainty\n  model.predict(test_pool_X)\n  individual_var = model.pred_var.diagonal()\n  ax.plot(test_pool_X[:,1], model.y_hat_map, color='black', label='model')\n  ax.fill_between(test_pool_X[:,1], model.y_hat_map-individual_var, model.y_hat_map+individual_var\n                  , alpha=0.2, color='black', label='uncertainty')\n  \n  # Plotting the train data\n  ax.scatter(model.x[:,1], model.y,s=40, color='k', marker='s', label='train data')\n  ax.scatter(model.x[-1,1], model.y[-1],s=80, color='r', marker='o', label='last added point')\n  \n  # Plotting MAE on the test set\n  model.predict(test_X)\n  ax.set_title(init_title+' MAE is '+str(np.mean(np.abs(test_Y - model.y_hat_map))))\n  ax.set_xlabel('x')\n  ax.set_ylabel('y')\n  ax.legend()\n\nPlotting the estimations and uncertainty.\n\nfig, ax = plt.subplots()\nplot(ax, models[0])\n\n\n\n\n\n\n\n\nLet’s check the maximum uncertainty about any point for the model.\n\nmodels[0].pred_var.diagonal().max()\n\n4.8261426545316604e-29\n\n\nOops!! There is almost no uncertainty in the model. Why? let’s try again with more train points.\n\ntrain_pool_X, test_X, train_pool_Y, test_Y = train_test_split(X, Y, test_size = 0.5, random_state=seed)\ntrain_X, pool_X, train_Y, pool_Y = train_test_split(train_pool_X, train_pool_Y, train_size=7, random_state=seed)\n\n\ntrain_X_iter[0] = train_X\ntrain_Y_iter[0] = train_Y\n\n\nS0 = np.eye(N_features)\nM0 = np.zeros((N_features, ))\nmodels[0] = BLR(S0, M0)\n\n\nmodels[0].fit(train_X_iter[0], train_Y_iter[0])\n\n\nfig, ax = plt.subplots()\nplot(ax, models[0])\n\n\n\n\n\n\n\n\nNow uncertainty is visible, and currently, it’s high at the left-most points. We are trying to fit a degree 5 polynomial here. So our linear regression coefficients are 6, including the bias. If we choose train points equal to or lesser than 6, our model perfectly fits the train points and has no uncertainty. Choosing train points more than 6 induces uncertainty in the model.\nLet’s evaluate the performance on the test set.\n\nestimations[0], _ = models[0].predict(test_X)\ntest_mae_error[0] = np.mean(np.abs(test_Y - estimations[0]))\n\nMean Absolute Error (MAE) on the test set is\n\ntest_mae_error[0]\n\n0.5783654195019617\n\n\n\n\nMoving the most uncertain point from the pool to the train set\nIn the previous plot, we saw that the model was least certain about the left-most point. We’ll move that point from the pool to the train set and see the effect.\n\nesimations_pool, _ = models[0].predict(pool_X)\n\nFinding out a point having the most uncertainty.\n\nin_var = models[0].pred_var.diagonal().argmax()\nto_add_x = pool_X[in_var,:]\nto_add_y = pool_Y[in_var]\n\nAdding the point from the pool to the train set.\n\ntrain_X_iter[1] = np.vstack([train_X_iter[0], to_add_x])\ntrain_Y_iter[1] = np.append(train_Y_iter[0], to_add_y)\n\nDeleting the point from the pool.\n\npool_X = np.delete(pool_X, in_var, axis=0)\npool_Y = np.delete(pool_Y, in_var)\n\n\n\nTraining again and visualising the results (Iteration 1)\nThis time, we will pass previously learnt prior to the next iteration.\n\nS0 = np.eye(N_features)\nmodels[1] = BLR(S0, models[0].MN)\n\n\nmodels[1].fit(train_X_iter[1], train_Y_iter[1])\n\n\nestimations[1], _ = models[1].predict(test_X)\ntest_mae_error[1] = np.mean(np.abs(test_Y - estimations[1]))\n\nMAE on the test set is\n\ntest_mae_error[1]\n\n0.5779411133071186\n\n\nVisualizing the results.\n\nfig, ax = plt.subplots()\nplot(ax, models[1])\n\n\n\n\n\n\n\n\nBefore & after adding most uncertain point\n\nfig, ax = plt.subplots(1,2, figsize=(13.5,4.5))\nplot(ax[0], models[0],'Before')\nplot(ax[1], models[1],'After')\n\n\n\n\n\n\n\n\nWe can see that including most uncertain point into the train set has produced a better fit and MAE for test set has been reduced. Also, uncertainty has reduced at the left part of the data but it has increased a bit on the right part of the data.\nNow let’s do this for few more iterations in a loop and visualise the results.\n\n\nActive learning procedure\n\nnum_iterations = 20\npoints_added_x= np.zeros((num_iterations+1, N_features))\n\npoints_added_y=[]\n\nprint(\"Iteration, Cost\\n\")\nprint(\"-\"*40)\n\nfor iteration in range(2, num_iterations+1):\n    # Making predictions on the pool set based on model learnt in the respective train set \n    estimations_pool, var = models[iteration-1].predict(pool_X)\n    \n    # Finding the point from the pool with highest uncertainty\n    in_var = var.diagonal().argmax()\n    to_add_x = pool_X[in_var,:]\n    to_add_y = pool_Y[in_var]\n    points_added_x[iteration-1,:] = to_add_x\n    points_added_y.append(to_add_y)\n    \n    # Adding the point to the train set from the pool\n    train_X_iter[iteration] = np.vstack([train_X_iter[iteration-1], to_add_x])\n    train_Y_iter[iteration] = np.append(train_Y_iter[iteration-1], to_add_y)\n    \n    # Deleting the point from the pool\n    pool_X = np.delete(pool_X, in_var, axis=0)\n    pool_Y = np.delete(pool_Y, in_var)\n    \n    # Training on the new set\n    models[iteration] = BLR(S0, models[iteration-1].MN)\n    models[iteration].fit(train_X_iter[iteration], train_Y_iter[iteration])\n    \n    estimations[iteration], _ = models[iteration].predict(test_X)\n    test_mae_error[iteration]= pd.Series(estimations[iteration] - test_Y.squeeze()).abs().mean()\n    print(iteration, (test_mae_error[iteration]))\n\nIteration, Cost\n\n----------------------------------------\n2 0.49023173501654815\n3 0.4923391714942153\n4 0.49040074812746753\n5 0.49610198614600165\n6 0.5015282102751122\n7 0.5051264429971314\n8 0.5099913097301352\n9 0.504455016053513\n10 0.5029219102020734\n11 0.5009762782262487\n12 0.5004883097883343\n13 0.5005169638980388\n14 0.5002731089932334\n15 0.49927485683909884\n16 0.49698416490822594\n17 0.49355398855432897\n18 0.49191185613804617\n19 0.491164833699368\n20 0.4908067530719673\n\n\n\npd.Series(test_mae_error).plot(style='ko-')\nplt.xlim((-0.5, num_iterations+0.5))\nplt.ylabel(\"MAE on test set\")\nplt.xlabel(\"# Points Queried\")\nplt.show()\n\n\n\n\n\n\n\n\nThe plot above shows that MAE on the test set fluctuates a bit initially then reduces gradually as we keep including more points from the pool to the train set. Let’s visualise fits for all the iterations. We’ll discuss this behaviour after that.\n\n\nVisualizing active learning procedure\n\nprint('Initial model')\nprint('Y = {0:0.2f} X^5 + {1:0.2f} X^4 + {2:0.2f} X^3 + {3:0.2f} X^2 + {4:0.2f} X + {5:0.2f}'.format(*models[0].MN[::-1]))\nprint('\\nFinal model')\nprint('Y = {0:0.2f} X^5 + {1:0.2f} X^4 + {2:0.2f} X^3 + {3:0.2f} X^2 + {4:0.2f} X + {5:0.2f}'.format(*models[num_iterations].MN[::-1]))\n\nInitial model\nY = 1.89 X^5 + 1.54 X^4 + 0.84 X^3 + -6.48 X^2 + 4.74 X + -1.63\n\nFinal model\nY = 2.50 X^5 + 3.11 X^4 + 0.83 X^3 + -7.08 X^2 + 4.47 X + -1.58\n\n\n\ndef update(iteration):\n    ax.cla()\n    plot(ax, models[iteration])\n    fig.tight_layout()\n\n\nfig, ax = plt.subplots()\nanim = FuncAnimation(fig, update, frames=np.arange(0, num_iterations+1, 1), interval=250)\nplt.close()\nrc('animation', html='jshtml')\n\n\nanim\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nWe can see that the point having highest uncertainty was chosen in first iteration and it produced the near optimal fit. After that, error reduced gradually.\nNow, let’s put everything together and create a class for active learning procedure\n\n\nCreating a class for active learning procedure\n\nclass ActiveL():\n  def __init__(self, X, y, S0=None, M0=None, test_size=0.5, degree = 5, iterations = 20, seed=1):\n    self.X_init = X\n    self.y = y\n    self.S0 = S0\n    self.M0 = M0\n    self.train_X_iter = {} # to store train points at each iteration\n    self.train_Y_iter = {} # to store corresponding labels to the train set at each iteration\n    self.models = {} # to store the models at each iteration\n    self.estimations = {} # to store the estimations on the test set at each iteration\n    self.test_mae_error = {} # to store MAE(Mean Absolute Error) at each iteration\n    self.test_size = test_size\n    self.degree = degree\n    self.iterations = iterations\n    self.seed = seed\n    self.train_size = degree + 2\n\n  def data_preperation(self):\n    # Adding polynomial features\n    self.X = PolynomialFeatures(degree=self.degree).fit_transform(self.X_init)\n    N_features = self.X.shape[1]\n    \n    # Splitting into train, test and pool\n    train_pool_X, self.test_X, train_pool_Y, self.test_Y = train_test_split(self.X, self.y, \n                                                                            test_size=self.test_size,\n                                                                            random_state=self.seed)\n    self.train_X, self.pool_X, self.train_Y, self.pool_Y = train_test_split(train_pool_X, train_pool_Y, \n                                                                            train_size=self.train_size, \n                                                                            random_state=self.seed)\n    \n    # Setting BLR prior incase of not given\n    if self.M0 == None:\n      self.M0 = np.zeros((N_features, ))\n    if self.S0 == None:\n      self.S0 = np.eye(N_features)\n    \n  def main(self):\n    # Training for iteration 0\n    self.train_X_iter[0] = self.train_X\n    self.train_Y_iter[0] = self.train_Y\n    self.models[0] = BLR(self.S0, self.M0)\n    self.models[0].fit(self.train_X, self.train_Y)\n\n    # Running loop for all iterations\n    for iteration in range(1, self.iterations+1):\n      # Making predictions on the pool set based on model learnt in the respective train set \n      estimations_pool, var = self.models[iteration-1].predict(self.pool_X)\n      \n      # Finding the point from the pool with highest uncertainty\n      in_var = var.diagonal().argmax()\n      to_add_x = self.pool_X[in_var,:]\n      to_add_y = self.pool_Y[in_var]\n      \n      # Adding the point to the train set from the pool\n      self.train_X_iter[iteration] = np.vstack([self.train_X_iter[iteration-1], to_add_x])\n      self.train_Y_iter[iteration] = np.append(self.train_Y_iter[iteration-1], to_add_y)\n      \n      # Deleting the point from the pool\n      self.pool_X = np.delete(self.pool_X, in_var, axis=0)\n      self.pool_Y = np.delete(self.pool_Y, in_var)\n      \n      # Training on the new set\n      self.models[iteration] = BLR(self.S0, self.models[iteration-1].MN)\n      self.models[iteration].fit(self.train_X_iter[iteration], self.train_Y_iter[iteration])\n      \n      self.estimations[iteration], _ = self.models[iteration].predict(self.test_X)\n      self.test_mae_error[iteration]= pd.Series(self.estimations[iteration] - self.test_Y.squeeze()).abs().mean()\n\n  def _plot_iter_MAE(self, ax, iteration):\n    ax.plot(list(self.test_mae_error.values())[:iteration+1], 'ko-')\n    ax.set_title('MAE on test set over iterations')\n    ax.set_xlim((-0.5, self.iterations+0.5))\n    ax.set_ylabel(\"MAE on test set\")\n    ax.set_xlabel(\"# Points Queried\")\n  \n  def _plot(self, ax, model):\n    # Plotting the pool\n    ax.scatter(self.pool_X[:,1], self.pool_Y, label='pool',s=1,color='r',alpha=0.4)\n    \n    # Plotting the test data\n    ax.scatter(self.test_X[:,1], self.test_Y, label='test data',s=1, color='b', alpha=0.4)\n    \n    # Combining test_pool\n    test_pool_X, test_pool_Y = np.append(self.test_X, self.pool_X, axis=0), np.append(self.test_Y, self.pool_Y)\n    \n    # Sorting test_pool\n    sorted_inds = np.argsort(test_pool_X[:,1])\n    test_pool_X, test_pool_Y = test_pool_X[sorted_inds], test_pool_Y[sorted_inds]\n    \n    # Plotting test_pool with uncertainty\n    preds, var = model.predict(test_pool_X)\n    individual_var = var.diagonal()\n    ax.plot(test_pool_X[:,1], model.y_hat_map, color='black', label='model')\n    ax.fill_between(test_pool_X[:,1], model.y_hat_map-individual_var, model.y_hat_map+individual_var\n                    , alpha=0.2, color='black', label='uncertainty')\n    \n    # plotting the train data\n    ax.scatter(model.x[:,1], model.y,s=10, color='k', marker='s', label='train data')\n    ax.scatter(model.x[-1,1], model.y[-1],s=80, color='r', marker='o', label='last added point')\n    \n    # plotting MAE\n    preds, var = model.predict(self.test_X)\n    ax.set_title('MAE is '+str(np.mean(np.abs(self.test_Y - preds))))\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.legend()\n    \n  def visualise_AL(self):\n    fig, ax = plt.subplots(1,2,figsize=(13,5))\n    def update(iteration):\n      ax[0].cla()\n      ax[1].cla()\n      self._plot(ax[0], self.models[iteration])\n      self._plot_iter_MAE(ax[1], iteration)\n      fig.tight_layout()\n\n    print('Initial model')\n    print('Y = '+' + '.join(['{0:0.2f}'.format(self.models[0].MN[i])+' X^'*min(i,1)+str(i)*min(i,1) for i in range(self.degree+1)]))\n    print('\\nFinal model')\n    print('Y = '+' + '.join(['{0:0.2f}'.format(self.models[self.iterations].MN[i])+' X^'*min(i,1)+str(i)*min(i,1) for i in range(self.degree+1)]))\n\n    anim = FuncAnimation(fig, update, frames=np.arange(0, self.iterations+1, 1), interval=250)\n    plt.close()\n\n    rc('animation', html='jshtml')\n    return anim\n\n\n\nVisualizing a different polynomial fit on the same dataset\nLet’s try to fit a degree 7 polynomial to the same data now.\n\nnp.random.seed(seed)\nX_init = np.linspace(-1, 1, 1000)\nnoise = np.random.randn(1000, ) * 0.5\nY = (5 * X_init**3 - 4 * X_init**2 + 3 * X_init - 2) + noise\n\n\nmodel = ActiveL(X_init.reshape(-1,1), Y, degree=7, iterations=20, seed=seed)\n\n\nmodel.data_preperation()\nmodel.main()\nmodel.visualise_AL()\n\nInitial model\nY = -1.92 + 3.79 X^1 + -1.81 X^2 + -0.43 X^3 + -0.51 X^4 + -0.27 X^5 + -0.18 X^6 + -0.11 X^7\n\nFinal model\nY = -1.79 + 4.86 X^1 + -5.38 X^2 + 0.50 X^3 + -0.17 X^4 + 1.19 X^5 + 1.83 X^6 + 1.31 X^7\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nWe can clearly see that model was fitting the train points well and uncertainty was high at the left-most position. After first iteration, the left-most point was added to the train set and MAE reduced significantly. Similar phenomeneon happened at iteration 2 with the right-most point. After that error kept reducing at slower rate gradually because fit was near optimal after just 2 iterations.\n\n\nActive learning for diabetes dataset from the Scikit-learn module\nLet’s run our model for diabetes data from sklearn module. The data have various features like age, sex, weight etc. of diabetic people and target is increment in disease after one year. We’ll choose only ‘weight’ feature, which seems to have more correlation with the target.\nWe’ll try to fit degree 1 polynomial to this data, as our data seems to have a linear fit. First, let’s check the performance of Scikit-learn linear regression model.\n\nX, Y = datasets.load_diabetes(return_X_y=True)\nX = X[:, 2].reshape(-1,1) # Choosing only feature 2 which seems more relevent to linear regression\n\n# Normalizing\nX = (X - X.min())/(X.max() - X.min())\nY = (Y - Y.min())/(Y.max() - Y.min())\n\nVisualizing the dataset.\n\nplt.scatter(X, Y)\nplt.xlabel('Weight of the patients')\nplt.ylabel('Increase in the disease after a year')\nplt.show()\n\n\n\n\n\n\n\n\nLet’s fit the Scikit-learn linear regression model with 50% train-test split.\n\nfrom sklearn.linear_model import LinearRegression\ntrain_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.5, random_state = seed)\n\n\nclf = LinearRegression()\n\n\nclf.fit(train_X, train_Y)\npred_Y = clf.predict(test_X)\n\nVisualizing the fit & MAE.\n\nplt.scatter(X, Y, label='data', s=5)\nplt.plot(test_X, pred_Y, label='model', color='r')\nplt.xlabel('Weight of the patients')\nplt.ylabel('Increase in the disease after a year')\nplt.title('MAE is '+str(np.mean(np.abs(pred_Y - test_Y))))\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNow we’ll fit the same data with our BLR model\n\nmodel = ActiveL(X.reshape(-1,1), Y, degree=1, iterations=20, seed=seed)\n\n\nmodel.data_preperation()\nmodel.main()\nmodel.visualise_AL()\n\nInitial model\nY = 0.41 + 0.16 X^1\n\nFinal model\nY = 0.13 + 0.86 X^1\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nInitially, the fit is leaning towards zero slope, which is the influence of bias due to a low number of training points. It’s interesting to see that our initial train points tend to make a vertical fit, but the model doesn’t get carried away by that and stabilizes the self with prior.\n\nprint('MAE for Scikit-learn Linear Regression is',np.mean(np.abs(pred_Y - test_Y)))\nprint('MAE for Bayesian Linear Regression is', model.test_mae_error[20])\n\nMAE for Scikit-learn Linear Regression is 0.15424985705353944\nMAE for Bayesian Linear Regression is 0.15738001811804758\n\n\nAt the end, results of sklearn linear regression and our active learning based BLR model are comparable even though we’ve used only 20 points to train our model over 221 points used by sklearn. This is because active learning enables us to choose those datapoints for training, which are going to contribute the most towards a precise fit."
  },
  {
    "objectID": "posts/2022-02-17-ppca.html",
    "href": "posts/2022-02-17-ppca.html",
    "title": "Probabilstic PCA using PyTorch distributions",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\n\ndist =torch.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n\nGenerative model for PPCA in PyTorch\n\ndata_dim = 2\nlatent_dim = 1\nnum_datapoints = 100\nz = dist.Normal(\n    loc=torch.zeros([latent_dim, num_datapoints]),\n    scale=torch.ones([latent_dim, num_datapoints]),)\n\nw = dist.Normal(\n    loc=torch.zeros([data_dim, latent_dim]),\n    scale=5.0 * torch.ones([data_dim, latent_dim]),\n)\n\n\nw_sample= w.sample()\nz_sample = z.sample()\n\n\nx = dist.Normal(loc = w_sample@z_sample, scale=1)\nx_sample = x.sample([100])\nplt.scatter(x_sample[:, 0], x_sample[:, 1], alpha=0.2, s=30)\n\n\n\n\n\n\n\n\n\n\nGenerative model for PPCA in Pyro\n\nimport pyro.distributions as dist\nimport pyro.distributions.constraints as constraints\nimport pyro\n\npyro.clear_param_store()\n\n\ndef ppca_model(data, latent_dim):\n    N, data_dim = data.shape\n    W = pyro.sample(\n        \"W\",\n        dist.Normal(\n            loc=torch.zeros([latent_dim, data_dim]),\n            scale=5.0 * torch.ones([latent_dim, data_dim]),\n        ),\n    )\n    Z = pyro.sample(\n        \"Z\",\n        dist.Normal(\n            loc=torch.zeros([N, latent_dim]),\n            scale=torch.ones([N, latent_dim]),\n        ),\n    )\n\n    mean = Z @ W\n\n    return pyro.sample(\"obs\", pyro.distributions.Normal(mean, 1.0), obs=data)\n\n\npyro.render_model(\n    ppca_model, model_args=(torch.randn(150, 2), 1), render_distributions=True\n)\n\n\n\n\n\n\n\n\n\nppca_model(x_sample[0], 3).shape\n\ntorch.Size([2, 100])\n\n\n\nfrom pyro import poutine\nwith pyro.plate(\"samples\", 10, dim=-3):\n    trace = poutine.trace(ppca_model).get_trace(x_sample[0], 1)\n\n\ntrace.nodes['W']['value'].squeeze()\n\ntorch.Size([10, 100])\n\n\n\ndata_dim = 3\nlatent_dim = 2\n\nW = pyro.sample(\n        \"W\",\n        dist.Normal(\n            loc=torch.zeros([latent_dim, data_dim]),\n            scale=5.0 * torch.ones([latent_dim, data_dim]),\n        ),\n    )\n\n\nN = 150\nZ = pyro.sample(\n        \"Z\",\n        dist.Normal(\n            loc=torch.zeros([N, latent_dim]),\n            scale=torch.ones([N, latent_dim]),\n        ),\n    )\n\n\nZ.shape, W.shape\n\n(torch.Size([150, 2]), torch.Size([2, 3]))\n\n\n\n(Z@W).shape\n\ntorch.Size([150, 3])"
  },
  {
    "objectID": "posts/2022-02-11-matrix.html",
    "href": "posts/2022-02-11-matrix.html",
    "title": "Matrix as transformation and interpreting low rank matrix",
    "section": "",
    "text": "Multiplying a matrix A with a vector x transforms x\n\n\n\n\nTransforming a vector via a low rank matrix in the shown examples leads to a line\n\nWe first study Goal 1. The interpretation of matrix vector product is borrowed from the excellent videos from the 3Blue1Brown channel. I’ll first set up the environment by importing a few relevant libraries.\n\n\n\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nfrom sympy import Matrix, MatrixSymbol, Eq, MatMul\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=0.75)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nsympy_A = MatrixSymbol(\"A\", 2, 2)\nsympy_x = MatrixSymbol(\"x\", 2, 1)\ny = MatrixSymbol(\"y\", 2, 1)\n\nEq(y, sympy_A*sympy_x, evaluate=False)\n\n\\(\\displaystyle y = A x\\)\n\n\nGiven a matrix A and a vector x, we are trying to get y=Ax. Let us first see the values for a specific instance in the 2d space.\n\nA = np.array([[2, 1], [1, 4]])\n\nx = np.array([1, 1])\nAx = A @ x\n\nEq(Matrix(Ax), MatMul(Matrix(A), Matrix(x)),evaluate=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}3\\\\5\\end{matrix}\\right] = \\left[\\begin{matrix}2 & 1\\\\1 & 4\\end{matrix}\\right] \\left[\\begin{matrix}1\\\\1\\end{matrix}\\right]\\)\n\n\nHere, we have A = \\(\\left[\\begin{matrix}2 & 1\\\\1 & 4\\end{matrix}\\right]\\) and x = \\({\\text{[1 1]}}\\)\nNow some code to create arrows to represent arrows.\n\ndef plot_arrow(ax, x, color, label):\n    x_head, y_head = x[0], x[1]\n    x_tail = 0.0\n    y_tail = 0.0\n    dx = x_head - x_tail\n    dy = y_head - y_tail\n\n    arrow = mpatches.FancyArrowPatch(\n        (x_tail, y_tail), (x_head, y_head), mutation_scale=10, color=color, label=label\n    )\n\n    ax.add_patch(arrow)\n    ax.legend(bbox_to_anchor=(1.6, 1), borderaxespad=0)\n\nNow some code to plot the vector corresponding to Ax\n\ndef plot_transform(A, x):\n    Ax = A @ x\n    fig, ax = plt.subplots()\n    plot_arrow(ax, x, \"k\", f\"Original (x) {x}\")\n    plot_arrow(ax, Ax, \"g\", f\"Transformed (Ax) {Ax}\")\n    plt.xlim((-5, 5))\n    plt.ylim((-5, 5))\n    plt.grid(alpha=0.1)\n    ax.set_aspect(\"equal\")\n    plt.title(f\"A = {A}\")\n    sns.despine(left=True, bottom=True)\n    plt.tight_layout()\n\n\nplot_transform(np.array([[1.0, 1.0], [1.0, -1.0]]), [1.0, 2.0])\nplt.savefig(\"Ax1.png\", dpi=100)\n\n\n\n\n\n\n\n\nIn the plot above, we can see that the vector [1, 2] is transformed to [3, -1] via the matrix A.\nLet us now write some code to create the rotation matrix and apply it on our input x\n\ndef rot(angle):\n    theta = np.radians(angle)\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array(((c, -s), (s, c)))\n    return np.round(R, 2)\n\n\nx = np.array([1.0, 2.0])\nplot_transform(rot(90), x)\nplt.savefig(\"Ax2\", dpi=100)\n\n\n\n\n\n\n\n\nAs we can see above, creating the 90 degree rotation matrix indeed transforms our vector anticlockwise 90 degrees.\nNow let us talk about matrices A that are low rank. I am creating a simple low rank matrix where the second row is some constant times the first row.\n\ndef plot_lr(x, slope):\n    low_rank = np.array([1.0, 2.0])\n    low_rank = np.vstack((low_rank, slope * low_rank))\n    plot_transform(low_rank, x)\n    x_lin = np.linspace(-5, 5, 100)\n    y = x_lin * slope\n    plt.plot(x_lin, y, alpha=0.4, lw=5, label=f\"y = {slope}x\")\n    plt.legend(bbox_to_anchor=(1.2, 1), borderaxespad=0)\n\n\nplot_lr(x, 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-1.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\n\nplot_lr([1.0, -1.0], 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-2.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\n\nplot_lr([0.5, -0.7], 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-3.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\n\nplot_lr([-1.0, 0.0], 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-4.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\nTo summarize\n\nIn the above plots we can see that changing our x to any vector in the 2d space leads to us to transformed vector not covering the whole 2d space, but on line in the 2d space. One can easily take this learning to higher dimensional matrices A."
  },
  {
    "objectID": "posts/2022-02-11-matrix.html#goals",
    "href": "posts/2022-02-11-matrix.html#goals",
    "title": "Matrix as transformation and interpreting low rank matrix",
    "section": "",
    "text": "Multiplying a matrix A with a vector x transforms x\n\n\n\n\nTransforming a vector via a low rank matrix in the shown examples leads to a line\n\nWe first study Goal 1. The interpretation of matrix vector product is borrowed from the excellent videos from the 3Blue1Brown channel. I’ll first set up the environment by importing a few relevant libraries.\n\n\n\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nfrom sympy import Matrix, MatrixSymbol, Eq, MatMul\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=0.75)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nsympy_A = MatrixSymbol(\"A\", 2, 2)\nsympy_x = MatrixSymbol(\"x\", 2, 1)\ny = MatrixSymbol(\"y\", 2, 1)\n\nEq(y, sympy_A*sympy_x, evaluate=False)\n\n\\(\\displaystyle y = A x\\)\n\n\nGiven a matrix A and a vector x, we are trying to get y=Ax. Let us first see the values for a specific instance in the 2d space.\n\nA = np.array([[2, 1], [1, 4]])\n\nx = np.array([1, 1])\nAx = A @ x\n\nEq(Matrix(Ax), MatMul(Matrix(A), Matrix(x)),evaluate=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}3\\\\5\\end{matrix}\\right] = \\left[\\begin{matrix}2 & 1\\\\1 & 4\\end{matrix}\\right] \\left[\\begin{matrix}1\\\\1\\end{matrix}\\right]\\)\n\n\nHere, we have A = \\(\\left[\\begin{matrix}2 & 1\\\\1 & 4\\end{matrix}\\right]\\) and x = \\({\\text{[1 1]}}\\)\nNow some code to create arrows to represent arrows.\n\ndef plot_arrow(ax, x, color, label):\n    x_head, y_head = x[0], x[1]\n    x_tail = 0.0\n    y_tail = 0.0\n    dx = x_head - x_tail\n    dy = y_head - y_tail\n\n    arrow = mpatches.FancyArrowPatch(\n        (x_tail, y_tail), (x_head, y_head), mutation_scale=10, color=color, label=label\n    )\n\n    ax.add_patch(arrow)\n    ax.legend(bbox_to_anchor=(1.6, 1), borderaxespad=0)\n\nNow some code to plot the vector corresponding to Ax\n\ndef plot_transform(A, x):\n    Ax = A @ x\n    fig, ax = plt.subplots()\n    plot_arrow(ax, x, \"k\", f\"Original (x) {x}\")\n    plot_arrow(ax, Ax, \"g\", f\"Transformed (Ax) {Ax}\")\n    plt.xlim((-5, 5))\n    plt.ylim((-5, 5))\n    plt.grid(alpha=0.1)\n    ax.set_aspect(\"equal\")\n    plt.title(f\"A = {A}\")\n    sns.despine(left=True, bottom=True)\n    plt.tight_layout()\n\n\nplot_transform(np.array([[1.0, 1.0], [1.0, -1.0]]), [1.0, 2.0])\nplt.savefig(\"Ax1.png\", dpi=100)\n\n\n\n\n\n\n\n\nIn the plot above, we can see that the vector [1, 2] is transformed to [3, -1] via the matrix A.\nLet us now write some code to create the rotation matrix and apply it on our input x\n\ndef rot(angle):\n    theta = np.radians(angle)\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array(((c, -s), (s, c)))\n    return np.round(R, 2)\n\n\nx = np.array([1.0, 2.0])\nplot_transform(rot(90), x)\nplt.savefig(\"Ax2\", dpi=100)\n\n\n\n\n\n\n\n\nAs we can see above, creating the 90 degree rotation matrix indeed transforms our vector anticlockwise 90 degrees.\nNow let us talk about matrices A that are low rank. I am creating a simple low rank matrix where the second row is some constant times the first row.\n\ndef plot_lr(x, slope):\n    low_rank = np.array([1.0, 2.0])\n    low_rank = np.vstack((low_rank, slope * low_rank))\n    plot_transform(low_rank, x)\n    x_lin = np.linspace(-5, 5, 100)\n    y = x_lin * slope\n    plt.plot(x_lin, y, alpha=0.4, lw=5, label=f\"y = {slope}x\")\n    plt.legend(bbox_to_anchor=(1.2, 1), borderaxespad=0)\n\n\nplot_lr(x, 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-1.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\n\nplot_lr([1.0, -1.0], 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-2.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\n\nplot_lr([0.5, -0.7], 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-3.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\n\nplot_lr([-1.0, 0.0], 1.01)\nplt.tight_layout()\nplt.savefig(\"lr-4.png\", bbox_inches=\"tight\", dpi=100)\n\n\n\n\n\n\n\n\nTo summarize\n\nIn the above plots we can see that changing our x to any vector in the 2d space leads to us to transformed vector not covering the whole 2d space, but on line in the 2d space. One can easily take this learning to higher dimensional matrices A."
  },
  {
    "objectID": "posts/2021-06-17-python-ssh.html",
    "href": "posts/2021-06-17-python-ssh.html",
    "title": "Running Python scripts on server over ssh and getting back content",
    "section": "",
    "text": "Context: I upload GIFs to my blog from the screencasts I create on my iPad. a-shell provides ffmpeg, but, it runs out of memory often.\nSolution: Send video to server and run a Python script to convert to GIF and get the content back\nI use two scripts:\nFirst called convert-video-gif.py that uses moviepy (FFMPEG under the hood) to convert an MP4 to a GIF\nfrom moviepy.editor import *\nimport sys\n\nvid = sys.argv[1]\nvid_name = vid.split(\".\")[0]\nclip = (VideoFileClip(vid).speedx(10).resize(0.3))\nclip.write_gif(vid_name + \".gif\")\nSecond called convert_video.py that accepts: - a video file as a command line argument - transfers the video files to the server using SFTP - transfers the convert-video-gif.py file to the server using SFTP - runs the python file convert-video-gif.py on the server and create the GIF - retreive the GIF back to my local machine\n\nimport sys\nimport paramiko\n\n# The file you wish to convert to GIF\nf = sys.argv[1]\nf_name_without_ext = f.split(\".\")[0]\nf_name_gif = f_name_without_ext + \".gif\"\n\nssh_client =paramiko.SSHClient()\nssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\nssh_client.connect(hostname='MY-HOSTNAME', username='MY-USERNAME', password='MY-PASSWORD')\nftp_client=ssh_client.open_sftp()\n\n# Transferring convert-video-gif.py to server\nftp_client.put('convert-video-gif.py', 'convert-video-gif.py')\n\n# Transferring video to server\nftp_client.put(f, f)\n\n# Running Python script\nstdin, stdout, stderr = ssh_client.exec_command(f\"python convert-video-gif.py {f}\")\ne = stderr.readlines()\n\n# Retreiving the video back from server\nftp_client.get(f_name_gif, f_name_gif)\nIn another previous post, I had also mentioned about the amazing SSH/SFTP apps: Termius and ShellFish. I am again pasting the GIF showing a similar to above workflow initiated via ShellFish."
  },
  {
    "objectID": "posts/2013-06-01-hmm_simulate.html",
    "href": "posts/2013-06-01-hmm_simulate.html",
    "title": "HMM simulate",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- hidden-markov-models- sequence-modeling- probabilistic-models- time-series- simulationdate: ’2013-06-01’output-file: 2013-06-01-hmm_simulate.htmltitle: HMM simulatetoc: true—\nIn this notebook we shall create a Hidden Markov Model [1] for the Unfair Casino problem [2]. In short the problem is as follows: In a casino there may be two die- one fair and the other biased. The biased die is much more likely to produce a 6 than the other numbers. With the fair die all the outcomes (1 through 6) are equally likely. For the biased die, probability of observing a 6 is 0.5 and observing 1,2,3,4,5 is 0.1 each. Also, there are probabilies associated with the choice of a die to be thrown. The observer is only able to observe the values of die being thrown, without having a knowldge whether a fair or biased die were used.\nIn all it matches the description of a discrete Hidden Markov Model. The different components of the Discrete HMM are as follows:\nNext, we import the basic set of libraries used for matrix manipulation and for plotting.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\n#Setting Font Size as 20\nmatplotlib.rcParams.update({'font.size': 20})\nNext, we define the different components of HMM which were described above.\n'''\nPi : Fair die is twice as likely as biased die\n\nA  : The die thrower likes to keep in one state (fair/biased), and the tranisition from \n1. Fair-&gt; Fair : .95\n2. Fair-&gt;Biased: 1-.95=.05\n3. Biased-&gt;Biased: .90\n4. Biased-&gt;Biased=1-.90=.10\n\nB  : The fair die is equally likely to produce observations 1 through 6, for the biased die\nPr(6)=0.5 and Pr(1)=Pr(2)=Pr(3)=Pr(4)=Pr(5)=0.1\n'''\npi=np.array([2.0/3,1.0/3])\nA=np.array([[.95,.05],[.1,.9]])\nB=np.array([[1.0/6 for i in range(6)],[.1,.1,.1,.1,.1,.5]])\nNow based on these probability sequences we need to produce a sequence of observed and hidden states. We use the notion of weighted sampling, which basically means that terms/states with higher probabilies assigned to them are more likely to be selected/sampled. For example,let us consider the starting state. For this we need to use the pi matrix, since that encodes the likiliness of starting in a particular state. We observe that for starting in Fair state the probability is .667 and twice that of starting in Biased state. Thus, it is much more likely that we start in Fair state. We use Fitness Proportionate Selection [3] to sample states based on weights (probability). For selection of starting state we would proceed as follows:\n'''\nReturns next state according to weigted probability array. Code based on Weighted random generation in Python [4]\n'''\ndef next_state(weights):\n    choice = random.random() * sum(weights)\n    for i, w in enumerate(weights):\n        choice -= w\n        if choice &lt; 0:\n            return i\nWe test the above function by making a call to it 1000 times and then we try to see how many times do we get a 0 (Fair) wrt 1 (Biased), given the pi vector.\ncount=0\nfor i in range(1000):\n    count+=next_state(pi)\nprint \"Expected number of Fair states:\",1000-count\nprint \"Expected number of Biased states:\",count\n\nExpected number of Fair states: 649\nExpected number of Biased states: 351\nThus, we can see that we get approximately twice the number of Fair states as Biased states which is as expected.\nNext, we write the following functions:\ndef create_hidden_sequence(pi,A,length):\n    out=[None]*length\n    out[0]=next_state(pi)\n    for i in range(1,length):\n        out[i]=next_state(A[out[i-1]])\n    return out\n   \ndef create_observation_sequence(hidden_sequence,B):\n    length=len(hidden_sequence)\n    out=[None]*length\n    for i in range(length):\n        out[i]=next_state(B[hidden_sequence[i]])\n    return out\nThus, using these functions and the HMM paramters we decided earlier, we create length 1000 sequence for hidden and observed states.\nhidden=np.array(create_hidden_sequence(pi,A,1000))\nobserved=np.array(create_observation_sequence(hidden,B))\nNow, we create helper functions to plot the two sequence in a way we can intuitively understand the HMM.\n'''Group all contiguous values in tuple. Recipe picked from Stack Overflow [5]'''\ndef group(L):\n    first = last = L[0]\n    for n in L[1:]:\n        if n - 1 == last: # Part of the group, bump the end\n            last = n\n        else: # Not part of the group, yield current group and start a new\n            yield first, last\n            first = last = n\n    yield first, last # Yield the last group\n    \n'''Create tuples of the form (start, number_of_continuous values'''\ndef create_tuple(x):\n    return [(a,b-a+1) for (a,b) in x]\n#Tuples of form index value, number of continuous values corresponding to Fair State\nindices_hidden_fair=np.where(hidden==0)[0]\ntuples_contiguous_values_fair=list(group(indices_hidden_fair))\ntuples_start_break_fair=create_tuple(tuples_contiguous_values_fair)\n\n#Tuples of form index value, number of continuous values corresponding to Biased State\nindices_hidden_biased=np.where(hidden==1)[0]\ntuples_contiguous_values_biased=list(group(indices_hidden_biased))\ntuples_start_break_biased=create_tuple(tuples_contiguous_values_biased)\n\n#Tuples for observations\nobservation_tuples=[]\nfor i in range(6):\n    observation_tuples.append(create_tuple(group(list(np.where(observed==i)[0]))))\nNow we plot the hidden and observation sequences\nplt.figsize(20,10)\nplt.subplot(2,1,1)\nplt.xlim((0,1000));\nplt.title('Observations');\nfor i in range(6):\n    plt.broken_barh(observation_tuples[i],(i+0.5,1),facecolor='k');\nplt.subplot(2,1,2);\nplt.xlim((0,1000));\nplt.title('Hidden States Green:Fair, Red: Biased');\nplt.broken_barh(tuples_start_break_fair,(0,1),facecolor='g');\nplt.broken_barh(tuples_start_break_biased,(0,1),facecolor='r');"
  },
  {
    "objectID": "posts/2013-06-01-hmm_simulate.html#references",
    "href": "posts/2013-06-01-hmm_simulate.html#references",
    "title": "HMM simulate",
    "section": "References",
    "text": "References\n\nhttp://en.wikipedia.org/wiki/Hidden_Markov_model\nhttp://www.stanford.edu/class/stats366/hmmR2.html\nhttp://en.wikipedia.org/wiki/Fitness_proportionate_selection\nhttp://eli.thegreenplace.net/2010/01/22/weighted-random-generation-in-python/\nhttp://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list"
  },
  {
    "objectID": "posts/pinn.html",
    "href": "posts/pinn.html",
    "title": "PINN",
    "section": "",
    "text": "Introduction\nPINNs are a class of neural networks for solving partial differential equations. They are trained to minimize the residual of the differential equation, and the boundary and initial conditions. This is done by defining a loss function that is the sum of the mean squared error of the differential equation and the boundary and initial conditions. The loss function is minimized using gradient descent.\nReference: https://www.youtube.com/watch?v=LQ33-GeD-4Y\nLet us assume our true function is:\n\\[u(x) = e^{ax} + x\\]\nWe have:\n\\[\\frac{du}{dx} = ae^{ax} + 1\\]\n\\[\\frac{d^2u}{dx^2} = a^2e^{ax}\\]\nWe can create a differential equation from this:\n\\[\\frac{d^2u}{dx^2} - a\\frac{du}{dx} = a\\]\nWe can also create a boundary condition from this:\n\\[u(0) = 1\\] \\[u(1) = e^a + 1\\]\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nx_lin = torch.linspace(0, 1, 100)\na = 2\nu_true = torch.e**(a*x_lin) +   x_lin\n\n\nplt.plot(x_lin, u_true)\n\n\n\n\n\n\n\n\n\nclass MLP(nn.Module):\n    def __init__(self, n_input=1, n_hidden=5, n_output=1):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(n_input, n_hidden)\n        self.fc2 = nn.Linear(n_hidden, n_hidden)\n        self.fc3 = nn.Linear(n_hidden, n_output)\n        \n    def forward(self, x):\n        x = torch.sin(self.fc1(x))\n        x = torch.sin(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nu_model = MLP(n_hidden=20).to(device)\nu_model\n\nMLP(\n  (fc1): Linear(in_features=1, out_features=20, bias=True)\n  (fc2): Linear(in_features=20, out_features=20, bias=True)\n  (fc3): Linear(in_features=20, out_features=1, bias=True)\n)\n\n\n\n# Let us compute du/dx for any x vector\n\nx_vec = torch.randn(10, 1, requires_grad=True).to(device)\nu_vec = u_model(x_vec)\nprint(u_vec)\n\ntensor([[0.1620],\n        [0.1934],\n        [0.0714],\n        [0.0571],\n        [0.1903],\n        [0.1520],\n        [0.1660],\n        [0.0063],\n        [0.0372],\n        [0.0696]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ndu_dx  = torch.autograd.grad(u_vec, # Whose gradient we want\n                            x_vec, # WRT what we want the gradient\n                            torch.ones_like(u_vec), # Shape of the gradient\n                            create_graph=True)[0] # We want to differentiate again\n\n\ndu_dx\n\ntensor([[-0.0515],\n        [-0.0306],\n        [-0.1101],\n        [-0.1171],\n        [-0.0325],\n        [-0.0587],\n        [-0.0487],\n        [-0.1360],\n        [-0.1257],\n        [-0.1111]], device='cuda:0', grad_fn=&lt;MmBackward0&gt;)\n\n\n\n# Now, let us compute d2u/dx2 for any x vector\n\nx_vec = torch.randn(10, 1, requires_grad=True).to(device)\nu_vec = u_model(x_vec)\ndu_dx  = torch.autograd.grad(u_vec, # Whose gradient we want\n                            x_vec, # WRT what we want the gradient\n                            torch.ones_like(u_vec), # Shape of the gradient\n                            create_graph=True)[0] # We want to differentiate again\n\nd2u_dx2  = torch.autograd.grad(du_dx, # Whose gradient we want\n                            x_vec, # WRT what we want the gradient\n                            torch.ones_like(du_dx), # Shape of the gradient\n                            create_graph=True)[0] # We want to differentiate again\n\n\nd2u_dx2\n\ntensor([[-0.0410],\n        [-0.0573],\n        [-0.0434],\n        [-0.0512],\n        [ 0.0402],\n        [-0.0564],\n        [ 0.0408],\n        [-0.0561],\n        [-0.0580],\n        [-0.0543]], device='cuda:0', grad_fn=&lt;MmBackward0&gt;)\n\n\n\n# PDE loss\n\ndef pde_loss(model, x):\n    u = model(x)\n    du_dx = torch.autograd.grad(u, # Whose gradient we want\n                            x, # WRT what we want the gradient\n                            torch.ones_like(u), # Shape of the gradient\n                            create_graph=True)[0] # We want to differentiate again\n    d2u_dx2 = torch.autograd.grad(du_dx, # Whose gradient we want\n                            x, # WRT what we want the gradient\n                            torch.ones_like(du_dx), # Shape of the gradient\n                            create_graph=True)[0] # We want to differentiate again\n    \n    # Our PDE is d2u/dx2 -a*du/dx = a\n    # Loss = (d2u/dx2 -a*du/dx - a)**2\n    loss = (d2u_dx2 - a*du_dx - a)**2\n    return loss.mean()\n    \n\n\n# Boundary loss\ndef boundary_loss(model):\n    # Boundary condition u(0) = 1\n    x = torch.tensor([[0.0]]).to(device)\n    u = model(x)\n    loss = (u - 1)**2\n    \n    # Boundary condition u(1) = e^a + 1\n    x = torch.tensor([[1.0]]).to(device)\n    u = model(x)\n    loss += (u - torch.e**(a) - 1)**2\n    return loss.mean()\n\n\n# Training loop\nu_model = MLP(n_hidden=30).to(device)\n\noptimizer = torch.optim.Adam(u_model.parameters(), lr=0.001)\n\nfor epoch in range(5000):\n    optimizer.zero_grad()\n    x_vec = torch.rand((400, 1), requires_grad=True).to(device)\n    loss = pde_loss(u_model, x_vec) + boundary_loss(u_model)\n    loss.backward()\n    optimizer.step()\n    if epoch % 50 == 0:\n        print(\"Epoch: {}, Loss: {:.4f}\".format(epoch, loss.item()))\n\n\n    \n\nEpoch: 0, Loss: 76.9179\nEpoch: 50, Loss: 44.1352\nEpoch: 100, Loss: 32.6026\nEpoch: 150, Loss: 29.2667\nEpoch: 200, Loss: 26.7229\nEpoch: 250, Loss: 25.0849\nEpoch: 300, Loss: 21.3763\nEpoch: 350, Loss: 15.6775\nEpoch: 400, Loss: 9.4585\nEpoch: 450, Loss: 5.4534\nEpoch: 500, Loss: 2.9488\nEpoch: 550, Loss: 1.8614\nEpoch: 600, Loss: 1.1479\nEpoch: 650, Loss: 0.7941\nEpoch: 700, Loss: 0.5778\nEpoch: 750, Loss: 0.4576\nEpoch: 800, Loss: 0.4216\nEpoch: 850, Loss: 0.3251\nEpoch: 900, Loss: 0.2402\nEpoch: 950, Loss: 0.2836\nEpoch: 1000, Loss: 0.1607\nEpoch: 1050, Loss: 0.1918\nEpoch: 1100, Loss: 0.1569\nEpoch: 1150, Loss: 0.1289\nEpoch: 1200, Loss: 0.1106\nEpoch: 1250, Loss: 0.0871\nEpoch: 1300, Loss: 0.0962\nEpoch: 1350, Loss: 0.0702\nEpoch: 1400, Loss: 0.0816\nEpoch: 1450, Loss: 0.0658\nEpoch: 1500, Loss: 0.0581\nEpoch: 1550, Loss: 0.0451\nEpoch: 1600, Loss: 0.0355\nEpoch: 1650, Loss: 0.0454\nEpoch: 1700, Loss: 0.0382\nEpoch: 1750, Loss: 0.0327\nEpoch: 1800, Loss: 0.0364\nEpoch: 1850, Loss: 0.0294\nEpoch: 1900, Loss: 0.0345\nEpoch: 1950, Loss: 0.0343\nEpoch: 2000, Loss: 0.0241\nEpoch: 2050, Loss: 0.0319\nEpoch: 2100, Loss: 0.0325\nEpoch: 2150, Loss: 0.0250\nEpoch: 2200, Loss: 0.0284\nEpoch: 2250, Loss: 0.0255\nEpoch: 2300, Loss: 0.0237\nEpoch: 2350, Loss: 0.0262\nEpoch: 2400, Loss: 0.0189\nEpoch: 2450, Loss: 0.0204\nEpoch: 2500, Loss: 0.0233\nEpoch: 2550, Loss: 0.0200\nEpoch: 2600, Loss: 0.0197\nEpoch: 2650, Loss: 0.0192\nEpoch: 2700, Loss: 0.0222\nEpoch: 2750, Loss: 0.0213\nEpoch: 2800, Loss: 0.0224\nEpoch: 2850, Loss: 0.0182\nEpoch: 2900, Loss: 0.0208\nEpoch: 2950, Loss: 0.0232\nEpoch: 3000, Loss: 0.0184\nEpoch: 3050, Loss: 0.0231\nEpoch: 3100, Loss: 0.0180\nEpoch: 3150, Loss: 0.0121\nEpoch: 3200, Loss: 0.0151\nEpoch: 3250, Loss: 0.0164\nEpoch: 3300, Loss: 0.0129\nEpoch: 3350, Loss: 0.0136\nEpoch: 3400, Loss: 0.0177\nEpoch: 3450, Loss: 0.0135\nEpoch: 3500, Loss: 0.0123\nEpoch: 3550, Loss: 0.0130\nEpoch: 3600, Loss: 0.0090\nEpoch: 3650, Loss: 0.0113\nEpoch: 3700, Loss: 0.0156\nEpoch: 3750, Loss: 0.0106\nEpoch: 3800, Loss: 0.0127\nEpoch: 3850, Loss: 0.0098\nEpoch: 3900, Loss: 0.0113\nEpoch: 3950, Loss: 0.0124\nEpoch: 4000, Loss: 0.0081\nEpoch: 4050, Loss: 0.0081\nEpoch: 4100, Loss: 0.0097\nEpoch: 4150, Loss: 0.0070\nEpoch: 4200, Loss: 0.0110\nEpoch: 4250, Loss: 0.0090\nEpoch: 4300, Loss: 0.0072\nEpoch: 4350, Loss: 0.0092\nEpoch: 4400, Loss: 0.0085\nEpoch: 4450, Loss: 0.0076\nEpoch: 4500, Loss: 0.0086\nEpoch: 4550, Loss: 0.0100\nEpoch: 4600, Loss: 0.0075\nEpoch: 4650, Loss: 0.0063\nEpoch: 4700, Loss: 0.0052\nEpoch: 4750, Loss: 0.0059\nEpoch: 4800, Loss: 0.0054\nEpoch: 4850, Loss: 0.0058\nEpoch: 4900, Loss: 0.0044\nEpoch: 4950, Loss: 0.0107\n\n\n\n# Plotting the results\nx_lin = torch.linspace(0, 1, 100).to(device)\nu_true = torch.e**(a*x_lin) +   x_lin\nu_pred = u_model(x_lin.unsqueeze(1)).cpu().detach()\n\nplt.plot(x_lin.cpu(), u_true.cpu(), label=\"True\")\nplt.plot(x_lin.cpu(), u_pred, label=\"Predicted\")\nplt.legend()"
  },
  {
    "objectID": "posts/2022-02-05-simple-dgm.html",
    "href": "posts/2022-02-05-simple-dgm.html",
    "title": "Simple Directed Graphical Models in TF Probability",
    "section": "",
    "text": "Basic Imports\n\n#import silence_tensorflow.auto\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport functools\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\n\ntfd = tfp.distributions\ntfl = tfp.layers\ntfb = tfp.bijectors\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import Callback\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nimport pygraphviz as pgv\n\nA = pgv.AGraph(directed=True)\nA.node_attr[\"style\"] = \"filled\"\nA.add_edge(\"Rain\", \"Sprinkler\", minlen=1, arrowsize=1, directed=True)\nA.layout(\"dot\")\nA.graph_attr.update(size=\"4,4!\")\nA.draw(\"dgm.png\")\n\n\n\nimport tensorflow as tf\ntf.Variable(2.)\n\nMetal device set to: Apple M1\n\n\n2022-02-06 14:56:37.170460: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n2022-02-06 14:56:37.170549: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)\n\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0&gt;\n\n\n\ndef grass_wet_model(rain_prob, rain_to_sprinkler_probs):\n    rain = yield tfp.distributions.JointDistributionCoroutine.Root(\n        tfp.distributions.Bernoulli(probs=rain_prob, name=\"Rain\")\n    )\n\n    sprinkler = yield tfp.distributions.Bernoulli(\n        probs=rain_to_sprinkler_probs[rain], name=\"Sprinkler\"\n    )\n\n\ntheta_rain = tf.constant(0.2)\ntheta_sprinkler = tf.constant([0.8, 0.3])\n\n\nmodel_joint_original = tfp.distributions.JointDistributionCoroutineAutoBatched(\n    lambda: grass_wet_model(theta_rain, theta_sprinkler), name=\"Original\"\n)\n\n\nmodel_joint_original\n\n&lt;tfp.distributions.JointDistributionCoroutineAutoBatched 'Original' batch_shape=[] event_shape=StructTuple(\n  Rain=[],\n  Sprinkler=[]\n) dtype=StructTuple(\n  Rain=int32,\n  Sprinkler=int32\n)&gt;\n\n\n\nmodel_joint_original.sample(10)\n\nWARNING:tensorflow:Note that RandomUniformInt inside pfor op may not give same output as inside a sequential loop.\nWARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\nWARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\nWARNING:tensorflow:Using a while_loop for converting StridedSlice\nWARNING:tensorflow:Note that RandomUniformInt inside pfor op may not give same output as inside a sequential loop.\nWARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\nWARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n\n\n\ndataset = model_joint_original.sample(500)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/var/folders/tw/hzny0jyj71q81kf8pk3vxdgm0000gn/T/ipykernel_11845/3461828570.py in &lt;module&gt;\n----&gt; 1 dataset = model_joint_original.sample(500)\n\nNameError: name 'model_joint_original' is not defined\n\n\n\n\ndataset\n\nStructTuple(\n  Rain=&lt;tf.Tensor: shape=(500,), dtype=int32, numpy=\n    array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n           1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n           0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n           1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n           0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n           0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n           0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n           0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n           1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n           0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n           1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n           0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n           0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int32)&gt;,\n  Sprinkler=&lt;tf.Tensor: shape=(500,), dtype=int32, numpy=\n    array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n           0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n           1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n           0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n           0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n           0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n           0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n           1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n           1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n           0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n           1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n           1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n           0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n           1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n           0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n           1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n           0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n           1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0], dtype=int32)&gt;\n)\n\n\n\ndataset.Sprinkler\n\n&lt;tf.Tensor: shape=(500,), dtype=int32, numpy=\narray([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0], dtype=int32)&gt;\n\n\n\ntheta_hat_rain = tfp.util.TransformedVariable(\n    0.5, bijector=tfp.bijectors.SoftClip(0.0, 1.0), name=\"theta_hat_rain\"\n)\n\ntheta_hat_sprinkler = tfp.util.TransformedVariable(\n    [0.6, 0.4], bijector=tfp.bijectors.SoftClip(0.0, 1.0), name=\"theta_hat_sprinkler\"\n)\n\n\nmodel_fit = tfp.distributions.JointDistributionCoroutineAutoBatched(\n    lambda: grass_wet_model(theta_hat_rain, theta_hat_sprinkler), name=\"Fit\"\n)\n\nprint(model_fit)\nmodel_fit.trainable_variables\n\ntfp.distributions.JointDistributionCoroutineAutoBatched(\"Fit\", batch_shape=[], event_shape=StructTuple(\n  Rain=[],\n  Sprinkler=[]\n), dtype=StructTuple(\n  Rain=int32,\n  Sprinkler=int32\n))\n\n\n(&lt;tf.Variable 'theta_hat_rain:0' shape=() dtype=float32, numpy=0.65663093&gt;,)\n\n\n\nneg_ll = lambda: -tf.reduce_mean(model_fit.log_prob(dataset))\n\n\ntrace_fn = lambda traceable_quantities: {\n    \"loss\": traceable_quantities.loss,\n    \"theta_hat_rain\": theta_hat_rain,\n    \"theta_hat_sprinkler\": theta_hat_sprinkler,\n}\n\n\ntrace = tfp.math.minimize(\n    loss_fn=neg_ll,\n    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n    num_steps=100,\n    trace_fn=trace_fn,\n)\n\nWARNING:tensorflow:Using a while_loop for converting StridedSlice\nWARNING:tensorflow:Using a while_loop for converting StridedSlice\n\n\n\nplt.plot(trace[\"theta_hat_rain\"])\nplt.plot(trace[\"loss\"])\n\n\n\n\n\n\n\n\n\nplt.plot(trace[\"theta_hat_sprinkler\"])\n\n\n\n\n\n\n\n\nReferences\n\nhttps://www.tensorflow.org/probability/examples/Probabilistic_PCA\nhttps://www.youtube.com/watch?v=l2f6Ic6SeqE&list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ&index=4\nhttps://jeffpollock9.github.io/almost-always-auto-batched/\nhttps://jeffpollock9.github.io/bayesian-workflow-with-tfp-and-arviz/"
  },
  {
    "objectID": "posts/2014-06-01-em.html",
    "href": "posts/2014-06-01-em.html",
    "title": "Programatically understanding Expectation Maximization",
    "section": "",
    "text": "I was recently studying the Expectation Maximization algorithm from this well cited Nature article. To be honest, I found it hard to get all the maths right initially. I had to infact resort to looking up a few forums to get a clear understanding of this algorithm. I decided to take a programming approach to clear up some concepts in this problem. Another reason to do this is the amount of calculations needed in this algorithm (though not difficult, can be time consuming).\n\nMaximum Likelihood\nWe are given two coins- A and B. Both these coins have a certain probability of getting heads. We choose one of the coin at random (with equal probability) and toss it 10 times noting down the heads-tails pattern. We also carefully account which coin was thrown. We repeat this procedure 5 times. The coin tosses observed in this case are show in the figure below in case A.\nOur aim is to determine the probability of getting a head on coin A and likewise for coin B. Intuitively, if we add up the number of heads observed when A was thrown and divide it by the total number of times A was tossed, we woud get this number. This comes from the well known principle of Maximum Likelihood.\n\nThis procedure of tossing a coin which may land as either heads or tails is an example of a Bernoulli trial. As per this Wiki page, its definition is as follows:\n\nIn the theory of probability and statistics, a Bernoulli trial (or binomial trial) is a random experiment with exactly two possible outcomes, “success” and “failure”, in which the probability of success is the same every time the experiment is conducted\n\nWhen \\(n\\) such trials are performed, it is called a binomial experiment. In the case of the coin toss experiment, if we have:\n\n\\(n\\) coin toss\n\\(p\\) probability of head in each trial -&gt; \\(1-p\\) probability of head in each throw\n\nthen we observe \\(k\\) heads as per the following:\n\\[{n\\choose{k}} p^k(1-p)^{n-k}\\]\nLet us write some code to see how this function varies. We fix \\(n\\)=10 and for varying \\(p\\) and observe how the probability distirbution(pmf) varies.\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ipywidgets import StaticInteract, RangeWidget\n%matplotlib inline\n\n\na=range(11)\ndef plot_binomial(p=0.5):\n    fig, ax = plt.subplots(figsize=(4,3))\n    y = [0]*11\n    for i in a:\n        y[i-1] =  stats.binom.pmf(i, 10, p)\n    ax.bar(a,y,label=\"$p = %.1f$\" % p)\n    ax.set_ylabel('PMF of $k$ heads')\n    ax.set_xlabel('$k$')\n    ax.set_ylim((0,0.5))\n    ax.set_xlim((0,10))\n    ax.legend()\n    return fig\n\n\nStaticInteract(plot_binomial, p=RangeWidget(0.0,1.0,0.1))\n\n\n    \n    \n    \n      \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n      p: \n    \n    \n\n\nAs expected, as we increase \\(p\\), there is a higher probability of getting more heads. Now, let us look at the Maximum likelihood problem. Say, we are given that we made \\(n\\) coin tosses and obtained \\(x\\) heads. Using this information and the nature of distribution, let us find what value of \\(p\\) would have most likely resulted in this data.\nIf we choose the probability of heads to be \\(p\\), the likelihood (probability) of obtaining \\(x\\) heads in \\(n\\) throws in our data $D $ is: \\[L(D|\\theta) \\propto p^x(1-p)^{n-x}\\] If we differentiate this term wrt \\(p\\) and equate to 0, we get: \\[ xp^{x-1}(1-p)^{n-x} - p^x (n-x)(1-p)^{n-x-1} = 0\\] or \\[ p^{x-1}(1-p)^{n-x-1}[x(1-p) - p(n-x)]= 0\\] or \\[ x - xp - pn + xp = 0\\] or \\[ p = \\frac{x}{n}\\]\nThis also generalizes over when multiple sets of throws are done. Thus, in the figure shown above, we find the probability of head for coins A and coins B, given the data, as : \\[ P (A=head|D) = \\frac{\\mathrm{heads~observed~when~A~was~thrown}}{\\mathrm{times~A~was~thrown}}\\] \\[ = \\frac{24}{24+6} = 0.8\\] Similarly, for coin B, we can find this ratio as 0.45.\n\n\nProblem description\nNow, we come to the main problem. What if we didn’t note down which coin was thrown in which iteration. Can we still find out the probabilities of heads for the different coins. It turns out that we can use the EM algorithm for this task. I would recommend reading the theory in the nature paper before resuming this section. Now, we present the programming route to EM and its different components under this setting.\n\n\nCreating the dataset\nA head is labeled as a 1 and a tail as a 0. The five rows correspond to the five set of throws.\n\nobservations = np.array([[1,0,0,0,1,1,0,1,0,1],\n                         [1,1,1,1,0,1,1,1,1,1],\n                         [1,0,1,1,1,1,1,0,1,1],\n                         [1,0,1,0,0,0,1,1,0,0],\n                         [0,1,1,1,0,1,1,1,0,1]])\n\nThe true coin choice- A =True, B= False\n\ncoins_id = np.array([False,True,True,False,True])\n\n\n\nCompletely observed case\nAs discussed before, if we know which coin was used when, this task reduces to Maximum likelihood.\nThe sets of observations corresponding to coin A can be found as:\n\nobservations[coins_id]\n\narray([[1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n       [1, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n       [0, 1, 1, 1, 0, 1, 1, 1, 0, 1]])\n\n\nNumber of heads recorded when A was thrown\n\nnp.sum(observations[coins_id])\n\n24\n\n\nThus, the probability of head for A given the data would be:\n\n1.0*np.sum(observations[coins_id])/observations[coins_id].size\n\n0.8\n\n\nThe same quantity for coin B would be the following:\n\n1.0*np.sum(observations[~coins_id])/observations[~coins_id].size\n\n0.45\n\n\n\n\nUnseen data settings\nNow, we follow the Step b in the first figure on this page (which is Figure 1 from the Nature article)\n\nStep 0: Assuming initial set of parameters\n\\[\\theta_A^0 = 0.6\\] \\[\\theta_B^0 = 0.5\\]\n\n\nIteration 1, Step 1 : E-step\nLet us take the first group of observation. We have 5 Heads and 5 tails. PMF according to binomial distribution is given by : \\({n\\choose{k}}p^k(1-p)^{n-k}\\). For coin A we have \\(p=\\theta^0_A=0.6\\) and \\(n=10\\). We calculate the \\(pmf\\) as follows:\n\ncoin_A_pmf_observation_1 = stats.binom.pmf(5,10,0.6)\n\n\ncoin_A_pmf_observation_1\n\n0.20065812480000034\n\n\nSimilarly, for coin B, we get\n\ncoin_B_pmf_observation_1 = stats.binom.pmf(5,10,0.5)\n\n\ncoin_B_pmf_observation_1\n\n0.24609375000000025\n\n\nSince coin_B_pmf_observation_1 is greater than coin_A_pmf_observation_1, coin B is more likely to have produced the sequence of 5 Heads and 5 Tails. We now normalize these \\(pmfs\\) to 1 and \\(weigh\\) our observations.\n\nnormalized_coin_A_pmf_observation_1 = coin_A_pmf_observation_1/(coin_A_pmf_observation_1+coin_B_pmf_observation_1)\nprint \"%0.2f\" %normalized_coin_A_pmf_observation_1\nnormalized_coin_B_pmf_observation_1 = coin_B_pmf_observation_1/(coin_A_pmf_observation_1+coin_B_pmf_observation_1)\nprint \"%0.2f\" %normalized_coin_B_pmf_observation_1\n\n0.45\n0.55\n\n\nWe now weigh in the observations according to this ratio. Thus, for observation set 1, we have:\n\nweighted_heads_A_obervation_1 = 5*normalized_coin_A_pmf_observation_1\nprint \"Coin A Weighted count for heads in observation 1: %0.2f\" %weighted_heads_A_obervation_1\nweighted_tails_A_obervation_1 = 5*normalized_coin_A_pmf_observation_1\nprint \"Coin A Weighted count for tails in observation 1: %0.2f\" %weighted_tails_A_obervation_1\nweighted_heads_B_obervation_1 = 5*normalized_coin_B_pmf_observation_1\nprint \"Coin B Weighted count for heads in observation 1: %0.2f\" %weighted_heads_B_obervation_1\nweighted_tails_B_obervation_1 = 5*normalized_coin_B_pmf_observation_1\nprint \"Coin B Weighted count for tails in observation 1: %0.2f\" %weighted_tails_B_obervation_1\n\nCoin A Weighted count for heads in observation 1: 2.25\nCoin A Weighted count for tails in observation 1: 2.25\nCoin B Weighted count for heads in observation 1: 2.75\nCoin B Weighted count for tails in observation 1: 2.75\n\n\nWe can similarly find out the weigted count in each observation set for both coin A and B. For now, we will pick up the numbers from the paper.\n\n\nIteration 1, Step 2: M-step\nWe now take the sum of weighted count of heads for both coin A and B. For coin A, we have 21.3 heads and 8.6 tails. Thus, we get the probability of getting a head at the end of this iteration as:\n\n21.3/(21.3+8.6)\n\n0.7123745819397994\n\n\nWe can find the same quantity for coin B as well. Next, we repeat the same procedure using these latest calculated probabilities of obtaining heads for coins A and B.\n\n\n\nEM single iteration\nLet us now write a procedure to do a single iteration of the EM algorithm. The function takes in as argument the following:\n\npriors \\(\\theta_A\\) and \\(\\theta_B\\)\nobservation matrix (5 X 10) in this case\n\nand outputs the new set of priors based on EM iteration.\n\ndef em_single(priors, observations):\n    \"\"\"\n    Performs a single EM step\n    Arguments\n    ---------\n    priors : [theta_A, theta_B]\n    observations : [m X n matrix]\n    \n    Returns\n    --------\n    new_priors: [new_theta_A, new_theta_B]\n    \"\"\"\n    counts = {'A':{'H':0,'T':0}, 'B':{'H':0,'T':0}}\n    theta_A = priors[0]\n    theta_B = priors[1]\n    # E step\n    for observation in observations: \n        len_observation = len(observation)\n        num_heads = observation.sum()\n        num_tails = len_observation - num_heads\n        contribution_A = stats.binom.pmf(num_heads,len_observation,theta_A)\n        contribution_B = stats.binom.pmf(num_heads,len_observation,theta_B)\n        weight_A = contribution_A/(contribution_A+contribution_B)\n        weight_B = contribution_B/(contribution_A+contribution_B)\n        # Incrementing counts\n        counts['A']['H']+= weight_A*num_heads\n        counts['A']['T']+= weight_A*num_tails\n        counts['B']['H']+= weight_B*num_heads\n        counts['B']['T']+= weight_B*num_tails\n    # M step\n    new_theta_A = counts['A']['H']/(counts['A']['H']+counts['A']['T'])\n    new_theta_B = counts['B']['H']/(counts['B']['H']+counts['B']['T'])\n    return [new_theta_A, new_theta_B]\n\n\n\nEM procedure\nThis procedure calls the single EM iteration untill convergence or some stopping condition. We specificy two stopping conditions and the procedure stops when either condition is met. * 10000 iterations * the change in prior is less than 1e-6\n\ndef em(observations, prior, tol=1e-6, iterations=10000):\n    import math\n    iteration = 0\n    while iteration&lt;iterations:\n        new_prior = em_single(prior, observations)\n        delta_change = np.abs(prior[0]-new_prior[0])\n        if delta_change&lt;tol:\n            break\n        else:\n            prior = new_prior\n            iteration+=1\n    return [new_prior, iteration]\n\n\n\nResults\nLet us run the algorithm for the priors used in the paper\n\nem(observations, [0.6,0.5])\n\n[[0.79678875938310978, 0.51958393567528027], 14]\n\n\nGreat! Our results match exactly! It took 14 iterations of the EM algorithm to reach this value.\nWhat if we reverse the priors for A and B\n\nem(observations, [0.5,0.6])\n\n[[0.51958345063012845, 0.79678895444393927], 15]\n\n\nOk. EM does not have a notion of A and B!! For it, there exists two coins and it agains finds the same results.\nWhat if prior for both A and B were equal?\n\nem(observations, [0.3,0.3])\n\n[[0.66000000000000003, 0.66000000000000003], 1]\n\n\nSo, this clearly is not a very good initialization strategy!!\nWhat if one of the priors is very close to 1\n\nem(observations, [0.9999,0.00000001])\n\n[[0.79678850504581944, 0.51958235686544463], 13]\n\n\nSo EM is still smart enough!\n\n\nReferences\n\nQuestion on math stack exchange\nAnother question on math stack exhange\n\nIf you have any suggestions feel free let me know."
  },
  {
    "objectID": "posts/mvn-nn.html",
    "href": "posts/mvn-nn.html",
    "title": "Using a neural network as a covariance function",
    "section": "",
    "text": "Basic Imports\n\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Retina mode\n%config InlineBackend.figure_format = 'retina'\n\n\n# Create training and test data\nx_overall = torch.linspace(-1, 1, 200)\n\nf_true = lambda x: torch.sin(2 * np.pi * x) + x\n\nnoise = torch.distributions.Normal(0, 0.2)\n\ny_overall = f_true(x_overall) + noise.sample(x_overall.shape)\n\nx_train = x_overall[::2]\ny_train = y_overall[::2]\n\nx_test = x_overall[1::2]\ny_test = y_overall[1::2]\n\ndef plot_train_test():\n    plt.plot(x_train, y_train, 'x', label='Training data')\n    plt.plot(x_test, y_test, '*', label='Test data')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()\n\nplot_train_test()\n\n\n\n\n\n\n\n\n\ndef mean_function(x):\n    return 0.0*x\n\ndef covariance_function(x1, x2):\n    return torch.exp(-0.5 * (x1 - x2).pow(2))\n\n\nmean_vector = mean_function(x_overall)\ncovariance_matrix = covariance_function(x_overall.unsqueeze(1), x_overall.unsqueeze(0))\n\n\nplt.imshow(covariance_matrix.detach().numpy())\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nmvn = torch.distributions.MultivariateNormal(mean_vector, covariance_matrix + 1e-4 * torch.eye(len(x_overall)))\ny_sample_overall = mvn.sample([500])\n\n\nplt.plot(x_overall, y_sample_overall.mean(dim=0), color='r')\nplt.fill_between(x_overall, y_sample_overall.mean(dim=0) - y_sample_overall.std(dim=0), \n                 y_sample_overall.mean(dim=0) + y_sample_overall.std(dim=0), alpha=0.2)\n\n# Draw some samples\nfor i in range(10):\n    plt.plot(x_overall, y_sample_overall[i], color='k', alpha=0.5)\n    \nplot_train_test()\n\n\n\n\n\n\n\n\n\nclass SimpleMLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(SimpleMLP, self).__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc4 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = x.view(-1, self.input_dim)\n        x = self.fc1(x)\n        x = torch.sin(x)\n        x = self.fc2(x)\n        x = torch.sin(x)\n        x = self.fc3(x)\n        x = torch.sin(x)\n        x = self.fc4(x)\n        return x\n\n\nmean_function = SimpleMLP(1, 10, 1)\ncov_function = SimpleMLP(1, 10, 1)\n\n\ndef plot_model(mean_function, cov_function, n_samples=0):\n    mu = mean_function(x_overall).squeeze()\n    print(mu.shape)\n    L = cov_function(x_overall)\n    L_transpose = torch.transpose(L, 0, 1)\n    cov_nn = torch.mm(L, L_transpose)\n    print(cov_nn.shape)\n    \n    mvn = torch.distributions.MultivariateNormal(mu, cov_nn + 1e-3 * torch.eye(len(mu)))\n    y_sample_overall = mvn.sample([500])\n    \n    plt.plot(x_overall, y_sample_overall.mean(dim=0), color='r')\n    plt.fill_between(x_overall, y_sample_overall.mean(dim=0) - y_sample_overall.std(dim=0), \n                    y_sample_overall.mean(dim=0) + y_sample_overall.std(dim=0), alpha=0.2)\n\n    if n_samples &gt; 0:\n        # Draw some samples\n        for i in range(n_samples):\n            plt.plot(x_overall, y_sample_overall[i], color='k', alpha=0.5)\n        \n#plot_train_test()\n    \nplot_model(mean_function, cov_function)\nplot_train_test()\n\ntorch.Size([200])\ntorch.Size([200, 200])\n\n\n\n\n\n\n\n\n\n\nplot_model(mean_function, cov_function, n_samples=10)\n\ntorch.Size([200])\ntorch.Size([200, 200])\n\n\n\n\n\n\n\n\n\n\n# Train the models for mean and covariance\n\nmean_function = SimpleMLP(1, 12, 1)\ncov_function = SimpleMLP(1, 12, 1)\n\nparams = list(mean_function.parameters()) + list(cov_function.parameters())\n\noptimizer = torch.optim.Adam(params, lr=1e-2)\n\nn_epochs = 6000\n\nfor i in range(n_epochs):\n    mu = mean_function(x_train.squeeze()).squeeze()\n    L = cov_function(x_train.squeeze())\n    L_transpose = torch.transpose(L, 0, 1)\n    cov_nn = torch.mm(L, L_transpose)\n\n    mvn = torch.distributions.MultivariateNormal(mu, cov_nn + 1e-3 * torch.eye(len(x_train)))\n    \n    loss = -mvn.log_prob(y_train).mean()\n    if i%200 == 0:\n        print(i, loss.item())\n    \n    \n    loss.backward()\n    optimizer.step()\n    \n    optimizer.zero_grad()\n    \n\n0 28416.58203125\n200 2226.45703125\n400 2104.8095703125\n600 2084.00341796875\n800 2081.75537109375\n1000 2111.228515625\n1200 2157.63525390625\n1400 2074.7109375\n1600 2064.028076171875\n1800 2079.3447265625\n2000 2040.37158203125\n2200 2034.6796875\n2400 2033.635009765625\n2600 2030.19921875\n2800 2030.730712890625\n3000 2032.0128173828125\n3200 2030.2120361328125\n3400 2029.049072265625\n3600 2027.9500732421875\n3800 2026.4254150390625\n4000 2032.843994140625\n4200 2028.046142578125\n4400 2051.522216796875\n4600 2026.2406005859375\n4800 2025.3114013671875\n5000 2023.988037109375\n5200 2022.708740234375\n5400 2023.7421875\n5600 2023.27490234375\n5800 2020.952392578125\n\n\n\nplot_model(mean_function, cov_function)\nplot_train_test()\n\ntorch.Size([200])\ntorch.Size([200, 200])"
  },
  {
    "objectID": "posts/2020-03-29-param-learning.html",
    "href": "posts/2020-03-29-param-learning.html",
    "title": "Learning Gaussian Process regression parameters using gradient descent",
    "section": "",
    "text": "In previous posts, I have talked about GP regression:\n\nPost 1 on programatically understanding GPs\nPost 2 on making use of a popular GP library called GPy\n\nIn this post, I will be talking about how to learn the parameters of a GP. I’ll keep this post simple and specific to a trivial example using RBF kernel (though the methods discussed are general.)\nTo keep things simple, we will assume a mean prior of zero and we will only be learning the parameters of the kernel function.\n\nKey Idea\n\nWrite the expression of log likelihood of data in terms of kernel parameters\nUse gradient descent to optimize the objective (negative log likelihood) and update the kernel parameters\n\n\n\nDefining log-likelihood\nIn our previous post we had mentioned (for the noiseless case):\nGiven train data \\[\nD=\\left(x_{i}, y_{i}\\right), i=1: N\n\\] Given a test set \\(X_{*}\\) of size \\(N_{*} \\times d\\) containing \\(N_{*}\\) points in \\(\\mathbb{R}^{d},\\) we want to predict function outputs \\(y_{*}\\) We can write: \\[\n\\left(\\begin{array}{l}\ny \\\\\ny_{*}\n\\end{array}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{array}{l}\n\\mu \\\\\n\\mu_{*}\n\\end{array}\\right),\\left(\\begin{array}{cc}\nK & K_{*} \\\\\nK_{*}^{T} & K_{* *}\n\\end{array}\\right)\\right)\n\\] where \\[\n\\begin{aligned}\nK &=\\operatorname{Ker}(X, X) \\in \\mathbb{R}^{N \\times N} \\\\\nK_{*} &=\\operatorname{Ker}\\left(X, X_{*}\\right) \\in \\mathbb{R}^{N \\times N} \\\\\nK_{* *} &=\\operatorname{Ker}\\left(X_{*}, X_{*}\\right) \\in \\mathbb{R}^{N_{*} \\times N_{*}}\n\\end{aligned}\n\\]\nThus, from the property of conditioning of multivariate Gaussian, we know that:\n\\[y \\sim \\mathcal{N}_N(\\mu, K)\\]\nWe will assume \\(\\mu\\) to be zero. Thus, we have for the train data, the following expression:\n\\[y \\sim \\mathcal{N}_N(0, K)\\]\nFor the noisy case, we have:\n\\[y \\sim \\mathcal{N}_N(0, K + \\sigma_{noise}^2\\mathcal{I}_N)\\]\nFrom this expression, we can write the log-likelihood of data computed over the kernel parameters \\(\\theta\\) as:\n\\[\\mathcal{LL}(\\theta) = \\log(\\frac{\\exp((-1/2)(y-0)^T (K+\\sigma_{noise}^2\\mathcal{I}_N)^{-1}(y-0))}{(2\\pi)^{N/2}|(K+\\sigma_{noise}^2\\mathcal{I}_N)|^{1/2}})\\]\nThus, we can write:\n\\[\\mathcal{LL}(\\theta) =\\log P(\\mathbf{y} | X, \\theta)=-\\frac{1}{2} \\mathbf{y}^{\\top} M^{-1} \\mathbf{y}-\\frac{1}{2} \\log |M|-\\frac{N}{2} \\log 2 \\pi\\]\nwhere \\[M = K + \\sigma_{noise}^2\\mathcal{I}_N\\]\n\n\nImports\nAs before, we will be using the excellent Autograd library for automatically computing the gradient of an objective function with respect to the parameters. We will also be using GPy for verifying our calculations.\nLet us start with some basic imports.\n\nimport autograd.numpy as np\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport GPy\n\n\n\nDefining our RBF kernel\nThe definition of the (1-dimensional) RBF kernel has a Gaussian-form, defined as:\n\\[\n    \\kappa_\\mathrm{rbf}(x_1,x_2) = \\sigma^2\\exp\\left(-\\frac{(x_1-x_2)^2}{2\\mathscr{l}^2}\\right)\n\\]\n\ndef rbf(x1, x2, sigma, l):\n    return (sigma**2)*(np.exp(-(x1-x2)**2/(2*(l**2))))    \n\n\n\nDefining GPy’s RBF kernel\n\n# Create a 1-D RBF kernel with default parameters\nk = GPy.kern.RBF(1)\n# Preview the kernel's parameters\nk\n\n\n\n\n\n\nrbf.\nvalue\nconstraints\npriors\n\n\nvariance\n1.0\n+ve\n\n\n\nlengthscale\n1.0\n+ve\n\n\n\n\n\n\n\n\nMatching our RBF kernel with GPy’s kernel\n\nrbf(1, 0, 1, 1)==k.K(np.array([[1]]), np.array([[0]])).flatten()\n\narray([ True])\n\n\nLooks good. Our function is matching GPy’s kernel.\n\n\nGP Regresion\n\nCreating a data set\n\n# lambda function, call f(x) to generate data\nf = lambda x: 0.4*x**2 - 0.15*x**3 + 0.5*x**2 - 0.002*x**5 + 0.0002*x**6 +0.5*(x-2)**2\nn = 20\nnp.random.seed(0)\nX = np.linspace(0.05, 4.95, n)[:,None]\nY = f(X) + np.random.normal(0., 0.1, (n,1)) # note that np.random.normal takes mean and s.d. (not variance), 0.1^2 = 0.01\nplt.plot(X, Y, \"kx\", mew=2, label='Train points')\nplt.xlabel(\"x\"), plt.ylabel(\"f\")\nplt.legend();\n\n\n\n\n\n\n\n\n\n\n\nFunction to compute negative log likelihood\nBased on our above mentioned theory, we can now write the NLL function as follows\n\ndef nll(sigma=1, l=1, noise_std=1):\n    n = X.shape[0]\n    cov = rbf(X, X.T, sigma, l) + (noise_std**2)*np.eye(X.shape[0])\n    nll_ar =  0.5*(Y.T@np.linalg.inv(cov)@Y) + 0.5*n*np.log(2*np.pi) + 0.5*np.log(np.linalg.det(cov)) \n    return nll_ar[0,0]\n\n\n\nComparing the NLL from our method with the NLL from GPy\nWe will now compare the NLL from our method with GPy for a fixed set of parameters\n\nnll(1, 1, 1)\n\n40.103960984801276\n\n\n\nk.lengthscale = 1\nk.variance = 1\nm = GPy.models.GPRegression(X, Y, k, normalizer=False)\nm.Gaussian_noise = 1\nprint(m)\n\n\nName : GP regression\n\nObjective : 40.103961039553916\n\nNumber of Parameters : 3\n\nNumber of Optimization Parameters : 3\n\nUpdates : True\n\nParameters:\n\n  GP_regression.           |  value  |  constraints  |  priors\n\n  rbf.variance             |    1.0  |      +ve      |        \n\n  rbf.lengthscale          |    1.0  |      +ve      |        \n\n  Gaussian_noise.variance  |    1.0  |      +ve      |        \n\n\n\n\nExcellent, we can see that our method gives the same NLL. Looks like we are on the right track! One caveat here is that I have set the normalizer to be False, which means that GPy will not be mean centering the data.\n\n\nOptimizing the GP using GPy\nWe will now use GPy to optimize the GP parameters\n\nm = GPy.models.GPRegression(X, Y, k, normalizer=False)\nm.optimize()\nprint(m)\n\n\nName : GP regression\n\nObjective : -2.9419881541130053\n\nNumber of Parameters : 3\n\nNumber of Optimization Parameters : 3\n\nUpdates : True\n\nParameters:\n\n  GP_regression.           |                 value  |  constraints  |  priors\n\n  rbf.variance             |    27.837243180547883  |      +ve      |        \n\n  rbf.lengthscale          |     2.732180018958835  |      +ve      |        \n\n  Gaussian_noise.variance  |  0.007573211752763481  |      +ve      |        \n\n\n\n\nIt seems that variance close to 28 and length scale close to 2.7 give the optimum objective for the GP\n\n\nPlotting the NLL as a function of variance and lenghtscale\nWe will now plot the NLL obtained from our calculations as a function of variance and lengthscale. For comparing our solution with GPy solution, I will be setting noise variance to be 0.0075\n\nimport numpy as numpy\nx_grid_2, y_grid_2 = numpy.mgrid[0.1:6:0.04, 0.1:4:0.03]\n\nli = np.zeros_like(x_grid_2)\nfor i in range(x_grid_2.shape[0]):\n    for j in range(x_grid_2.shape[1]):\n        li[i, j] = nll(x_grid_2[i, j], y_grid_2[i, j], np.sqrt(.007573211752763481))\n\n\nplt.contourf(x_grid_2, y_grid_2, li)\nplt.gca().set_aspect('equal')\nplt.xlabel(r\"$\\sigma$\")\nplt.ylabel(r\"$l$\")\nplt.colorbar()\nplt.title(r\"NLL ($\\sigma, l$)\")\n\nText(0.5, 1.0, 'NLL ($\\\\sigma, l$)')\n\n\n\n\n\n\n\n\n\nWe will now try to find the “optimum” \\(\\sigma\\) and lengthscale from this NLL space.\n\nprint(li.min())\naa, bb = np.unravel_index(li.argmin(), li.shape)\nprint(x_grid_2[aa, 0]**2, y_grid_2[bb, 0])\n\n-2.9418973674348727\n28.09 0.1\n\n\nExcellent, it looks like we are pretty close to the optimum NLL as reported by GPy and our parameters learnt are also pretty similar. But, we have not even done a thorough search. We will now be using gradient descent to help us find the optimum set of parameters.\n\n\nGradient descent using autograd\n\nfrom autograd import elementwise_grad as egrad\nfrom autograd import grad\n\n\ngrad_objective = grad(nll, argnum=[0, 1, 2])\n\n\nVisualising the objective as a function of iteration\n\nsigma = 2.\nl = 2.\nnoise = 1.\nlr = 1e-3\nnum_iter = 100\nnll_arr = np.zeros(num_iter)\nfor iteration in range(num_iter):\n    nll_arr[iteration] = nll(sigma, l, noise)\n    del_sigma, del_l, del_noise = grad_objective(sigma, l, noise)\n    sigma = sigma - lr*del_sigma\n    l = l - lr*del_l\n    noise = noise - lr*del_noise\n\n\nprint(sigma**2, l, noise)\n\n5.108812267877177 1.9770216805277476 0.11095385387537618\n\n\n\nplt.plot(nll_arr)\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"NLL\")\n\nText(0, 0.5, 'NLL')\n\n\n\n\n\n\n\n\n\n\n\nApplying gradient descent and visualising the learnt function\n\nsigma = 2.\nl = 2.\nnoise = 1.\nlr = 1e-3\nnum_iter = 100\nnll_arr = np.zeros(num_iter)\nfig, ax = plt.subplots()\nfor iteration in range(num_iter):\n    nll_arr[iteration] = nll(sigma, l, noise)\n    del_sigma, del_l, del_noise = grad_objective(sigma, l, noise)\n    sigma = sigma - lr*del_sigma\n    l = l - lr*del_l\n    noise = noise - lr*del_noise\n    k.lengthscale = l\n    k.variance = sigma**2\n    m = GPy.models.GPRegression(X, Y, k, normalizer=False)\n    m.Gaussian_noise = noise**2\n    m.plot(ax=ax)['dataplot'];\n    plt.ylim((0, 6))\n    plt.title(f\"Iteration: {iteration:04}, Objective :{nll_arr[iteration]}\")\n    plt.savefig(f\"/home/nipunbatra-pc/Desktop/gp_learning/{iteration:04}.png\")\n    plt.cla();\nplt.clf()\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n!convert -delay 20 -loop 0 /home/nipunbatra-pc/Desktop/gp_learning/*.png gp-learning.gif\n\n\nExcellent, we can see the “learning” process over time. Our final objective is comparable to GPy’s objective.\nThere are a few things I have mentioned, yet have not gone into their details and I would encourage you to try those out.\n\nFirst, you should try the gradient descent procedure with restarts. Run with different random initialisations and finally report the parameters which give the optimum likelihood.\nWe assume mean zero prior here. However, we are not processing the data and thus the zero mean assumption is not very well suited to our data. If you reduce the number of data points, you would quickly see the GP prediction to fall close to zero.\n\nThere you go. Till next time!"
  },
  {
    "objectID": "posts/svd.html",
    "href": "posts/svd.html",
    "title": "Understanding Singular Value Decomposition with Visualizations",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- linear-algebra- matrix-decomposition- dimensionality-reduction- visualization- jaxdate: ’2023-02-01’output-file: svd.htmltitle: Understanding Singular Value Decomposition with Visualizationstoc: true—\n\n\nfrom jax import vmap, jit, grad, vmap\nimport jax.numpy as jnp\n\n# Enable 64-bit mode\nfrom jax.config import config\nconfig.update(\"jax_enable_x64\", True)\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import ConnectionPatch\n%matplotlib inline\nplt.style.use('dark_background')\n\n# Retina display\n%config InlineBackend.figure_format = 'retina'\n\n\n# Create an array of 8 points around a unit circle, each at 45 degrees distance\nx = jnp.array([[1, 0], [0.707, 0.707], [0, 1], [-0.707, 0.707], [-1, 0], [-0.707, -0.707], [0, -1], [0.707, -0.707]])\n\n# Define the matrix A\nA = jnp.array([[3, 0], [4, 5]])\n\n# Compute the SVD of A\nU, S, VT = jnp.linalg.svd(A, full_matrices=False)\nV = VT.T\n\nWARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\n\ndef matvec(A, vec):\n    \"\"\"\n    vec: (2,)\n    A: (2, 2)\n    \"\"\"\n    return A@vec\n\n\nmatvec(A, x[0]), matvec(A, x[1])\n\n(DeviceArray([3., 4.], dtype=float64),\n DeviceArray([2.121, 6.363], dtype=float64))\n\n\n\n# vmap the matvec function\nvmap_matvec = vmap(matvec, in_axes=(None, 0))\nAx = vmap_matvec(A, x)\nAx\n\nDeviceArray([[ 3.   ,  4.   ],\n             [ 2.121,  6.363],\n             [ 0.   ,  5.   ],\n             [-2.121,  0.707],\n             [-3.   , -4.   ],\n             [-2.121, -6.363],\n             [ 0.   , -5.   ],\n             [ 2.121, -0.707]], dtype=float64)\n\n\n\nVx = vmap_matvec(VT, x)\nVx\n\nDeviceArray([[-7.07106781e-01, -7.07106781e-01],\n             [-9.99848989e-01,  6.74518966e-18],\n             [-7.07106781e-01,  7.07106781e-01],\n             [-6.74518966e-18,  9.99848989e-01],\n             [ 7.07106781e-01,  7.07106781e-01],\n             [ 9.99848989e-01, -6.74518966e-18],\n             [ 7.07106781e-01, -7.07106781e-01],\n             [ 6.74518966e-18, -9.99848989e-01]], dtype=float64)\n\n\n\nSV = Vx*S\nSV\n\nDeviceArray([[-4.74341649e+00, -1.58113883e+00],\n             [-6.70719092e+00,  1.50827026e-17],\n             [-4.74341649e+00,  1.58113883e+00],\n             [-4.52481078e-17,  2.23573031e+00],\n             [ 4.74341649e+00,  1.58113883e+00],\n             [ 6.70719092e+00, -1.50827026e-17],\n             [ 4.74341649e+00, -1.58113883e+00],\n             [ 4.52481078e-17, -2.23573031e+00]], dtype=float64)\n\n\n\nvmap_matvec(U, SV)\n\nDeviceArray([[ 3.00000000e+00,  4.00000000e+00],\n             [ 2.12100000e+00,  6.36300000e+00],\n             [ 9.53863757e-16,  5.00000000e+00],\n             [-2.12100000e+00,  7.07000000e-01],\n             [-3.00000000e+00, -4.00000000e+00],\n             [-2.12100000e+00, -6.36300000e+00],\n             [-9.53863757e-16, -5.00000000e+00],\n             [ 2.12100000e+00, -7.07000000e-01]], dtype=float64)\n\n\n\njnp.allclose(vmap_matvec(U, SV), vmap_matvec(A, x))\n\nDeviceArray(True, dtype=bool)\n\n\n\nvmap_matvec(U, SV)\n\nDeviceArray([[ 3.00000000e+00,  4.00000000e+00],\n             [ 2.12100000e+00,  6.36300000e+00],\n             [ 9.53863757e-16,  5.00000000e+00],\n             [-2.12100000e+00,  7.07000000e-01],\n             [-3.00000000e+00, -4.00000000e+00],\n             [-2.12100000e+00, -6.36300000e+00],\n             [-9.53863757e-16, -5.00000000e+00],\n             [ 2.12100000e+00, -7.07000000e-01]], dtype=float64)\n\n\n\nvmap_matvec(A, x)\n\nDeviceArray([[ 3.   ,  4.   ],\n             [ 2.121,  6.363],\n             [ 0.   ,  5.   ],\n             [-2.121,  0.707],\n             [-3.   , -4.   ],\n             [-2.121, -6.363],\n             [ 0.   , -5.   ],\n             [ 2.121, -0.707]], dtype=float64)\n\n\n\n# Plot subplots of the above transformations in one figure with arrows showing the direction of transformation.\n# We have 2 rows and 2 columns\n\nfs = 8\nfig, ax = plt.subplots(2, 2, figsize=(8, 8))\n\n# Modify the plot function to accept an axis object\ndef plot(x, ax):\n    ax.set_facecolor((0.0, 0.0, 0.0, 1))\n    ax.scatter(x[:, 0], x[:, 1], c=jnp.arange(x.shape[0]), cmap='viridis', s=100)\n    # Add the index of the point as a label\n    for i in range(x.shape[0]):\n        ax.text(x[i, 0], x[i, 1], str(i), color='white', fontsize=8, ha='center', va='center')\n    ax.set_xlim(-fs, fs)\n    ax.set_ylim(-fs, fs)\n    ax.set_aspect('equal')\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.zorder = -1\n\n    # Disable the border axis\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n\n    \n\n\n# Plot the original points\nplot(x, ax[0, 0])\n\n# Plot transformed points by A using JAX.vmap\nxa = vmap_matvec(A, x)\nplot(xa, ax[0, 1])\n\n# Plot rotated points by VT\nxv = vmap_matvec(VT, x)\n\n# Find the angle of rotation by V\nangle_v = jnp.arctan2(VT[1, 0], VT[0, 0])\nprint('Angle of rotation by V: {:.2f} degrees'.format(angle_v*180/jnp.pi))\nplot(xv, ax[1, 0])\n\nangle_u = jnp.arctan2(U[1, 0], U[0, 0])\n\n# plot the above points scaled by S\nxs = xv*S\nplot(xs, ax[1, 1])\n\n# Add an arrow between [0, 0] and [0, 1] subplots using the matplotlib.patch.ConnectionPatch\n# add some text \"transformed via A\" to the arrow\ncon = ConnectionPatch(xyA=(fs, 0), xyB=(-fs, 0), coordsA=\"data\", coordsB=\"data\", axesA=ax[0, 0], axesB=ax[0, 1], \n                      color=\"w\", zorder=1, arrowstyle='-&gt;', lw=2)\nax[0, 0].add_artist(con)\nax[0, 0].text(2*fs, 2, 'Transformed via A', color='w', fontsize=10, ha='center', va='center', zorder=1)\n\ncon1 = ConnectionPatch(xyA=(0, -fs), xyB=(0, fs), coordsA=\"data\", coordsB=\"data\", axesA=ax[0, 0], axesB=ax[1, 0], \n                      color=\"w\", zorder=1, arrowstyle='-&gt;', lw=2)\nax[0, 0].add_artist(con1)\nax[0, 0].text(2, -2*fs, r'$V^T$' +f' (Rotation by {angle_v*180/jnp.pi:0.2f})', color='w', fontsize=10, ha='center', va='center', zorder=1, rotation=90)\n\ncon2 = ConnectionPatch(xyA=(fs, 0), xyB=(-fs, 0), coordsA=\"data\", coordsB=\"data\", axesA=ax[1, 0], axesB=ax[1, 1], \n                      color=\"w\", zorder=1, arrowstyle='-&gt;', lw=2)\nax[1, 0].add_artist(con2)\nax[1, 0].text(2*fs, 2, f'Scaled by S\\n Horizontally by {S[0]:0.2f}\\n Vertically by {S[1]:0.2f}', color='w', fontsize=10, ha='center', va='center', zorder=1)\n\ncon3 = ConnectionPatch(xyA=(0, fs), xyB=(0, -fs), coordsA=\"data\", coordsB=\"data\", axesA=ax[1, 1], axesB=ax[0, 1], \n                      color=\"w\", zorder=1, arrowstyle='-&gt;', lw=2)\nax[1, 1].add_artist(con3)\nax[1, 1].text(2, 2*fs, f'U (Rotation  by {angle_u*180/jnp.pi:0.2f})', color='w', fontsize=10, ha='center', va='center', zorder=1, rotation=90)\n\n\n\n# Add a lot of spacing between the subplots\nfig.subplots_adjust(hspace=0.5, wspace=0.5)\n\nfig.suptitle('Singular Value Decomposition\\n' +r'$A = USV^T$', fontsize=18, color='w')\nfig.tight_layout()\nfig.savefig('svd.png', dpi=600, bbox_inches='tight')\n\nAngle of rotation by V: -135.00 degrees"
  },
  {
    "objectID": "posts/2021-09-01-hello-julia-language.html",
    "href": "posts/2021-09-01-hello-julia-language.html",
    "title": "Linear Regression from scratch in Julia",
    "section": "",
    "text": "using Plots\ntheme(:default)\n\nusing LinearAlgebra\nusing LaTeXStrings\n\n\nx = 1:20; y = 4*x + 8*(0.5.-rand(20));\nplot(x, y, seriestype = :scatter, title = \"Dataset\", xlabel = \"X\", ylabel= \"Y\", label=\"Noisy dataset\", legend = :outertopright)\nplot!(x, 4*x, seriestype = :line, label=\"True relationship\", lw=2 )\n\n\n\n\n\n\n\n\n\nfunction error(a, b)\n    err = norm(y .- a[1] .- (b[1] .* x))\nend\n\nerror (generic function with 1 method)\n\n\n\na = b = -5:0.1:7\n\n-5.0:0.1:7.0\n\n\n\nerror.([1, 2]', [1, 4])\n\n2×2 Matrix{Float64}:\n 152.259  148.372\n  12.56    15.7808\n\n\n\nz = error.(a', b)\nargmin_b, argmin_a = Tuple(argmin(z))\n\n(90, 54)\n\n\n\nsurface(a, b, z , xlabel=L\"\\theta_0\", ylabel=L\"\\theta_1\", zlabel=L\"Cost~(\\theta_0, \\theta_1)\")\n\n\n\n\n\n\n\n\n\na[argmin_a], b[argmin_b]\n\n(0.3, 3.9)\n\n\n\ncontourf(a, b, error.(a', b), xlabel=L\"\\theta_0\", ylabel=L\"\\theta_1\", title=\"Contour Plot\")\nplot!([a[argmin_a]], [b[argmin_b]], seriestype=:scatter, label=\"MLE\", markersize=10)"
  },
  {
    "objectID": "posts/2014-05-01-gibbs-sampling.html",
    "href": "posts/2014-05-01-gibbs-sampling.html",
    "title": "Gibbs sampling",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- bayesian- mcmc- gibbs-sampling- probabilistic-models- sampling-methodsdate: ’2014-05-01’output-file: 2014-05-01-gibbs-sampling.htmltitle: Gibbs samplingtoc: true—\n\nImports\n\nimport networkx as nx\nimport itertools\nfrom matplotlib import rc\nrc(\"font\", family=\"serif\", size=12)\nrc(\"text\", usetex=True)\nimport daft\nimport random\nimport requests\nimport numpy as np\nfrom IPython.display import HTML\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\n\n\n\nDefining the network\n\nnetwork={\n    \"V\": [\"Letter\", \"Grade\", \"Intelligence\", \"SAT\", \"Difficulty\"],\n    \"E\": [[\"Intelligence\", \"Grade\"],\n        [\"Difficulty\", \"Grade\"],\n        [\"Intelligence\", \"SAT\"],\n        [\"Grade\", \"Letter\"]],\n    \"Vdata\": {\n        \"Letter\": {\n            \"ord\": 4,\n            \"numoutcomes\": 2,\n            \"vals\": [\"weak\", \"strong\"],\n            \"parents\": [\"Grade\"],\n            \"children\": None,\n            \"cprob\": {\n                \"['A']\": [.1, .9],\n                \"['B']\": [.4, .6],\n                \"['C']\": [.99, .01]\n            }\n        },\n\n        \"SAT\": {\n            \"ord\": 3,\n            \"numoutcomes\": 2,\n            \"vals\": [\"lowscore\", \"highscore\"],\n            \"parents\": [\"Intelligence\"],\n            \"children\": None,\n            \"cprob\": {\n                \"['low']\": [.95, .05],\n                \"['high']\": [.2, .8]\n            }\n        },\n\n        \"Grade\": {\n            \"ord\": 2,\n            \"numoutcomes\": 3,\n            \"vals\": [\"A\", \"B\", \"C\"],\n            \"parents\": [\"Difficulty\", \"Intelligence\"],\n            \"children\": [\"Letter\"],\n            \"cprob\": {\n                \"['easy', 'low']\": [.3, .4, .3],\n                \"['easy', 'high']\": [.9, .08, .02],\n                \"['hard', 'low']\": [.05, .25, .7],\n                \"['hard', 'high']\": [.5, .3, .2]\n            }\n        },\n\n        \"Intelligence\": {\n            \"ord\": 1,\n            \"numoutcomes\": 2,\n            \"vals\": [\"low\", \"high\"],\n            \"parents\": None,\n            \"children\": [\"SAT\", \"Grade\"],\n            \"cprob\": [.7, .3]\n        },\n\n        \"Difficulty\": {\n            \"ord\": 0,\n            \"numoutcomes\": 2,\n            \"vals\": [\"easy\", \"hard\"],\n            \"parents\": None,\n            \"children\": [\"Grade\"],\n            \"cprob\":  [.6, .4]\n        }\n    }\n}\n\n\n\nDrawing the Bayesian Network\n\npgm = daft.PGM([8, 8], origin=[0, 0])\n\npgm.add_node(daft.Node('Difficulty',r\"Difficulty\",2,6,aspect=3))   \npgm.add_node(daft.Node('Intelligence',r\"Intelligence\",5,6,aspect=3))\npgm.add_node(daft.Node('Grade',r\"Grade\",3,4,aspect=3))    \npgm.add_node(daft.Node('SAT',r\"SAT\",6,4,aspect=3))    \npgm.add_node(daft.Node('Letter',r\"Letter\",4,2,aspect=3))   \n\nfor node in network['Vdata']:\n    parents=network['Vdata'][node]['parents']\n    if parents is not None:        \n        for parent in parents:\n            pgm.add_edge(parent, node) \npgm.render()\n\n\n\n\n\n\n\n\n\n\nFinding the Markov blanket of a node\n\ndef find_markov_blanket(node,network):\n    '''\n    Find the Markov Blanket of the node in the given network\n    Markov Blanket is given by:\n    1. The parents of the node\n    2. The children of the node\n    3. The parents of the children of the node\n    '''\n    \n    mb=[]\n    #Finding the parents of the node\n    parents=network['Vdata'][node]['parents']\n    if parents is not None:\n        mb.append(parents)\n    \n    #Finding children of the node\n    children=network['Vdata'][node]['children']\n    if children is not None:\n        mb.append(children)\n        \n        #Finding parent of each node\n        for child in children:\n            parents_child=network['Vdata'][child]['parents']\n            if parents is not None:\n                mb.append(parents)\n                \n    #Flattening out list of lists\n    mb=list(itertools.chain(*mb)) \n    \n    #Removing repeated elements\n    mb=list(set(mb))\n    return mb\n\n\nfind_markov_blanket('Grade',network)\n\n['Difficulty', 'Letter', 'Intelligence']\n\n\n\n\nGibbs Sampling Procedures\n\n\nAssigning a random state to a node in the network\n\ndef pick_random(node,network):\n    '''\n    Assigns a random state to a given node\n    N\n    '''\n    num_outcomes=network['Vdata'][node][\"numoutcomes\"]\n    random_index=random.randint(0,num_outcomes-1)\n    return network['Vdata'][node][\"vals\"][random_index]\n\n\npick_random('SAT',network)\n\n'lowscore'\n\n\n\n\nPick a random non evidence node to the update in the current iteration\n\ndef pick_random_non_evidence_node(non_evidence_nodes):\n    return non_evidence_nodes[random.randint(0,len(non_evidence_nodes)-1)]\n\n\n\nUpdate the value of a node given assignment in previous iteration\n\ndef get_next_value(node, network,simulation):\n    parents_current_node_to_update=network['Vdata'][node]['parents']\n    if parents_current_node_to_update is None:\n        #The node has no parent and we can update it based on the prior\n        cumsum=np.cumsum(network['Vdata'][node][\"cprob\"])    \n    else:\n        #Find the row corresponding to the values of the parents in the previous iteration\n        #NB We need to maintain the order, so we will do it \n        values_parents=[simulation[-1][parent] for parent in parents_current_node_to_update]\n        row=network['Vdata'][node][\"cprob\"][str(values_parents)]\n        cumsum=np.cumsum(row)\n    choice=random.random()\n    index=np.argmax(cumsum&gt;choice)\n    return network['Vdata'][node][\"vals\"][index]\n    \n\n\n\nMain procedure: Iteratively pick up a non evidence node to update\n\ndef gibbs_sampling(network, evidence, niter=2):\n    simulation=[]\n    nodes=network['V']\n    non_evidence_nodes=[node for node in nodes if node not in evidence.keys()]        \n    #First iteration random value for all nodes\n    d={}\n    for node in nodes:\n        d[node]=pick_random(node,network)    \n    #Put evidence\n    for node in evidence:\n        d[node]=evidence[node]        \n    simulation.append(d.copy())        \n    #Now iterate \n    for count in xrange(niter):\n        #Pick up a random node to start\n        current_node_to_update=pick_random_non_evidence_node(non_evidence_nodes)\n        d[current_node_to_update]=get_next_value(current_node_to_update,network,simulation)\n        simulation.append(d.copy())\n    return simulation      \n\n\nIllustration 1\n\n\n\nDistribution of Letter given that the student is Intelligent\n\niterations=int(1e4)\nsim=gibbs_sampling(network, {\"Intelligence\":\"high\"},iterations)\n\nRemoving first 10% samples\n\nafter_removing_burnt_samples=sim[iterations/10:]\ncount={val:0 for val in network['Vdata']['Letter']['vals']}\n\nFinding the distribution of letter\n\nfor assignment in after_removing_burnt_samples:\n    count[assignment['Letter']]+=1    \n\nCounts\n\ncount\n\n{'strong': 7061, 'weak': 1940}\n\n\nCounts to Probabilites\n\nprobabilites={}\nfor l in count:\n    probabilites[l]=count[l]*1.0/(.90*iterations)\nprobabilites\n\n{'strong': 0.7845555555555556, 'weak': 0.21555555555555556}\n\n\n\n\nWait a min! What about the marginal distribution of Letter given NO evidence\n\niterations=int(1e4)\nsim=gibbs_sampling(network, {},iterations)\nafter_removing_burnt_samples=sim[iterations/10:]\ncount={val:0 for val in network['Vdata']['Letter']['vals']}\nfor assignment in after_removing_burnt_samples:\n    count[assignment['Letter']]+=1\nprobabilites_no_evidence={}\nfor l in count:\n    probabilites_no_evidence[l]=count[l]*1.0/(.90*iterations)\nprobabilites_no_evidence\n\n{'strong': 0.4766666666666667, 'weak': 0.5234444444444445}\n\n\n\n\nHow does the evidence about “Intelligent” student affect the quality of letters?\n\nplt.figure(figsize=(10, 8))\nplt.subplot(2,2,1)\nplt.bar(range(2),[probabilites['strong'],probabilites['weak']])\nplt.xticks([0.5,1.5],['Strong','Weak'])\nplt.title('Letter Quality given Intelligent Student')\nplt.ylim((0,1.0))\nplt.subplot(2,2,2)\nplt.bar(range(2),[probabilites_no_evidence['strong'],probabilites_no_evidence['weak']])\nplt.xticks([0.5,1.5],['Strong','Weak'])\nplt.title('Letter Quality given no prior information')\nplt.ylim((0,1.0));"
  },
  {
    "objectID": "posts/2022-10-25-mogp.html",
    "href": "posts/2022-10-25-mogp.html",
    "title": "Multi-output Gaussian Process",
    "section": "",
    "text": "In this notebook, we cover multi-output GPs. The presentation follows the excellent video from GPSS\n\nimport numpy as np\nfrom scipy.stats import multivariate_normal\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nimport matplotlib\n#matplotlib.rcParams['figure.figsize'] = (8,6)\nfrom matplotlib import pyplot as plt\nimport GPy\n\n\nICM\n\\(u \\sim GP (0, k)\\)\nsample from u to get a sample \\(u^1\\)\n\\(f_1(x) = a^1_1 u^1(x)\\)\n\\(f_2(x) = a^1_2 u^1(x)\\)\n\nX = np.linspace(-3.,3., 50)\n\n\nkernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=2.)\n\n\nkernel\n\n\n\n\n\n\nrbf.\nvalue\nconstraints\npriors\n\n\nvariance\n1.0\n+ve\n\n\n\nlengthscale\n2.0\n+ve\n\n\n\n\n\n\n\ndef jitter(C,  j = 1e-6):\n    return C + np.eye(len(C))*j\n\n\ncov = jitter(kernel.K(X.reshape(-1, 1)))\n\n\nplt.imshow(cov)\n\n\n\n\n\n\n\n\n\nmvn = multivariate_normal(cov=cov)\n\n\nu1 = mvn.rvs(random_state=0)\nplt.plot(X, u1)\n\n\n\n\n\n\n\n\n\na11 = 0.9\na12 = 0.7\n\na = np.array([a11, a12]).reshape(-1, 1)\n\n\na\n\narray([[0.9],\n       [0.7]])\n\n\n\nB = a@a.T\nB\n\narray([[0.81, 0.63],\n       [0.63, 0.49]])\n\n\n\ncov_f = np.kron(B, cov)\n\n\nplt.imshow(cov_f, cmap='Purples')\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nf_sample = multivariate_normal(cov=jitter(cov_f)).rvs(size=500)\nf1_samples, f2_samples = f_sample[:, :50], f_sample[:, 50:]\n\n\n#plt.plot(X, u1, label=\"u1\")\nfor i in range(2):\n    plt.plot(X, f1_samples[i], color='g') \n    plt.plot(X, f2_samples[i], color='r' )\n\n\n\n\n\n\n\n\n\nf1_samples[i]/f2_samples[i]\n\narray([1.28521323, 1.2870487 , 1.28169798, 1.29387391, 1.28381124,\n       1.29063798, 1.28399272, 1.28787108, 1.27634933, 1.29367057,\n       1.19405718, 0.81421541, 1.29366628, 1.23932848, 1.28601429,\n       1.31178054, 1.27596873, 1.28139033, 1.28548127, 1.28874727,\n       1.288544  , 1.28851575, 1.27706874, 1.28929381, 1.27167387,\n       1.30216154, 1.28769528, 1.28397652, 1.2896767 , 1.29357874,\n       1.28743778, 1.28867757, 1.29135504, 1.28085954, 1.27832016,\n       1.29113682, 1.28346876, 1.28115477, 1.28579679, 1.28664088,\n       1.2836771 , 1.28690568, 1.28521466, 1.28474094, 1.28147929,\n       1.28752966, 1.28577663, 1.28154063, 1.28312776, 1.2869964 ])\n\n\n\n## Learning in MOGP setting\n\nf1_dataset = f1_samples[4]\nf2_dataset  = f2_samples[4]\n\n\nplt.plot(X, f1_dataset, label='f1')\nplt.plot(X, f2_dataset, label='f2')\nplt.legend()\n\n\n\n\n\n\n\n\n\n## What all we want to learn:\n\n# 1. GP kernel parameters\n# 2. a11, a12\n\n\nimport jax\nimport jax.numpy as jnp\nfrom jax.config import config\nconfig.update(\"jax_enable_x64\", True)\nimport tensorflow_probability.substrates.jax as tfp\n\n\nf = jnp.hstack([f1_dataset, f2_dataset])\n\n\ndef sqexp(a, b, var=1.0, ls=4):\n    diff = (a-b)/ls\n    d = jnp.sum(diff ** 2)\n    return var*jnp.exp(-0.5 * d)\n\ndef all_pairs(f):\n    f = jax.vmap(f, in_axes= (None, 0, None, None))\n    f = jax. vmap (f, in_axes= (0, None, None, None))\n    return f\n\n\nkernel.K(X.reshape(-1, 1))\n\narray([[1.        , 0.99812754, 0.99253116, ..., 0.01592046, 0.01332383,\n        0.011109  ],\n       [0.99812754, 1.        , 0.99812754, ..., 0.01895197, 0.01592046,\n        0.01332383],\n       [0.99253116, 0.99812754, 1.        , ..., 0.02247631, 0.01895197,\n        0.01592046],\n       ...,\n       [0.01592046, 0.01895197, 0.02247631, ..., 1.        , 0.99812754,\n        0.99253116],\n       [0.01332383, 0.01592046, 0.01895197, ..., 0.99812754, 1.        ,\n        0.99812754],\n       [0.011109  , 0.01332383, 0.01592046, ..., 0.99253116, 0.99812754,\n        1.        ]])\n\n\n\nnp.allclose(np.array(all_pairs(sqexp)(X, X, 1.0, 2.0)), kernel.K(X.reshape(-1, 1)))\n\nTrue\n\n\n\nrank = 1\noutput_dim = 2\nA = jax.random.normal(key=jax.random.PRNGKey(0), shape=(output_dim,rank))/10.0\nA@A.T, A\n\n(DeviceArray([[ 0.03298171, -0.01370936],\n              [-0.01370936,  0.00569851]], dtype=float64),\n DeviceArray([[ 0.18160867],\n              [-0.07548848]], dtype=float64))\n\n\n\noutput_dim = 2\nrank = 4\nA = jax.random.normal(key=jax.random.PRNGKey(0), shape=(output_dim,rank))/2.0\nA@A.T\n\nDeviceArray([[ 1.24957827, -0.04698574],\n             [-0.04698574,  0.57577417]], dtype=float64)\n\n\n\ndef covariance_f(var, ls, A):\n    \"\"\"\n    A: (output_dim, rank)    \n    A can be generated as:\n    A = jax.random.normal(key=jax.random.PRNGKey(0), shape=(output_dim,rank))\n    \"\"\"\n    B = A@A.T\n    cov = all_pairs(sqexp)(X, X, var, ls)\n    cov_f = jitter(jnp.kron(B, cov))\n    return cov_f\n\n\ndef cost(var, ls, A):\n    cov_f = covariance_f(var, ls, A)\n    dist = tfp.distributions.MultivariateNormalFullCovariance(loc = jnp.zeros_like(f), covariance_matrix = cov_f)\n    return -dist.log_prob(f)\n\n\nplt.imshow(covariance_f(1.0, 2.0, A), cmap='Purples')\nplt.colorbar()\n\n\n\n\n\n\n\n\n\ncost(1.0, 2.0, A)\n\nDeviceArray(-431.60947116, dtype=float64)\n\n\n\ncost(1.0, 1.0, A)\n\nDeviceArray(-387.35267033, dtype=float64)\n\n\n\ngrads = jax.grad(cost, argnums=[0, 1, 2])(0.1, 1.0, A)\n\nvar = 0.1\nls = 1.0\n\nlr = 1e-3\n\n\nfor i in range(500):\n    grads = jax.grad(cost, argnums=[0, 1, 2])(var, ls, A)\n    var = var-lr*grads[0]\n    ls = ls-lr*grads[1]\n    A = A-lr*grads[2]\n    if i%100==0:\n        print(i, cost(1.0, 1.0, A), var, ls)\n\n0 -387.06097276826193 0.500429427376359 1.0913929924306696\n100 -306.72979544101435 3.6414838350262055 2.363476650308803\n200 -305.64842462218047 3.514293617054404 2.3873529546968477\n300 -304.7976816183849 3.379382170959892 2.403204858135416\n400 -304.0941499412901 3.236859846397818 2.4140771572105426\n\n\n\nC_learnt = covariance_f(var, ls, A)\nplt.imshow(C_learnt, cmap='Purples')\nplt.colorbar()\n\n\n\n\n\n\n\n\n\ndist = tfp.distributions.MultivariateNormalFullCovariance(covariance_matrix=C_learnt)\nsamples_f1 = dist.sample(sample_shape=(10, ), seed = jax.random.PRNGKey(0))\nfor s in samples_f1:\n    plt.plot(X, s[:50], color='k')\nplt.plot(X, f1_dataset)\n\n\n\n\n\n\n\n\n\n\nSLFM\n\ndef covariance_f_SLFM(var1, ls1, A1, var2, ls2, A2):\n    \"\"\"\n\n    \"\"\"\n    B1 = A1@A1.T\n    B2 = A2@A2.T\n    cov1 = all_pairs(sqexp)(X, X, var1, ls1)\n    cov2 = all_pairs(sqexp)(X, X, var1, ls1)\n    cov_f = jitter(jnp.kron(B1, cov1) + jnp.kron(B2, cov2))\n    return cov_f\n\n\nrank = 1\na1 = jax.random.normal(key=jax.random.PRNGKey(0), shape=(output_dim,rank))/2.0\na2 = jax.random.normal(key=jax.random.PRNGKey(0), shape=(output_dim,rank))/2.0\n\n\n\nC_SLFM = covariance_f_SLFM(1.0, 2.0, a1@a1.T, 1.0, 4.0, a2@a2.T)\n\n\nplt.imshow(C_SLFM, cmap='Purples')\nplt.colorbar()"
  },
  {
    "objectID": "posts/2024-attention-sequence.html",
    "href": "posts/2024-attention-sequence.html",
    "title": "Attention in Sequence to Sequence",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- attention-mechanism- sequence-to-sequence- deep-learning- neural-networks- transformers- nlp- pytorchdate: ’2024-05-30’title: Attention in Sequence to Sequencetoc: true—\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass Attention(nn.Module):\n    def __init__(self, input_dim):\n        super(Attention, self).__init__()\n        self.attention = nn.Sequential(\n            nn.Linear(input_dim, input_dim),\n            nn.Tanh(),\n            nn.Linear(input_dim, 1)\n        )\n    \n    def forward(self, x):\n        attn_weights = self.attention(x)  # Shape: (batch_size, seq_len, 1)\n        attn_weights = torch.softmax(attn_weights, dim=1)  # Shape: (batch_size, seq_len, 1)\n        context = torch.sum(attn_weights * x, dim=1)  # Shape: (batch_size, input_dim)\n        return context, attn_weights\n\n\nclass CNNWithAttention(nn.Module):\n    def __init__(self, input_channels, output_size, conv_filters, kernel_size, attention_dim):\n        super(CNNWithAttention, self).__init__()\n        self.conv1 = nn.Conv1d(input_channels, conv_filters, kernel_size)\n        self.relu = nn.ReLU()\n        self.attention = Attention(conv_filters)\n        self.fc = nn.Linear(conv_filters, output_size)\n    \n    def forward(self, x):\n        # Input shape: (batch_size, input_channels, seq_len)\n        x = self.conv1(x)  # Shape: (batch_size, conv_filters, seq_len)\n        x = self.relu(x)\n        x = x.permute(0, 2, 1)  # Shape: (batch_size, seq_len, conv_filters)\n        context, attn_weights = self.attention(x)  # Shape: (batch_size, conv_filters)\n        output = self.fc(context)  # Shape: (batch_size, output_size)\n        return output, attn_weights\n\n\ndef generate_sine_wave(seq_len, num_samples):\n    X = np.linspace(0, 4 * np.pi, seq_len * num_samples)\n    y = np.sin(X)\n    X = X.reshape(num_samples, seq_len)\n    y = y.reshape(num_samples, seq_len)\n    return X, y\n\nseq_len = 50\nnum_samples = 1000\nX, y = generate_sine_wave(seq_len, num_samples)\n\n\nplt.plot(X[150], y[150])\n\n\n\n\n\n\n\n\n\n# Prepare data for 1 time step ahead forecasting\ntrain_X = np.array([y[i, :-1] for i in range(num_samples)]).reshape(num_samples, 1, seq_len-1)\ntrain_y = np.array([y[i, 1:] for i in range(num_samples)]).reshape(num_samples, seq_len-1)\n\n# Convert to PyTorch tensors\ntrain_X = torch.tensor(train_X, dtype=torch.float32)\ntrain_y = torch.tensor(train_y[:, :, None], dtype=torch.float32)  # Shape: (num_samples, seq_len-1, 1)\n\ntrain_dataset = TensorDataset(train_X, train_y)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        for inputs, targets in train_loader:\n            optimizer.zero_grad()\n            outputs, attn_weights = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n\n# Initialize model, loss function, and optimizer\ninput_channels = 1\noutput_size = 1\nconv_filters = 64\nkernel_size = 3\nattention_dim = 64\nnum_epochs = 10\n\n\nmodel = CNNWithAttention(input_channels, output_size, conv_filters, kernel_size, attention_dim)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\ntrain_model(model, train_loader, criterion, optimizer, num_epochs)\n\n/home/nipun.batra/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 49, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 6\n      3 optimizer = optim.Adam(model.parameters(), lr=0.001)\n      5 # Train the model\n----&gt; 6 train_model(model, train_loader, criterion, optimizer, num_epochs)\n\nCell In[14], line 7, in train_model(model, train_loader, criterion, optimizer, num_epochs)\n      5 optimizer.zero_grad()\n      6 outputs, attn_weights = model(inputs)\n----&gt; 7 loss = criterion(outputs, targets)\n      8 loss.backward()\n      9 optimizer.step()\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1510 else:\n-&gt; 1511     return self._call_impl(*args, **kwargs)\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)\n   1515 # If we don't have any hooks, we want to skip the rest of the logic in\n   1516 # this function, and just call forward.\n   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1518         or _global_backward_pre_hooks or _global_backward_hooks\n   1519         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1520     return forward_call(*args, **kwargs)\n   1522 try:\n   1523     result = None\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/modules/loss.py:535, in MSELoss.forward(self, input, target)\n    534 def forward(self, input: Tensor, target: Tensor) -&gt; Tensor:\n--&gt; 535     return F.mse_loss(input, target, reduction=self.reduction)\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/nn/functional.py:3338, in mse_loss(input, target, size_average, reduce, reduction)\n   3335 if size_average is not None or reduce is not None:\n   3336     reduction = _Reduction.legacy_get_string(size_average, reduce)\n-&gt; 3338 expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n   3339 return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/torch/functional.py:76, in broadcast_tensors(*tensors)\n     74 if has_torch_function(tensors):\n     75     return handle_torch_function(broadcast_tensors, tensors, *tensors)\n---&gt; 76 return _VF.broadcast_tensors(tensors)\n\nRuntimeError: The size of tensor a (32) must match the size of tensor b (49) at non-singleton dimension 1"
  },
  {
    "objectID": "posts/2020-02-20-bayesian-linear-regression.html",
    "href": "posts/2020-02-20-bayesian-linear-regression.html",
    "title": "Bayesian Linear Regression",
    "section": "",
    "text": "—aliases:- /ML/2020/02/20/bayesian-linear-regressionauthor: Nipun Batrabadges: truecategories:- ML- bayesian- linear-regression- uncertainty-quantification- probabilistic-models- statisticsdate: ’2020-02-20’description: A programming introduction to Bayesian Linear Regression.image: images/blr-map.pngoutput-file: 2020-02-20-bayesian-linear-regression.htmltitle: Bayesian Linear Regressiontoc: true—\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nx = np.linspace(-1, 1, 50).reshape(-1, 1)\n\n\ny = 5*x + 4 \nnoise = (np.abs(x.flatten())*np.random.randn(len(x))).reshape(-1,1)\ny = y + noise\n\n\nplt.scatter(x, y)\nplt.plot(x, 5*x + 4, 'k')\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import multivariate_normal\nfrom matplotlib import cm\ncov = np.array([[ 1 , 0], [0,  1]])\nvar = multivariate_normal(mean=[0,0], cov=cov)\nx_grid, y_grid = np.mgrid[-1:1:.01, -1:1:.01]\npos = np.dstack((x_grid, y_grid))\nz = var.pdf(pos)\nplt.contourf(x_grid, y_grid, z)\nplt.gca().set_aspect('equal')\nplt.xlabel(r\"$\\theta_0$\")\nplt.ylabel(r\"$\\theta_1$\")\nplt.title(r\"Prior distribution of $\\theta = f(\\mu, \\Sigma)$\")\nplt.colorbar()\n\n\n\n\n\n\n\n\n\\[\n\\prod_{i=1}^{n} \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} e^{-\\frac{(y_{i}-\\hat{y}_{i})^{2}}{2 \\sigma^{2}}}\n\\]\n\nSample from prior\n\nn_samples = 20\nfor n in range(n_samples):\n    theta_0_s, theta_1_s = var.rvs()\n    plt.plot(x, theta_1_s*x + theta_0_s, color='k',alpha=0.2)\nplt.scatter(x, y)\n\n\n\n\n\n\n\n\n\n\nLikelihood of theta\n\ndef likelihood(theta_0, theta_1, x, y, sigma):\n    s = 0\n    x_plus_1 = np.hstack((np.ones_like(x), x))\n\n    for i in range(len(x)):\n        y_i_hat = x_plus_1[i, :]@np.array([theta_0, theta_1])\n        s += (y[i,:]-y_i_hat)**2\n    \n    \n    return np.exp(-s/(2*sigma*sigma))/np.sqrt(2*np.pi*sigma*sigma)\n\n\nlikelihood(-1, 1, x, y, 4)\n\narray([1.00683395e-22])\n\n\n\nx_grid_2, y_grid_2 = np.mgrid[0:8:.1, 0:8:.1]\n\nli = np.zeros_like(x_grid_2)\nfor i in range(x_grid_2.shape[0]):\n    for j in range(x_grid_2.shape[1]):\n        li[i, j] = likelihood(x_grid_2[i, j], y_grid_2[i, j], x, y, 4)\n        \n\n\nplt.contourf(x_grid_2, y_grid_2, li)\nplt.gca().set_aspect('equal')\nplt.xlabel(r\"$\\theta_0$\")\nplt.ylabel(r\"$\\theta_1$\")\nplt.colorbar()\nplt.scatter(4, 5, s=200, marker='*', color='r')\nplt.title(r\"Likelihood as a function of ($\\theta_0, \\theta_1$)\")\n\nText(0.5, 1.0, 'Likelihood as a function of ($\\\\theta_0, \\\\theta_1$)')\n\n\n\n\n\n\n\n\n\n\n\nLikelihood of \\(\\sigma^2\\)\n\nx_plus_1 = np.hstack((np.ones_like(x), x))\n\ntheta_mle = np.linalg.inv(x_plus_1.T@x_plus_1)@(x_plus_1.T@y)\nsigma_2_mle = np.linalg.norm(y - x_plus_1@theta_mle)**2\nsigma_mle = np.sqrt(sigma_2_mle)\nsigma_mle\n\n4.128685902124939\n\n\n\n\nPosterior\n\\[\n\\begin{aligned}\np(\\boldsymbol{\\theta} | \\mathcal{X}, \\mathcal{Y}) &=\\mathcal{N}\\left(\\boldsymbol{\\theta} | \\boldsymbol{m}_{N}, \\boldsymbol{S}_{N}\\right) \\\\\n\\boldsymbol{S}_{N} &=\\left(\\boldsymbol{S}_{0}^{-1}+\\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{\\Phi}\\right)^{-1} \\\\\n\\boldsymbol{m}_{N} &=\\boldsymbol{S}_{N}\\left(\\boldsymbol{S}_{0}^{-1} \\boldsymbol{m}_{0}+\\sigma^{-2} \\boldsymbol{\\Phi}^{\\top} \\boldsymbol{y}\\right)\n\\end{aligned}\n\\]\n\nS0 = np.array([[ 1 , 0], [0,  1]])\nM0 = np.array([0, 0])\n\nSN = np.linalg.inv(np.linalg.inv(S0) + (sigma_mle**-2)*x_plus_1.T@x_plus_1)\nMN = SN@(np.linalg.inv(S0)@M0 + (sigma_mle**-2)*(x_plus_1.T@y).squeeze())\n\n\nMN, SN\n\n(array([2.97803341, 2.54277597]), array([[2.54243881e-01, 2.97285330e-17],\n        [2.97285330e-17, 4.95625685e-01]]))\n\n\n\nfrom scipy.stats import multivariate_normal\nfrom matplotlib import cm\ncov = np.array([[ 1 , 0], [0,  1]])\nvar_pos = multivariate_normal(mean=MN, cov=SN)\nx_grid, y_grid = np.mgrid[0:8:.1, 0:8:.1]\npos = np.dstack((x_grid, y_grid))\nz = var_pos.pdf(pos)\nplt.contourf(x_grid, y_grid, z)\nplt.gca().set_aspect('equal')\nplt.xlabel(r\"$\\theta_0$\")\nplt.ylabel(r\"$\\theta_1$\")\nplt.title(r\"Posterior distribution of $\\theta = f(\\mu, \\Sigma)$\")\nplt.scatter(4, 5, s=200, marker='*', color='r', label='MLE')\nplt.scatter(MN[0], MN[1], s=100, marker='^', color='black', label='MAP')\n\nplt.colorbar()\nplt.legend()\nplt.savefig(\"../images/blr-map.png\")\n\n\n\n\n\n\n\n\nSample from posterior\n\nn_samples = 20\nfor n in range(n_samples):\n    theta_0_s, theta_1_s = var_pos.rvs()\n    plt.plot(x, theta_1_s*x + theta_0_s, color='k',alpha=0.2)\nplt.scatter(x, y)\n\n\n\n\n\n\n\n\n\n\nPosterior predictions\n\\[\n\\begin{aligned}\np\\left(y_{*} | \\mathcal{X}, \\mathcal{Y}, \\boldsymbol{x}_{*}\\right) &=\\int p\\left(y_{*} | \\boldsymbol{x}_{*}, \\boldsymbol{\\theta}\\right) p(\\boldsymbol{\\theta} | \\mathcal{X}, \\mathcal{Y}) \\mathrm{d} \\boldsymbol{\\theta} \\\\\n&=\\int \\mathcal{N}\\left(y_{*} | \\boldsymbol{\\phi}^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{\\theta}, \\sigma^{2}\\right) \\mathcal{N}\\left(\\boldsymbol{\\theta} | \\boldsymbol{m}_{N}, \\boldsymbol{S}_{N}\\right) \\mathrm{d} \\boldsymbol{\\theta} \\\\\n&=\\mathcal{N}\\left(y_{*} | \\boldsymbol{\\phi}^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{m}_{N}, \\boldsymbol{\\phi}^{\\top}\\left(\\boldsymbol{x}_{*}\\right) \\boldsymbol{S}_{N} \\boldsymbol{\\phi}\\left(\\boldsymbol{x}_{*}\\right)+\\sigma^{2}\\right)\n\\end{aligned}\n\\]\nFor a point \\(x*\\)\nPredictive mean = \\(X^Tm_N\\)\nPredictive variance = \\(X^TS_NX + \\sigma^2\\)\n\nx_plus_1.T.shape, SN.shape, x_plus_1.shape\n\n((2, 50), (2, 2), (50, 2))\n\n\n\npred_var = x_plus_1@SN@x_plus_1.T\npred_var.shape\n\n(50, 50)\n\n\n\n## Marginal\nindividual_var = pred_var.diagonal()\n\n\ny_hat_map = x_plus_1@MN\n\nplt.plot(x, y_hat_map, color='black')\nplt.fill_between(x.flatten(), y_hat_map-individual_var, y_hat_map+individual_var, alpha=0.2, color='black')\nplt.scatter(x, y)"
  },
  {
    "objectID": "posts/sr.html",
    "href": "posts/sr.html",
    "title": "Super Resolution using U-Net like architecture",
    "section": "",
    "text": "Basic Imports\n\nimport matplotlib.pyplot as plt\nimport torch\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n# Download some MNIST to demonstrate super-resolution\nfrom torchvision import datasets, transforms\nmnist = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\nmnist_test = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n\n\n\n\n# Displaying an image\ndef show_image(img):\n    plt.imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n    plt.axis('off')\n\n# Displaying a batch of images in 1 row and n columns\ndef show_batch(batch):\n    fig, ax = plt.subplots(1, len(batch), figsize=(20, 20))\n    for i, img in enumerate(batch):\n        ax[i].imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n        ax[i].axis('off')\n    \n\n\nshow_image(mnist[0][0])\n\n\n\n\n\n\n\n\n\nshow_batch(torch.stack([mnist[i][0] for i in range(10)]))\n\n\n\n\n\n\n\n\n\nmnist[0][0].shape\n\ntorch.Size([1, 28, 28])\n\n\n\n# Downsample the images\ndownsample = transforms.Resize(7)\n\n# First 10000 images X\nmnist_small = [downsample(mnist[i][0]) for i in range(10000)]\nmnist_small = torch.stack(mnist_small)\n\n# First 10000 images Y\nmnist_large = torch.stack([mnist[i][0] for i in range(10000)])\n\n# Test set X\nmnist_test_small = [downsample(mnist_test[i][0]) for i in range(10000)]\nmnist_test_small = torch.stack(mnist_test_small)\n\n# Test set Y\nmnist_test_large = torch.stack([mnist_test[i][0] for i in range(10000)])\n\n\n/home/nipun.batra/miniforge3/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n\n\n\n# Show the downsampled images and the original images side-by-side\n\nshow_batch(torch.stack([mnist_small[i] for i in range(10)]))\nplt.figure()\nshow_batch(torch.stack([mnist[i][0] for i in range(10)]))\n\n\n\n\n\n\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nmnist_small.shape, mnist.data.shape\n\n(torch.Size([10000, 1, 7, 7]), torch.Size([60000, 28, 28]))\n\n\n\nimport torch\nimport torch.nn as nn\n\nclass SinActivation(nn.Module):\n    def forward(self, x):\n        return torch.sin(x)\n\n# Create an instance of the custom SinActivation module\nsin_activation = SinActivation()\n\nclass UNet(nn.Module):\n    def __init__(self, activation=sin_activation):\n        super(UNet, self).__init__()\n\n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # Input: (batch_size, 1, 7, 7), Output: (batch_size, 16, 7, 7)\n            # Use the custom activation function\n            activation,\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # Input: (batch_size, 16, 7, 7), Output: (batch_size, 32, 7, 7)\n            activation,\n            nn.MaxPool2d(kernel_size=2, stride=2)  # Input: (batch_size, 32, 7, 7), Output: (batch_size, 32, 3, 3)\n        )\n\n        # Bottleneck\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Input: (batch_size, 32, 3, 3), Output: (batch_size, 64, 3, 3)\n            activation,\n        )\n\n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=4, padding=0),  # Input: (batch_size, 64, 3, 3), Output: (batch_size, 32, 12, 12)\n            activation,\n            # Input (batch_size, 32, 12, 12), Output: (batch_size, 16, 12, 12)\n            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=0),\n            activation,\n            # Input (batch_size, 16, 12, 12), Output: (batch_size, 1, 28, 28)\n            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1)\n            \n            )\n\n    def forward(self, x):\n        # Encoder\n        x1 = self.encoder(x)\n\n        # Bottleneck\n        x = self.bottleneck(x1)\n\n        # Decoder\n        x = self.decoder(x)\n\n        return x\n\n# Create an instance of the modified UNet model\nmodel = UNet(nn.GELU())\n\n# Print the model architecture with input and output shape\nbatch_size = 1\ninput_size = (batch_size, 1, 7, 7)\ndummy_input = torch.randn(input_size)\noutput = model(dummy_input)\nprint(model)\nprint(f\"Input shape: {input_size}\")\nprint(f\"Output shape: {output.shape}\")\n\nUNet(\n  (encoder): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): GELU(approximate='none')\n    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): GELU(approximate='none')\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (bottleneck): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): GELU(approximate='none')\n  )\n  (decoder): Sequential(\n    (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(4, 4))\n    (1): GELU(approximate='none')\n    (2): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n    (3): GELU(approximate='none')\n    (4): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n  )\n)\nInput shape: (1, 1, 7, 7)\nOutput shape: torch.Size([1, 1, 28, 28])\n\n\n\n\nDrawing the model (using ONNX and Netron)\n\n#Provide an example input to the model\nbatch_size = 1\ninput_size = (batch_size, 1, 7, 7)\ndummy_input = torch.randn(input_size)\n\n# Export the model to ONNX\nonnx_path = \"unet_model.onnx\"\ntorch.onnx.export(model, dummy_input, onnx_path, verbose=False)\n\nprint(\"Model exported to ONNX successfully.\")\n\n============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\nModel exported to ONNX successfully.\n\n\n\n\n# Input to the model is a batch of 1-channel 7x7 images\nbatch_size = 1\ninput_size = (batch_size, 1, 7, 7)\n\n# Create an instance of the modified UNet model\n\n# Output of the model is a batch of 1-channel 28x28 images\noutput_size = (batch_size, 1, 28, 28)\n\n\n# Create X_train, Y_train, X_test, Y_test\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nX_train = mnist_small.float().to(device)\nY_train = mnist_large.float().to(device)\n\nX_test = mnist_test_small.float().to(device)\nY_test = mnist_test_large.float().to(device)\n\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n\nmodel = UNet(activation=sin_activation).to(device)\n\n\n# Define the loss function\nloss_fn = nn.MSELoss()\n\n# Define the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n# Number of epochs\nn_epochs = 5001\n\n# List to store losses\nlosses = []\n\n# Loop over epochs\nfor epoch in range(n_epochs):\n    # Forward pass\n    Y_pred = model(X_train)\n\n    # Compute Loss\n    loss = loss_fn(Y_pred, Y_train)\n\n    # Print loss\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch+1} loss: {loss.item()}\")\n\n    # Store loss\n    losses.append(loss.item())\n\n    # Zero the gradients\n    optimizer.zero_grad()\n\n    # Backpropagation\n    loss.backward()\n\n    # Update the weights\n    optimizer.step()\n\nEpoch 1 loss: 0.11794766038656235\nEpoch 101 loss: 0.05467110872268677\nEpoch 201 loss: 0.04051697999238968\nEpoch 301 loss: 0.035081446170806885\nEpoch 401 loss: 0.03266175091266632\nEpoch 501 loss: 0.03106730245053768\nEpoch 601 loss: 0.0299631766974926\nEpoch 701 loss: 0.029240472242236137\nEpoch 801 loss: 0.028751315549016\nEpoch 901 loss: 0.028380418196320534\nEpoch 1001 loss: 0.02808808535337448\nEpoch 1101 loss: 0.027867494150996208\nEpoch 1201 loss: 0.02763254940509796\nEpoch 1301 loss: 0.027589663863182068\nEpoch 1401 loss: 0.027285786345601082\nEpoch 1501 loss: 0.027152569964528084\nEpoch 1601 loss: 0.02700323611497879\nEpoch 1701 loss: 0.026871109381318092\nEpoch 1801 loss: 0.026826491579413414\nEpoch 1901 loss: 0.026641741394996643\nEpoch 2001 loss: 0.02652570977807045\nEpoch 2101 loss: 0.026443270966410637\nEpoch 2201 loss: 0.026303958147764206\nEpoch 2301 loss: 0.02622942440211773\nEpoch 2401 loss: 0.026109065860509872\nEpoch 2501 loss: 0.026039674878120422\nEpoch 2601 loss: 0.025937331840395927\nEpoch 2701 loss: 0.02582435868680477\nEpoch 2801 loss: 0.02569013461470604\nEpoch 2901 loss: 0.025580981746315956\nEpoch 3001 loss: 0.025458581745624542\nEpoch 3101 loss: 0.025304477661848068\nEpoch 3201 loss: 0.025146884843707085\nEpoch 3301 loss: 0.024986406788229942\nEpoch 3401 loss: 0.024766957387328148\nEpoch 3501 loss: 0.024587564170360565\nEpoch 3601 loss: 0.02433406375348568\nEpoch 3701 loss: 0.024068517610430717\nEpoch 3801 loss: 0.023816896602511406\nEpoch 3901 loss: 0.02363565005362034\nEpoch 4001 loss: 0.023380018770694733\nEpoch 4101 loss: 0.023191582411527634\nEpoch 4201 loss: 0.02309882454574108\nEpoch 4301 loss: 0.02286476083099842\nEpoch 4401 loss: 0.022712064906954765\nEpoch 4501 loss: 0.022565141320228577\nEpoch 4601 loss: 0.02246268466114998\nEpoch 4701 loss: 0.022299710661172867\nEpoch 4801 loss: 0.022198667749762535\nEpoch 4901 loss: 0.02206907607614994\nEpoch 5001 loss: 0.021999521180987358\n\n\n\n# Plot the losses\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\n\nViz. super resolution on a subset of train images\n\n# Extract a mini-batch of 10 images\nX_mini = X_train[:10]\nY_mini = Y_train[:10]\n\n# Forward pass\nY_hat = model(X_mini)\n\n# Move the tensors to CPU\nX_mini = X_mini.cpu()\nY_mini = Y_mini.cpu()\nY_hat = Y_hat.cpu()\n\ndef plot_images(X_mini, Y_mini, Y_hat=None):\n\n    # Plot 3 rows\n    rows = 3\n\n    # 10 images X 3 \n    # First row: 10 images from the mini-batch\n    # Second row: 10 ground truth images\n    # Third row: 10 predicted images\n\n    fig, ax = plt.subplots(rows, 10, figsize=(20, 6))\n\n    for i in range(rows):\n        for j in range(10):\n            if i == 0:\n                ax[i][j].imshow(X_mini[j].squeeze(), cmap=\"gray\")\n            elif i == 1:\n                ax[i][j].imshow(Y_mini[j].squeeze(), cmap=\"gray\")\n            else:\n                ax[i][j].imshow(Y_hat[j].detach().squeeze(), cmap=\"gray\")\n\n            ax[i][j].axis(\"off\")\n\n    # Put labels for the three rows using suptitle()\n    fig.suptitle(\"MNIST Image Generation using U-Net\", fontsize=16)\n\n    ax[0][0].set_title(\"Input Images\")\n    ax[1][0].set_title(\"Ground Truth Images\")\n    ax[2][0].set_title(\"Predicted Images\")\n\nplot_images(X_mini, Y_mini, Y_hat)\n\n\n\n\n\n\n\n\n\n\nTest images\n\n# Get unseen images from the test set\nX_test = mnist_test_small.float().to(device)\nY_test = mnist_test_large.float().to(device)\n\n# Forward pass\nY_hat = model(X_test)\n\nplot_images(X_test.cpu(), Y_test.cpu(), Y_hat.cpu())"
  },
  {
    "objectID": "posts/2020-02-28-xor-relu-vector.html",
    "href": "posts/2020-02-28-xor-relu-vector.html",
    "title": "Learning neural network for XOR",
    "section": "",
    "text": "import autograd.numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.numpy_boxes.ArrayBox.__repr__ = lambda self: str(self._value)\n\n\nX = np.array([[0, 0],\n             [0, 1],\n             [1, 0],\n             [1, 1]\n             ])\n\ny = np.array([[0], [1], [1], [0]])\n\n\nX.shape, y.shape\n\n((4, 2), (4, 1))\n\n\n\nN, N_0 = X.shape\nN, N_2 = y.shape\nN_1 = 2\n\n\nW = [np.array([0]), np.array([[1, 1], [1, 1]]), np.array([[1, -2]])]\n\nb = [np.array([0]), np.array([[0], [-1]]), np.array([[0]])]\nB = []\n\n\nA = [X]\nA.extend([None]*(len(W)-1))\nZ = [None]*(len(W))\n\n\ndef relu(z):\n    temp = z.copy()\n    temp[temp&lt;0] = 0\n    return temp\n\ndef sigmoid(z):\n    return 1./(1+np.exp(-z))\n\n\nfor i in range(1, len(W)):\n    Z[i] = A[i-1]@(W[i].T) + b[i].T\n    A[i] =relu(Z[i])\n\n\nA[2]==y\n\narray([[ True],\n       [ True],\n       [ True],\n       [ True]])\n\n\nExcellent, now let us start from random weight initialisations and use backprop to come to our result\n\nshapes = [X.shape[1], 2, 1]\nactivations = ['empty','sigmoid','sigmoid']\n\nactivation_func = {'sigmoid':sigmoid, 'relu':relu}\n\n\nW = [None]*(len(shapes))\nb = [None]*(len(shapes))\n\nnp.random.seed(0)\n# Dummy\nW[0] = np.array([0])\nb[0] = np.array([0])\n\nfor i in range(1, len(shapes)):\n    W[i] = np.random.randn(shapes[i], shapes[i-1])\n    b[i] = np.random.randn(shapes[i], 1)\n    \nZ = [None]*(len(W))\nZ[0] = np.array([0])\n\nA = [X]\nA.extend([None]*(len(W)-1))\n\n\ndef make_plot(iteration, loss, W, b, cmap='PRGn',close=True):\n    h = 100\n    xx, yy = np.meshgrid(np.linspace(-0.1, 1.1, h),\n                             np.linspace(-0.1, 1.1, h))\n    XX = np.c_[xx.ravel(), yy.ravel()]\n    A = [XX]\n    A.extend([None]*(len(W)-1))\n    Z = [None]*(len(W))\n    for i in range(1, len(W)):\n        Z[i] = A[i-1]@(W[i].T) + b[i].T\n        A[i] =sigmoid(Z[i])\n    pred= A[2].reshape(xx.shape)\n    pred[pred&gt;0.5] = 1\n    pred[pred&lt;=0.5] = 0\n    \n    contours = plt.contourf(xx, yy, pred, h , cmap=cmap, alpha=0.2)\n    plt.colorbar()\n    plt.title(f\"Iteration: {iteration}\\n Loss: {loss}\")\n    plt.scatter(X[:, 0], X[:, 1], c= y.flatten(), cmap=cmap, s=200)\n    plt.savefig(f\"/home/nipunbatra-pc/Desktop/xor/{iteration:04}.png\")\n    if close:\n        plt.clf()\n\n\nmake_plot(0, 2.9, W, b, close=False)\n\n\n\n\n\n\n\n\n\ndef objective(W, b):\n    for i in range(1, len(W)):\n        Z[i] = A[i-1]@(W[i].T) + b[i].T\n        A[i] = activation_func[activations[i]](Z[i])\n    y_hat = A[2]\n    loss = (-y.T@np.log(y_hat) - (1-y).T@np.log(1-y_hat)).squeeze()\n    return loss\n\n\nobjective(W, b)\n\narray(2.9991465)\n\n\n\nfrom autograd import elementwise_grad as egrad\nfrom autograd import grad\n\n\ngrad_objective = grad(objective, argnum=[0, 1])\n\n\n(del_W0_auto, del_W1_auto, del_W2_auto), (del_b0_auto, del_b1_auto, del_b2_auto) =  grad_objective(W, b)\n\n\ndel_W2_auto\n\narray([[0.60353799, 0.35399637]])\n\n\n\ndel_W2_ours = (A[2]-y).T@A[1]\n\n\ndel_W2_ours,del_W2_auto\n\n([[0.60353799 0.35399637]], array([[0.60353799, 0.35399637]]))\n\n\n\ndel_b2_ours = (A[2]-y).sum(axis=0).reshape(-1, 1)\n\n\ndel_b2_ours,del_b2_auto\n\n([[0.6632421]], array([[0.6632421]]))\n\n\n\ndel_A1_ours = (A[2]-y)@W[2]\ndel_Z1_ours  = np.multiply(del_A1_ours, sigmoid(Z[1])*(1-sigmoid(Z[1])))\ndel_W1_ours = del_Z1_ours.T@A[0]\nnp.allclose(del_W1_ours, del_W1_auto)\n\nTrue\n\n\n\ndel_b1_ours = (del_Z1_ours.sum(axis=0)).reshape(-1, 1)\nnp.allclose(del_b1_ours, del_b1_auto)\n\nTrue\n\n\n\nepochs = 140\nalpha =1\nlosses = np.zeros(epochs)\n\nprint_every = 20\n\nW = [None]*(len(shapes))\nb = [None]*(len(shapes))\n\nnp.random.seed(0)\n# Dummy\nW[0] = np.array([0])\nb[0] = np.array([0])\n\nfor i in range(1, len(shapes)):\n    W[i] = np.random.randn(shapes[i], shapes[i-1])\n    b[i] = np.random.randn(shapes[i], 1)\n    \nZ = [None]*(len(W))\nZ[0] = np.array([0])\n\nA = [X]\nA.extend([None]*(len(W)-1))\n\ndel_Z = [None]*(len(W)+1)\ndel_A = [None]*(len(W)+1)\ndel_W = [None]*(len(W))\ndel_b = [None]*(len(W))\n\nfor iteration in range(epochs):\n    \n    for i in range(1, len(W)):\n        Z[i] = A[i-1]@(W[i].T) + b[i].T\n        A[i] = activation_func[activations[i]](Z[i])\n\n    y_hat = A[2]\n    loss = (-y.T@np.log(y_hat) - (1-y).T@np.log(1-y_hat)).squeeze()\n    losses[iteration] = loss\n    if iteration%print_every==0:\n        print(iteration, loss)\n    \n    make_plot(iteration, loss, W, b, close=True)\n        \n    del_A[2] = -np.multiply(y, A[2]) + np.multiply((1-y), (1-A[2]))\n    del_Z[2] = A[2]-y\n    del_W[2] = (A[2]-y).T@A[1]\n    del_b[2] = (del_Z[2].sum(axis=0)).reshape(-1, 1)\n    del_A[1] = del_Z[2]@W[2]\n    del_Z[1]  = np.multiply(del_A[1], sigmoid(Z[1])*(1-sigmoid(Z[1])))\n    del_W[1] = del_Z[1].T@A[0]\n    del_b[1] = (del_Z[1].sum(axis=0)).reshape(-1, 1)\n    \n    for i in range(1, len(shapes)):\n        W[i] = W[i] - alpha*del_W[i]\n        b[i] = b[i] - alpha*del_b[i]\n\n0 2.9991464995409807\n20 2.850067543754094\n40 2.5045921819726082\n60 1.5756597251036364\n80 0.5779054501565161\n100 0.3097308274202594\n120 0.2028529568023768\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\nmake_plot(iteration, loss, W, b, close=False)\n\n\n\n\n\n\n\n\n\nmake_plot(0, 2.9, W, b, close=False)\n\narray([[0],\n       [1],\n       [1],\n       [0]])\n\n\n\n!convert -delay 20 -loop 0 /home/nipunbatra-pc/Desktop/xor/*.png xor-own.gif"
  },
  {
    "objectID": "posts/2014-06-02-latexify.html",
    "href": "posts/2014-06-02-latexify.html",
    "title": "Latexify Matplotlib",
    "section": "",
    "text": "Every time I would prepare a matplotlib graph for a paper, I would iteratively adjust the figure size, the font size, scaling in LaTeX. This turns to be a tedious process. Fortunately, when along with Jack and Oliver, I was writing our nilmtk paper, Jack demonstrated a function to “latexify” plots. This function would take care of font sizes and scaling, so that in one go one could generate a plot and stick in LaTeX. In this post I’ll illustrate this technique to save all that iterative effort and make plots look nicer.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib\n\n\nfrom math import sqrt\nSPINE_COLOR = 'gray'\n\nThe following is the latexify function. It allows you to create 2 column or 1 column figures. You may also wish to alter the height or width of the figure. The default settings are good for most cases. You may also change the parameters such as labelsize and fontsize based on your classfile. For this post, I’ll use the following ACM classfile.\n\ndef latexify(fig_width=None, fig_height=None, columns=1):\n    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n    Call this before plotting a figure.\n\n    Parameters\n    ----------\n    fig_width : float, optional, inches\n    fig_height : float,  optional, inches\n    columns : {1, 2}\n    \"\"\"\n\n    # code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n\n    # Width and max height in inches for IEEE journals taken from\n    # computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf\n\n    assert(columns in [1,2])\n\n    if fig_width is None:\n        fig_width = 3.39 if columns==1 else 6.9 # width in inches\n\n    if fig_height is None:\n        golden_mean = (sqrt(5)-1.0)/2.0    # Aesthetic ratio\n        fig_height = fig_width*golden_mean # height in inches\n\n    MAX_HEIGHT_INCHES = 8.0\n    if fig_height &gt; MAX_HEIGHT_INCHES:\n        print(\"WARNING: fig_height too large:\" + fig_height + \n              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n        fig_height = MAX_HEIGHT_INCHES\n\n    params = {'backend': 'ps',\n              'text.latex.preamble': [r'\\usepackage{gensymb}'],\n              'axes.labelsize': 8, # fontsize for x and y labels (was 10)\n              'axes.titlesize': 8,\n              'font.size': 8, # was 10\n              'legend.fontsize': 8, # was 10\n              'xtick.labelsize': 8,\n              'ytick.labelsize': 8,\n              'text.usetex': True,\n              'figure.figsize': [fig_width,fig_height],\n              'font.family': 'serif'\n    }\n\n    matplotlib.rcParams.update(params)\n\n\ndef format_axes(ax):\n\n    for spine in ['top', 'right']:\n        ax.spines[spine].set_visible(False)\n\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_color(SPINE_COLOR)\n        ax.spines[spine].set_linewidth(0.5)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    for axis in [ax.xaxis, ax.yaxis]:\n        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n\n    return ax\n\n\n%matplotlib inline\n\nLet us create a dummy data frame\n\ndf = pd.DataFrame(np.random.randn(10,2))\ndf.columns = ['Column 1', 'Column 2']\n\n\nax = df.plot()\nax.set_xlabel(\"X label\")\nax.set_ylabel(\"Y label\")\nax.set_title(\"Title\")\nplt.tight_layout()\nplt.savefig(\"image1.pdf\")\n\n\n\n\n\n\n\n\nNow, let us call the latexify function to alter matplotlib parameters suited to our LaTeX classfile.\n\nlatexify()\n\n\nax = df.plot()\nax.set_xlabel(\"X label\")\nax.set_ylabel(\"Y label\")\nax.set_title(\"Title\")\nplt.tight_layout()\nformat_axes(ax)\nplt.savefig(\"image2.pdf\")\n\n\n\n\n\n\n\n\nLet us have a quick look at our latex source file. I have scaled down the plot generated by default matploltib settings by 50%. The next plot which is generated using latexified settings doesn’t need any scaling.\n\n! cat 1.tex\n\n\\documentclass{sig-alternate}\n\\title{Python plots for LaTeX}\n\\begin{document}\n\\maketitle\n\\section{Introduction}\nSome random text out here!\n\\noindent\n\n\\begin{figure}\n\\centering \\includegraphics[scale=0.5]{image1.pdf}\n\\caption{Scaled down of the originial matplotlib plot. Now, the text looks very small.}\n\\label{image1}\n\\end{figure}\n\n\\begin{figure}\n\\centering \\includegraphics{image2.pdf}\n\\caption{LaTeXified plot :)}\n\\label{image2}\n\\end{figure}\n\n\n\\end{document}\n\n\nFinally, let us look at the “png” version of our generated pdf.\n\nClearly, the LaTeXified version is likely to save you a lot of figure tweaking! You don’t need to play with different scaling settings. Nor, do you have to play with font sizes and ofcourse not with a combination of these two which can be pretty hard."
  },
  {
    "objectID": "posts/2017-08-02-fifty-ggplot-python-1.html",
    "href": "posts/2017-08-02-fifty-ggplot-python-1.html",
    "title": "Fifty ggplot python 1",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- visualization- data-visualization- ggplot- plotnine- python- data-analysisdate: ’2017-08-02’output-file: 2017-08-02-fifty-ggplot-python-1.htmltitle: Fifty ggplot python 1toc: true—\nA while back, I read this wonderful article called “Top 50 ggplot2 Visualizations - The Master List (With Full R Code)”. Many of the plots looked very useful. In this post, I’ll look at creating the first of the plot in Python (with the help of Stack Overflow).\nHere’s how the end result should look like.\n\nHow the final plot should look like\n\n\n\nAttributes of above plot\n\nX-Y scatter for area vs population\nColor by state\nMarker-size by population\n\nI’ll first use Pandas to create the plot. Pandas plotting capabilites are almost the first thing I use to create plots. Next, I’ll show how to use Seaborn to reduce some complexity. Lastly, I’ll use Altair, ggplot and Plotnine to show how it focuses on getting directly to the point, i.e. expressing the 3 required attributes!\n\n\nTLDR: Declarative visualisatio) is super useful!\n\n\nOriginal R code\n# install.packages(\"ggplot2\")\n# load package and data\noptions(scipen=999)  # turn-off scientific notation like 1e+48\nlibrary(ggplot2)\ntheme_set(theme_bw())  # pre-set the bw theme.\ndata(\"midwest\", package = \"ggplot2\")\n# midwest &lt;- read.csv(\"http://goo.gl/G1K41K\")  # bkup data source\n\n# Scatterplot\ngg &lt;- ggplot(midwest, aes(x=area, y=poptotal)) + \n  geom_point(aes(col=state, size=popdensity)) + \n  geom_smooth(method=\"loess\", se=F) + \n  xlim(c(0, 0.1)) + \n  ylim(c(0, 500000)) + \n  labs(subtitle=\"Area Vs Population\", \n       y=\"Population\", \n       x=\"Area\", \n       title=\"Scatterplot\", \n       caption = \"Source: midwest\")\n\nplot(gg)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n\n\nColor scheme (borrowed from Randy Olson’s website)\n\n# Tableau 20 Colors\ntableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]\n             \n\n# Rescale to values between 0 and 1 \nfor i in range(len(tableau20)):  \n    r, g, b = tableau20[i]  \n    tableau20[i] = (r / 255., g / 255., b / 255.)\n\n\n\nGetting the data\n\nmidwest= pd.read_csv(\"http://goo.gl/G1K41K\") \n# Filtering\nmidwest= midwest[midwest.poptotal&lt;50000]\n\n\nmidwest.head().loc[:, ['area'] ]\n\n\n\n\n\n\n\narea\n\n\n\n\n1\n0.014\n\n\n2\n0.022\n\n\n3\n0.017\n\n\n4\n0.018\n\n\n5\n0.050\n\n\n\n\n\n\n\n\n\nDefault Pandas scatter plot with marker size by population density\n\nmidwest.plot(kind='scatter', x='area', y='poptotal', ylim=((0, 50000)), xlim=((0., 0.1)), s=midwest['popdensity']*0.1)\n\n\n\n\n\n\n\n\nIf we just use the default Pandas scatter, we won’t get the colour by state. For that we wil group the dataframe by states and then scatter plot each group individually.\n\n\nComplete Pandas’ solution (hand-wavy at times!)\n\nfig, ax = plt.subplots()\ngroups = midwest.groupby('state')\ncolors = tableau20[::2]\n\n# Plotting each group \nfor i, (name, group) in enumerate(groups):\n    group.plot(kind='scatter', x='area', y='poptotal', ylim=((0, 50000)), xlim=((0., 0.1)),\n               s=10+group['popdensity']*0.1, # hand-wavy :(\n               label=name, ax=ax, color=colors[i])\n\n# Legend for State colours\nlgd = ax.legend(numpoints=1, loc=1, borderpad=1, \n            frameon=True, framealpha=0.9, title=\"state\")\nfor handle in lgd.legendHandles:\n    handle.set_sizes([100.0])\n\n# Make a legend for popdensity. Hand-wavy. Error prone!\npws = (pd.cut(midwest['popdensity'], bins=4, retbins=True)[1]).round(0)\nfor pw in pws:\n    plt.scatter([], [], s=(pw**2)/2e4, c=\"k\",label=str(pw))\n\nh, l = plt.gca().get_legend_handles_labels()\nplt.legend(h[5:], l[5:], labelspacing=1.2, title=\"popdensity\", borderpad=1, \n            frameon=True, framealpha=0.9, loc=4, numpoints=1)\n\nplt.gca().add_artist(lgd)\n\n\n\n\n\n\n\n\n\n\nUsing Seaborn\nThe solution using Seaborn is slightly less complicated as we won’t need to write the code for plotting different states on different colours. However, the legend jugglery for markersize would still be required!\n\nsizes = [10, 40, 70, 100] \nmarker_size = pd.cut(midwest['popdensity'], range(0, 2500, 500), labels=sizes) \nsns.lmplot('area', 'poptotal', data=midwest, hue='state', fit_reg=False, scatter_kws={'s':marker_size})\nplt.ylim((0, 50000))\n\n\n\n\n\n\n\n\n\n\nAltair (could not get simpler!)\n\nfrom altair import Chart\n\nchart = Chart(midwest)\nchart.mark_circle().encode(\n    x='area',\n    y='poptotal',\n    color='state',\n    size='popdensity',\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot\n\nfrom ggplot import *\n\nggplot(aes(x='area', y='poptotal', color='state', size='popdensity'), data=midwest) +\\\n    geom_point() +\\\n    theme_bw() +\\\n    xlab(\"Area\") +\\\n    ylab(\"Population\") +\\\n    ggtitle(\"Area vs Population\")\n\n\n\n\n\n\n\n\nIt was great fun (and frustration) trying to make this plot. Still some bits like LOESS are not included in the visualisation I made. The best thing about this exercise was discovering Altair! Declarative visualisation looks so natural. Way to go declarative visualisation!"
  },
  {
    "objectID": "posts/2020-03-02-linear-scratch.html",
    "href": "posts/2020-03-02-linear-scratch.html",
    "title": "Neural Networks from scratch",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef relu(x):\n    return np.max(0, x)\n\n\nX = np.array([[0, 0],\n             [0, 1],\n             [1, 0],\n             [1, 1]])\ny = np.array([0, 1, 1, 0])\n\n\nplt.scatter(X[:, 0], X[:, 1],c=y)\n\n\n\n\n\n\n\n\n\nX.shape\n\n(4, 2)\n\n\n\nX\n\narray([[0, 0],\n       [0, 1],\n       [1, 0],\n       [1, 1]])\n\n\n\nlayers = [2, 1]\n\n\nB = [np.zeros(n) for n in layers]\n\n\nW = [None]*len(layers)\n\n\nW[0] = np.zeros((X.shape[1], layers[0]))\n\n\nW\n\n[array([[0., 0.],\n        [0., 0.]]), None]\n\n\n\nfor i in range(1, len(layers)):\n    W[i] = np.zeros((layers[i-1], layers[i]))\n\n\nW[1]\n\narray([[0.],\n       [0.]])\n\n\n\nX.shape, W[0].shape\n\n((4, 2), (2, 2))\n\n\n\nX.shape\n\n(4, 2)"
  },
  {
    "objectID": "posts/2017-06-15-linear-regression-prior.html",
    "href": "posts/2017-06-15-linear-regression-prior.html",
    "title": "Linear regression with prior (using gradient descent)",
    "section": "",
    "text": "Let’s say we have a prior on the linear model, i.e. we start with a known W (W_prior) and b (b_prior). Further, we say that the learnt function can be such that:\n\\[W = \\alpha \\times W_{prior} + \\delta\\] \\[b = \\beta + b_{prior} + \\eta\\]\nOur task reduces to learn \\(\\alpha\\), \\(\\beta\\), \\(\\delta\\) and \\(\\eta\\). This can be solved as we would usually do using Gradient descent, the only difference being that we will compute the gradient wrt \\(\\alpha\\) , \\(\\beta\\), \\(\\delta\\), \\(\\eta\\). I will use autograd to compute the gradients.\nIn a typical model we might have 2 parameters (w and b). In our refined one, we have four- \\(\\alpha\\) , \\(\\beta\\), \\(\\delta\\), \\(\\eta\\).\n\nCustomary imports\n\nimport autograd.numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n\nTrue model\n\\[Y = 10 X + 6\\]\n\n\nGenerating data\n\nnp.random.seed(0)\nn_samples = 50\nX = np.linspace(1, 50, n_samples)\nY = 10*X + 6 + 3*np.random.randn(n_samples)\n\n\nplt.plot(X, Y, 'k.')\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\");\n\n\n\n\n\n\n\n\n\n\nDefining priors (bad ones!)\n\nw_prior = -2\nb_prior = -2\n\n\n\nDefining the cost function in terms of alpha and beta\n\ndef cost(alpha, beta, delta, eta):\n    pred = np.dot(X, alpha*w_prior+delta) + b_prior + beta + eta\n    return np.sqrt(((pred - Y) ** 2).mean(axis=None))\n\nfrom autograd import grad, multigrad\ngrad_cost= multigrad(cost, argnums=[0, 1, 2, 3])\n\n\n\nGradient descent\n\nalpha = np.random.randn()\nbeta = np.random.randn()\neta = np.random.randn()\ndelta = np.random.randn()\nlr = 0.001\n# We will also save the values for plotting later\nw_s = [alpha*w_prior+delta]\nb_s = [alpha*w_prior+delta]\nfor i in range(10001):\n    \n    del_alpha, del_beta, del_delta, del_eta = grad_cost(alpha, beta, delta, eta)\n    alpha = alpha - del_alpha*lr\n    beta = beta - del_beta*lr\n    delta = delta - del_delta*lr\n    eta = eta - del_eta*lr\n    w_s.append(alpha*w_prior+delta)\n    b_s.append(alpha*w_prior+delta)\n    if i%500==0:\n        print \"*\"*20\n        print i\n        print \"*\"*20\n    \n        print cost(alpha, beta, delta, eta), alpha*w_prior+delta, alpha*w_prior+delta\n\n********************\n0\n********************\n277.717926153 0.756766902473 0.756766902473\n********************\n500\n********************\n5.95005440573 10.218493676 10.218493676\n********************\n1000\n********************\n5.77702829051 10.2061390906 10.2061390906\n********************\n1500\n********************\n5.60823669668 10.1939366275 10.1939366275\n********************\n2000\n********************\n5.44395500928 10.1818982949 10.1818982949\n********************\n2500\n********************\n5.28446602486 10.1700368748 10.1700368748\n********************\n3000\n********************\n5.1300568557 10.158365894 10.158365894\n********************\n3500\n********************\n4.98101499128 10.1468995681 10.1468995681\n********************\n4000\n********************\n4.83762347034 10.1356527141 10.1356527141\n********************\n4500\n********************\n4.70015516667 10.1246406278 10.1246406278\n********************\n5000\n********************\n4.56886626032 10.1138789219 10.1138789219\n********************\n5500\n********************\n4.44398905185 10.1033833225 10.1033833225\n********************\n6000\n********************\n4.32572437603 10.0931694258 10.0931694258\n********************\n6500\n********************\n4.21423397192 10.0832524173 10.0832524173\n********************\n7000\n********************\n4.10963325557 10.0736467626 10.0736467626\n********************\n7500\n********************\n4.01198500112 10.0643658801 10.0643658801\n********************\n8000\n********************\n3.92129444852 10.0554218111 10.0554218111\n********************\n8500\n********************\n3.83750630808 10.046824905 10.046824905\n********************\n9000\n********************\n3.7605040187 10.0385835381 10.0385835381\n********************\n9500\n********************\n3.69011144573 10.0307038843 10.0307038843\n********************\n10000\n********************\n3.6260969956 10.023189752 10.023189752\n\n\nWe are able to learn a reasonably accurate W=10.07 and b=2.7.\n\n\nBonus: Animation\nMaking the plots look nicer.\n\ndef format_axes(ax):\n    for spine in ['top', 'right']:\n        ax.spines[spine].set_visible(False)\n\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_color('grey')\n        ax.spines[spine].set_linewidth(0.5)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    for axis in [ax.xaxis, ax.yaxis]:\n        axis.set_tick_params(direction='out', color='grey')\n    return ax\n\n\n# Code courtesy: http://eli.thegreenplace.net/2016/drawing-animated-gifs-with-matplotlib/\nfrom matplotlib.animation import FuncAnimation\n\nfig, ax = plt.subplots(figsize=(4, 3))\nfig.set_tight_layout(True)\n\n# Query the figure's on-screen size and DPI. Note that when saving the figure to\n# a file, we need to provide a DPI for that separately.\nprint('fig size: {0} DPI, size in inches {1}'.format(\n    fig.get_dpi(), fig.get_size_inches()))\n\n# Plot a scatter that persists (isn't redrawn) and the initial line.\n\nax.scatter(X, Y, color='grey', alpha=0.8, s=1)\n# Initial line\n\nline, = ax.plot(X, X*w_prior+b_prior, 'r-', linewidth=1)\n\ndef update(i):\n    label = 'Iteration {0}'.format(i)\n    line.set_ydata(X*w_s[i]+b_s[i])\n    ax.set_xlabel(label)\n    format_axes(ax)\n    return line, ax\n\nanim = FuncAnimation(fig, update, frames=np.arange(0, 100), interval=1)\nanim.save('line_prior.gif', dpi=80, writer='imagemagick')\nplt.close()\n\nfig size: 72.0 DPI, size in inches [ 4.  3.]"
  },
  {
    "objectID": "posts/2022-02-05-lr.html",
    "href": "posts/2022-02-05-lr.html",
    "title": "Linear Regression in TF Probability using JointDistributionCoroutineAutoBatched",
    "section": "",
    "text": "Basic Imports\n\nfrom silence_tensorflow import silence_tensorflow\nsilence_tensorflow()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport functools\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\n\ntfd = tfp.distributions\ntfl = tfp.layers\ntfb = tfp.bijectors\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nnp.random.seed(0)\ntf.random.set_seed(0)\n\n\ndef lr(x, stddv_datapoints):\n    num_datapoints, data_dim = x.shape\n    b = yield tfd.Normal(\n        loc=0.0,\n        scale=2.0,\n        name=\"b\",\n    )\n    w = yield tfd.Normal(\n        loc=tf.zeros([data_dim]), scale=2.0 * tf.ones([data_dim]), name=\"w\"\n    )\n\n    y = yield tfd.Normal(\n        loc=tf.linalg.matvec(x, w) + b, scale=stddv_datapoints, name=\"y\"\n    )\n\n\nx = tf.linspace(-5.0, 5.0, 100)\nx = tf.expand_dims(x, 1)\n\n\nstddv_datapoints = 1\n\nconcrete_lr_model = functools.partial(lr, x=x, stddv_datapoints=stddv_datapoints)\n\nmodel = tfd.JointDistributionCoroutineAutoBatched(concrete_lr_model)\n\n\nmodel\n\n&lt;tfp.distributions.JointDistributionCoroutineAutoBatched 'JointDistributionCoroutineAutoBatched' batch_shape=[] event_shape=StructTuple(\n  b=[],\n  w=[1],\n  y=[100]\n) dtype=StructTuple(\n  b=float32,\n  w=float32,\n  y=float32\n)&gt;\n\n\n\nactual_b, actual_w, y_train = model.sample()\n\n\nplt.scatter(x, y_train, s=30, alpha=0.6)\nplt.plot(x, tf.linalg.matvec(x, actual_w) + actual_b, color=\"k\")\nsns.despine()\n\n\n\n\n\n\n\n\n\ntrace_fn = lambda traceable_quantities: {\n    \"loss\": traceable_quantities.loss,\n    \"w\": w,\n    \"b\": b,\n}\n\n\ndata_dim = 1\nw = tf.Variable(tf.zeros_like(actual_w))\n\nb = tf.Variable(tf.zeros_like(actual_b))\n\ntarget_log_prob_fn = lambda w, b: model.log_prob((b, w, y_train))\ntarget_log_prob_fn\n\n&lt;function __main__.&lt;lambda&gt;(w, b)&gt;\n\n\n\ntrace = tfp.math.minimize(\n    lambda: -target_log_prob_fn(w, b),\n    optimizer=tf.optimizers.Adam(learning_rate=0.05),\n    trace_fn=trace_fn,\n    num_steps=200,\n)\n\n\nw, b, actual_w, actual_b\n\n(&lt;tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([2.1811483], dtype=float32)&gt;,\n &lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0149531&gt;,\n &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.1337605], dtype=float32)&gt;,\n &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.0221252&gt;)\n\n\n\nplt.plot(trace[\"w\"], label=\"w\")\nplt.plot(trace[\"b\"], label=\"b\")\nplt.legend()\nsns.despine()\n\n\n\n\n\n\n\n\n\nqw_mean = tf.Variable(tf.random.normal([data_dim]))\nqb_mean = tf.Variable(tf.random.normal([1]))\nqw_stddv = tfp.util.TransformedVariable(\n    1e-4 * tf.ones([data_dim]), bijector=tfb.Softplus()\n)\nqb_stddv = tfp.util.TransformedVariable(1e-4 * tf.ones([1]), bijector=tfb.Softplus())\n\n\ndef factored_normal_variational_model():\n    qw = yield tfd.Normal(loc=qw_mean, scale=qw_stddv, name=\"qw\")\n    qb = yield tfd.Normal(loc=qb_mean, scale=qb_stddv, name=\"qb\")\n\n\nsurrogate_posterior = tfd.JointDistributionCoroutineAutoBatched(\n    factored_normal_variational_model\n)\n\nlosses = tfp.vi.fit_surrogate_posterior(\n    target_log_prob_fn,\n    surrogate_posterior=surrogate_posterior,\n    optimizer=tf.optimizers.Adam(learning_rate=0.05),\n    num_steps=200,\n)\n\n/Users/nipun/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/vectorization_util.py:87: UserWarning: Saw Tensor seed Tensor(\"seed:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n  warnings.warn(\n/Users/nipun/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/vectorization_util.py:87: UserWarning: Saw Tensor seed Tensor(\"seed:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n  warnings.warn(\n\n\n\nqw_mean, qw_stddv, qb_mean, qb_stddv\n\n(&lt;tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([2.1905935], dtype=float32)&gt;,\n &lt;TransformedVariable: name=softplus, dtype=float32, shape=[1], fn=\"softplus\", numpy=array([0.04352505], dtype=float32)&gt;,\n &lt;tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([3.0260112], dtype=float32)&gt;,\n &lt;TransformedVariable: name=softplus, dtype=float32, shape=[1], fn=\"softplus\", numpy=array([0.09258726], dtype=float32)&gt;)\n\n\n\ns_qw, s_qb = surrogate_posterior.sample(500)\n\n\nys = tf.linalg.matvec(x, s_qw) + s_qb\n\n\nx.shape, ys.shape\n\n(TensorShape([100, 1]), TensorShape([500, 100]))\n\n\n\nplt.plot(x, ys.numpy().T, color='k', alpha=0.05);\nplt.scatter(x, y_train, s=30, alpha=0.6)\nsns.despine()\n\n\n\n\n\n\n\n\nTODO\n\nHow to replace x in lr function from x_train to x_test?\n\nReferences\n\nhttps://www.tensorflow.org/probability/examples/Probabilistic_PCA\nhttps://www.youtube.com/watch?v=l2f6Ic6SeqE&list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ&index=4\nhttps://jeffpollock9.github.io/almost-always-auto-batched/\nhttps://jeffpollock9.github.io/bayesian-workflow-with-tfp-and-arviz/"
  },
  {
    "objectID": "posts/2018-06-21-aq-india-map.html",
    "href": "posts/2018-06-21-aq-india-map.html",
    "title": "Mapping location of air quality sensing in India",
    "section": "",
    "text": "In this notebook, I’ll show a quick example of how to use Folium (which internally uses LeafletJS) for visualising the location of air quality monitors in India. The purpose of this notebook is eductional in nature.\n\nStandard Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\n\n\nDownloading data from OpenAQ for 2018-04-06\n\n!wget --no-check-certificate https://openaq-data.s3.amazonaws.com/2018-04-06.csv -P /Users/nipun/Downloads/\n\n--2020-02-29 17:52:50--  https://openaq-data.s3.amazonaws.com/2018-04-06.csv\nResolving openaq-data.s3.amazonaws.com (openaq-data.s3.amazonaws.com)... 52.216.99.123\nConnecting to openaq-data.s3.amazonaws.com (openaq-data.s3.amazonaws.com)|52.216.99.123|:443... connected.\nWARNING: cannot verify openaq-data.s3.amazonaws.com's certificate, issued by ‘CN=DigiCert Baltimore CA-2 G2,OU=www.digicert.com,O=DigiCert Inc,C=US’:\n  Unable to locally verify the issuer's authority.\nHTTP request sent, awaiting response... 200 OK\nLength: 133839107 (128M) [text/csv]\nSaving to: ‘/Users/nipun/Downloads/2018-04-06.csv.1’\n\n2018-04-06.csv.1     37%[======&gt;             ]  47.37M  3.79MB/s    eta 40s    ^C\n\n\n\nimport pandas as pd\ndf = pd.read_csv(\"/Users/nipun/Downloads/2018-04-06.csv\")\ndf = df[(df.country=='IN')&(df.parameter=='pm25')].dropna().groupby(\"location\").mean()\n\n\ndf\n\n\n\n\n\n\n\n\nvalue\nlatitude\nlongitude\n\n\nlocation\n\n\n\n\n\n\n\nAdarsh Nagar, Jaipur - RSPCB\n79.916667\n26.902909\n75.836853\n\n\nAnand Kala Kshetram, Rajamahendravaram - APPCB\n42.750000\n16.987287\n81.736318\n\n\nArdhali Bazar, Varanasi - UPPCB\n103.666667\n25.350599\n82.908307\n\n\nAsanol Court Area, Asanol - WBPCB\n56.833333\n23.685297\n86.945968\n\n\nAshok Nagar, Udaipur - RSPCB\n114.750000\n24.588617\n73.632140\n\n\n...\n...\n...\n...\n\n\nVasundhara, Ghaziabad, UP - UPPCB\n223.333333\n28.660335\n77.357256\n\n\nVikas Sadan, Gurgaon, Haryana - HSPCB\n280.250000\n28.450124\n77.026305\n\n\nVindhyachal STPS, Singrauli - MPPCB\n144.000000\n24.108970\n82.645580\n\n\nWard-32 Bapupara, Siliguri - WBPCB\n195.000000\n26.688305\n88.412668\n\n\nZoo Park, Hyderabad - TSPCB\n82.500000\n17.349694\n78.451437\n\n\n\n\n79 rows × 3 columns\n\n\n\n\n\nDownloading World GeoJson file\n\n!wget --no-check-certificate https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/world-countries.json\n\n--2020-02-29 17:53:17--  https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/world-countries.json\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.8.133|:443... connected.\nWARNING: cannot verify raw.githubusercontent.com's certificate, issued by ‘CN=DigiCert SHA2 High Assurance Server CA,OU=www.digicert.com,O=DigiCert Inc,C=US’:\n  Unable to locally verify the issuer's authority.\nHTTP request sent, awaiting response... 200 OK\nLength: 252515 (247K) [text/plain]\nSaving to: ‘world-countries.json’\n\nworld-countries.jso 100%[===================&gt;] 246.60K   376KB/s    in 0.7s    \n\n2020-02-29 17:53:19 (376 KB/s) - ‘world-countries.json’ saved [252515/252515]\n\n\n\n\n\nCreating india.json correspdonding to Indian data\n\nimport json\ne = json.load(open('world-countries.json','r'))\njson.dump(e['features'][73], open('india.json','w'))\n\n\nimport folium\n\nfolium_map = folium.Map(width = '60%',height=800,location=[20, 77],\n                        zoom_start=5,\n                        tiles=\"Stamen Terrain\",min_lat=7, max_lat=35, min_lon=73, max_lon=90)\nfor x in df.iterrows():\n    name = x[0]\n    lat, lon = x[1]['latitude'], x[1]['longitude']\n    folium.CircleMarker([lat, lon], radius=5, color='#000000',fill_color='#D3D3D3' , fill_opacity=1).add_to(folium_map)\n\nfolium.GeoJson('india.json').add_to(folium_map)\n\n&lt;folium.features.GeoJson at 0x11e497bd0&gt;\n\n\n\nfolium_map.save(\"map.html\")\n\n\nThere you go!Till next time."
  },
  {
    "objectID": "posts/comparing-gp.html",
    "href": "posts/comparing-gp.html",
    "title": "Comparing GP libraries",
    "section": "",
    "text": "In this notebook, we will show how to compare different GP libraries to give the same loss for a simple GP regression problem.\n\nimport numpy as np\nimport GPy\nimport gpytorch\nimport torch\n\n\nfrom jax.config import config\nimport jax.numpy as jnp\nimport optax as ox\nimport jax.random as jr\n\nfrom jaxutils import Dataset\nimport jaxkern as jk\n\nimport gpjax as gpx\n\n# Enable Float64 for more stable matrix inversions.\nconfig.update(\"jax_enable_x64\", True)\nkey = jr.PRNGKey(123)\n\nfrom pprint import PrettyPrinter\npp = PrettyPrinter(indent=4)\n\n\n\n# Generate the 1D regression dataset\nnp.random.seed(0)\nN = 100\nX = np.linspace(0, 1, N).reshape(-1, 1)\ny = np.sin(2 * np.pi * X).ravel() + 0.05 * np.random.randn(N)\n\n# Create the GPy model\nkernel = GPy.kern.RBF(input_dim=1, lengthscale=1)\ngpy_model = GPy.models.GPRegression(X, y.reshape(-1, 1), kernel)\n\n# Evaluate the GPy loss\ngpy_loss = -gpy_model.log_likelihood()\n\n# Create the gpytorch model\nclass GPRegressionModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ConstantMean()\n        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n\n# Initialize the likelihood and model\nlikelihood_gpytorch = gpytorch.likelihoods.GaussianLikelihood()\n\n# Set likelihood noise to the GPy value\nlikelihood_gpytorch.noise = gpy_model.likelihood.variance[0]\n\ngpytorch_model = GPRegressionModel(torch.from_numpy(X).float(), torch.from_numpy(y).float(), likelihood_gpytorch)\n\n# Set the kernel parameters to the GPy values\ngpytorch_model.covar_module.base_kernel.lengthscale = gpy_model.kern.lengthscale[0]\ngpytorch_model.covar_module.outputscale = gpy_model.kern.variance[0]\n\n# Confirm that the GPy and gpytorch models have the same parameters\nassert gpy_model.kern.lengthscale[0] == gpytorch_model.covar_module.base_kernel.lengthscale.item()\nassert gpy_model.kern.variance[0] == gpytorch_model.covar_module.outputscale.item()\nassert gpy_model.likelihood.variance[0] == gpytorch_model.likelihood.noise.item()\n\n# Find the gpytorch loss\noutput = gpytorch_model(torch.from_numpy(X).float())\n# MLL\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_gpytorch, gpytorch_model)\n\n# Find the gpytorch loss\ngpytorch_loss = -mll(output, torch.from_numpy(y).float())\n\n# Print the losses\nprint('GPy loss: {}'.format(gpy_loss))\n# We multiply by N because the gpytorch loss is the average loss per data point\nprint('gpytorch loss: {}'.format(gpytorch_loss.item()*N))\n\nGPy loss: 106.72974515800342\ngpytorch loss: 106.72974586486816\n\n\n\n# Set the GPy model parameters to the GPJax model\nkernel = jk.RBF()\nprior = gpx.Prior(kernel=kernel)\n\nlikelihood = gpx.Gaussian(num_datapoints=N)\n\n# Set the likelihood variance to the GPy model\nlikelihood.variance = gpy_model.likelihood.variance[0]\n\n\nparameter_state = gpx.initialise(prior, key)\nposterior = prior * likelihood\n\n# Set the kernel parameters to the GPy values\nparameter_state = gpx.initialise(\n    posterior, key, kernel={\"lengthscale\": jnp.array([gpy_model.kern.lengthscale[0]]), \"variance\": jnp.array([gpy_model.kern.variance[0]])}\n)\n\n\nparams, trainable, bijectors = parameter_state.unpack()\n\n\nparams\n\n{'kernel': {'lengthscale': Array([1.], dtype=float64),\n  'variance': Array([1.], dtype=float64)},\n 'mean_function': {},\n 'likelihood': {'obs_noise': Array([1.], dtype=float64)}}\n\n\n\nX.shape, y.shape\n\n((100, 1), (100,))\n\n\n\n# Create GPJax dataset object\nds = Dataset(X=X, y=y.reshape(-1, 1))\nnegative_mll = posterior.marginal_log_likelihood(ds, negative=True)\nnegative_mll(params)\n\nArray(106.72978404, dtype=float64)\n\n\n\n# Now train both the GPy, gpytorch and GPJax models and compare the losses and parameters\n# Use multiple restarts to find the best GPy model\n# Initialize the GPy model and then use the same hyperparameters in the gpytorch model\n# Use same optimizer and training iterations for both models\n\n# Train the GPy model with multiple restarts and 100 iterations\ngpy_model.optimize(max_iters=100)\n\n# Train the gpytorch model\ngpytorch_model.train()\nlikelihood_gpytorch.train()\n\n# Train using Adam\noptimizer = torch.optim.Adam(gpytorch_model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n\n# \"Loss\" for GPs - the marginal log likelihood\nmll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_gpytorch, gpytorch_model)\n\ntraining_iter = 100\n\n# Training loop\n\nfor i in range(training_iter):\n    # Zero backprop gradients\n    optimizer.zero_grad()\n    # Get output from model\n    output = gpytorch_model(torch.from_numpy(X).float())\n    # Calc loss and backprop gradients\n    loss = -mll(output, torch.from_numpy(y).float())\n    loss.backward()\n    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))\n    optimizer.step()\n\n    \n\n# Print the GPy and gpytorch losses\n\nprint('GPy loss: {}'.format(gpy_model.log_likelihood()))\nprint('gpytorch loss: {}'.format(-mll(output, torch.from_numpy(y).float()).item()))\n\n\n\nIter 1/100 - Loss: 1.067\nIter 2/100 - Loss: 1.040\nIter 3/100 - Loss: 1.012\nIter 4/100 - Loss: 0.983\nIter 5/100 - Loss: 0.954\nIter 6/100 - Loss: 0.923\nIter 7/100 - Loss: 0.889\nIter 8/100 - Loss: 0.853\nIter 9/100 - Loss: 0.811\nIter 10/100 - Loss: 0.765\nIter 11/100 - Loss: 0.713\nIter 12/100 - Loss: 0.659\nIter 13/100 - Loss: 0.605\nIter 14/100 - Loss: 0.553\nIter 15/100 - Loss: 0.505\nIter 16/100 - Loss: 0.460\nIter 17/100 - Loss: 0.417\nIter 18/100 - Loss: 0.375\nIter 19/100 - Loss: 0.334\nIter 20/100 - Loss: 0.291\nIter 21/100 - Loss: 0.248\nIter 22/100 - Loss: 0.204\nIter 23/100 - Loss: 0.158\nIter 24/100 - Loss: 0.112\nIter 25/100 - Loss: 0.064\nIter 26/100 - Loss: 0.016\nIter 27/100 - Loss: -0.033\nIter 28/100 - Loss: -0.083\nIter 29/100 - Loss: -0.134\nIter 30/100 - Loss: -0.185\nIter 31/100 - Loss: -0.236\nIter 32/100 - Loss: -0.287\nIter 33/100 - Loss: -0.338\nIter 34/100 - Loss: -0.388\nIter 35/100 - Loss: -0.437\nIter 36/100 - Loss: -0.486\nIter 37/100 - Loss: -0.533\nIter 38/100 - Loss: -0.579\nIter 39/100 - Loss: -0.625\nIter 40/100 - Loss: -0.671\nIter 41/100 - Loss: -0.717\nIter 42/100 - Loss: -0.763\nIter 43/100 - Loss: -0.809\nIter 44/100 - Loss: -0.854\nIter 45/100 - Loss: -0.897\nIter 46/100 - Loss: -0.940\nIter 47/100 - Loss: -0.980\nIter 48/100 - Loss: -1.019\nIter 49/100 - Loss: -1.057\nIter 50/100 - Loss: -1.093\nIter 51/100 - Loss: -1.128\nIter 52/100 - Loss: -1.162\nIter 53/100 - Loss: -1.193\nIter 54/100 - Loss: -1.223\nIter 55/100 - Loss: -1.251\nIter 56/100 - Loss: -1.277\nIter 57/100 - Loss: -1.300\nIter 58/100 - Loss: -1.321\nIter 59/100 - Loss: -1.339\nIter 60/100 - Loss: -1.355\nIter 61/100 - Loss: -1.368\nIter 62/100 - Loss: -1.379\nIter 63/100 - Loss: -1.388\nIter 64/100 - Loss: -1.395\nIter 65/100 - Loss: -1.399\nIter 66/100 - Loss: -1.402\nIter 67/100 - Loss: -1.404\nIter 68/100 - Loss: -1.404\nIter 69/100 - Loss: -1.403\nIter 70/100 - Loss: -1.401\nIter 71/100 - Loss: -1.399\nIter 72/100 - Loss: -1.397\nIter 73/100 - Loss: -1.395\nIter 74/100 - Loss: -1.393\nIter 75/100 - Loss: -1.391\nIter 76/100 - Loss: -1.390\nIter 77/100 - Loss: -1.390\nIter 78/100 - Loss: -1.389\nIter 79/100 - Loss: -1.390\nIter 80/100 - Loss: -1.390\nIter 81/100 - Loss: -1.391\nIter 82/100 - Loss: -1.393\nIter 83/100 - Loss: -1.394\nIter 84/100 - Loss: -1.396\nIter 85/100 - Loss: -1.397\nIter 86/100 - Loss: -1.399\nIter 87/100 - Loss: -1.400\nIter 88/100 - Loss: -1.401\nIter 89/100 - Loss: -1.402\nIter 90/100 - Loss: -1.403\nIter 91/100 - Loss: -1.403\nIter 92/100 - Loss: -1.404\nIter 93/100 - Loss: -1.404\nIter 94/100 - Loss: -1.404\nIter 95/100 - Loss: -1.405\nIter 96/100 - Loss: -1.405\nIter 97/100 - Loss: -1.405\nIter 98/100 - Loss: -1.404\nIter 99/100 - Loss: -1.404\nIter 100/100 - Loss: -1.404\nGPy loss: 140.45346660653308\ngpytorch loss: -1.4040359258651733\n\n\n\n\n# Train the GPJax model\n# Use the same optimizer and training iterations as GPy and gpytorch\n\n# Create the GPJax model\noptimiser = ox.adam(learning_rate=0.01)\n\ninference_state = gpx.fit(\n    objective=negative_mll,\n    parameter_state=parameter_state,\n    optax_optim=optimiser,\n    num_iters=500,\n)\n\n\n\n\n\nlearned_params, training_history = inference_state.unpack()\n\npp.pprint(learned_params)\n\n{   'kernel': {   'lengthscale': Array([0.3214367], dtype=float64),\n                  'variance': Array([1.2552691], dtype=float64)},\n    'likelihood': {'obs_noise': Array([0.0072137], dtype=float64)},\n    'mean_function': {}}\n\n\n\n# Print the learnt GPy parameters\nprint('GPy lengthscale: {}'.format(gpy_model.kern.lengthscale[0]))\nprint('GPy variance: {}'.format(gpy_model.kern.variance[0]))\nprint('GPy noise: {}'.format(gpy_model.likelihood.variance[0]))\n\nGPy lengthscale: 0.3498749924084259\nGPy variance: 1.736410964793945\nGPy noise: 0.002260382918441148\n\n\n\n# Print GPytorch parameters\nprint('gpytorch lengthscale: {}'.format(gpytorch_model.covar_module.base_kernel.lengthscale.item()))\nprint('gpytorch variance: {}'.format(gpytorch_model.covar_module.outputscale.item()))\nprint('gpytorch noise: {}'.format(gpytorch_model.likelihood.noise.item()))\n\ngpytorch lengthscale: 0.3494666516780853\ngpytorch variance: 1.6869200468063354\ngpytorch noise: 0.0023756392765790224\n\n\n\n# plot the GPy, gpytorch and gpjax model predictions in 3 subplots sharing the x axis and having same ylim\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Retina display\n%config InlineBackend.figure_format = 'retina'\n\nfig, axs = plt.subplots(3, 1, sharex=True, figsize=(8, 6))\n\n# Get the GPy predictions\ngpy_mean, gpy_var = gpy_model.predict(X)\n\n# Get the gpytorch predictions\ngpytorch_model.eval()\nlikelihood_gpytorch.eval()\nwith torch.no_grad(), gpytorch.settings.fast_pred_var():\n    observed_pred = likelihood_gpytorch(gpytorch_model(torch.from_numpy(X).float()))\n\n# Get the GPJax predictions\nlatent_dist = posterior(learned_params, ds)(X)\npredictive_dist = likelihood(learned_params, latent_dist)\n\npredictive_mean = predictive_dist.mean()\npredictive_std = predictive_dist.stddev()\n\naxs[0].plot(X, y, 'kx', mew=2)\naxs[0].plot(X, gpy_mean, 'b', lw=2, label='GPy mean')\n\naxs[1].plot(X, y, 'kx', mew=2)\n\naxs[1].plot(X, observed_pred.mean.numpy(), 'r', lw=2, label='gpytorch mean')\naxs[2].plot(X, y, 'kx', mew=2)\n\naxs[2].plot(X, predictive_mean, 'g', lw=2, label='GPJax mean')\n\n\n\n\naxs[0].fill_between(X.flatten(), gpy_mean.flatten() - 2 * np.sqrt(gpy_var.flatten()), gpy_mean.flatten() + 2 * np.sqrt(gpy_var.flatten()), alpha=0.5, color='blue', label='GPy uncertainty')\n\n# Get the lower and upper confidence bounds for the gpytorch model\nlower, upper = observed_pred.confidence_region()\naxs[1].fill_between(X.flatten(), lower.numpy().flatten(), upper.numpy().flatten(), alpha=0.5, color='red', label='gpytorch uncertainty')\n\naxs[2].fill_between(X.flatten(), predictive_mean.flatten() - 2 * predictive_std.flatten(), predictive_mean.flatten() + 2 * predictive_std.flatten(), alpha=0.5, color='green', label='GPJax uncertainty')\nfig.legend(loc='upper left')\n\n /Users/nipun/miniconda3/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:274: GPInputWarning:The input matches the stored training data. Did you forget to call model.train()?"
  },
  {
    "objectID": "posts/stacking.html",
    "href": "posts/stacking.html",
    "title": "Stacking (Ensemble Learning)",
    "section": "",
    "text": "In this post, we study a simple meta learning technique called Stacking\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\n\n%config InlineBackend.figure_format = 'retina'\n\n\nCreate a noisy dataset using a 3rd degree polynomial\n\nnp.random.seed(42)\nx = np.linspace(-5, 5, 500)\nf = lambda x: 0.1*x**3 + 0.2**x**2 + x + 4\ny = f(x) + 0.05*np.random.normal(0, 100, 500)\n\nplt.plot(x, y, 'o', label = 'data')\nplt.plot(x, f(x), 'r', label = 'true')\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nCreate a train, validation and test set and plot them\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n\nplt.plot(x_train, y_train, 'o', label = 'train', alpha = 0.5)\nplt.plot(x_val, y_val, 'o', label = 'validation', alpha = 0.5)\nplt.plot(x_test, y_test, 'o', label = 'test', alpha = 0.5)\nplt.plot(x, f(x), 'r', label = 'true', lw=3)\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nFirst layer of models\n\n\n# Create a pipeline for linear regression using a polynomial feature transformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\nlr = Pipeline([('poly', PolynomialFeatures(degree=4)),\n                ('linear', LinearRegression(fit_intercept=True))])\n\n# Fit the model\nlr.fit(x_train.reshape(-1, 1), y_train)\n\n\ndt = DecisionTreeRegressor(max_depth=3)\n_ = dt.fit(x_train.reshape(-1, 1), y_train)\n\n\n\nPlot fits on 1d grid\n\nx_grid = np.linspace(-5, 5, 1000)\nplt.plot(x_grid, lr.predict(x_grid.reshape(-1, 1)), label='linear', lw=3)\nplt.plot(x_grid, dt.predict(x_grid.reshape(-1, 1)), label='tree', lw=3)\nplt.plot(x, y, 'o', label='data', alpha=0.2)\nplt.plot(x, f(x), 'r', label='true', lw=3)\nplt.legend()\n\n\n\n\n\n\n\n\n\n# Train and test errors using sklearn.metrics.mean_squared_error\nfrom sklearn.metrics import mean_squared_error\n\nprint('Train error linear: ', mean_squared_error(y_train, lr.predict(x_train.reshape(-1, 1))))\nprint('Test error linear: ', mean_squared_error(y_test, lr.predict(x_test.reshape(-1, 1))))\nprint('Train error tree: ', mean_squared_error(y_train, dt.predict(x_train.reshape(-1, 1))))\nprint('Test error tree: ', mean_squared_error(y_test, dt.predict(x_test.reshape(-1, 1))))\n\nTrain error linear:  23.00595790199621\nTest error linear:  29.527934658588585\nTrain error tree:  21.577144246319136\nTest error tree:  35.03378245179331\n\n\n\n\nSecond layer of models trained on the predictions of the first layer on the validation set\n\n\n# Create a new dataset with the predictions of the first layer\nx_val_lr = lr.predict(x_val.reshape(-1, 1))\nx_val_dt = dt.predict(x_val.reshape(-1, 1))\nx_val_2d = np.column_stack((x_val_lr, x_val_dt))\n\n# Fit a linear regression model on the new dataset\nlr2 = LinearRegression()\nlr2.fit(x_val_2d, y_val)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n# Errors on the test set\n\n# Feature set for the test set\nx_test_lr = lr.predict(x_test.reshape(-1, 1))\nx_test_dt = dt.predict(x_test.reshape(-1, 1))\nx_test_2d = np.column_stack((x_test_lr, x_test_dt))\n\n# Test error\nprint('Test error META: ', mean_squared_error(y_test, lr2.predict(x_test_2d)))\nprint('Test error linear: ', mean_squared_error(y_test, lr.predict(x_test.reshape(-1, 1))))\nprint('Test error tree: ', mean_squared_error(y_test, dt.predict(x_test.reshape(-1, 1))))\n\nTest error META:  29.023123374054247\nTest error linear:  29.527934658588585\nTest error tree:  35.03378245179331\n\n\n\n\nInclude the raw features in the second layer\n\n\n# Feature set for the test set\nx_test_3d = np.column_stack((x_test_lr, x_test_dt, x_test))\n\n# Fit a linear regression model on the new dataset\nlr3 = LinearRegression()\nlr3.fit(x_test_3d, y_test)\n\n\n# Test error\nprint('Test error Meta (with original features): ', mean_squared_error(y_test, lr3.predict(x_test_3d)))\nprint('Test error linear: ', mean_squared_error(y_test, lr.predict(x_test.reshape(-1, 1))))\nprint('Test error tree: ', mean_squared_error(y_test, dt.predict(x_test.reshape(-1, 1))))\n\nTest error Meta (with original features):  27.931843644775036\nTest error linear:  29.527934658588585\nTest error tree:  35.03378245179331\n\n\n\n# Plot the fits on the 1d grid\nx_grid_lr = lr.predict(x_grid.reshape(-1, 1))\nx_grid_dt = dt.predict(x_grid.reshape(-1, 1))\nx_grid_2d = np.column_stack((x_grid_lr, x_grid_dt))\nx_grid_3d = np.column_stack((x_grid_lr, x_grid_dt, x_grid))\n\nplt.plot(x_grid, lr2.predict(x_grid_2d), label='meta', lw=3, linestyle='--')\nplt.plot(x_grid, lr3.predict(x_grid_3d), label='meta (with original features)', lw=3, linestyle='-.')\nplt.plot(x_grid, lr.predict(x_grid.reshape(-1, 1)), label='linear', lw=3, ls=':')\nplt.plot(x_grid, dt.predict(x_grid.reshape(-1, 1)), label='tree', lw=3, ls='-')\n#plt.plot(x, y, 'o', label='data', alpha=0.2)\n#plt.plot(x, f(x), 'r', label='true', lw=3)\nplt.legend()\n\n\n\n\n\n\n\n\n\n# bar plot for showing the errors for all models\n\n# Create a dataframe with the errors\ndf = pd.DataFrame({'model': ['linear', 'tree', 'meta', 'meta (with original features)'],\n                     'test_error': [mean_squared_error(y_test, lr.predict(x_test.reshape(-1, 1))),\n                                    mean_squared_error(y_test, dt.predict(x_test.reshape(-1, 1))),\n                                    mean_squared_error(y_test, lr2.predict(x_test_2d)),\n                                    mean_squared_error(y_test, lr3.predict(x_test_3d))]})\ndf.plot(x='model', y='test_error', kind='bar', legend=False, rot=45)\n# Put the numbers on the bars\nfor i, v in enumerate(df.test_error):\n    plt.text(i - 0.05, v , str(round(v, 3)))"
  },
  {
    "objectID": "posts/2021-06-14-setup-ipad.html",
    "href": "posts/2021-06-14-setup-ipad.html",
    "title": "My iPad Setup",
    "section": "",
    "text": "My laptop is broken. I am away from office. I have an iPad Pro 2020. I got my office desktop’s magic keyboard and trackpad. In this post I am discussing if iPad can help given that I do not have (physical) access to my main computers. Would I recommend this over a main computer - No! But, can you do some things on the iPad reasonably well enough given keyboard and trackpad - Yes!"
  },
  {
    "objectID": "posts/2021-06-14-setup-ipad.html#setting-up-the-terminal-app-a-shell",
    "href": "posts/2021-06-14-setup-ipad.html#setting-up-the-terminal-app-a-shell",
    "title": "My iPad Setup",
    "section": "Setting up the terminal app (a-Shell)",
    "text": "Setting up the terminal app (a-Shell)\n\nConfiguration\nFirst, after installing a-Shell, I like to set the font size, terminal background and foreground color. Here is how the a-shell app looks like\n\nconfig -b black -f white -s 20\n\n\nText editing and bookmarks\nSometimes I like using vim for editing documents and interfacing with WorkingCopy. a-Shell provides vim!\nI like to setup a bookmark to the WorkingCopy folder so that I can direcly edit files in that location.\nI do so by: writing pickFolder in a-Shell and setting it to WorkingCopy folder. Now I can set a bookmark to this location. I do so by: bookmark git in the current location (set by pickFolder)\n\n\n\nGit\nInterestingly, the latest testflight version of a-shell also provides a “Git-like” interface called libgit2. Configuring it requires specific steps that I’m writing below. Some of these steps are borrowed from this nice tutorial and some are specific to a-shell that I was able to get working courtesy a Twitter discussion with the creator of a-shell.\n\nNow, the steps.\nFirst, we need to create a new ssh key.\nWe do so by\nssh-keygen -t rsa -b 4096 -C \"email@domain.com\"\nWhile configuring I did not setup the passphrase.\nThe private and public keys are stored in .ssh with the name id_rsa\n$ ls -lah .ssh|grep \"id\"\n-rw-------   1 mobile  mobile   3.3K Jun 14 15:43 id_rsa\n-rw-------   1 mobile  mobile   747B Jun 14 15:43 id_rsa.pub\nNext, I copied the public key in a newly generated ssh key in Github and gave it a name.\nNext, I modified .gitconfig as follows\n$ cat .gitconfig \n[user]\n        email = MY EMAIL ID\n        name = MY NAME\n        identityFile =  id_rsa \nNow, I was almost done!\nI was able to push and pull from some old Github repositories but the same did not work with the newer repositories. Again, after a discussion with the creator of a-shell, I figured, this was due to the fact that Github changed the name of the default branch as “main” instead of the earlier “master” whereas libgit2 implementation was expecting “master”.\nAs a quickfix I renamed the branch on my Github repo as “master” and for now set the default branch to be named “master”.\nFinally, I am able to pull and push to the repositories. The next image infact is showing commits and pushes made to the repository generating the blog post you are reading.\n\n\n\nSSH/SFTP\nThere are a couple of amazing apps: Termius and SecureShell. Both have very neat interfaces. I found the intergrations with the Files app very good!\nThe GIF below shows the SecureShell app in action where I transfer a file from my local storage (iPad) to remote server, process that file, and quickly copy the processed file back to local storage.\n\nAnother great functionality of the SecureShell is the “Offline” folder.\nAnother setting that I use is the Powerline fonts on my remote systems. Using Fontcase, I installed the corresponding powerline fonts on the iPad so that my SecureShell session looks great.\n\n\n\nSome other amazing tools\nI like the “view” utility in a-shell a lot. It can quickly help you preview various filetypes.\n\nAlso, as a quick tip, one can use Command + W to quickly exit the preview and use the back and forward keys to cycle through the files. This is very useful!\nI also like the fact that the convert tool now comes in inbuilt. It can convert between a variety of formats easily.\npbcopy and pbpaste are very convenient utilities to copy to and from the clipboard. Here is how I copied the content of factorial.py into the clipboard.\npbcopy &lt; factorial.py  \n\n\nShortcuts\na-Shell interfaces nicely with Shortcuts. The following gif shows an interface where I take an input from Shortcuts app -&gt; Pass it to a Python script and execute it inside a-shell -&gt; Store the results in a text file -&gt; View the content of the text file in Shortcuts.\n\nThe link to this shortcut is here\nThe following is the simple Python script I used called factorial.py\nimport math\nimport sys\n\nnum = int(sys.argv[1])\nprint(f\"The factorial of {num} is {math.factorial(num)}\")\nThe following is an image of the shortcut.\n\nBased on the suggestion here, I used pbcopy to copy the content to the clipboard and use it directly. It reduces the number of lines!"
  },
  {
    "objectID": "posts/2021-06-14-setup-ipad.html#using-the-workingcopy-app",
    "href": "posts/2021-06-14-setup-ipad.html#using-the-workingcopy-app",
    "title": "My iPad Setup",
    "section": "Using the WorkingCopy App",
    "text": "Using the WorkingCopy App\nWorkingCopy is a very nicely made Git app on the iPad. It is one of the best made apps I have used!\nI’ll let the pictures do the talking."
  },
  {
    "objectID": "posts/2021-06-14-setup-ipad.html#editors",
    "href": "posts/2021-06-14-setup-ipad.html#editors",
    "title": "My iPad Setup",
    "section": "Editors",
    "text": "Editors\nI use one of the following for editing:\n\nKoder App\nWorkingCopy App\nvim (in a-Shell)\nTextastic\nTypewriter for Markdown — is an editor only for markdown but gives a nice quick preview. The image below shows the screenshot from Typewriter for Markdown app."
  },
  {
    "objectID": "posts/2024-object-detection.html",
    "href": "posts/2024-object-detection.html",
    "title": "Object detection",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- computer-vision- object-detection- deep-learning- neural-networks- yolo- pytorchdate: ’2024-05-30’title: Object detectiontoc: true—\n\nfrom ultralytics import YOLO, checks, hub\nimport pandas as pd\n\n\nchecks()\n\nUltralytics YOLOv8.2.5 🚀 Python-3.11.7 torch-2.2.0+cu121 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\nSetup complete ✅ (16 CPUs, 187.6 GB RAM, 38.5/184.8 GB disk)\n\n\n\nfrom ultralytics import YOLO\n\n# Load a model\n#model = YOLO('yolov8n.yaml')  # build a new model from scratch\nmodel = YOLO('yolov8n.pt') \n\n\nimport requests\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\n\n# Download the image locally\nimage_url = 'https://ultralytics.com/images/bus.jpg'\nresponse = requests.get(image_url)\nwith open('bus.jpg', 'wb') as f:\n    f.write(response.content)\n\n\n# Load a model\nmodel = YOLO('yolov8n.pt') \n\n\n\ndef show_image(img, confidence_threshold=0.5):\n    \n    results = model(img)[0]\n\n    # Get the image and detections\n    image = Image.open('bus.jpg')\n    confidences = []\n    classes = []\n    for box in results.boxes:\n        box_coords = box.xyxy[0].cpu().numpy()\n        confidence = box.conf[0].cpu().numpy()\n        confidences.append(confidence.item())\n        class_name = model.names[int(box.cls)]\n        classes.append(class_name)\n        if confidence &lt; confidence_threshold:\n            continue\n        plt.gca().add_patch(plt.Rectangle((box_coords[0], box_coords[1]), \n                                        box_coords[2]-box_coords[0], \n                                        box_coords[3]-box_coords[1], \n                                        fill=False, edgecolor='r', lw=2))\n        # Put label\n        \n        plt.text(box_coords[0], box_coords[1], class_name, color='r')\n\n    plt.imshow(image, alpha=0.5)\n    return pd.Series(confidences, classes, )\n\n\nshow_image('bus.jpg')\n\n\nimage 1/1 /home/nipun.batra/git/blog/posts/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 55.8ms\nSpeed: 3.2ms preprocess, 55.8ms inference, 1384.5ms postprocess per image at shape (1, 3, 640, 480)\n\n\nbus          0.870545\nperson       0.868980\nperson       0.853604\nperson       0.819305\nstop sign    0.346069\nperson       0.301294\ndtype: float64\n\n\n\n\n\n\n\n\n\n\nimg = Image.open('bus.jpg')\nres = model(img)[0]\n\n\n0: 640x480 4 persons, 1 bus, 1 stop sign, 9.9ms\nSpeed: 20.6ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n\n\n\nres.boxes[0].prob\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 res.boxes[0].prob\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/ultralytics/utils/__init__.py:160, in SimpleClass.__getattr__(self, attr)\n    158 \"\"\"Custom attribute access error message with helpful information.\"\"\"\n    159 name = self.__class__.__name__\n--&gt; 160 raise AttributeError(f\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\")\n\nAttributeError: 'Boxes' object has no attribute 'prob'. See valid attributes below.\n\n    Manages detection boxes, providing easy access and manipulation of box coordinates, confidence scores, class\n    identifiers, and optional tracking IDs. Supports multiple formats for box coordinates, including both absolute and\n    normalized forms.\n\n    Attributes:\n        data (torch.Tensor): The raw tensor containing detection boxes and their associated data.\n        orig_shape (tuple): The original image size as a tuple (height, width), used for normalization.\n        is_track (bool): Indicates whether tracking IDs are included in the box data.\n\n    Properties:\n        xyxy (torch.Tensor | numpy.ndarray): Boxes in [x1, y1, x2, y2] format.\n        conf (torch.Tensor | numpy.ndarray): Confidence scores for each box.\n        cls (torch.Tensor | numpy.ndarray): Class labels for each box.\n        id (torch.Tensor | numpy.ndarray, optional): Tracking IDs for each box, if available.\n        xywh (torch.Tensor | numpy.ndarray): Boxes in [x, y, width, height] format, calculated on demand.\n        xyxyn (torch.Tensor | numpy.ndarray): Normalized [x1, y1, x2, y2] boxes, relative to `orig_shape`.\n        xywhn (torch.Tensor | numpy.ndarray): Normalized [x, y, width, height] boxes, relative to `orig_shape`.\n\n    Methods:\n        cpu(): Moves the boxes to CPU memory.\n        numpy(): Converts the boxes to a numpy array format.\n        cuda(): Moves the boxes to CUDA (GPU) memory.\n        to(device, dtype=None): Moves the boxes to the specified device.\n    \n\n\n\n\n# Access the detection results\nresults = model(img)\n\nboxes = results[0].boxes\n\n# Print class probabilities for each detected object\nfor box in boxes:\n    class_probs = box.probs\n    print(f\"Bounding Box: {box.xyxy}\")\n    for class_id, prob in enumerate(class_probs):\n        print(f\"Class ID: {class_id}, Probability: {prob:.4f}\")\n\n\n0: 640x480 4 persons, 1 bus, 1 stop sign, 8.5ms\nSpeed: 23.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[22], line 8\n      6 # Print class probabilities for each detected object\n      7 for box in boxes:\n----&gt; 8     class_probs = box.probs\n      9     print(f\"Bounding Box: {box.xyxy}\")\n     10     for class_id, prob in enumerate(class_probs):\n\nFile ~/miniconda3/envs/ml/lib/python3.11/site-packages/ultralytics/utils/__init__.py:160, in SimpleClass.__getattr__(self, attr)\n    158 \"\"\"Custom attribute access error message with helpful information.\"\"\"\n    159 name = self.__class__.__name__\n--&gt; 160 raise AttributeError(f\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\")\n\nAttributeError: 'Boxes' object has no attribute 'probs'. See valid attributes below.\n\n    Manages detection boxes, providing easy access and manipulation of box coordinates, confidence scores, class\n    identifiers, and optional tracking IDs. Supports multiple formats for box coordinates, including both absolute and\n    normalized forms.\n\n    Attributes:\n        data (torch.Tensor): The raw tensor containing detection boxes and their associated data.\n        orig_shape (tuple): The original image size as a tuple (height, width), used for normalization.\n        is_track (bool): Indicates whether tracking IDs are included in the box data.\n\n    Properties:\n        xyxy (torch.Tensor | numpy.ndarray): Boxes in [x1, y1, x2, y2] format.\n        conf (torch.Tensor | numpy.ndarray): Confidence scores for each box.\n        cls (torch.Tensor | numpy.ndarray): Class labels for each box.\n        id (torch.Tensor | numpy.ndarray, optional): Tracking IDs for each box, if available.\n        xywh (torch.Tensor | numpy.ndarray): Boxes in [x, y, width, height] format, calculated on demand.\n        xyxyn (torch.Tensor | numpy.ndarray): Normalized [x1, y1, x2, y2] boxes, relative to `orig_shape`.\n        xywhn (torch.Tensor | numpy.ndarray): Normalized [x, y, width, height] boxes, relative to `orig_shape`.\n\n    Methods:\n        cpu(): Moves the boxes to CPU memory.\n        numpy(): Converts the boxes to a numpy array format.\n        cuda(): Moves the boxes to CUDA (GPU) memory.\n        to(device, dtype=None): Moves the boxes to the specified device.\n    \n\n\n\n\nresults[0].boxes[0].data\n\ntensor([[ 17.2858, 230.5922, 801.5182, 768.4058,   0.8705,   5.0000]], device='cuda:0')\n\n\n\nmodel\n\nYOLO(\n  (model): DetectionModel(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (1): Conv(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (2): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (4): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (6): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (8): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (9): SPPF(\n        (cv1): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n      )\n      (10): Upsample(scale_factor=2.0, mode='nearest')\n      (11): Concat()\n      (12): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (13): Upsample(scale_factor=2.0, mode='nearest')\n      (14): Concat()\n      (15): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (16): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (17): Concat()\n      (18): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (19): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (20): Concat()\n      (21): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (22): Detect(\n        (cv2): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (cv3): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (dfl): DFL(\n          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n      )\n    )\n  )\n)\n\n\n\nimport numpy as np\nimport os\nimport torch\n\nfrom ultralytics import YOLO\nfrom ultralytics.nn.modules.head import Detect\nfrom ultralytics.utils import ops\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport cv2\nfrom PIL import Image\n\nimport json\n\nclass SaveIO:\n    \"\"\"Simple PyTorch hook to save the output of a nn.module.\"\"\"\n    def __init__(self):\n        self.input = None\n        self.output = None\n        \n    def __call__(self, module, module_in, module_out):\n        self.input = module_in\n        self.output = module_out\n\ndef load_and_prepare_model(model_path):\n    # we are going to register a PyTorch hook on the important parts of the YOLO model,\n    # then reverse engineer the outputs to get boxes and logits\n    # first, we have to register the hooks to the model *before running inference*\n    # then, when inference is run, the hooks will save the inputs/outputs of their respective modules\n    model = YOLO(model_path)\n    detect = None\n    cv2_hooks = None\n    cv3_hooks = None\n    detect_hook = SaveIO()\n    for i, module in enumerate(model.model.modules()):\n        if type(module) is Detect:\n            module.register_forward_hook(detect_hook)\n            detect = module\n\n            cv2_hooks = [SaveIO() for _ in range(module.nl)]\n            cv3_hooks = [SaveIO() for _ in range(module.nl)]\n            for i in range(module.nl):\n                module.cv2[i].register_forward_hook(cv2_hooks[i])\n                module.cv3[i].register_forward_hook(cv3_hooks[i])\n            break\n    input_hook = SaveIO()\n    model.model.register_forward_hook(input_hook)\n\n    # save and return these for later\n    hooks = [input_hook, detect, detect_hook, cv2_hooks, cv3_hooks]\n\n    return model, hooks\n\n\ndef is_text_file(file_path):\n    # Check if the file extension indicates a text file\n    text_extensions = ['.txt'] #, '.csv', '.json', '.xml']  # Add more extensions if needed\n    return any(file_path.lower().endswith(ext) for ext in text_extensions)\n\ndef is_image_file(file_path):\n    # Check if the file extension indicates an image file\n    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']  # Add more extensions if needed\n    return any(file_path.lower().endswith(ext) for ext in image_extensions)\n\n\ndef plot_image(img_path, results, category_mapping=None, suffix='test', show_labels=True, include_legend=True):\n    \"\"\"\n    Display the image with bounding boxes and their corresponding class scores.\n\n    Args:\n        img_path (str): Path to the image file.\n        results (list): List of dictionaries containing bounding box information.\n        category_mapping:\n        suffix: what to append to the original image name when saving\n\n    Returns:\n        None\n    \"\"\"\n\n    img = Image.open(img_path)\n    fig, ax = plt.subplots()\n    ax.imshow(img)\n\n    for box in results:\n        x0, y0, x1, y1 = map(int, box['bbox'])\n\n        box_color = \"r\"  # red\n        tag_color = \"k\"  # black\n        max_score = max(box['activations'])\n        max_category_id = box['activations'].index(max_score)\n        category_name = max_category_id\n\n        if category_mapping:\n            max_category_name = category_mapping.get(max_category_id, \"Unknown\")\n            category_name = max_category_name\n\n        rect = patches.Rectangle(\n            (x0, y0),\n            x1 - x0,\n            y1 - y0,\n            edgecolor=box_color,\n            label=f\"{max_category_id}: {category_name} ({max_score:.2f})\",\n            facecolor='none'\n        )\n        ax.add_patch(rect)\n\n        if show_labels:\n            plt.text(\n                x0,\n                y0 - 50,\n                f\"{max_category_id} ({max_score:.2f})\",\n                fontsize=\"5\",\n                color=tag_color,\n                backgroundcolor=box_color,\n            )\n\n    if include_legend:\n        ax.legend(fontsize=\"5\")\n\n    plt.axis(\"off\")\n    plt.savefig(f'{os.path.basename(img_path).rsplit(\".\", 1)[0]}_{suffix}.jpg', bbox_inches=\"tight\", dpi=300)\n\n\ndef write_json(results):\n    # Create a list to store the predictions data\n    predictions = []\n\n    for result in results:\n        image_id = os.path.basename(result['image_id'])#.split('.')[0]\n        # image_id = result[\"image_id\"]\n        #image_id = os.path.basename(img_path).split('.')[0]\n        max_category_id = result['activations'].index(max(result['activations']))\n        category_id = max_category_id\n        bbox = result['bbox']\n        score = max(result['activations'])\n        activations = result['activations']\n\n        prediction = {\n            'image_id': image_id,\n            'category_id': category_id,\n            'bbox': bbox,\n            'score': score,\n            'activations': activations\n        }\n\n        predictions.append(prediction)\n\n    # Write the predictions list to a JSON file\n    with open('predictions.json', 'w') as f:\n        json.dump(predictions, f)\n\n\ndef calculate_iou(box1, box2):\n    \"\"\"\n    Calculates the Intersection over Union (IoU) between two bounding boxes.\n\n    Args:\n        box1 (list): Bounding box coordinates [x1, y1, w1, h1].\n        box2 (list): Bounding box coordinates [x2, y2, w2, h2].\n\n    Returns:\n        float: Intersection over Union (IoU) value.\n    \"\"\"\n    x1, y1, w1, h1 = box1\n    x2, y2, w2, h2 = box2\n\n    intersect_x1 = max(x1, x2)\n    intersect_y1 = max(y1, y2)\n    intersect_x2 = min(x1 + w1, x2 + w2)\n    intersect_y2 = min(y1 + h1, y2 + h2)\n\n    intersect_area = max(0, intersect_x2 - intersect_x1 + 1) * max(0, intersect_y2 - intersect_y1 + 1)\n    box1_area = w1 * h1\n    box2_area = w2 * h2\n\n    iou = intersect_area / float(box1_area + box2_area - intersect_area)\n    return iou\n\n\n# Apply Non-Maximum Suppression\ndef nms(boxes, iou_threshold=0.7):\n    \"\"\"\n    Applies Non-Maximum Suppression (NMS) to a list of bounding box dictionaries.\n\n    Args:\n        boxes (list): List of dictionaries, each containing 'bbox', 'logits', and 'activations'.\n        iou_threshold (float, optional): Intersection over Union (IoU) threshold for NMS. Default is 0.7.\n\n    Returns:\n        list: List of selected bounding box dictionaries after NMS.\n    \"\"\"\n    # Sort boxes by confidence score in descending order\n    sorted_boxes = sorted(boxes, key=lambda x: max(x['activations']), reverse=True)\n    selected_boxes = []\n\n    # Keep the box with highest confidence and remove overlapping boxes\n    delete_idxs = []\n    for i, box0 in enumerate(sorted_boxes):\n        for j, box1 in enumerate(sorted_boxes):\n            if i &lt; j and calculate_iou(box0['bbox'], box1['bbox']) &gt; iou_threshold:\n                delete_idxs.append(j)\n\n    # Reverse the order of delete_idxs\n    delete_idxs.reverse()\n\n    # now delete by popping them in reverse order\n    filtered_boxes = [box for idx, box in enumerate(sorted_boxes) if idx not in delete_idxs]\n\n    return filtered_boxes\n\n\ndef results_predict(img_path, model, hooks, threshold=0.5, iou=0.7, save_image = False, category_mapping = None):\n    \"\"\"\n    Run prediction with a YOLO model and apply Non-Maximum Suppression (NMS) to the results.\n\n    Args:\n        img_path (str): Path to an image file.\n        model (YOLO): YOLO model object.\n        hooks (list): List of hooks for the model.\n        threshold (float, optional): Confidence threshold for detection. Default is 0.5.\n        iou (float, optional): Intersection over Union (IoU) threshold for NMS. Default is 0.7.\n        save_image (bool, optional): Whether to save the image with boxes plotted. Default is False.\n\n    Returns:\n        list: List of selected bounding box dictionaries after NMS.\n    \"\"\"\n    # unpack hooks from load_and_prepare_model()\n    input_hook, detect, detect_hook, cv2_hooks, cv3_hooks = hooks\n\n    # run inference; we don't actually need to store the results because\n    # the hooks store everything we need\n    model(img_path)\n\n    # now reverse engineer the outputs to find the logits\n    # see Detect.forward(): https://github.com/ultralytics/ultralytics/blob/b638c4ed9a24270a6875cdd47d9eeda99204ef5a/ultralytics/nn/modules/head.py#L22\n    shape = detect_hook.input[0][0].shape  # BCHW\n    x = []\n    for i in range(detect.nl):\n        x.append(torch.cat((cv2_hooks[i].output, cv3_hooks[i].output), 1))\n    x_cat = torch.cat([xi.view(shape[0], detect.no, -1) for xi in x], 2)\n    box, cls = x_cat.split((detect.reg_max * 4, detect.nc), 1)\n\n    # assumes batch size = 1 (i.e. you are just running with one image)\n    # if you want to run with many images, throw this in a loop\n    batch_idx = 0\n    xywh_sigmoid = detect_hook.output[0][batch_idx]\n    all_logits = cls[batch_idx]\n\n    # figure out the original img shape and model img shape so we can transform the boxes\n    img_shape = input_hook.input[0].shape[2:]\n    orig_img_shape = model.predictor.batch[1][batch_idx].shape[:2]\n\n    # compute predictions\n    boxes = []\n    for i in range(xywh_sigmoid.shape[-1]): # for each predicted box...\n        x0, y0, x1, y1, *class_probs_after_sigmoid = xywh_sigmoid[:,i]\n        x0, y0, x1, y1 = ops.scale_boxes(img_shape, np.array([x0.cpu(), y0.cpu(), x1.cpu(), y1.cpu()]), orig_img_shape)\n        logits = all_logits[:,i]\n        \n        boxes.append({\n            'image_id': img_path,\n            'bbox': [x0.item(), y0.item(), x1.item(), y1.item()], # xyxy\n            'bbox_xywh': [(x0.item() + x1.item())/2, (y0.item() + y1.item())/2, x1.item() - x0.item(), y1.item() - y0.item()],\n            'logits': logits.cpu().tolist(),\n            'activations': [p.item() for p in class_probs_after_sigmoid]\n        })\n\n    # for debugging\n    # top10 = sorted(boxes, key=lambda x: max(x['activations']), reverse=True)[:10]\n    # plot_image(img_path, top10, suffix=\"before_nms\")\n\n    # NMS\n    # we can keep the activations and logits around via the YOLOv8 NMS method, but only if we\n    # append them as an additional time to the prediction vector. It's a weird hacky way to do it, but\n    # it works. We also have to pass in the num classes (nc) parameter to make it work.\n    boxes_for_nms = torch.stack([\n        torch.tensor([*b['bbox_xywh'], *b['activations'], *b['activations'], *b['logits']]) for b in boxes\n    ], dim=1).unsqueeze(0)\n    \n    # do the NMS\n    nms_results = ops.non_max_suppression(boxes_for_nms, conf_thres=threshold, iou_thres=iou, nc=detect.nc)[0]\n    \n    # unpack it and return it\n    boxes = []\n    for b in range(nms_results.shape[0]):\n        box = nms_results[b, :]\n        x0, y0, x1, y1, conf, cls, *acts_and_logits = box\n        activations = acts_and_logits[:detect.nc]\n        logits = acts_and_logits[detect.nc:]\n        box_dict = {\n            'bbox': [x0.item(), y0.item(), x1.item(), y1.item()], # xyxy\n            'bbox_xywh': [(x0.item() + x1.item())/2, (y0.item() + y1.item())/2, x1.item() - x0.item(), y1.item() - y0.item()],\n            'best_conf': conf.item(),\n            'best_cls': cls.item(),\n            'image_id': img_path,\n            'activations': [p.item() for p in activations],\n            'logits': [p.item() for p in logits]\n        }\n        boxes.append(box_dict)\n\n    return boxes\n\n\ndef run_predict(input_path, model, hooks, score_threshold=0.5, iou_threshold=0.7, save_image = False, save_json = False, category_mapping = None):\n    \"\"\"\n    Run prediction with a YOLO model.\n\n    Args:\n        input_path (str): Path to an image file or txt file containing paths to image files.\n        model (YOLO): YOLO model object.\n        hooks (list): List of hooks for the model.\n        threshold (float, optional): Confidence threshold for detection. Default is 0.5.\n        iou_threshold (float, optional): Intersection over Union (IoU) threshold for NMS. Default is 0.7.\n        save_image (bool, optional): Whether to save the image with boxes plotted. Default is False.\n        save_json (bool, optional): Whether to save the results in a json file. Default is False.\n\n    Returns:\n        list: List of selected bounding box dictionaries for all the images given as input.\n    \"\"\"\n    use_txt_input = False\n\n    if is_text_file(input_path):\n        use_txt_input = True\n\n    if use_txt_input:\n        with open(input_path, 'r') as f:\n            img_paths = f.read().splitlines()\n    else:\n        img_paths = [input_path]\n\n    all_results = []\n\n    for img_path in img_paths:\n        results = results_predict(img_path, model, hooks, score_threshold, iou=iou_threshold, save_image=save_image, category_mapping=category_mapping)\n\n        all_results.extend(results)\n\n    if save_json:\n        write_json(all_results)\n\n    return all_results\n\n\n### Start example script here ###\n### (This shows how to use the methods in this file) ###\n\n# change these, of course :)\nSAVE_TEST_IMG = True\nmodel_path = 'yolov8n.pt'\nimg_path = 'bus.jpg'\nthreshold = 0.5\nnms_threshold = 0.7\n\n# load the model\nmodel, hooks = load_and_prepare_model(model_path)\n\n# run inference\nresults = run_predict(img_path, model, hooks, score_threshold=threshold, iou_threshold=nms_threshold)\n\nprint(\"Processed\", len(results), \"boxes\")\nprint(\"The first one is\", results[0])\n\nif SAVE_TEST_IMG:\n    plot_image(img_path, results)\n\n\n\nimage 1/1 /home/nipun.batra/git/blog/posts/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 6.9ms\nSpeed: 2.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\nProcessed 4 boxes\nThe first one is {'bbox': [17.28582763671875, 230.59222412109375, 801.5181884765625, 768.4058227539062], 'bbox_xywh': [409.4020080566406, 499.4990234375, 784.2323608398438, 537.8135986328125], 'best_conf': 0.8705450892448425, 'best_cls': 5.0, 'image_id': 'bus.jpg', 'activations': [1.0311242476745974e-05, 9.112093721341807e-06, 0.0003611394204199314, 6.673172902083024e-05, 0.00022987156989984214, 0.8705450892448425, 0.0009488395880907774, 0.007086973637342453, 0.0001582797704031691, 9.052685527422e-06, 4.503397406097065e-07, 1.0215371730737388e-05, 1.730335316096898e-05, 4.165742666373262e-06, 5.312303414939379e-07, 1.9164923514836119e-07, 9.471239650338248e-07, 4.973830982635263e-06, 2.5008853654640006e-08, 4.033859681840113e-07, 0.0005047211889177561, 6.792038220737595e-07, 4.306784262553265e-07, 9.298752411268651e-05, 4.2397550714667886e-07, 6.426890467992052e-05, 3.322290240248549e-06, 1.4765126934435102e-06, 2.1423567886813544e-05, 1.0903042948484654e-06, 2.7694509299180936e-06, 3.31359643723772e-07, 1.1906087138413568e-06, 5.6864570069592446e-05, 5.980197329336079e-06, 9.176978892355692e-07, 6.090281658543972e-06, 8.041779437917285e-06, 4.321082087699324e-05, 2.43568738369504e-05, 4.93736079079099e-05, 1.2213927220727783e-05, 3.2120142350322567e-06, 5.898335757592577e-07, 6.751507157787273e-07, 1.514082214271184e-06, 7.679868474497198e-08, 5.769239237451984e-07, 2.8340421067696298e-06, 4.807910954696126e-06, 2.058711316976769e-07, 2.196402647314244e-06, 2.783847776299808e-06, 7.796339195920154e-05, 1.7758512171894836e-07, 2.9252541366986407e-07, 4.3183670641155913e-05, 8.449018423561938e-06, 1.572124688209442e-06, 4.166020971752005e-06, 1.1690817700582556e-05, 1.4325351571642386e-07, 3.190975985489786e-05, 1.2439878673831117e-06, 9.514394605503185e-07, 9.426859719496861e-07, 5.968039204162778e-06, 8.346189133590087e-05, 2.026550646405667e-05, 5.310462256602477e-06, 9.205886271956842e-06, 4.1557203900310924e-08, 4.2926520109176636e-05, 2.642763683979865e-05, 2.686474908841774e-05, 2.5954559532692656e-05, 6.725371122229262e-07, 5.926154926783056e-07, 1.19427056688437e-06, 2.642658500917605e-07], 'logits': [-11.48226547241211, -11.6058988571167, -7.925885200500488, -9.614763259887695, -8.37775993347168, 1.9057865142822266, -6.95932149887085, -4.942384719848633, -8.750988006591797, -11.61244010925293, -14.613263130187988, -11.491606712341309, -10.964592933654785, -12.388611793518066, -14.44806957244873, -15.467598915100098, -13.869834899902344, -12.211315155029297, -17.50403594970703, -14.723371505737305, -7.590999603271484, -14.202343940734863, -14.657903671264648, -9.282952308654785, -14.673589706420898, -9.65237045288086, -12.614852905273438, -13.425826072692871, -10.750997543334961, -13.729052543640137, -12.796858787536621, -14.920061111450195, -13.641044616699219, -9.774781227111816, -12.027050971984863, -13.901396751403809, -12.008810043334961, -11.730852127075195, -10.049376487731934, -10.622672080993652, -9.916045188903809, -11.312921524047852, -12.648609161376953, -14.343424797058105, -14.208329200744629, -13.400699615478516, -16.382078170776367, -14.365554809570312, -12.7738037109375, -12.245243072509766, -15.396015167236328, -13.028687477111816, -12.79167366027832, -9.459193229675293, -15.543815612792969, -15.044713973999023, -10.050004959106445, -11.681451797485352, -13.363080978393555, -12.388545036315918, -11.356695175170898, -15.758649826049805, -10.352566719055176, -13.597187042236328, -13.865288734436035, -13.874531745910645, -12.029086112976074, -9.391036987304688, -10.806570053100586, -12.14582633972168, -11.595658302307129, -16.99619483947754, -10.055977821350098, -10.5410737991333, -10.52466869354248, -10.559137344360352, -14.212207794189453, -14.338719367980957, -13.63797378540039, -15.146309852600098]}\n\n\n\n\n\n\n\n\n\n\nresults\n\n[{'bbox': [17.28582763671875,\n   230.59222412109375,\n   801.5181884765625,\n   768.4058227539062],\n  'bbox_xywh': [409.4020080566406,\n   499.4990234375,\n   784.2323608398438,\n   537.8135986328125],\n  'best_conf': 0.8705450892448425,\n  'best_cls': 5.0,\n  'image_id': 'bus.jpg',\n  'activations': [1.0311242476745974e-05,\n   9.112093721341807e-06,\n   0.0003611394204199314,\n   6.673172902083024e-05,\n   0.00022987156989984214,\n   0.8705450892448425,\n   0.0009488395880907774,\n   0.007086973637342453,\n   0.0001582797704031691,\n   9.052685527422e-06,\n   4.503397406097065e-07,\n   1.0215371730737388e-05,\n   1.730335316096898e-05,\n   4.165742666373262e-06,\n   5.312303414939379e-07,\n   1.9164923514836119e-07,\n   9.471239650338248e-07,\n   4.973830982635263e-06,\n   2.5008853654640006e-08,\n   4.033859681840113e-07,\n   0.0005047211889177561,\n   6.792038220737595e-07,\n   4.306784262553265e-07,\n   9.298752411268651e-05,\n   4.2397550714667886e-07,\n   6.426890467992052e-05,\n   3.322290240248549e-06,\n   1.4765126934435102e-06,\n   2.1423567886813544e-05,\n   1.0903042948484654e-06,\n   2.7694509299180936e-06,\n   3.31359643723772e-07,\n   1.1906087138413568e-06,\n   5.6864570069592446e-05,\n   5.980197329336079e-06,\n   9.176978892355692e-07,\n   6.090281658543972e-06,\n   8.041779437917285e-06,\n   4.321082087699324e-05,\n   2.43568738369504e-05,\n   4.93736079079099e-05,\n   1.2213927220727783e-05,\n   3.2120142350322567e-06,\n   5.898335757592577e-07,\n   6.751507157787273e-07,\n   1.514082214271184e-06,\n   7.679868474497198e-08,\n   5.769239237451984e-07,\n   2.8340421067696298e-06,\n   4.807910954696126e-06,\n   2.058711316976769e-07,\n   2.196402647314244e-06,\n   2.783847776299808e-06,\n   7.796339195920154e-05,\n   1.7758512171894836e-07,\n   2.9252541366986407e-07,\n   4.3183670641155913e-05,\n   8.449018423561938e-06,\n   1.572124688209442e-06,\n   4.166020971752005e-06,\n   1.1690817700582556e-05,\n   1.4325351571642386e-07,\n   3.190975985489786e-05,\n   1.2439878673831117e-06,\n   9.514394605503185e-07,\n   9.426859719496861e-07,\n   5.968039204162778e-06,\n   8.346189133590087e-05,\n   2.026550646405667e-05,\n   5.310462256602477e-06,\n   9.205886271956842e-06,\n   4.1557203900310924e-08,\n   4.2926520109176636e-05,\n   2.642763683979865e-05,\n   2.686474908841774e-05,\n   2.5954559532692656e-05,\n   6.725371122229262e-07,\n   5.926154926783056e-07,\n   1.19427056688437e-06,\n   2.642658500917605e-07],\n  'logits': [-11.48226547241211,\n   -11.6058988571167,\n   -7.925885200500488,\n   -9.614763259887695,\n   -8.37775993347168,\n   1.9057865142822266,\n   -6.95932149887085,\n   -4.942384719848633,\n   -8.750988006591797,\n   -11.61244010925293,\n   -14.613263130187988,\n   -11.491606712341309,\n   -10.964592933654785,\n   -12.388611793518066,\n   -14.44806957244873,\n   -15.467598915100098,\n   -13.869834899902344,\n   -12.211315155029297,\n   -17.50403594970703,\n   -14.723371505737305,\n   -7.590999603271484,\n   -14.202343940734863,\n   -14.657903671264648,\n   -9.282952308654785,\n   -14.673589706420898,\n   -9.65237045288086,\n   -12.614852905273438,\n   -13.425826072692871,\n   -10.750997543334961,\n   -13.729052543640137,\n   -12.796858787536621,\n   -14.920061111450195,\n   -13.641044616699219,\n   -9.774781227111816,\n   -12.027050971984863,\n   -13.901396751403809,\n   -12.008810043334961,\n   -11.730852127075195,\n   -10.049376487731934,\n   -10.622672080993652,\n   -9.916045188903809,\n   -11.312921524047852,\n   -12.648609161376953,\n   -14.343424797058105,\n   -14.208329200744629,\n   -13.400699615478516,\n   -16.382078170776367,\n   -14.365554809570312,\n   -12.7738037109375,\n   -12.245243072509766,\n   -15.396015167236328,\n   -13.028687477111816,\n   -12.79167366027832,\n   -9.459193229675293,\n   -15.543815612792969,\n   -15.044713973999023,\n   -10.050004959106445,\n   -11.681451797485352,\n   -13.363080978393555,\n   -12.388545036315918,\n   -11.356695175170898,\n   -15.758649826049805,\n   -10.352566719055176,\n   -13.597187042236328,\n   -13.865288734436035,\n   -13.874531745910645,\n   -12.029086112976074,\n   -9.391036987304688,\n   -10.806570053100586,\n   -12.14582633972168,\n   -11.595658302307129,\n   -16.99619483947754,\n   -10.055977821350098,\n   -10.5410737991333,\n   -10.52466869354248,\n   -10.559137344360352,\n   -14.212207794189453,\n   -14.338719367980957,\n   -13.63797378540039,\n   -15.146309852600098]},\n {'bbox': [48.739479064941406,\n   399.263916015625,\n   244.50173950195312,\n   902.501220703125],\n  'bbox_xywh': [146.62060928344727,\n   650.882568359375,\n   195.76226043701172,\n   503.2373046875],\n  'best_conf': 0.8689801096916199,\n  'best_cls': 0.0,\n  'image_id': 'bus.jpg',\n  'activations': [0.8689801096916199,\n   2.159083720698618e-07,\n   7.267921660059073e-07,\n   4.954289352099295e-07,\n   3.9690485209575854e-06,\n   3.6866176742478274e-06,\n   1.924761590998969e-06,\n   5.504815590029466e-07,\n   8.782559461906203e-07,\n   1.8101994783137343e-06,\n   1.012005441225483e-06,\n   1.725299512145284e-07,\n   1.9031394913326949e-06,\n   1.7214931347098172e-07,\n   2.6558041099633556e-06,\n   1.7690776985546108e-06,\n   4.047087259095861e-06,\n   1.6409081808888004e-06,\n   7.941423518786905e-07,\n   1.1039174978577648e-06,\n   1.4459410522249527e-06,\n   1.3210571978561347e-06,\n   4.1252138771596947e-07,\n   1.2257790331204887e-05,\n   9.701152521301992e-07,\n   5.426437610367429e-07,\n   4.6731869929317327e-07,\n   1.5046108501337585e-06,\n   6.04137326831733e-08,\n   3.9817462038627127e-07,\n   1.8838558162315167e-06,\n   1.1097992000941304e-06,\n   1.1555634955584537e-06,\n   7.810695024090819e-06,\n   2.828919605235569e-06,\n   2.9941506340946944e-07,\n   5.739046855524066e-07,\n   1.1345385928507312e-06,\n   4.880649271399307e-07,\n   2.7935711841564626e-06,\n   1.2807398661607294e-06,\n   3.5370536011214426e-07,\n   3.775756454160728e-07,\n   2.3527961729996605e-06,\n   9.562232889948064e-07,\n   4.1244192061640206e-07,\n   6.125056870587287e-07,\n   2.33453351938806e-06,\n   5.989752480672905e-07,\n   1.124500272453588e-06,\n   9.676870149633032e-07,\n   1.5129870007513091e-05,\n   3.98353768105153e-06,\n   6.566142474184744e-06,\n   6.885069296913571e-07,\n   5.487340786203276e-07,\n   7.767624765619985e-07,\n   5.031957925893948e-07,\n   2.001876282520243e-06,\n   9.961429441318614e-07,\n   1.2013529158139136e-06,\n   4.2538695765870216e-07,\n   2.504941676306771e-06,\n   2.0721746807339514e-07,\n   2.624780393034598e-07,\n   7.277583904397034e-07,\n   4.963558453141559e-08,\n   1.2240196838320117e-06,\n   3.9281539443436486e-07,\n   1.3602493709186092e-06,\n   2.1281984174947866e-07,\n   9.780134746506519e-08,\n   1.0565305501586408e-06,\n   4.288276045372186e-07,\n   3.775760148982954e-07,\n   2.0054291383075906e-07,\n   1.2226444141560933e-06,\n   1.0907050636888016e-05,\n   1.6243636764556868e-06,\n   5.100530984236684e-07],\n  'logits': [1.8919711112976074,\n   -15.348411560058594,\n   -14.134624481201172,\n   -14.517841339111328,\n   -12.436980247497559,\n   -12.510797500610352,\n   -13.160706520080566,\n   -14.412471771240234,\n   -13.945326805114746,\n   -13.222071647644043,\n   -13.80357551574707,\n   -15.572694778442383,\n   -13.172003746032715,\n   -15.57490348815918,\n   -12.838760375976562,\n   -13.245050430297852,\n   -12.417509078979492,\n   -13.320259094238281,\n   -14.046002388000488,\n   -13.716644287109375,\n   -13.446748733520508,\n   -13.537076950073242,\n   -14.700977325439453,\n   -11.30933666229248,\n   -13.845849990844727,\n   -14.426812171936035,\n   -14.576253890991211,\n   -13.406974792480469,\n   -16.62204933166504,\n   -14.736374855041504,\n   -13.182188034057617,\n   -13.71133041381836,\n   -13.670921325683594,\n   -11.760008811950684,\n   -12.775612831115723,\n   -15.021434783935547,\n   -14.37080192565918,\n   -13.68928337097168,\n   -14.532816886901855,\n   -12.788187026977539,\n   -13.568071365356445,\n   -14.854801177978516,\n   -14.789494514465332,\n   -12.959903717041016,\n   -13.860273361206055,\n   -14.701169967651367,\n   -14.305706977844238,\n   -12.967696189880371,\n   -14.328044891357422,\n   -13.69817066192627,\n   -13.848356246948242,\n   -11.098824501037598,\n   -12.43333625793457,\n   -11.933577537536621,\n   -14.188739776611328,\n   -14.415651321411133,\n   -14.068130493164062,\n   -14.502285957336426,\n   -13.121423721313477,\n   -13.819374084472656,\n   -13.632061004638672,\n   -14.670266151428223,\n   -12.897242546081543,\n   -15.389496803283691,\n   -15.153098106384277,\n   -14.133296012878418,\n   -16.818557739257812,\n   -13.61336898803711,\n   -14.74992561340332,\n   -13.507841110229492,\n   -15.36281967163086,\n   -16.14032745361328,\n   -13.760519027709961,\n   -14.662210464477539,\n   -14.789493560791016,\n   -15.422237396240234,\n   -13.614493370056152,\n   -11.426090240478516,\n   -13.330392837524414,\n   -14.488750457763672]},\n {'bbox': [670.269287109375,\n   380.2840270996094,\n   809.858154296875,\n   875.6907958984375],\n  'bbox_xywh': [740.063720703125,\n   627.9874114990234,\n   139.5888671875,\n   495.4067687988281],\n  'best_conf': 0.8536035418510437,\n  'best_cls': 0.0,\n  'image_id': 'bus.jpg',\n  'activations': [0.8536035418510437,\n   8.206617394534987e-07,\n   1.2038118484269944e-06,\n   1.1462942666184972e-06,\n   1.5739009313620045e-06,\n   3.3411379263270646e-06,\n   3.73882085114019e-06,\n   4.4993788606007e-07,\n   1.2424654869391816e-06,\n   3.6132853438175516e-06,\n   2.934745680249762e-06,\n   1.105569964465758e-07,\n   1.0381992296970566e-06,\n   5.935368676546204e-07,\n   1.4730724160472164e-06,\n   3.304354777355911e-06,\n   4.168759005551692e-06,\n   3.27019665746775e-06,\n   5.449832656267972e-07,\n   5.046072146797087e-07,\n   1.3525707345252158e-06,\n   9.852926723397104e-07,\n   1.1722339650077629e-06,\n   7.1923359428183176e-06,\n   2.579861757112667e-06,\n   7.465223461622372e-07,\n   1.0459139048180077e-06,\n   1.3547731896323967e-06,\n   3.88375610782532e-07,\n   3.233400320823421e-07,\n   1.6130819631143822e-06,\n   8.577525818509457e-07,\n   1.0866494903893908e-06,\n   3.3366293337167008e-06,\n   2.0756035610247636e-06,\n   3.148159635202319e-07,\n   6.232777991499461e-07,\n   7.360301310654904e-07,\n   9.060752290679375e-07,\n   2.585813035693718e-06,\n   1.3577079016613425e-06,\n   4.043033925427153e-07,\n   3.105890868937422e-07,\n   1.355843437522708e-06,\n   3.1056660532158276e-07,\n   1.5147954002259212e-07,\n   3.9362166148748656e-07,\n   1.426429321327305e-06,\n   1.4964024330765824e-07,\n   4.153795600814192e-07,\n   3.13703480969707e-07,\n   2.565983777458314e-06,\n   1.2322219617999508e-06,\n   9.984036068999558e-07,\n   1.9590237343436456e-07,\n   4.869207828051003e-07,\n   2.924327418440953e-06,\n   1.931917267938843e-06,\n   7.152341822802555e-06,\n   5.519689239008585e-06,\n   1.5743992207717383e-06,\n   2.096727712341817e-06,\n   2.2192562028067186e-06,\n   3.0115475624370447e-07,\n   3.523186933307443e-07,\n   3.960224432830728e-07,\n   3.5972377077087e-08,\n   8.289633797176066e-07,\n   3.8832413906675356e-07,\n   8.207001087612298e-07,\n   1.5001531039615656e-07,\n   8.185835298490929e-08,\n   1.6670093145876308e-06,\n   2.5175890527862066e-07,\n   3.8390692225220846e-07,\n   7.335270879593736e-07,\n   1.5532028783127316e-06,\n   1.81348677870119e-05,\n   1.4697145616082707e-06,\n   5.530769158212934e-07],\n  'logits': [1.763148307800293,\n   -14.013154029846191,\n   -13.630016326904297,\n   -13.678975105285645,\n   -13.36195182800293,\n   -12.609195709228516,\n   -12.496736526489258,\n   -14.614155769348145,\n   -13.598411560058594,\n   -12.530889511108398,\n   -12.738886833190918,\n   -16.01773452758789,\n   -13.778021812438965,\n   -14.337165832519531,\n   -13.4281587600708,\n   -12.62026596069336,\n   -12.387887954711914,\n   -12.630657196044922,\n   -14.422510147094727,\n   -14.49948501586914,\n   -13.51350212097168,\n   -13.830326080322266,\n   -13.656598091125488,\n   -11.842487335205078,\n   -12.867772102355957,\n   -14.107839584350586,\n   -13.770618438720703,\n   -13.51187515258789,\n   -14.761292457580566,\n   -14.944561004638672,\n   -13.337362289428711,\n   -13.968949317932129,\n   -13.732410430908203,\n   -12.610546112060547,\n   -13.085256576538086,\n   -14.971277236938477,\n   -14.288272857666016,\n   -14.121994018554688,\n   -13.914142608642578,\n   -12.86546802520752,\n   -13.509711265563965,\n   -14.721099853515625,\n   -14.984794616699219,\n   -13.511085510253906,\n   -14.984867095947266,\n   -15.702815055847168,\n   -14.747875213623047,\n   -13.460334777832031,\n   -15.715031623840332,\n   -14.694072723388672,\n   -14.974817276000977,\n   -12.87316608428955,\n   -13.606690406799316,\n   -13.817107200622559,\n   -15.445649147033691,\n   -14.535163879394531,\n   -12.742443084716797,\n   -13.15699577331543,\n   -11.848063468933105,\n   -12.107183456420898,\n   -13.361635208129883,\n   -13.075130462646484,\n   -13.018336296081543,\n   -15.015641212463379,\n   -14.858729362487793,\n   -14.74179458618164,\n   -17.140514373779297,\n   -14.00308895111084,\n   -14.761425018310547,\n   -14.013107299804688,\n   -15.712528228759766,\n   -16.318275451660156,\n   -13.30447769165039,\n   -15.194793701171875,\n   -14.772865295410156,\n   -14.12540054321289,\n   -13.375189781188965,\n   -10.917655944824219,\n   -13.430440902709961,\n   -14.407768249511719]},\n {'bbox': [221.39376831054688,\n   405.79168701171875,\n   344.7171936035156,\n   857.3920288085938],\n  'bbox_xywh': [283.05548095703125,\n   631.5918579101562,\n   123.32342529296875,\n   451.600341796875],\n  'best_conf': 0.8193051218986511,\n  'best_cls': 0.0,\n  'image_id': 'bus.jpg',\n  'activations': [0.8193051218986511,\n   4.0964692971101613e-07,\n   2.936613100246177e-06,\n   1.382118284709577e-06,\n   1.6149664588738233e-05,\n   8.412195711571258e-06,\n   9.894216645989218e-07,\n   1.2228890682308702e-06,\n   1.2646942195715383e-06,\n   1.9066765162278898e-06,\n   6.240153425096651e-07,\n   7.205974128510206e-08,\n   2.2608073777519166e-06,\n   1.6783783962637244e-07,\n   4.693410573963774e-06,\n   3.116812195003149e-06,\n   7.556559467047919e-06,\n   3.5700793432624778e-06,\n   8.197254715014424e-07,\n   1.5916730262688361e-06,\n   2.326829417143017e-06,\n   1.0168097333007609e-06,\n   2.1919508697010315e-07,\n   4.784199973073555e-06,\n   1.3443328725770698e-06,\n   4.94625453484332e-07,\n   4.1110206439043395e-07,\n   6.275794248722377e-07,\n   1.2701826790362247e-07,\n   3.41750705956656e-07,\n   1.7371836520396755e-06,\n   1.0280481319568935e-06,\n   1.6011792922654422e-06,\n   5.354379027266987e-06,\n   4.389916284708306e-06,\n   3.4768410728247545e-07,\n   1.3610668929686653e-06,\n   1.0928538358712103e-06,\n   7.004660460552259e-07,\n   3.702946060002432e-06,\n   2.8141175789642148e-06,\n   6.319215231087583e-07,\n   4.0783669419397484e-07,\n   1.7733005961417803e-06,\n   1.152611616817012e-06,\n   2.805371650538291e-07,\n   8.198293812711199e-07,\n   3.066387762373779e-06,\n   8.176439223461784e-07,\n   6.666024887636013e-07,\n   1.3133955008015619e-06,\n   9.064304322237149e-06,\n   3.986513547715731e-06,\n   2.927407876995858e-06,\n   2.5427269179090217e-07,\n   4.65552773221134e-07,\n   2.3654131382500054e-06,\n   7.987733283698617e-07,\n   1.5470428706976236e-06,\n   5.12271185471036e-07,\n   4.3607190036709653e-07,\n   5.852278945894795e-07,\n   1.5100877135409974e-06,\n   3.0730282674085174e-07,\n   5.032850936004252e-07,\n   7.947044764478051e-07,\n   6.477876013377681e-08,\n   2.3970601432665717e-06,\n   1.9725838740214385e-07,\n   3.763364588849072e-07,\n   2.017427789269277e-07,\n   1.4345364718337805e-07,\n   8.217072036131867e-07,\n   3.7514539030780725e-07,\n   2.626693742513453e-07,\n   2.2584059422570135e-07,\n   9.443388080399018e-07,\n   1.2512692592281383e-05,\n   2.4881660465325695e-06,\n   7.62891602335003e-07],\n  'logits': [1.5116467475891113,\n   -14.707969665527344,\n   -12.738250732421875,\n   -13.491891860961914,\n   -11.033595085144043,\n   -11.685819625854492,\n   -13.826144218444824,\n   -13.614293098449707,\n   -13.580678939819336,\n   -13.170146942138672,\n   -14.287090301513672,\n   -16.445770263671875,\n   -12.999786376953125,\n   -15.60026741027832,\n   -12.269346237182617,\n   -12.678696632385254,\n   -11.793087005615234,\n   -12.542919158935547,\n   -14.01429557800293,\n   -13.350723266601562,\n   -12.971001625061035,\n   -13.798839569091797,\n   -15.333303451538086,\n   -12.250186920166016,\n   -13.519611358642578,\n   -14.519464492797852,\n   -14.704423904418945,\n   -14.281394958496094,\n   -15.878934860229492,\n   -14.88918399810791,\n   -13.263243675231934,\n   -13.787847518920898,\n   -13.344768524169922,\n   -12.137590408325195,\n   -12.336195945739746,\n   -14.871971130371094,\n   -13.507240295410156,\n   -13.726716995239258,\n   -14.17151927947998,\n   -12.506378173828125,\n   -12.780858993530273,\n   -14.274499893188477,\n   -14.712398529052734,\n   -13.242666244506836,\n   -13.673479080200195,\n   -15.086559295654297,\n   -14.014168739318848,\n   -12.69500732421875,\n   -14.016838073730469,\n   -14.221071243286133,\n   -13.542893409729004,\n   -11.611157417297363,\n   -12.432589530944824,\n   -12.741390228271484,\n   -15.184858322143555,\n   -14.580039978027344,\n   -12.95455551147461,\n   -14.04018783569336,\n   -13.37916374206543,\n   -14.484411239624023,\n   -14.645458221435547,\n   -14.351263999938965,\n   -13.403341293334961,\n   -14.995431900024414,\n   -14.502108573913574,\n   -14.045294761657715,\n   -16.552288055419922,\n   -12.941265106201172,\n   -15.438751220703125,\n   -14.792781829833984,\n   -15.416272163391113,\n   -15.757253646850586,\n   -14.011880874633789,\n   -14.795951843261719,\n   -15.152369499206543,\n   -15.303436279296875,\n   -13.872779846191406,\n   -11.2887544631958,\n   -12.903962135314941,\n   -14.086149215698242]}]"
  },
  {
    "objectID": "posts/2024-attention.html",
    "href": "posts/2024-attention.html",
    "title": "Character-Level Attention Mechanism for Name Generation",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- MLdate: ’2024-05-30’title: Character-Level Attention Mechanism for Name Generationtoc: true—\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange, reduce, repeat\n\n\n!wget https://raw.githubusercontent.com/MASTREX/List-of-Indian-Names/master/2.%20First.txt -O names-indian.txt\n\n--2024-05-30 09:41:48--  https://raw.githubusercontent.com/MASTREX/List-of-Indian-Names/master/2.%20First.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 8752 (8.5K) [text/plain]\nSaving to: ‘names-indian.txt’\n\nnames-indian.txt    100%[===================&gt;]   8.55K  --.-KB/s    in 0s      \n\n2024-05-30 09:41:49 (33.8 MB/s) - ‘names-indian.txt’ saved [8752/8752]\n\n\n\n\nimport pandas as pd\npd.read_csv('names-indian.txt', header=None)\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\nAbhishek\n\n\n1\nAman\n\n\n2\nHarsh\n\n\n3\nAyush\n\n\n4\nAditi\n\n\n...\n...\n\n\n1160\nPrasoon\n\n\n1161\nMadhusudan\n\n\n1162\nPrastuti\n\n\n1163\nRampratap\n\n\n1164\nMadhukar\n\n\n\n\n1165 rows × 1 columns\n\n\n\n\n# convert all names to lowercase\nnames = pd.read_csv('names-indian.txt', header=None)[0].str.lower().values\n\n\nnames\n\narray(['abhishek', 'aman', 'harsh', ..., 'prastuti', 'rampratap',\n       'madhukar'], dtype=object)\n\n\n\n# KDE plot of name lengths\nplt.figure(figsize=(8, 4))\nplt.hist([len(name) for name in names], bins=range(1, 20), density=True, alpha=0.7)\nplt.xlabel('Name length')\nplt.ylabel('Density')\n\nText(0, 0.5, 'Density')\n\n\n\n\n\n\n\n\n\n\n# Attach START and END tokens to each name. Need to add these two to the vocabulary.\nstart_symbol = '^'\nend_symbol = '$'\n\nnames = [start_symbol + name + end_symbol for name in names]\nnames[:5]\n\n['^abhishek$', '^aman$', '^harsh$', '^ayush$', '^aditi$']\n\n\n\n# Find unique characters in the dataset\nvocab = set(''.join(names))\nvocab = sorted(vocab)\nprint(vocab, len(vocab))\n\n['$', '^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] 28\n\n\n\n# Create a d dimensional lookup table for each character in the vocabulary\nclass CharTable:\n    def __init__(self, vocab):\n        self.vocab = vocab\n        self.char2index = {c: i for i, c in enumerate(vocab)}\n        self.index2char = {i: c for i, c in enumerate(vocab)}\n        self.vocab_size = len(vocab)\n    \n    def encode(self, name):\n        return torch.tensor([self.char2index[c] for c in name])\n    \n    def decode(self, tensor):\n        if type(tensor) == torch.Tensor:\n            tensor = tensor.cpu().numpy()\n        return ''.join([self.index2char[i] for i in tensor])\n\n\nct = CharTable(vocab)\n\nLet us process the first name in the dataset\n\n# create embedding layer\nclass CharEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_size):\n        super(CharEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        \n    def forward(self, x):\n        return self.embedding(x)\n\nembedding_dim = 8\nchar_embedding = CharEmbedding(ct.vocab_size, embedding_dim )\n\n\nname = names[0]\n\nencoding = ct.encode(name)\nprint(name, encoding, ct.decode(encoding), char_embedding(encoding))\n\n^abhishek$ tensor([ 1,  2,  3,  9, 10, 20,  9,  6, 12,  0]) ^abhishek$ tensor([[-1.3499, -0.8886, -0.6833, -2.4340, -0.3476, -0.2824,  0.3694, -1.2859],\n        [ 0.6961, -0.3760, -1.1183,  2.2782, -1.3446,  0.2088,  0.4919, -0.1777],\n        [-0.3584,  0.3688,  0.3429,  0.2168,  2.0347, -1.5288, -0.4697, -0.3612],\n        [-1.5195,  2.0605,  0.2935,  0.0287,  0.2705, -1.4502, -0.6650,  0.3143],\n        [-0.6630,  0.0302,  0.4576,  0.3651, -1.6005, -0.5861, -1.9137, -0.4006],\n        [ 0.0552,  0.1175,  1.7384,  0.0691,  1.1881,  0.1506, -0.3215,  2.6402],\n        [-1.5195,  2.0605,  0.2935,  0.0287,  0.2705, -1.4502, -0.6650,  0.3143],\n        [-0.1919,  1.4137,  0.0158, -0.0030, -0.6109,  0.4661, -0.1131,  0.2733],\n        [ 0.8686,  0.3222, -0.2661,  2.1850, -1.3195, -0.6661,  0.8780,  0.2122],\n        [ 0.6729,  0.4587, -0.3165,  1.4831,  0.1030, -1.4689,  0.4894,  1.2956]],\n       grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\nprint(char_embedding(encoding).shape)\n\ntorch.Size([10, 8])\n\n\n\nxs=[]\nfor i in range(len(name)):\n    xs.append(char_embedding(ct.encode(name[i])))\n\n\nlength_name = len(name)\n\n\nd = 4\nval_linear = nn.Linear(embedding_dim, embedding_dim)\n\nquery_linear = nn.Linear(embedding_dim, d)\nkey_linear = nn.Linear(embedding_dim, d)\n\n\nvs = []\nfor i in range(length_name):\n    vs.append(val_linear(xs[i]))\n\n\nvs\n\n[tensor([[-0.5005,  1.1128,  0.8048,  0.3994,  0.8465, -1.2007, -0.3687,  0.2159]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.2514, -0.1905, -0.5204,  0.0249, -0.1457,  0.2114,  0.3625,  0.5944]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.2653, -0.4796, -0.9962,  0.3799,  0.1251,  0.3504,  0.2554, -0.4853]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.1296, -0.0862, -0.9042, -0.4130, -0.2025, -0.7218,  0.4927, -0.0048]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-1.1825,  0.4473, -0.7623, -0.5004, -0.6020, -0.9123, -0.4412,  0.3128]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.5342, -0.9138, -0.6400, -0.0377, -0.0354,  0.3041, -1.2578,  0.3234]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.1296, -0.0862, -0.9042, -0.4130, -0.2025, -0.7218,  0.4927, -0.0048]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.0751, -0.1357, -0.5498, -0.0227,  0.0025, -0.0453, -0.2706, -0.0690]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.1425, -0.2478, -0.5700, -0.0055, -0.2560,  0.2981,  0.7119,  0.5840]],\n        grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.9592, -0.7415, -0.7288, -0.1082,  0.1099, -0.0595,  0.4140,  0.6418]],\n        grad_fn=&lt;AddmmBackward0&gt;)]\n\n\n\nqs = []\nfor i in range(length_name):\n    qs.append(query_linear(xs[i]))\n\nks = []\nfor i in range(length_name):\n    ks.append(key_linear(xs[i]))\n    \n\n\nqs\n\n[tensor([[-0.5431, -0.8826, -2.0655,  0.3620]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.2952, -0.6107, -0.4607,  1.6180]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[0.3232, 0.1415, 0.1938, 0.1639]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.0149, -0.6881, -0.9877,  0.9795]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 1.0182,  0.6256,  1.4679, -0.5539]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.2207, -0.9287, -0.9676,  0.4366]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.0149, -0.6881, -0.9877,  0.9795]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.6503, -1.5170, -0.6902,  1.8153]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.2690, -0.6013, -0.9059,  0.4749]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[ 0.2936, -0.5395, -0.8663,  0.6923]], grad_fn=&lt;AddmmBackward0&gt;)]\n\n\n\nks\n\n[tensor([[-0.0686, -0.6523, -0.3398, -0.2891]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-1.8098, -0.3927, -0.2086,  0.4891]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.5030,  0.1248, -0.1280, -0.0116]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.9497, -0.3944, -0.1638,  0.1935]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[0.2378, 0.7928, 0.6968, 0.3017]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.0548,  0.0063,  0.2924,  0.2715]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.9497, -0.3944, -0.1638,  0.1935]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-1.5675,  0.1323, -0.1190,  0.7133]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.4218, -0.1489, -0.2049, -0.0142]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.5909, -0.3664,  0.1543,  0.2502]], grad_fn=&lt;AddmmBackward0&gt;)]\n\n\n\nattns = torch.zeros(length_name, length_name)\nfor i in range(length_name):\n    for j in range(length_name):\n        attns[i, j] = torch.matmul(qs[i], ks[j].T)\n\n\nattns\n\ntensor([[ 1.2102,  1.9374,  0.4234,  1.2723, -2.1590, -0.4814,  1.2723,  1.2385,\n          0.7785,  0.4162],\n        [ 0.0670,  0.5930, -0.1845,  0.3490, -0.2468,  0.2845,  0.3490,  0.6654,\n          0.0378,  0.3831],\n        [-0.2277, -0.6008, -0.1716, -0.3628,  0.3736,  0.0843, -0.3628, -0.3941,\n         -0.1994, -0.1719],\n        [ 0.5024,  0.9822,  0.0367,  0.6368, -0.9418, -0.0264,  0.6368,  0.7484,\n          0.2971,  0.3536],\n        [-0.8166, -2.6654, -0.6156, -1.5613,  1.5939,  0.2270, -1.5613, -2.0829,\n         -0.8154, -0.7429],\n        [ 0.8236,  1.1794,  0.1140,  0.8188, -1.3313, -0.1581,  0.8188,  0.6496,\n          0.4234,  0.4306],\n        [ 0.5024,  0.9822,  0.0367,  0.6368, -0.9418, -0.0264,  0.6368,  0.7484,\n          0.2971,  0.3536],\n        [ 0.7440,  2.8044,  0.2052,  1.6802, -1.2906,  0.3171,  1.6802,  2.1955,\n          0.6157,  1.2878],\n        [ 0.5812,  1.1442,  0.1708,  0.7329, -1.0286, -0.1250,  0.7329,  0.7886,\n          0.3818,  0.3583],\n        [ 0.4260,  0.1997, -0.1121,  0.2098, -0.7526, -0.0848,  0.2098,  0.0653,\n          0.1241,  0.0637]], grad_fn=&lt;CopySlices&gt;)\n\n\n\n# applt softmax to get attention weights\nattns = F.softmax(attns, dim=-1)\nattns\n\ntensor([[0.1023, 0.1169, 0.0955, 0.1031, 0.0907, 0.0924, 0.1031, 0.1026, 0.0979,\n         0.0955],\n        [0.0981, 0.1038, 0.0964, 0.1008, 0.0960, 0.1001, 0.1008, 0.1049, 0.0979,\n         0.1012],\n        [0.0994, 0.0965, 0.0999, 0.0982, 0.1074, 0.1029, 0.0982, 0.0980, 0.0996,\n         0.0999],\n        [0.1007, 0.1075, 0.0967, 0.1022, 0.0927, 0.0963, 0.1022, 0.1037, 0.0987,\n         0.0992],\n        [0.0938, 0.0899, 0.0949, 0.0914, 0.1571, 0.1030, 0.0914, 0.0905, 0.0938,\n         0.0942],\n        [0.1031, 0.1091, 0.0964, 0.1031, 0.0918, 0.0950, 0.1031, 0.1010, 0.0987,\n         0.0988],\n        [0.1007, 0.1075, 0.0967, 0.1022, 0.0927, 0.0963, 0.1022, 0.1037, 0.0987,\n         0.0992],\n        [0.0942, 0.1282, 0.0924, 0.1010, 0.0905, 0.0927, 0.1010, 0.1091, 0.0937,\n         0.0973],\n        [0.1007, 0.1092, 0.0971, 0.1025, 0.0924, 0.0953, 0.1025, 0.1032, 0.0987,\n         0.0985],\n        [0.1043, 0.1013, 0.0983, 0.1014, 0.0945, 0.0985, 0.1014, 0.0999, 0.1005,\n         0.0999]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.imshow(attns.detach().numpy(), cmap='hot', interpolation='nearest')\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(attns.detach().numpy())\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n0\n0.102279\n0.116902\n0.095548\n0.103101\n0.090652\n0.092365\n0.103101\n0.102647\n0.097894\n0.095509\n\n\n1\n0.098137\n0.103838\n0.096373\n0.100781\n0.096004\n0.100102\n0.100781\n0.104920\n0.097907\n0.101158\n\n\n2\n0.099379\n0.096506\n0.099920\n0.098203\n0.107403\n0.102867\n0.098203\n0.097955\n0.099648\n0.099917\n\n\n3\n0.100661\n0.107542\n0.096716\n0.102229\n0.092731\n0.096318\n0.102229\n0.103722\n0.098675\n0.099177\n\n\n4\n0.093831\n0.089897\n0.094899\n0.091359\n0.157125\n0.103029\n0.091359\n0.090467\n0.093837\n0.094197\n\n\n5\n0.103120\n0.109096\n0.096438\n0.103056\n0.091776\n0.094960\n0.103056\n0.100971\n0.098732\n0.098796\n\n\n6\n0.100661\n0.107542\n0.096716\n0.102229\n0.092731\n0.096318\n0.102229\n0.103722\n0.098675\n0.099177\n\n\n7\n0.094160\n0.128211\n0.092408\n0.100973\n0.090542\n0.092696\n0.100973\n0.109109\n0.093650\n0.097276\n\n\n8\n0.100667\n0.109200\n0.097085\n0.102458\n0.092360\n0.095326\n0.102458\n0.103196\n0.098727\n0.098525\n\n\n9\n0.104278\n0.101318\n0.098286\n0.101434\n0.094502\n0.098512\n0.101434\n0.099883\n0.100485\n0.099867\n\n\n\n\n\n\n\n\ndf.sum(axis=1)\n\n0    1.0\n1    1.0\n2    1.0\n3    1.0\n4    1.0\n5    1.0\n6    1.0\n7    1.0\n8    1.0\n9    1.0\ndtype: float32\n\n\n\nupdated_embedding_1.shape\n\ntorch.Size([10, 10, 8])\n\n\n\nvs[0].shape\n\ntorch.Size([1, 8])"
  },
  {
    "objectID": "posts/2017-08-12-linear-regression-adagrad-vs-gd.html",
    "href": "posts/2017-08-12-linear-regression-adagrad-vs-gd.html",
    "title": "Linear regression adagrad vs gd",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- optimization- gradient-descent- adagrad- linear-regression- algorithmsdate: ’2017-08-12’output-file: 2017-08-12-linear-regression-adagrad-vs-gd.htmltitle: Linear regression adagrad vs gdtoc: true—\nIn this post, I’ll be using Adagrad for solving linear regression. As usual, the purpose of this post is educational. This link gives a good overview of Adagrad alongwith other variants of Gradient Descent. To summarise from the link:\n\nIt adapts the learning rate to the parameters, performing larger updates for infrequent and smaller updates for frequent parameters. For this reason, it is well-suited for dealing with sparse data.\n\nAs I’d done previously, I’ll be using Autograd to compute the gradients. Please note Autograd and not Adagrad!\n\nFormulation ([borrowed from here])((http://ruder.io/optimizing-gradient-descent/)))\nIn regular gradient descent, we would update the \\(i^{th}\\) parameter in the \\(t+1^{th}\\) iteration, given the learning rate \\(\\eta\\), where \\(g_{t, i}\\) represents the gradient of the cost wrt \\(i^{th}\\) param at time \\(t\\).\n\\[ \\theta_{t+1, i} = \\theta_{t, i} - \\eta \\cdot g_{t, i}  \\tag{Eq 1} \\]\nIn Adagrad, we update as follows:\n\\[\\theta_{t+1, i} = \\theta_{t, i} - \\dfrac{\\eta}{\\sqrt{G_{t, ii} + \\epsilon}} \\cdot g_{t, i} \\tag{Eq 2}\\]\nHere,\n\\(G_{t} \\in \\mathbb{R}^{d \\times d}\\) is a diagonal matrix where each diagonal element \\(i, i\\) is the sum of the squares of the gradients w.r.t. \\(\\theta_i\\) up to time step \\(t\\) , while \\(\\epsilon\\) is a smoothing term that avoids division by zero (usually on the order of 1e−8).\n\n\nCustomary imports\n\nimport autograd.numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\n\n\nTrue model\n\\[Y = 10 X + 6\\]\n\n\nGenerating data\n\nnp.random.seed(0)\nn_samples = 50\nX = np.linspace(1, 50, n_samples)\nY = 10*X + 6 + 2*np.random.randn(n_samples)\n\n\nplt.plot(X, Y, 'k.')\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\");\n\n\n\n\n\n\n\n\n\n\nModel to be learnt\nWe want to learn W and b such that:\n\\[Y = 10 W+ b\\]\n\n\nDefining the cost function\nWe will now write a general cost function that accepts a list of parameters.\n\ndef cost(param_list):\n    w, b = param_list\n    pred = w*X+b\n    return np.sqrt(((pred - Y) ** 2).mean(axis=None))/(2*len(Y))\n\n\n\nDry run of cost and gradient functioning\n\n# Cost of w=0, b=0\nw, b = 0., 0.\nprint(\"Cost at w={}, b={} is: {}\".format(w, b, cost([w, b])))\n\n# Cost of w=10, b=4. Should be lower than w=0, b=0\nw, b = 10., 4.\nprint(\"Cost at w={}, b={} is: {}\".format(w, b, cost([w, b])))\n\n# Computing the gradient at w=0, b=0\nfrom autograd import grad\ngrad_cost =grad(cost)\nw, b = 0., 0.\nprint(\"Gradient at w={}, b={} is: {}\".format(w, b, grad_cost([w, b])))\n\n# Computing the gradient at w=10, b=4. We would expect it to be smaller than at 0, 0\nw, b = 10., 4.\nprint(\"Gradient at w={}, b={} is: {}\".format(w, b, grad_cost([w, b])))\n\nCost at w=0.0, b=0.0 is: 2.98090446495\nCost at w=10.0, b=4.0 is: 0.0320479471939\nGradient at w=0.0, b=0.0 is: [array(-0.29297046699711365), array(-0.008765162440358071)]\nGradient at w=10.0, b=4.0 is: [array(-0.14406455246023858), array(-0.007117830452061141)]\n\n\n\n\nAdagrad algorithm (applied on whole data batch)\n\ndef adagrad_gd(param_init, cost, niter=5, lr=1e-2, eps=1e-8, random_seed=0):\n    \"\"\"\n    param_init: List of initial values of parameters\n    cost: cost function\n    niter: Number of iterations to run\n    lr: Learning rate\n    eps: Fudge factor, to avoid division by zero\n    \"\"\"\n    from copy import deepcopy\n    import math\n    # Fixing the random_seed\n    np.random.seed(random_seed)\n    \n    # Function to compute the gradient of the cost function\n    grad_cost = grad(cost)\n    params = deepcopy(param_init)\n    param_array, grad_array, lr_array, cost_array = [params], [], [[lr for _ in params]], [cost(params)]\n    # Initialising sum of squares of gradients for each param as 0\n    sum_squares_gradients = [np.zeros_like(param) for param in params]\n    for i in range(niter):\n        out_params = []\n        gradients = grad_cost(params)\n        # At each iteration, we add the square of the gradients to `sum_squares_gradients`\n        sum_squares_gradients= [eps + sum_prev + np.square(g) for sum_prev, g in zip(sum_squares_gradients, gradients)]\n        # Adapted learning rate for parameter list\n        lrs = [np.divide(lr, np.sqrt(sg)) for sg in sum_squares_gradients]\n        # Paramter update\n        params = [param-(adapted_lr*grad_param) for param, adapted_lr, grad_param in zip(params, lrs, gradients)]\n        param_array.append(params)\n        lr_array.append(lrs)\n        grad_array.append(gradients)\n        cost_array.append(cost(params))\n        \n    return params, param_array, grad_array, lr_array, cost_array\n\n\n\nExperiment time!\n\nEvolution of learning rates for W and b\nLet us see how the learning rate for W and b will evolve over time. I will fix the initial learning rate to 0.01 as mot of the Adagrad literature out there seems to suggest.\n\n# Fixing the random seed for reproducible init params for `W` and `b`\nnp.random.seed(0)\nparam_init = [np.random.randn(), np.random.randn()]\nlr = 0.01\neps=1e-8\nniter=1000\nada_params, ada_param_array, ada_grad_array, ada_lr_array, ada_cost_array = adagrad_gd(param_init, cost, niter=niter, lr=lr, eps=eps)\n\nLet us first see the evolution of cost wrt time\n\npd.Series(ada_cost_array, name='Cost').plot(title='Adagrad: Cost v/s # Iterations')\nplt.ylabel(\"Cost\")\nplt.xlabel(\"# Iterations\");\n\n\n\n\n\n\n\n\nOk. While There seems to be a drop in the cost, the converegence will be very slow. Remember that we had earlier found\n\nCost at w=10.0, b=4.0 is: 0.0320479471939\n\nI’m sure this means that our parameter estimates are similar to the initial parameters and far from the true parameters. Let’s just confirm the same.\n\nprint(\"After {} iterations, learnt `W` = {} and learnt `b` = {}\".format(niter, *ada_params))\n\nAfter 1000 iterations, learnt `W` = 2.38206194526 and learnt `b` = 1.01811878873\n\n\nI would suspect that the learning rate, courtesy of the adaptive nature is falling very rapidly! How would the vanilla gradient descent have done starting with the same learning rate and initial values? My hunch is it would do better. Let’s confirm!\n\n\nGD vs Adagrad!\n\ndef gd(param_init, cost,  niter=5, lr=0.01, random_seed=0):\n    np.random.seed(random_seed)\n    from copy import deepcopy\n    grad_cost = grad(cost)\n    params = deepcopy(param_init)\n    param_array, grad_array, cost_array = [params], [], [cost(params)]\n    for i in range(niter):\n        out_params = []\n        gradients = grad_cost(params)\n        params = [param-lr*grad_param for param, grad_param in zip(params, gradients)]\n        param_array.append(params)\n        grad_array.append(gradients)\n        cost_array.append(cost(params))\n    return params, param_array, grad_array, cost_array\n\n\n# Fixing the random seed for reproducible init params for `W` and `b`\nnp.random.seed(0)\nparam_init = [np.random.randn(), np.random.randn()]\nlr = 0.01\nniter=1000\ngd_params, gd_param_array, gd_grad_array, gd_cost = gd(param_init, cost, niter=niter, lr=lr)\n\n\npd.Series(ada_cost_array, name='Cost').plot(label='Adagrad')\npd.Series(gd_cost, name='Cost').plot(label='GD')\nplt.ylabel(\"Cost\")\nplt.xlabel(\"# Iterations\")\nplt.legend()\n\n\n\n\n\n\n\n\nOk. So, indeed with learning rate of 0.01, gradient descent fares better. Let’s just confirm that for Adagrad, the learning rates diminish rapidly leading to little reduction in cost!\n\npd.DataFrame(np.array(ada_lr_array), columns=['LR for W', 'LR for b'])[::50].plot(subplots=True, marker='o')\nplt.xlabel(\"# Iterations\")\n\n\n\n\n\n\n\n\nThere are a couple of interesting observations:\n\nThe learning rate for b actually increases from its initial value of 0.01. Even after 1000 iterations, it remains more than its initial value. This can be explained by the fact that the suim of squares gradients wrt b would be less than 1. Thus, the denominator term by which the learning rate gets divided will be less than 1. Thus, increasing the learning rate wrt b. This can however be fixed by choosing \\(\\epsilon=1.0\\)\nThe learning rate for W falls very rapidly. Learning would be negligble for W after the initial few iterations. This can be fixed by choosing a larger initial learning rate \\(\\eta\\).\n\n\n\nEvolution of W and b, wrt \\(\\eta\\) and \\(\\epsilon\\)\n\n# Fixing the random seed for reproducible init params for `W` and `b`\nout = {}\nfor lr in [0.01, 0.1, 1, 10]:\n    out[lr] = {}\n    for eps in [1e-8, 1e-1, 1]:\n        print(lr, eps)\n        np.random.seed(0)\n        param_init = [np.random.randn(), np.random.randn()]\n        niter=10000\n        ada_params, ada_param_array, ada_grad_array, ada_lr_array, ada_cost_array = adagrad_gd(param_init,\n                                                                                               cost, \n                                                                                               niter=niter,\n                                                                                               lr=lr, \n                                                                                               eps=eps)\n        out[lr][eps] = {'Final-params':ada_params,\n                       'Param-array':ada_param_array,\n                       'Cost-array':ada_cost_array}\n\n(0.01, 1e-08)\n(0.01, 0.1)\n(0.01, 1)\n(0.1, 1e-08)\n(0.1, 0.1)\n(0.1, 1)\n(1, 1e-08)\n(1, 0.1)\n(1, 1)\n(10, 1e-08)\n(10, 0.1)\n(10, 1)\n\n\n\nPlotting cost v/s # Iterations\n\nfig, ax = plt.subplots(nrows=3, ncols=4, sharex=True, figsize=(8, 6), sharey=True)\nfor row, eps in enumerate([1e-8, 1e-1, 1]):\n    for column, lr in enumerate([0.01, 0.1, 1, 10]):\n        pd.Series(out[lr][eps]['Cost-array']).plot(ax=ax[row, column])\n        ax[0, column].set_title(\"Eta={}\".format(lr))\n    ax[row, 0].set_ylabel(\"Eps={}\".format(eps))\nfig.text(0.5, 0.0, '# Iterations')\nplt.suptitle(\"Cost v/s # Iterations\");\n\n\n\n\n\n\n\n\nIt seems that choosing \\(\\eta=1\\) or above the cost usually converges quickly. This seems to be different from most literature recommending \\(\\eta=0.01\\). Aside: I confirmed that even using Tensorflow on the same dataset with Adagrad optimizer, the optimal learning rates are similar to the ones we found here!\n\n\nW v/s # Iterations\n\nfig, ax = plt.subplots(nrows=3, ncols=4, sharex=True, figsize=(8, 6), sharey=True)\nfor row, eps in enumerate([1e-8, 1e-1, 1]):\n    for column, lr in enumerate([0.01, 0.1, 1, 10]):\n        pd.DataFrame(out[lr][eps]['Param-array'])[0].plot(ax=ax[row, column])\n        ax[0, column].set_title(\"Eta={}\".format(lr))\n    ax[row, 0].set_ylabel(\"Eps={}\".format(eps))\nfig.text(0.5, 0.0, '# Iterations')\nplt.suptitle(\"W v/s # Iterations\");\n\n\n\n\n\n\n\n\n\n\nb v/s # Iterations\n\nfig, ax = plt.subplots(nrows=3, ncols=4, sharex=True, figsize=(8, 6), sharey=True)\nfor row, eps in enumerate([1e-8, 1e-1, 1]):\n    for column, lr in enumerate([0.01, 0.1, 1, 10]):\n        pd.DataFrame(out[lr][eps]['Param-array'])[1].plot(ax=ax[row, column])\n        ax[0, column].set_title(\"Eta={}\".format(lr))\n    ax[row, 0].set_ylabel(\"Eps={}\".format(eps))\nfig.text(0.5, 0.0, '# Iterations')\nplt.suptitle(\"b v/s # Iterations\");\n\n\n\n\n\n\n\n\nAcross the above two plots, we can see that at high \\(\\eta\\), there are oscillations! In general, \\(\\eta=1\\) and \\(\\epsilon=1e-8\\) seem to give the best set of results.\n\n\n\nVisualising the model learning\n\nfrom matplotlib.animation import FuncAnimation\n\nfig, ax = plt.subplots(nrows=3, ncols=4, sharex=True, figsize=(8, 6), sharey=True)\n\ndef update(i):\n    #fig.clf()\n    for row, eps in enumerate([1e-8, 1e-1, 1]):\n        for column, lr in enumerate([0.01, 0.1, 1, 10]):\n            params_i =  out[lr][eps]['Param-array'][i]\n            ax[row, column].cla()\n            w_i, b_i = params_i\n            ax[row, column].plot(X, Y, 'k.', ms=1)\n            ax[row, column].plot(X, w_i*X+b_i, 'r')\n            ax[row, column].tick_params( #https://stackoverflow.com/questions/12998430/remove-xticks-in-a-matplotlib-plot\n                axis='both',         \n                which='both',      \n                bottom='off', \n                left='off',\n                top='off',         \n                labelbottom='off',\n                labelleft='off') \n            ax[0, column].set_title(\"Eta={}\".format(lr))\n        ax[row, 0].set_ylabel(\"Eps={}\".format(eps))\n    fig.suptitle(\"Iteration number: {}\".format(i))\n\nanim = FuncAnimation(fig, update, frames=np.arange(0, 5000, 200), interval=500)\nanim.save('adagrad.gif', dpi=80, writer='imagemagick')\nplt.close()\n\n\nSo, there you go. Implementing Adagrad and running this experiment was a lot of fun and learning. Feel free to comment!"
  },
  {
    "objectID": "posts/2018-06-26-map-electricity-access.html",
    "href": "posts/2018-06-26-map-electricity-access.html",
    "title": "Visualising Electricity Access Over Space and Time",
    "section": "",
    "text": "In this post, I’ll explore electricity access, i.e. globally what fraction of people have access to electricity. Beyond the goal of finding the electricity access, this post will also serve to illustrate how the coolness coefficient of the Python visualisation ecosystem!\nI’ll be using data from World Bank for electricity access. See the image below for the corresponding page.\n\n\nDownloading World Bank data\nNow, a Python package called wbdata provides a fairly easy way to access World Bank data. I’d be using it to get data in Pandas DataFrame.\n\n%matplotlib inline\nimport pandas as pd\nimport wbdata\nimport matplotlib.pyplot as plt\nimport datetime\ndata_date = (datetime.datetime(1990, 1, 1), datetime.datetime(2016, 1, 1))\ndf_elec = wbdata.get_data(\"EG.ELC.ACCS.ZS\", pandas=True, data_date=data_date)\n\n\ndf_elec.head()\n\ncountry     date\nArab World  2016    88.768654\n            2015    88.517967\n            2014    88.076774\n            2013    88.389705\n            2012    87.288244\nName: value, dtype: float64\n\n\n\n\nDownloading Geodata and Reading Using GeoPandas\nI’d now be downloading shapefile data for different countries. This will help us to spatially plot the data for the different countries.\n\n!wget http://naciscdn.org/naturalearth/10m/cultural/ne_10m_admin_0_countries_lakes.zip\n\n--2018-06-26 15:52:50--  http://naciscdn.org/naturalearth/10m/cultural/ne_10m_admin_0_countries_lakes.zip\nResolving naciscdn.org (naciscdn.org)... 146.201.97.163\nConnecting to naciscdn.org (naciscdn.org)|146.201.97.163|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5077755 (4.8M) [application/x-zip-compressed]\nSaving to: ‘ne_10m_admin_0_countries_lakes.zip’\n\nne_10m_admin_0_coun 100%[===================&gt;]   4.84M   246KB/s    in 22s     \n\n2018-06-26 15:53:12 (228 KB/s) - ‘ne_10m_admin_0_countries_lakes.zip’ saved [5077755/5077755]\n\n\n\n\nExtracting shapefile\n\nimport zipfile\nzip_ref = zipfile.ZipFile('ne_10m_admin_0_countries_lakes.zip', 'r')\nzip_ref.extractall('.')\nzip_ref.close()\n\n\nimport geopandas as gpd\ngdf = gpd.read_file('ne_10m_admin_0_countries_lakes.shp')[['ADM0_A3', 'geometry']]\n\n\ngdf.head()\n\n\n\n\n\n\n\n\nADM0_A3\ngeometry\n\n\n\n\n0\nIDN\n(POLYGON ((117.7036079039552 4.163414542001791...\n\n\n1\nMYS\n(POLYGON ((117.7036079039552 4.163414542001791...\n\n\n2\nCHL\n(POLYGON ((-69.51008875199994 -17.506588197999...\n\n\n3\nBOL\nPOLYGON ((-69.51008875199994 -17.5065881979999...\n\n\n4\nPER\n(POLYGON ((-69.51008875199994 -17.506588197999...\n\n\n\n\n\n\n\n\n\n\nVisualising electricity access in 2016\n\nGetting electricity access data for 2016\n\ndf_2016 = df_elec.unstack()[['2016']].dropna()\n\n\ndf_2016.head()\n\n\n\n\n\n\n\ndate\n2016\n\n\ncountry\n\n\n\n\n\nAfghanistan\n84.137138\n\n\nAlbania\n100.000000\n\n\nAlgeria\n99.439568\n\n\nAndorra\n100.000000\n\n\nAngola\n40.520607\n\n\n\n\n\n\n\nIn order to visualise electricity access data over the map, we would have to join the GeoPandas object gdf and df_elec\n\n\nJoining gdf and df_2016\nNow, gdf uses alpha_3 codes for country names like AFG, etc., whereas df_2016 uses country names. We will thus use pycountry package to get code names corresponding to countries in df_2016 as shown in this StackOverflow post.\n\nimport pycountry\ncountries = {}\nfor country in pycountry.countries:\n    countries[country.name] = country.alpha_3\ncodes = [countries.get(country, 'Unknown code') for country in df_2016.index]\ndf_2016['Code'] = codes\n\n\ndf_2016.head()\n\n\n\n\n\n\n\ndate\n2016\nCode\n\n\ncountry\n\n\n\n\n\n\nAfghanistan\n84.137138\nAFG\n\n\nAlbania\n100.000000\nALB\n\n\nAlgeria\n99.439568\nDZA\n\n\nAndorra\n100.000000\nAND\n\n\nAngola\n40.520607\nAGO\n\n\n\n\n\n\n\nNow, we can join the two data sources\n\nmerged_df_2016 = gpd.GeoDataFrame(pd.merge(gdf, df_2016, left_on='ADM0_A3', right_on='Code'))\n\n\nmerged_df_2016.head()\n\n\n\n\n\n\n\n\nADM0_A3\ngeometry\n2016\nCode\n\n\n\n\n0\nIDN\n(POLYGON ((117.7036079039552 4.163414542001791...\n97.620000\nIDN\n\n\n1\nMYS\n(POLYGON ((117.7036079039552 4.163414542001791...\n100.000000\nMYS\n\n\n2\nCHL\n(POLYGON ((-69.51008875199994 -17.506588197999...\n100.000000\nCHL\n\n\n3\nPER\n(POLYGON ((-69.51008875199994 -17.506588197999...\n94.851746\nPER\n\n\n4\nARG\n(POLYGON ((-68.4486097329999 -52.3466170159999...\n100.000000\nARG\n\n\n\n\n\n\n\n\n\nFinally plotting!\n\n# Example borrowed from http://ramiro.org/notebook/geopandas-choropleth/\ncmap='OrRd'\nfigsize = (16, 5)\nax = merged_df_2016.plot(column='2016', cmap=cmap, figsize=figsize,legend=True)\ntitle = 'Electricity Access(% of population) in {}'.format('2016')\ngdf[~gdf.ADM0_A3.isin(merged_df_2016.ADM0_A3)].plot(ax=ax, color='#fffafa', hatch='///')\nax.set_title(title, fontdict={'fontsize': 15}, loc='left')\nax.set_axis_off()\n\n\n\n\n\n\n\n\n\n\n\nCreating animation for access across time\n\n!mkdir -p elec_access\n\n\ndef save_png_year(year, path=\"elec_access\"):\n    df_year = df_elec.unstack()[['{}'.format(year)]].dropna()\n    codes = [countries.get(country, 'Unknown code') for country in df_year.index]\n    df_year['Code'] = codes\n    merged_df_year = gpd.GeoDataFrame(pd.merge(gdf, df_year, left_on='ADM0_A3', right_on='Code'))\n    figsize = (16, 5)\n    ax = merged_df_year.plot(column='{}'.format(year), cmap=cmap, figsize=figsize,legend=True,vmin=0.0, vmax=100.0)\n    title = 'Electricity Access(% of population) in {}'.format(year)\n    gdf[~gdf.ADM0_A3.isin(merged_df_year.ADM0_A3)].plot(ax=ax, color='#fffafa', hatch='///')\n    ax.set_title(title, fontdict={'fontsize': 15}, loc='left')\n    ax.set_axis_off()\n    plt.savefig('{}/{}.png'.format(path, year), dpi=300)\n    plt.close()\n\n\nfor year in range(1990, 2017):\n    save_png_year(year)\n\n\n# Borrowed from http://www.kevinwampler.com/blog/2016/09/10/creating-animated-gifs-using-python.html\ndef create_gifv(input_files, output_base_name, fps):\n    import imageio\n    output_extensions = [\"gif\"]\n    input_filenames = ['elec_access/{}.png'.format(year) for year in range(1990, 2017)]\n\n    poster_writer = imageio.get_writer(\"{}.png\".format(output_base_name), mode='i')\n    video_writers = [\n        imageio.get_writer(\"{}.{}\".format(output_base_name, ext), mode='I', fps=fps)\n        for ext in output_extensions]\n\n    is_first = True\n    for filename in input_filenames:\n        img = imageio.imread(filename)\n\n        for writer in video_writers:\n            writer.append_data(img)\n        if is_first:\n            poster_writer.append_data(img)\n\n        is_first = False\n\n    for writer in video_writers + [poster_writer]:\n        writer.close()\n\n\ncreate_gifv(\"elec_access/*.png\", \"electricity_access\", 4)\n\n\nAcross Africa and SE Asia, one can clearly see a gradual improvement in access! Hope you had fun reading this post :)"
  },
  {
    "objectID": "posts/rl.html",
    "href": "posts/rl.html",
    "title": "Reinforcement Learning",
    "section": "",
    "text": "Reference\n\nDetailed Explanation and Python Implementation of Q-Learning Algorithm in OpenAI Gym (Cart-Pole)\n\n\nBasic Imports\n\nimport matplotlib.pyplot as plt\nimport torch\nimport gymnasium as gym\nimport numpy as np\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n# List of environments\nlist(gym.envs.registry.keys())\n\n['CartPole-v0',\n 'CartPole-v1',\n 'MountainCar-v0',\n 'MountainCarContinuous-v0',\n 'Pendulum-v1',\n 'Acrobot-v1',\n 'phys2d/CartPole-v0',\n 'phys2d/CartPole-v1',\n 'phys2d/Pendulum-v0',\n 'LunarLander-v2',\n 'LunarLanderContinuous-v2',\n 'BipedalWalker-v3',\n 'BipedalWalkerHardcore-v3',\n 'CarRacing-v2',\n 'Blackjack-v1',\n 'FrozenLake-v1',\n 'FrozenLake8x8-v1',\n 'CliffWalking-v0',\n 'Taxi-v3',\n 'tabular/Blackjack-v0',\n 'tabular/CliffWalking-v0',\n 'Reacher-v2',\n 'Reacher-v4',\n 'Pusher-v2',\n 'Pusher-v4',\n 'InvertedPendulum-v2',\n 'InvertedPendulum-v4',\n 'InvertedDoublePendulum-v2',\n 'InvertedDoublePendulum-v4',\n 'HalfCheetah-v2',\n 'HalfCheetah-v3',\n 'HalfCheetah-v4',\n 'Hopper-v2',\n 'Hopper-v3',\n 'Hopper-v4',\n 'Swimmer-v2',\n 'Swimmer-v3',\n 'Swimmer-v4',\n 'Walker2d-v2',\n 'Walker2d-v3',\n 'Walker2d-v4',\n 'Ant-v2',\n 'Ant-v3',\n 'Ant-v4',\n 'Humanoid-v2',\n 'Humanoid-v3',\n 'Humanoid-v4',\n 'HumanoidStandup-v2',\n 'HumanoidStandup-v4',\n 'GymV21Environment-v0',\n 'GymV26Environment-v0']\n\n\n\nenv = gym.make(\"CartPole-v0\")\nobservation, info = env.reset(seed=42)\n\n\n/Users/nipun/miniconda3/lib/python3.9/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: WARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\n\n  logger.deprecation(\n\n\n\n\n\nenv.action_space\n\nDiscrete(2)\n\n\n\nenv.action_space.sample()\n\n1\n\n\n\nenv.action_space.sample()\n\n1\n\n\n\nprint(env.observation_space)\n\nBox([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n\n\n\nobservation\n\narray([ 0.0273956 , -0.00611216,  0.03585979,  0.0197368 ], dtype=float32)\n\n\n\naction = env.action_space.sample()\nprint(action)\n\n0\n\n\n\nobservation, reward, terminated, truncated, info = env.step(action)\n\n\nprint(observation, reward, terminated, truncated, info)\n\n[ 0.02727336 -0.20172954  0.03625453  0.32351476] 1.0 False False {}\n\n\n\nobservation, reward, terminated, truncated, info = env.step(action)\nprint(observation, reward, terminated, truncated, info)\n\n[ 0.02323877 -0.39734846  0.04272482  0.62740684] 1.0 False False {}\n\n\n\nobservation, info = env.reset(seed=42)\nfor i in range(100):\n    action = 1\n    observation, reward, terminated, truncated, info = env.step(action)\n    print(observation, reward, terminated, truncated, info)\n    if terminated:\n        break\n    \n\n[ 0.02727336  0.18847767  0.03625453 -0.26141977] 1.0 False False {}\n[ 0.03104291  0.38306385  0.03102613 -0.5424507 ] 1.0 False False {}\n[ 0.03870419  0.5777363   0.02017712 -0.8251987 ] 1.0 False False {}\n[ 0.05025892  0.7725766   0.00367314 -1.111468  ] 1.0 False False {}\n[ 0.06571045  0.96765006 -0.01855621 -1.4029963 ] 1.0 False False {}\n[ 0.08506345  1.1629975  -0.04661614 -1.7014222 ] 1.0 False False {}\n[ 0.1083234   1.3586243  -0.08064459 -2.0082438 ] 1.0 False False {}\n[ 0.13549589  1.554488   -0.12080947 -2.3247683 ] 1.0 False False {}\n[ 0.16658565  1.7504818  -0.16730483 -2.652048  ] 1.0 False False {}\n[ 0.20159529  1.9464185  -0.22034578 -2.9908078 ] 1.0 True False {}\n\n\n\nobservation, info = env.reset(seed=42)\nfor i in range(100):\n    action = 0\n    observation, reward, terminated, truncated, info = env.step(action)\n    print(observation, reward, terminated, truncated, info)\n    if terminated:\n        break\n    \n\n[ 0.02727336 -0.20172954  0.03625453  0.32351476] 1.0 False False {}\n[ 0.02323877 -0.39734846  0.04272482  0.62740684] 1.0 False False {}\n[ 0.0152918  -0.5930399   0.05527296  0.9332334 ] 1.0 False False {}\n[ 0.003431   -0.7888622   0.07393762  1.2427603 ] 1.0 False False {}\n[-0.01234624 -0.9848512   0.09879284  1.5576583 ] 1.0 False False {}\n[-0.03204326 -1.1810076   0.129946    1.8794562 ] 1.0 False False {}\n[-0.05566342 -1.3772845   0.16753513  2.209486  ] 1.0 False False {}\n[-0.0832091  -1.573571    0.21172485  2.5488186 ] 1.0 True False {}\n\n\n\nfor _ in range(100):\n   action = env.action_space.sample()  # this is where you would insert your policy\n   observation, reward, terminated, truncated, info = env.step(action)\n\n   if terminated or truncated:\n      observation, info = env.reset()\n\n\n\n/Users/nipun/miniconda3/lib/python3.9/site-packages/gymnasium/envs/classic_control/cartpole.py:180: UserWarning: WARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\n\n  logger.warn(\n\n\n\n\n\n# Now, let us take only the action 1\nobservation, info = env.reset(seed=42)\nfor i in range(100):\n   action = 0  # this is where you would insert your policy\n   observation, reward, terminated, truncated, info = env.step(action)\n\n   if terminated or truncated:\n        print(\"Episode finished after {} timesteps\".format(i+1))\n        observation, info = env.reset()\n\nEpisode finished after 8 timesteps\nEpisode finished after 17 timesteps\nEpisode finished after 27 timesteps\nEpisode finished after 37 timesteps\nEpisode finished after 46 timesteps\nEpisode finished after 54 timesteps\nEpisode finished after 64 timesteps\nEpisode finished after 73 timesteps\nEpisode finished after 83 timesteps\nEpisode finished after 93 timesteps\n\n\n\n# Create a q table\nnum_states = env.observation_space.shape[0]\nnum_actions = env.action_space.n\n\n\ni = 1\nbins = np.linspace(env.observation_space.low[i], env.observation_space.high[i], num_bins[i] + 1)[1:-1]\n\n\nnp.digitize([env.observation_space.low[2]], bins)\n\narray([1])\n\n\n\n# Define the number of bins for each dimension\nnum_bins = [4, 4, 4, 4]  # Adjust these values based on your preference\n\n# Discretize the continuous state space\ndef discretize_state(state, num_bins):\n    state_discrete = []\n    for i in range(len(state)):\n        bins = np.linspace(env.observation_space.low[i], env.observation_space.high[i], num_bins[i] + 1)[1:-1]\n        state_discrete.append(np.digitize(state[i], bins))\n    return tuple(state_discrete)\n\n\n# Initialize Q-table with zeros\nq_table = 1e-2*torch.randn(num_bins + [env.action_space.n])\n\ndef update_q_table(q_table, state, action, reward, next_state, learning_rate, discount_factor):\n    state = tuple(state)\n    next_state = tuple(next_state)\n    q_table[state][action] = (1 - learning_rate) * q_table[state][action] + learning_rate * (reward + discount_factor * torch.max(q_table[next_state]))\n\n    return q_table\n\n\nq_table\n\ntensor([[[[[ 7.5282e-03, -5.0158e-03],\n           [ 1.8066e-04, -1.1957e-02],\n           [ 1.7809e-02,  1.9935e-02],\n           [ 1.2077e-02,  1.2135e-03]],\n\n          [[ 1.1068e-02,  1.3167e-02],\n           [-3.6065e-03, -2.3091e-02],\n           [-5.3917e-03, -3.6806e-03],\n           [-2.0194e-02,  1.4977e-02]],\n\n          [[-3.9683e-03, -1.1291e-03],\n           [ 1.6093e-03,  1.7743e-02],\n           [ 3.1133e-03, -1.3254e-02],\n           [-2.2300e-03,  1.5660e-02]],\n\n          [[-9.9277e-03, -3.0461e-03],\n           [ 1.5977e-02, -9.5863e-03],\n           [ 9.4414e-03, -4.6137e-03],\n           [-6.0294e-03,  3.8514e-03]]],\n\n\n         [[[ 3.2934e-03, -2.7038e-03],\n           [ 1.1472e-03, -7.2562e-03],\n           [ 7.2273e-03, -7.4928e-03],\n           [-3.5465e-03, -1.3511e-02]],\n\n          [[-1.1883e-02, -3.6573e-03],\n           [-9.0871e-03, -1.4479e-02],\n           [ 1.2498e-04,  2.4612e-03],\n           [-1.4339e-02, -3.3635e-03]],\n\n          [[ 1.4458e-02,  2.2707e-02],\n           [ 1.1106e-03, -1.9436e-02],\n           [ 1.7882e-02,  5.9812e-03],\n           [ 2.0743e-02, -8.5244e-03]],\n\n          [[-3.0426e-03, -1.1320e-03],\n           [-1.7067e-02,  5.2065e-03],\n           [ 5.5506e-03, -2.2826e-03],\n           [-3.7662e-03, -9.6092e-03]]],\n\n\n         [[[ 4.2712e-03, -1.7112e-02],\n           [-7.6057e-04,  1.5980e-02],\n           [ 2.6001e-03,  4.0400e-03],\n           [-1.3805e-03, -1.1307e-02]],\n\n          [[ 5.0641e-03, -1.3241e-02],\n           [ 1.7783e-03,  8.7516e-03],\n           [-9.8789e-03, -9.4022e-03],\n           [ 1.1799e-02, -8.4989e-03]],\n\n          [[-8.7781e-03, -1.9099e-02],\n           [-2.1311e-03,  1.3072e-02],\n           [-9.6554e-03, -9.8139e-03],\n           [ 1.0881e-02, -7.0734e-03]],\n\n          [[-1.2324e-02, -1.8049e-02],\n           [ 2.6147e-03,  7.3541e-03],\n           [-1.2201e-02, -2.3215e-02],\n           [ 1.8518e-02,  1.3268e-02]]],\n\n\n         [[[-3.7732e-04,  6.0749e-03],\n           [ 9.5228e-03,  1.7512e-03],\n           [-6.6485e-03, -6.8077e-04],\n           [-1.4016e-02,  4.3504e-03]],\n\n          [[-1.1826e-02,  3.7322e-03],\n           [-1.4521e-02, -5.1530e-03],\n           [-8.8820e-04,  5.4113e-03],\n           [ 1.0400e-02, -1.4762e-03]],\n\n          [[ 1.0607e-02,  6.7451e-03],\n           [ 1.0964e-02,  2.8386e-03],\n           [ 5.6247e-03,  1.0890e-02],\n           [ 4.6335e-03, -3.7274e-03]],\n\n          [[-9.0740e-03,  6.4783e-03],\n           [-1.2299e-03, -5.6999e-03],\n           [-1.6512e-02,  1.0905e-02],\n           [ 2.4370e-03, -1.5498e-02]]]],\n\n\n\n        [[[[ 8.5643e-03,  1.1855e-02],\n           [-4.0238e-03, -1.9470e-02],\n           [ 8.6876e-03, -1.3815e-03],\n           [ 1.3968e-02, -1.1944e-02]],\n\n          [[-4.9274e-03, -3.5420e-03],\n           [ 1.1639e-02, -3.9007e-03],\n           [-6.9517e-03, -9.7298e-03],\n           [-9.1168e-03,  1.6739e-03]],\n\n          [[ 9.1662e-03,  3.5723e-04],\n           [-7.4430e-04, -2.2149e-03],\n           [-3.0224e-03,  1.0551e-02],\n           [-5.0447e-03, -1.4064e-02]],\n\n          [[-3.5565e-03, -7.7704e-04],\n           [-7.0354e-03,  8.5815e-03],\n           [-8.7700e-03, -1.2051e-02],\n           [ 8.8658e-03, -2.5521e-02]]],\n\n\n         [[[-1.2974e-03, -8.8698e-03],\n           [-3.6456e-03,  1.5029e-02],\n           [-8.8230e-03,  9.4439e-03],\n           [ 2.5990e-03,  1.5128e-02]],\n\n          [[ 5.6906e-03,  4.9925e-03],\n           [ 1.2224e-04, -1.1197e-02],\n           [-1.9241e-02,  2.9079e-03],\n           [ 7.9246e-03, -1.4221e-02]],\n\n          [[ 1.8949e-04, -9.8628e-03],\n           [-1.2586e-02,  2.9915e-02],\n           [ 1.6699e-02, -3.6897e-03],\n           [-6.5158e-03,  1.5208e-03]],\n\n          [[ 2.0201e-04, -2.1695e-02],\n           [-2.6849e-04, -1.5498e-02],\n           [-1.1011e-02,  1.1365e-03],\n           [-7.1765e-03,  1.2924e-02]]],\n\n\n         [[[ 9.7294e-03,  2.4206e-02],\n           [-1.2685e-02, -1.0336e-03],\n           [ 8.7326e-03, -2.7275e-02],\n           [-2.1335e-02,  4.4139e-03]],\n\n          [[-1.5349e-02, -5.3750e-03],\n           [ 5.4290e-03,  3.5145e-03],\n           [ 9.8669e-03,  5.5941e-03],\n           [-2.8471e-03,  4.4822e-03]],\n\n          [[-3.5157e-03,  5.6956e-03],\n           [ 8.4872e-03, -6.3729e-03],\n           [-5.0063e-03, -1.1296e-02],\n           [-1.5232e-02, -1.2576e-02]],\n\n          [[-1.5377e-02,  4.6587e-03],\n           [-1.2515e-02, -8.6466e-03],\n           [-3.5109e-03,  1.8327e-02],\n           [ 5.5513e-03, -7.4427e-03]]],\n\n\n         [[[-1.2366e-02, -1.8556e-02],\n           [-7.6673e-03, -6.9909e-03],\n           [-1.7524e-02, -1.2405e-02],\n           [-2.0454e-04, -1.0710e-02]],\n\n          [[-7.5223e-04,  8.1430e-03],\n           [-4.2421e-03, -2.4979e-03],\n           [-2.6400e-03, -7.0397e-03],\n           [ 7.2088e-03,  1.2598e-02]],\n\n          [[ 5.4684e-03, -2.1672e-03],\n           [ 7.8071e-04,  8.7978e-04],\n           [-4.5486e-03, -1.1562e-02],\n           [-1.2760e-02, -4.7683e-03]],\n\n          [[-5.0534e-03,  2.6844e-02],\n           [ 6.5477e-03, -2.0174e-03],\n           [-2.3228e-03, -1.9718e-03],\n           [-1.0325e-02,  1.4051e-02]]]],\n\n\n\n        [[[[ 1.2235e-02,  3.8194e-03],\n           [-1.2756e-02,  2.0048e-03],\n           [-1.0588e-02, -6.2585e-03],\n           [-1.1622e-02,  7.8146e-03]],\n\n          [[-1.3627e-02,  4.8715e-03],\n           [-2.6081e-03, -1.2547e-02],\n           [ 2.5712e-02,  6.9268e-04],\n           [ 5.7297e-03,  1.6908e-02]],\n\n          [[-6.0016e-03,  3.8388e-03],\n           [-4.2425e-03,  5.6236e-03],\n           [-2.2077e-03,  8.3500e-03],\n           [-6.5338e-03, -5.6204e-03]],\n\n          [[ 3.6226e-03,  6.5813e-03],\n           [ 8.4147e-03, -4.6316e-03],\n           [ 1.1701e-03, -3.8150e-03],\n           [ 3.4847e-03, -1.6027e-02]]],\n\n\n         [[[-1.2393e-03, -8.3570e-03],\n           [ 4.4231e-03, -6.3459e-03],\n           [-6.1139e-04,  5.3770e-03],\n           [ 5.4646e-03,  3.0140e-03]],\n\n          [[-2.6489e-04,  3.1112e-04],\n           [ 4.5194e-03,  3.8941e-03],\n           [-1.0284e-02, -3.8570e-04],\n           [-7.3893e-03,  1.7081e-04]],\n\n          [[ 1.2995e-02,  4.9129e-03],\n           [-3.2257e-03,  4.4844e-03],\n           [-1.6129e-03, -3.0462e-03],\n           [-4.6639e-03,  9.7619e-03]],\n\n          [[-3.7702e-03, -1.7440e-02],\n           [ 2.7172e-03, -7.0420e-04],\n           [ 1.0267e-02,  6.5922e-03],\n           [-4.3092e-03, -6.1909e-03]]],\n\n\n         [[[ 8.2225e-03,  2.0020e-02],\n           [ 1.3149e-02, -1.5706e-02],\n           [ 1.4529e-02,  2.0051e-02],\n           [-3.3207e-03,  2.9005e-03]],\n\n          [[ 1.6814e-02, -1.1611e-02],\n           [ 1.1958e-02, -1.1217e-02],\n           [-7.3994e-03,  3.3478e-03],\n           [-1.9186e-03, -3.3058e-03]],\n\n          [[ 1.8627e-02, -4.3313e-03],\n           [-2.5333e-04,  9.4670e-03],\n           [ 1.6627e-02, -3.7056e-03],\n           [-4.0002e-03, -4.0428e-03]],\n\n          [[-5.8534e-03, -8.5589e-03],\n           [ 1.8699e-02,  1.4041e-02],\n           [-4.5634e-03, -1.2667e-02],\n           [ 2.9807e-03, -1.0735e-02]]],\n\n\n         [[[ 2.3185e-03, -1.1426e-02],\n           [ 1.0432e-02,  8.7466e-03],\n           [-2.0517e-02, -6.4246e-03],\n           [ 1.6325e-02, -2.2658e-03]],\n\n          [[-1.3443e-03, -7.4122e-03],\n           [ 2.6692e-03,  1.6455e-03],\n           [-1.2263e-02, -3.9807e-04],\n           [-1.1106e-02, -1.2117e-03]],\n\n          [[ 1.2348e-02, -4.9474e-03],\n           [-5.5995e-03, -2.2941e-03],\n           [-8.0381e-03,  8.6414e-03],\n           [-1.2672e-02, -8.6333e-03]],\n\n          [[ 2.2708e-03,  1.5464e-02],\n           [-6.9604e-07,  9.0496e-03],\n           [ 4.9665e-03, -1.3779e-04],\n           [ 2.5279e-03, -9.1125e-03]]]],\n\n\n\n        [[[[-4.1377e-03, -5.1594e-04],\n           [-3.2999e-03, -3.2629e-03],\n           [ 1.5395e-02, -1.9373e-03],\n           [-2.1155e-02, -2.2015e-03]],\n\n          [[-4.7272e-03,  4.2632e-03],\n           [-7.7089e-03, -4.4246e-03],\n           [ 1.1186e-02,  1.2331e-02],\n           [-8.5431e-03,  9.3936e-03]],\n\n          [[ 2.0678e-02, -1.5143e-03],\n           [ 1.1107e-03, -1.5056e-03],\n           [-1.5841e-02, -1.0837e-03],\n           [ 1.2758e-03, -1.2761e-03]],\n\n          [[-1.0277e-02, -2.0925e-02],\n           [ 2.1294e-04, -7.8277e-03],\n           [-8.0540e-04,  6.9005e-03],\n           [ 8.6584e-03, -3.0194e-03]]],\n\n\n         [[[ 1.7248e-02, -6.2072e-03],\n           [ 5.1232e-03, -8.9823e-03],\n           [-1.4095e-02, -1.8089e-02],\n           [ 8.5848e-03, -7.7452e-03]],\n\n          [[ 6.3832e-03, -9.4521e-04],\n           [-6.0866e-03, -1.7911e-02],\n           [ 7.1645e-03,  1.8826e-03],\n           [-1.1272e-03, -1.6942e-03]],\n\n          [[-1.9407e-04,  2.6855e-02],\n           [ 2.4922e-03,  4.0395e-03],\n           [-9.0179e-03,  1.1456e-02],\n           [ 6.2417e-03,  1.6225e-03]],\n\n          [[-1.3302e-02, -7.9396e-03],\n           [ 1.6342e-02, -8.3640e-04],\n           [ 8.2515e-03, -1.9994e-02],\n           [-1.5314e-02,  1.1206e-03]]],\n\n\n         [[[-1.6801e-02,  2.5082e-03],\n           [-1.2035e-02,  1.0600e-02],\n           [-3.4271e-03,  8.3387e-03],\n           [ 1.1338e-03, -1.3025e-03]],\n\n          [[-4.3297e-04,  6.9727e-03],\n           [-9.4044e-03, -1.8042e-02],\n           [-1.6318e-02, -1.8721e-03],\n           [ 9.9107e-03, -1.0611e-02]],\n\n          [[ 1.3804e-02, -5.9115e-03],\n           [-8.4717e-03,  1.2661e-02],\n           [ 5.9259e-03,  6.3610e-03],\n           [-1.8119e-03, -1.0934e-02]],\n\n          [[-6.4295e-03,  1.4941e-03],\n           [-1.3924e-02,  1.0059e-02],\n           [ 3.7694e-03,  1.3317e-02],\n           [ 7.0841e-03,  8.2705e-03]]],\n\n\n         [[[ 5.0314e-03, -1.1748e-03],\n           [-6.9476e-03, -6.9823e-05],\n           [ 3.5111e-03, -3.0028e-03],\n           [-6.3763e-03,  1.4920e-03]],\n\n          [[-9.0027e-04, -3.8365e-03],\n           [ 1.1627e-04, -4.9486e-03],\n           [ 1.3806e-02,  5.5603e-03],\n           [-1.1555e-02, -3.8007e-03]],\n\n          [[-3.6884e-04,  1.0951e-02],\n           [ 2.6923e-03,  6.7217e-04],\n           [ 1.1842e-02, -1.7159e-02],\n           [ 1.3960e-04,  8.7688e-03]],\n\n          [[-6.5861e-03,  1.1069e-03],\n           [-9.9205e-03,  1.4599e-02],\n           [-4.2275e-03, -3.8720e-03],\n           [ 1.4915e-02, -2.9827e-03]]]]])\n\n\n\n# Learn the q table\n\n# Hyperparameters\nlearning_rate = 0.1\ndiscount_factor = 0.9\n\n\n# Learn q-table without epsilon greedy approach and print rewards\nnum_episodes = 50\nrender_mode = False\n\n    \n\n\n# Print all possible states\nprint(\"All possible states:\")\nprint(env.observation_space)\n\nAll possible states:\nBox([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n\n\n\n# Print some sample states\nfor _ in range(10):\n    state = env.observation_space.sample()\n    print(\"Sample State:\", state)\n\nSample State: [-2.1946154e+00 -2.5122178e+38  8.9282773e-02 -1.3416754e+38]\nSample State: [ 2.7149630e-01  1.2149416e+37 -9.9354312e-02 -1.2340108e+38]\nSample State: [ 4.0275431e+00 -2.6682660e+38 -2.4785740e-02  2.4654679e+38]\nSample State: [-2.3548093e-01 -6.2527667e+37  3.5589758e-01 -4.8273950e+37]\nSample State: [ 1.6777289e+00 -6.2703186e+37  3.0708086e-01  1.9350419e+38]\nSample State: [-2.8664367e+00 -9.9032201e+37 -4.1302589e-01  3.0742409e+38]\nSample State: [-2.4482067e+00 -6.4236516e+37 -1.9836776e-01  2.5115714e+38]\nSample State: [-4.2023139e+00 -1.8168436e+37 -6.5094754e-02  1.7452279e+38]\nSample State: [-2.8398631e+00 -3.0210992e+38 -1.6737616e-01 -2.1272714e+38]\nSample State: [-2.1986934e-04  9.8844897e+36 -7.7146210e-02 -7.3564386e+37]\n\n\n\neps = 1.0\nnum_episodes = 2000\nrewards = []  # List to store rewards for each episode\n\n# Training loop\nfor episode in range(num_episodes):\n    eps = eps * 0.99\n    print(\"Episode:\", episode)\n    state, info = env.reset(seed=episode)\n    state = discretize_state(state, num_bins)\n    episode_reward = 0\n\n    while True:\n        # Choose action using the current Q-table or explore the environment\n        if np.random.random() &gt; eps:\n            action = torch.argmax(q_table[state]).item()\n        else:\n            action = env.action_space.sample()\n\n        # Take the chosen action and observe the next state and reward\n        next_state, reward, terminated, truncated, info = env.step(action)\n        next_state = discretize_state(next_state, num_bins)\n\n        # Update the Q-table using the Q-learning update rule\n        q_table = update_q_table(q_table, state, action, reward, next_state, learning_rate, discount_factor)\n\n        episode_reward += reward\n        state = next_state\n\n        if truncated or terminated:\n            break\n    rewards.append(episode_reward)\n    print(\"Episode reward:\", episode_reward)\n\n# Print the learned Q-table\nprint(\"Learned Q-table:\")\nprint(q_table)\n\nEpisode: 0\nEpisode reward: 26.0\nEpisode: 1\nEpisode reward: 24.0\nEpisode: 2\nEpisode reward: 15.0\nEpisode: 3\nEpisode reward: 15.0\nEpisode: 4\nEpisode reward: 14.0\nEpisode: 5\nEpisode reward: 18.0\nEpisode: 6\nEpisode reward: 34.0\nEpisode: 7\nEpisode reward: 15.0\nEpisode: 8\nEpisode reward: 30.0\nEpisode: 9\nEpisode reward: 12.0\nEpisode: 10\nEpisode reward: 23.0\nEpisode: 11\nEpisode reward: 21.0\nEpisode: 12\nEpisode reward: 17.0\nEpisode: 13\nEpisode reward: 23.0\nEpisode: 14\nEpisode reward: 18.0\nEpisode: 15\nEpisode reward: 24.0\nEpisode: 16\nEpisode reward: 13.0\nEpisode: 17\nEpisode reward: 12.0\nEpisode: 18\nEpisode reward: 9.0\nEpisode: 19\nEpisode reward: 15.0\nEpisode: 20\nEpisode reward: 20.0\nEpisode: 21\nEpisode reward: 14.0\nEpisode: 22\nEpisode reward: 16.0\nEpisode: 23\nEpisode reward: 24.0\nEpisode: 24\nEpisode reward: 18.0\nEpisode: 25\nEpisode reward: 21.0\nEpisode: 26\nEpisode reward: 10.0\nEpisode: 27\nEpisode reward: 11.0\nEpisode: 28\nEpisode reward: 37.0\nEpisode: 29\nEpisode reward: 18.0\nEpisode: 30\nEpisode reward: 10.0\nEpisode: 31\nEpisode reward: 11.0\nEpisode: 32\nEpisode reward: 23.0\nEpisode: 33\nEpisode reward: 10.0\nEpisode: 34\nEpisode reward: 11.0\nEpisode: 35\nEpisode reward: 13.0\nEpisode: 36\nEpisode reward: 13.0\nEpisode: 37\nEpisode reward: 14.0\nEpisode: 38\nEpisode reward: 12.0\nEpisode: 39\nEpisode reward: 11.0\nEpisode: 40\nEpisode reward: 14.0\nEpisode: 41\nEpisode reward: 14.0\nEpisode: 42\nEpisode reward: 9.0\nEpisode: 43\nEpisode reward: 12.0\nEpisode: 44\nEpisode reward: 18.0\nEpisode: 45\nEpisode reward: 12.0\nEpisode: 46\nEpisode reward: 15.0\nEpisode: 47\nEpisode reward: 32.0\nEpisode: 48\nEpisode reward: 32.0\nEpisode: 49\nEpisode reward: 16.0\nEpisode: 50\nEpisode reward: 11.0\nEpisode: 51\nEpisode reward: 23.0\nEpisode: 52\nEpisode reward: 12.0\nEpisode: 53\nEpisode reward: 27.0\nEpisode: 54\nEpisode reward: 14.0\nEpisode: 55\nEpisode reward: 28.0\nEpisode: 56\nEpisode reward: 28.0\nEpisode: 57\nEpisode reward: 19.0\nEpisode: 58\nEpisode reward: 24.0\nEpisode: 59\nEpisode reward: 23.0\nEpisode: 60\nEpisode reward: 16.0\nEpisode: 61\nEpisode reward: 36.0\nEpisode: 62\nEpisode reward: 19.0\nEpisode: 63\nEpisode reward: 12.0\nEpisode: 64\nEpisode reward: 16.0\nEpisode: 65\nEpisode reward: 11.0\nEpisode: 66\nEpisode reward: 23.0\nEpisode: 67\nEpisode reward: 12.0\nEpisode: 68\nEpisode reward: 14.0\nEpisode: 69\nEpisode reward: 14.0\nEpisode: 70\nEpisode reward: 17.0\nEpisode: 71\nEpisode reward: 24.0\nEpisode: 72\nEpisode reward: 20.0\nEpisode: 73\nEpisode reward: 25.0\nEpisode: 74\nEpisode reward: 13.0\nEpisode: 75\nEpisode reward: 10.0\nEpisode: 76\nEpisode reward: 59.0\nEpisode: 77\nEpisode reward: 53.0\nEpisode: 78\nEpisode reward: 18.0\nEpisode: 79\nEpisode reward: 11.0\nEpisode: 80\nEpisode reward: 11.0\nEpisode: 81\nEpisode reward: 48.0\nEpisode: 82\nEpisode reward: 14.0\nEpisode: 83\nEpisode reward: 43.0\nEpisode: 84\nEpisode reward: 20.0\nEpisode: 85\nEpisode reward: 20.0\nEpisode: 86\nEpisode reward: 24.0\nEpisode: 87\nEpisode reward: 16.0\nEpisode: 88\nEpisode reward: 12.0\nEpisode: 89\nEpisode reward: 19.0\nEpisode: 90\nEpisode reward: 28.0\nEpisode: 91\nEpisode reward: 39.0\nEpisode: 92\nEpisode reward: 12.0\nEpisode: 93\nEpisode reward: 13.0\nEpisode: 94\nEpisode reward: 28.0\nEpisode: 95\nEpisode reward: 10.0\nEpisode: 96\nEpisode reward: 47.0\nEpisode: 97\nEpisode reward: 10.0\nEpisode: 98\nEpisode reward: 35.0\nEpisode: 99\nEpisode reward: 30.0\nEpisode: 100\nEpisode reward: 17.0\nEpisode: 101\nEpisode reward: 9.0\nEpisode: 102\nEpisode reward: 11.0\nEpisode: 103\nEpisode reward: 12.0\nEpisode: 104\nEpisode reward: 9.0\nEpisode: 105\nEpisode reward: 13.0\nEpisode: 106\nEpisode reward: 23.0\nEpisode: 107\nEpisode reward: 11.0\nEpisode: 108\nEpisode reward: 44.0\nEpisode: 109\nEpisode reward: 11.0\nEpisode: 110\nEpisode reward: 60.0\nEpisode: 111\nEpisode reward: 12.0\nEpisode: 112\nEpisode reward: 11.0\nEpisode: 113\nEpisode reward: 9.0\nEpisode: 114\nEpisode reward: 13.0\nEpisode: 115\nEpisode reward: 40.0\nEpisode: 116\nEpisode reward: 20.0\nEpisode: 117\nEpisode reward: 9.0\nEpisode: 118\nEpisode reward: 62.0\nEpisode: 119\nEpisode reward: 9.0\nEpisode: 120\nEpisode reward: 35.0\nEpisode: 121\nEpisode reward: 19.0\nEpisode: 122\nEpisode reward: 32.0\nEpisode: 123\nEpisode reward: 31.0\nEpisode: 124\nEpisode reward: 27.0\nEpisode: 125\nEpisode reward: 24.0\nEpisode: 126\nEpisode reward: 16.0\nEpisode: 127\nEpisode reward: 13.0\nEpisode: 128\nEpisode reward: 35.0\nEpisode: 129\nEpisode reward: 25.0\nEpisode: 130\nEpisode reward: 19.0\nEpisode: 131\nEpisode reward: 33.0\nEpisode: 132\nEpisode reward: 19.0\nEpisode: 133\nEpisode reward: 10.0\nEpisode: 134\nEpisode reward: 16.0\nEpisode: 135\nEpisode reward: 12.0\nEpisode: 136\nEpisode reward: 11.0\nEpisode: 137\nEpisode reward: 10.0\nEpisode: 138\nEpisode reward: 16.0\nEpisode: 139\nEpisode reward: 20.0\nEpisode: 140\nEpisode reward: 26.0\nEpisode: 141\nEpisode reward: 85.0\nEpisode: 142\nEpisode reward: 51.0\nEpisode: 143\nEpisode reward: 46.0\nEpisode: 144\nEpisode reward: 26.0\nEpisode: 145\nEpisode reward: 55.0\nEpisode: 146\nEpisode reward: 35.0\nEpisode: 147\nEpisode reward: 50.0\nEpisode: 148\nEpisode reward: 22.0\nEpisode: 149\nEpisode reward: 18.0\nEpisode: 150\nEpisode reward: 11.0\nEpisode: 151\nEpisode reward: 30.0\nEpisode: 152\nEpisode reward: 21.0\nEpisode: 153\nEpisode reward: 14.0\nEpisode: 154\nEpisode reward: 12.0\nEpisode: 155\nEpisode reward: 15.0\nEpisode: 156\nEpisode reward: 19.0\nEpisode: 157\nEpisode reward: 63.0\nEpisode: 158\nEpisode reward: 21.0\nEpisode: 159\nEpisode reward: 13.0\nEpisode: 160\nEpisode reward: 10.0\nEpisode: 161\nEpisode reward: 20.0\nEpisode: 162\nEpisode reward: 9.0\nEpisode: 163\nEpisode reward: 17.0\nEpisode: 164\nEpisode reward: 9.0\nEpisode: 165\nEpisode reward: 45.0\nEpisode: 166\nEpisode reward: 17.0\nEpisode: 167\nEpisode reward: 17.0\nEpisode: 168\nEpisode reward: 10.0\nEpisode: 169\nEpisode reward: 65.0\nEpisode: 170\nEpisode reward: 30.0\nEpisode: 171\nEpisode reward: 19.0\nEpisode: 172\nEpisode reward: 17.0\nEpisode: 173\nEpisode reward: 9.0\nEpisode: 174\nEpisode reward: 22.0\nEpisode: 175\nEpisode reward: 22.0\nEpisode: 176\nEpisode reward: 10.0\nEpisode: 177\nEpisode reward: 75.0\nEpisode: 178\nEpisode reward: 28.0\nEpisode: 179\nEpisode reward: 26.0\nEpisode: 180\nEpisode reward: 20.0\nEpisode: 181\nEpisode reward: 30.0\nEpisode: 182\nEpisode reward: 14.0\nEpisode: 183\nEpisode reward: 17.0\nEpisode: 184\nEpisode reward: 45.0\nEpisode: 185\nEpisode reward: 10.0\nEpisode: 186\nEpisode reward: 22.0\nEpisode: 187\nEpisode reward: 22.0\nEpisode: 188\nEpisode reward: 50.0\nEpisode: 189\nEpisode reward: 29.0\nEpisode: 190\nEpisode reward: 11.0\nEpisode: 191\nEpisode reward: 18.0\nEpisode: 192\nEpisode reward: 20.0\nEpisode: 193\nEpisode reward: 32.0\nEpisode: 194\nEpisode reward: 14.0\nEpisode: 195\nEpisode reward: 14.0\nEpisode: 196\nEpisode reward: 21.0\nEpisode: 197\nEpisode reward: 12.0\nEpisode: 198\nEpisode reward: 24.0\nEpisode: 199\nEpisode reward: 22.0\nEpisode: 200\nEpisode reward: 30.0\nEpisode: 201\nEpisode reward: 11.0\nEpisode: 202\nEpisode reward: 12.0\nEpisode: 203\nEpisode reward: 25.0\nEpisode: 204\nEpisode reward: 47.0\nEpisode: 205\nEpisode reward: 22.0\nEpisode: 206\nEpisode reward: 10.0\nEpisode: 207\nEpisode reward: 37.0\nEpisode: 208\nEpisode reward: 15.0\nEpisode: 209\nEpisode reward: 31.0\nEpisode: 210\nEpisode reward: 16.0\nEpisode: 211\nEpisode reward: 31.0\nEpisode: 212\nEpisode reward: 40.0\nEpisode: 213\nEpisode reward: 34.0\nEpisode: 214\nEpisode reward: 9.0\nEpisode: 215\nEpisode reward: 9.0\nEpisode: 216\nEpisode reward: 12.0\nEpisode: 217\nEpisode reward: 20.0\nEpisode: 218\nEpisode reward: 19.0\nEpisode: 219\nEpisode reward: 8.0\nEpisode: 220\nEpisode reward: 10.0\nEpisode: 221\nEpisode reward: 8.0\nEpisode: 222\nEpisode reward: 25.0\nEpisode: 223\nEpisode reward: 19.0\nEpisode: 224\nEpisode reward: 45.0\nEpisode: 225\nEpisode reward: 24.0\nEpisode: 226\nEpisode reward: 28.0\nEpisode: 227\nEpisode reward: 21.0\nEpisode: 228\nEpisode reward: 24.0\nEpisode: 229\nEpisode reward: 12.0\nEpisode: 230\nEpisode reward: 17.0\nEpisode: 231\nEpisode reward: 9.0\nEpisode: 232\nEpisode reward: 30.0\nEpisode: 233\nEpisode reward: 13.0\nEpisode: 234\nEpisode reward: 30.0\nEpisode: 235\nEpisode reward: 24.0\nEpisode: 236\nEpisode reward: 10.0\nEpisode: 237\nEpisode reward: 38.0\nEpisode: 238\nEpisode reward: 41.0\nEpisode: 239\nEpisode reward: 33.0\nEpisode: 240\nEpisode reward: 22.0\nEpisode: 241\nEpisode reward: 46.0\nEpisode: 242\nEpisode reward: 30.0\nEpisode: 243\nEpisode reward: 22.0\nEpisode: 244\nEpisode reward: 10.0\nEpisode: 245\nEpisode reward: 26.0\nEpisode: 246\nEpisode reward: 50.0\nEpisode: 247\nEpisode reward: 18.0\nEpisode: 248\nEpisode reward: 23.0\nEpisode: 249\nEpisode reward: 18.0\nEpisode: 250\nEpisode reward: 25.0\nEpisode: 251\nEpisode reward: 10.0\nEpisode: 252\nEpisode reward: 19.0\nEpisode: 253\nEpisode reward: 57.0\nEpisode: 254\nEpisode reward: 57.0\nEpisode: 255\nEpisode reward: 9.0\nEpisode: 256\nEpisode reward: 28.0\nEpisode: 257\nEpisode reward: 17.0\nEpisode: 258\nEpisode reward: 24.0\nEpisode: 259\nEpisode reward: 16.0\nEpisode: 260\nEpisode reward: 20.0\nEpisode: 261\nEpisode reward: 25.0\nEpisode: 262\nEpisode reward: 18.0\nEpisode: 263\nEpisode reward: 28.0\nEpisode: 264\nEpisode reward: 44.0\nEpisode: 265\nEpisode reward: 51.0\nEpisode: 266\nEpisode reward: 41.0\nEpisode: 267\nEpisode reward: 54.0\nEpisode: 268\nEpisode reward: 48.0\nEpisode: 269\nEpisode reward: 39.0\nEpisode: 270\nEpisode reward: 77.0\nEpisode: 271\nEpisode reward: 58.0\nEpisode: 272\nEpisode reward: 53.0\nEpisode: 273\nEpisode reward: 52.0\nEpisode: 274\nEpisode reward: 71.0\nEpisode: 275\nEpisode reward: 43.0\nEpisode: 276\nEpisode reward: 48.0\nEpisode: 277\nEpisode reward: 41.0\nEpisode: 278\nEpisode reward: 48.0\nEpisode: 279\nEpisode reward: 46.0\nEpisode: 280\nEpisode reward: 58.0\nEpisode: 281\nEpisode reward: 62.0\nEpisode: 282\nEpisode reward: 49.0\nEpisode: 283\nEpisode reward: 27.0\nEpisode: 284\nEpisode reward: 43.0\nEpisode: 285\nEpisode reward: 35.0\nEpisode: 286\nEpisode reward: 44.0\nEpisode: 287\nEpisode reward: 59.0\nEpisode: 288\nEpisode reward: 17.0\nEpisode: 289\nEpisode reward: 60.0\nEpisode: 290\nEpisode reward: 25.0\nEpisode: 291\nEpisode reward: 47.0\nEpisode: 292\nEpisode reward: 54.0\nEpisode: 293\nEpisode reward: 65.0\nEpisode: 294\nEpisode reward: 56.0\nEpisode: 295\nEpisode reward: 37.0\nEpisode: 296\nEpisode reward: 84.0\nEpisode: 297\nEpisode reward: 27.0\nEpisode: 298\nEpisode reward: 34.0\nEpisode: 299\nEpisode reward: 41.0\nEpisode: 300\nEpisode reward: 54.0\nEpisode: 301\nEpisode reward: 39.0\nEpisode: 302\nEpisode reward: 47.0\nEpisode: 303\nEpisode reward: 42.0\nEpisode: 304\nEpisode reward: 94.0\nEpisode: 305\nEpisode reward: 89.0\nEpisode: 306\nEpisode reward: 26.0\nEpisode: 307\nEpisode reward: 47.0\nEpisode: 308\nEpisode reward: 39.0\nEpisode: 309\nEpisode reward: 38.0\nEpisode: 310\nEpisode reward: 46.0\nEpisode: 311\nEpisode reward: 43.0\nEpisode: 312\nEpisode reward: 35.0\nEpisode: 313\nEpisode reward: 23.0\nEpisode: 314\nEpisode reward: 47.0\nEpisode: 315\nEpisode reward: 16.0\nEpisode: 316\nEpisode reward: 9.0\nEpisode: 317\nEpisode reward: 8.0\nEpisode: 318\nEpisode reward: 20.0\nEpisode: 319\nEpisode reward: 27.0\nEpisode: 320\nEpisode reward: 70.0\nEpisode: 321\nEpisode reward: 20.0\nEpisode: 322\nEpisode reward: 28.0\nEpisode: 323\nEpisode reward: 40.0\nEpisode: 324\nEpisode reward: 36.0\nEpisode: 325\nEpisode reward: 31.0\nEpisode: 326\nEpisode reward: 52.0\nEpisode: 327\nEpisode reward: 60.0\nEpisode: 328\nEpisode reward: 15.0\nEpisode: 329\nEpisode reward: 32.0\nEpisode: 330\nEpisode reward: 51.0\nEpisode: 331\nEpisode reward: 31.0\nEpisode: 332\nEpisode reward: 14.0\nEpisode: 333\nEpisode reward: 64.0\nEpisode: 334\nEpisode reward: 23.0\nEpisode: 335\nEpisode reward: 9.0\nEpisode: 336\nEpisode reward: 9.0\nEpisode: 337\nEpisode reward: 29.0\nEpisode: 338\nEpisode reward: 16.0\nEpisode: 339\nEpisode reward: 21.0\nEpisode: 340\nEpisode reward: 21.0\nEpisode: 341\nEpisode reward: 31.0\nEpisode: 342\nEpisode reward: 46.0\nEpisode: 343\nEpisode reward: 34.0\nEpisode: 344\nEpisode reward: 23.0\nEpisode: 345\nEpisode reward: 21.0\nEpisode: 346\nEpisode reward: 10.0\nEpisode: 347\nEpisode reward: 10.0\nEpisode: 348\nEpisode reward: 38.0\nEpisode: 349\nEpisode reward: 71.0\nEpisode: 350\nEpisode reward: 17.0\nEpisode: 351\nEpisode reward: 49.0\nEpisode: 352\nEpisode reward: 36.0\nEpisode: 353\nEpisode reward: 30.0\nEpisode: 354\nEpisode reward: 16.0\nEpisode: 355\nEpisode reward: 46.0\nEpisode: 356\nEpisode reward: 48.0\nEpisode: 357\nEpisode reward: 29.0\nEpisode: 358\nEpisode reward: 46.0\nEpisode: 359\nEpisode reward: 35.0\nEpisode: 360\nEpisode reward: 22.0\nEpisode: 361\nEpisode reward: 39.0\nEpisode: 362\nEpisode reward: 61.0\nEpisode: 363\nEpisode reward: 15.0\nEpisode: 364\nEpisode reward: 39.0\nEpisode: 365\nEpisode reward: 18.0\nEpisode: 366\nEpisode reward: 41.0\nEpisode: 367\nEpisode reward: 23.0\nEpisode: 368\nEpisode reward: 52.0\nEpisode: 369\nEpisode reward: 35.0\nEpisode: 370\nEpisode reward: 26.0\nEpisode: 371\nEpisode reward: 90.0\nEpisode: 372\nEpisode reward: 81.0\nEpisode: 373\nEpisode reward: 20.0\nEpisode: 374\nEpisode reward: 109.0\nEpisode: 375\nEpisode reward: 14.0\nEpisode: 376\nEpisode reward: 39.0\nEpisode: 377\nEpisode reward: 31.0\nEpisode: 378\nEpisode reward: 55.0\nEpisode: 379\nEpisode reward: 68.0\nEpisode: 380\nEpisode reward: 59.0\nEpisode: 381\nEpisode reward: 22.0\nEpisode: 382\nEpisode reward: 75.0\nEpisode: 383\nEpisode reward: 40.0\nEpisode: 384\nEpisode reward: 35.0\nEpisode: 385\nEpisode reward: 109.0\nEpisode: 386\nEpisode reward: 73.0\nEpisode: 387\nEpisode reward: 52.0\nEpisode: 388\nEpisode reward: 35.0\nEpisode: 389\nEpisode reward: 107.0\nEpisode: 390\nEpisode reward: 20.0\nEpisode: 391\nEpisode reward: 62.0\nEpisode: 392\nEpisode reward: 32.0\nEpisode: 393\nEpisode reward: 46.0\nEpisode: 394\nEpisode reward: 27.0\nEpisode: 395\nEpisode reward: 54.0\nEpisode: 396\nEpisode reward: 44.0\nEpisode: 397\nEpisode reward: 57.0\nEpisode: 398\nEpisode reward: 25.0\nEpisode: 399\nEpisode reward: 10.0\nEpisode: 400\nEpisode reward: 39.0\nEpisode: 401\nEpisode reward: 47.0\nEpisode: 402\nEpisode reward: 63.0\nEpisode: 403\nEpisode reward: 98.0\nEpisode: 404\nEpisode reward: 39.0\nEpisode: 405\nEpisode reward: 30.0\nEpisode: 406\nEpisode reward: 67.0\nEpisode: 407\nEpisode reward: 49.0\nEpisode: 408\nEpisode reward: 93.0\nEpisode: 409\nEpisode reward: 30.0\nEpisode: 410\nEpisode reward: 42.0\nEpisode: 411\nEpisode reward: 40.0\nEpisode: 412\nEpisode reward: 59.0\nEpisode: 413\nEpisode reward: 8.0\nEpisode: 414\nEpisode reward: 64.0\nEpisode: 415\nEpisode reward: 23.0\nEpisode: 416\nEpisode reward: 10.0\nEpisode: 417\nEpisode reward: 9.0\nEpisode: 418\nEpisode reward: 44.0\nEpisode: 419\nEpisode reward: 12.0\nEpisode: 420\nEpisode reward: 22.0\nEpisode: 421\nEpisode reward: 28.0\nEpisode: 422\nEpisode reward: 38.0\nEpisode: 423\nEpisode reward: 22.0\nEpisode: 424\nEpisode reward: 61.0\nEpisode: 425\nEpisode reward: 24.0\nEpisode: 426\nEpisode reward: 33.0\nEpisode: 427\nEpisode reward: 21.0\nEpisode: 428\nEpisode reward: 33.0\nEpisode: 429\nEpisode reward: 28.0\nEpisode: 430\nEpisode reward: 22.0\nEpisode: 431\nEpisode reward: 50.0\nEpisode: 432\nEpisode reward: 71.0\nEpisode: 433\nEpisode reward: 109.0\nEpisode: 434\nEpisode reward: 55.0\nEpisode: 435\nEpisode reward: 41.0\nEpisode: 436\nEpisode reward: 33.0\nEpisode: 437\nEpisode reward: 77.0\nEpisode: 438\nEpisode reward: 19.0\nEpisode: 439\nEpisode reward: 22.0\nEpisode: 440\nEpisode reward: 12.0\nEpisode: 441\nEpisode reward: 71.0\nEpisode: 442\nEpisode reward: 49.0\nEpisode: 443\nEpisode reward: 52.0\nEpisode: 444\nEpisode reward: 26.0\nEpisode: 445\nEpisode reward: 43.0\nEpisode: 446\nEpisode reward: 24.0\nEpisode: 447\nEpisode reward: 35.0\nEpisode: 448\nEpisode reward: 30.0\nEpisode: 449\nEpisode reward: 11.0\nEpisode: 450\nEpisode reward: 46.0\nEpisode: 451\nEpisode reward: 38.0\nEpisode: 452\nEpisode reward: 9.0\nEpisode: 453\nEpisode reward: 49.0\nEpisode: 454\nEpisode reward: 56.0\nEpisode: 455\nEpisode reward: 126.0\nEpisode: 456\nEpisode reward: 47.0\nEpisode: 457\nEpisode reward: 61.0\nEpisode: 458\nEpisode reward: 61.0\nEpisode: 459\nEpisode reward: 24.0\nEpisode: 460\nEpisode reward: 104.0\nEpisode: 461\nEpisode reward: 56.0\nEpisode: 462\nEpisode reward: 26.0\nEpisode: 463\nEpisode reward: 13.0\nEpisode: 464\nEpisode reward: 18.0\nEpisode: 465\nEpisode reward: 26.0\nEpisode: 466\nEpisode reward: 43.0\nEpisode: 467\nEpisode reward: 10.0\nEpisode: 468\nEpisode reward: 25.0\nEpisode: 469\nEpisode reward: 75.0\nEpisode: 470\nEpisode reward: 30.0\nEpisode: 471\nEpisode reward: 29.0\nEpisode: 472\nEpisode reward: 33.0\nEpisode: 473\nEpisode reward: 25.0\nEpisode: 474\nEpisode reward: 27.0\nEpisode: 475\nEpisode reward: 88.0\nEpisode: 476\nEpisode reward: 49.0\nEpisode: 477\nEpisode reward: 18.0\nEpisode: 478\nEpisode reward: 35.0\nEpisode: 479\nEpisode reward: 64.0\nEpisode: 480\nEpisode reward: 26.0\nEpisode: 481\nEpisode reward: 26.0\nEpisode: 482\nEpisode reward: 40.0\nEpisode: 483\nEpisode reward: 36.0\nEpisode: 484\nEpisode reward: 51.0\nEpisode: 485\nEpisode reward: 39.0\nEpisode: 486\nEpisode reward: 37.0\nEpisode: 487\nEpisode reward: 29.0\nEpisode: 488\nEpisode reward: 69.0\nEpisode: 489\nEpisode reward: 34.0\nEpisode: 490\nEpisode reward: 48.0\nEpisode: 491\nEpisode reward: 40.0\nEpisode: 492\nEpisode reward: 29.0\nEpisode: 493\nEpisode reward: 20.0\nEpisode: 494\nEpisode reward: 19.0\nEpisode: 495\nEpisode reward: 37.0\nEpisode: 496\nEpisode reward: 12.0\nEpisode: 497\nEpisode reward: 21.0\nEpisode: 498\nEpisode reward: 11.0\nEpisode: 499\nEpisode reward: 29.0\nEpisode: 500\nEpisode reward: 34.0\nEpisode: 501\nEpisode reward: 12.0\nEpisode: 502\nEpisode reward: 80.0\nEpisode: 503\nEpisode reward: 75.0\nEpisode: 504\nEpisode reward: 31.0\nEpisode: 505\nEpisode reward: 26.0\nEpisode: 506\nEpisode reward: 40.0\nEpisode: 507\nEpisode reward: 46.0\nEpisode: 508\nEpisode reward: 12.0\nEpisode: 509\nEpisode reward: 32.0\nEpisode: 510\nEpisode reward: 66.0\nEpisode: 511\nEpisode reward: 13.0\nEpisode: 512\nEpisode reward: 42.0\nEpisode: 513\nEpisode reward: 99.0\nEpisode: 514\nEpisode reward: 48.0\nEpisode: 515\nEpisode reward: 26.0\nEpisode: 516\nEpisode reward: 8.0\nEpisode: 517\nEpisode reward: 40.0\nEpisode: 518\nEpisode reward: 43.0\nEpisode: 519\nEpisode reward: 36.0\nEpisode: 520\nEpisode reward: 28.0\nEpisode: 521\nEpisode reward: 27.0\nEpisode: 522\nEpisode reward: 59.0\nEpisode: 523\nEpisode reward: 82.0\nEpisode: 524\nEpisode reward: 89.0\nEpisode: 525\nEpisode reward: 53.0\nEpisode: 526\nEpisode reward: 27.0\nEpisode: 527\nEpisode reward: 86.0\nEpisode: 528\nEpisode reward: 26.0\nEpisode: 529\nEpisode reward: 71.0\nEpisode: 530\nEpisode reward: 37.0\nEpisode: 531\nEpisode reward: 27.0\nEpisode: 532\nEpisode reward: 23.0\nEpisode: 533\nEpisode reward: 23.0\nEpisode: 534\nEpisode reward: 125.0\nEpisode: 535\nEpisode reward: 28.0\nEpisode: 536\nEpisode reward: 25.0\nEpisode: 537\nEpisode reward: 117.0\nEpisode: 538\nEpisode reward: 22.0\nEpisode: 539\nEpisode reward: 51.0\nEpisode: 540\nEpisode reward: 29.0\nEpisode: 541\nEpisode reward: 35.0\nEpisode: 542\nEpisode reward: 28.0\nEpisode: 543\nEpisode reward: 81.0\nEpisode: 544\nEpisode reward: 104.0\nEpisode: 545\nEpisode reward: 50.0\nEpisode: 546\nEpisode reward: 27.0\nEpisode: 547\nEpisode reward: 98.0\nEpisode: 548\nEpisode reward: 87.0\nEpisode: 549\nEpisode reward: 61.0\nEpisode: 550\nEpisode reward: 23.0\nEpisode: 551\nEpisode reward: 10.0\nEpisode: 552\nEpisode reward: 36.0\nEpisode: 553\nEpisode reward: 37.0\nEpisode: 554\nEpisode reward: 28.0\nEpisode: 555\nEpisode reward: 22.0\nEpisode: 556\nEpisode reward: 76.0\nEpisode: 557\nEpisode reward: 26.0\nEpisode: 558\nEpisode reward: 35.0\nEpisode: 559\nEpisode reward: 22.0\nEpisode: 560\nEpisode reward: 68.0\nEpisode: 561\nEpisode reward: 47.0\nEpisode: 562\nEpisode reward: 25.0\nEpisode: 563\nEpisode reward: 40.0\nEpisode: 564\nEpisode reward: 34.0\nEpisode: 565\nEpisode reward: 22.0\nEpisode: 566\nEpisode reward: 29.0\nEpisode: 567\nEpisode reward: 51.0\nEpisode: 568\nEpisode reward: 40.0\nEpisode: 569\nEpisode reward: 26.0\nEpisode: 570\nEpisode reward: 51.0\nEpisode: 571\nEpisode reward: 23.0\nEpisode: 572\nEpisode reward: 36.0\nEpisode: 573\nEpisode reward: 34.0\nEpisode: 574\nEpisode reward: 74.0\nEpisode: 575\nEpisode reward: 42.0\nEpisode: 576\nEpisode reward: 22.0\nEpisode: 577\nEpisode reward: 23.0\nEpisode: 578\nEpisode reward: 32.0\nEpisode: 579\nEpisode reward: 62.0\nEpisode: 580\nEpisode reward: 23.0\nEpisode: 581\nEpisode reward: 53.0\nEpisode: 582\nEpisode reward: 28.0\nEpisode: 583\nEpisode reward: 28.0\nEpisode: 584\nEpisode reward: 17.0\nEpisode: 585\nEpisode reward: 57.0\nEpisode: 586\nEpisode reward: 49.0\nEpisode: 587\nEpisode reward: 63.0\nEpisode: 588\nEpisode reward: 17.0\nEpisode: 589\nEpisode reward: 39.0\nEpisode: 590\nEpisode reward: 39.0\nEpisode: 591\nEpisode reward: 35.0\nEpisode: 592\nEpisode reward: 27.0\nEpisode: 593\nEpisode reward: 22.0\nEpisode: 594\nEpisode reward: 59.0\nEpisode: 595\nEpisode reward: 22.0\nEpisode: 596\nEpisode reward: 9.0\nEpisode: 597\nEpisode reward: 42.0\nEpisode: 598\nEpisode reward: 28.0\nEpisode: 599\nEpisode reward: 19.0\nEpisode: 600\nEpisode reward: 62.0\nEpisode: 601\nEpisode reward: 27.0\nEpisode: 602\nEpisode reward: 37.0\nEpisode: 603\nEpisode reward: 27.0\nEpisode: 604\nEpisode reward: 20.0\nEpisode: 605\nEpisode reward: 100.0\nEpisode: 606\nEpisode reward: 56.0\nEpisode: 607\nEpisode reward: 23.0\nEpisode: 608\nEpisode reward: 120.0\nEpisode: 609\nEpisode reward: 39.0\nEpisode: 610\nEpisode reward: 26.0\nEpisode: 611\nEpisode reward: 36.0\nEpisode: 612\nEpisode reward: 49.0\nEpisode: 613\nEpisode reward: 20.0\nEpisode: 614\nEpisode reward: 37.0\nEpisode: 615\nEpisode reward: 12.0\nEpisode: 616\nEpisode reward: 117.0\nEpisode: 617\nEpisode reward: 32.0\nEpisode: 618\nEpisode reward: 81.0\nEpisode: 619\nEpisode reward: 59.0\nEpisode: 620\nEpisode reward: 12.0\nEpisode: 621\nEpisode reward: 28.0\nEpisode: 622\nEpisode reward: 30.0\nEpisode: 623\nEpisode reward: 40.0\nEpisode: 624\nEpisode reward: 24.0\nEpisode: 625\nEpisode reward: 107.0\nEpisode: 626\nEpisode reward: 79.0\nEpisode: 627\nEpisode reward: 68.0\nEpisode: 628\nEpisode reward: 29.0\nEpisode: 629\nEpisode reward: 27.0\nEpisode: 630\nEpisode reward: 45.0\nEpisode: 631\nEpisode reward: 42.0\nEpisode: 632\nEpisode reward: 87.0\nEpisode: 633\nEpisode reward: 56.0\nEpisode: 634\nEpisode reward: 29.0\nEpisode: 635\nEpisode reward: 26.0\nEpisode: 636\nEpisode reward: 26.0\nEpisode: 637\nEpisode reward: 53.0\nEpisode: 638\nEpisode reward: 35.0\nEpisode: 639\nEpisode reward: 28.0\nEpisode: 640\nEpisode reward: 42.0\nEpisode: 641\nEpisode reward: 62.0\nEpisode: 642\nEpisode reward: 53.0\nEpisode: 643\nEpisode reward: 34.0\nEpisode: 644\nEpisode reward: 23.0\nEpisode: 645\nEpisode reward: 52.0\nEpisode: 646\nEpisode reward: 27.0\nEpisode: 647\nEpisode reward: 49.0\nEpisode: 648\nEpisode reward: 39.0\nEpisode: 649\nEpisode reward: 36.0\nEpisode: 650\nEpisode reward: 21.0\nEpisode: 651\nEpisode reward: 89.0\nEpisode: 652\nEpisode reward: 38.0\nEpisode: 653\nEpisode reward: 45.0\nEpisode: 654\nEpisode reward: 39.0\nEpisode: 655\nEpisode reward: 41.0\nEpisode: 656\nEpisode reward: 75.0\nEpisode: 657\nEpisode reward: 19.0\nEpisode: 658\nEpisode reward: 34.0\nEpisode: 659\nEpisode reward: 32.0\nEpisode: 660\nEpisode reward: 63.0\nEpisode: 661\nEpisode reward: 61.0\nEpisode: 662\nEpisode reward: 29.0\nEpisode: 663\nEpisode reward: 36.0\nEpisode: 664\nEpisode reward: 40.0\nEpisode: 665\nEpisode reward: 51.0\nEpisode: 666\nEpisode reward: 17.0\nEpisode: 667\nEpisode reward: 105.0\nEpisode: 668\nEpisode reward: 38.0\nEpisode: 669\nEpisode reward: 74.0\nEpisode: 670\nEpisode reward: 38.0\nEpisode: 671\nEpisode reward: 22.0\nEpisode: 672\nEpisode reward: 45.0\nEpisode: 673\nEpisode reward: 19.0\nEpisode: 674\nEpisode reward: 64.0\nEpisode: 675\nEpisode reward: 115.0\nEpisode: 676\nEpisode reward: 43.0\nEpisode: 677\nEpisode reward: 61.0\nEpisode: 678\nEpisode reward: 53.0\nEpisode: 679\nEpisode reward: 23.0\nEpisode: 680\nEpisode reward: 32.0\nEpisode: 681\nEpisode reward: 36.0\nEpisode: 682\nEpisode reward: 89.0\nEpisode: 683\nEpisode reward: 19.0\nEpisode: 684\nEpisode reward: 23.0\nEpisode: 685\nEpisode reward: 38.0\nEpisode: 686\nEpisode reward: 49.0\nEpisode: 687\nEpisode reward: 83.0\nEpisode: 688\nEpisode reward: 53.0\nEpisode: 689\nEpisode reward: 62.0\nEpisode: 690\nEpisode reward: 29.0\nEpisode: 691\nEpisode reward: 25.0\nEpisode: 692\nEpisode reward: 24.0\nEpisode: 693\nEpisode reward: 27.0\nEpisode: 694\nEpisode reward: 9.0\nEpisode: 695\nEpisode reward: 39.0\nEpisode: 696\nEpisode reward: 78.0\nEpisode: 697\nEpisode reward: 115.0\nEpisode: 698\nEpisode reward: 38.0\nEpisode: 699\nEpisode reward: 23.0\nEpisode: 700\nEpisode reward: 41.0\nEpisode: 701\nEpisode reward: 18.0\nEpisode: 702\nEpisode reward: 37.0\nEpisode: 703\nEpisode reward: 37.0\nEpisode: 704\nEpisode reward: 23.0\nEpisode: 705\nEpisode reward: 119.0\nEpisode: 706\nEpisode reward: 41.0\nEpisode: 707\nEpisode reward: 37.0\nEpisode: 708\nEpisode reward: 23.0\nEpisode: 709\nEpisode reward: 36.0\nEpisode: 710\nEpisode reward: 66.0\nEpisode: 711\nEpisode reward: 33.0\nEpisode: 712\nEpisode reward: 33.0\nEpisode: 713\nEpisode reward: 61.0\nEpisode: 714\nEpisode reward: 66.0\nEpisode: 715\nEpisode reward: 44.0\nEpisode: 716\nEpisode reward: 19.0\nEpisode: 717\nEpisode reward: 72.0\nEpisode: 718\nEpisode reward: 25.0\nEpisode: 719\nEpisode reward: 26.0\nEpisode: 720\nEpisode reward: 29.0\nEpisode: 721\nEpisode reward: 40.0\nEpisode: 722\nEpisode reward: 41.0\nEpisode: 723\nEpisode reward: 37.0\nEpisode: 724\nEpisode reward: 70.0\nEpisode: 725\nEpisode reward: 56.0\nEpisode: 726\nEpisode reward: 37.0\nEpisode: 727\nEpisode reward: 85.0\nEpisode: 728\nEpisode reward: 22.0\nEpisode: 729\nEpisode reward: 23.0\nEpisode: 730\nEpisode reward: 50.0\nEpisode: 731\nEpisode reward: 23.0\nEpisode: 732\nEpisode reward: 24.0\nEpisode: 733\nEpisode reward: 96.0\nEpisode: 734\nEpisode reward: 18.0\nEpisode: 735\nEpisode reward: 23.0\nEpisode: 736\nEpisode reward: 23.0\nEpisode: 737\nEpisode reward: 42.0\nEpisode: 738\nEpisode reward: 22.0\nEpisode: 739\nEpisode reward: 27.0\nEpisode: 740\nEpisode reward: 72.0\nEpisode: 741\nEpisode reward: 39.0\nEpisode: 742\nEpisode reward: 18.0\nEpisode: 743\nEpisode reward: 22.0\nEpisode: 744\nEpisode reward: 23.0\nEpisode: 745\nEpisode reward: 22.0\nEpisode: 746\nEpisode reward: 26.0\nEpisode: 747\nEpisode reward: 23.0\nEpisode: 748\nEpisode reward: 20.0\nEpisode: 749\nEpisode reward: 32.0\nEpisode: 750\nEpisode reward: 17.0\nEpisode: 751\nEpisode reward: 33.0\nEpisode: 752\nEpisode reward: 56.0\nEpisode: 753\nEpisode reward: 22.0\nEpisode: 754\nEpisode reward: 43.0\nEpisode: 755\nEpisode reward: 91.0\nEpisode: 756\nEpisode reward: 39.0\nEpisode: 757\nEpisode reward: 43.0\nEpisode: 758\nEpisode reward: 49.0\nEpisode: 759\nEpisode reward: 38.0\nEpisode: 760\nEpisode reward: 66.0\nEpisode: 761\nEpisode reward: 147.0\nEpisode: 762\nEpisode reward: 172.0\nEpisode: 763\nEpisode reward: 146.0\nEpisode: 764\nEpisode reward: 187.0\nEpisode: 765\nEpisode reward: 135.0\nEpisode: 766\nEpisode reward: 153.0\nEpisode: 767\nEpisode reward: 145.0\nEpisode: 768\nEpisode reward: 153.0\nEpisode: 769\nEpisode reward: 191.0\nEpisode: 770\nEpisode reward: 114.0\nEpisode: 771\nEpisode reward: 160.0\nEpisode: 772\nEpisode reward: 195.0\nEpisode: 773\nEpisode reward: 200.0\nEpisode: 774\nEpisode reward: 151.0\nEpisode: 775\nEpisode reward: 196.0\nEpisode: 776\nEpisode reward: 113.0\nEpisode: 777\nEpisode reward: 158.0\nEpisode: 778\nEpisode reward: 141.0\nEpisode: 779\nEpisode reward: 160.0\nEpisode: 780\nEpisode reward: 200.0\nEpisode: 781\nEpisode reward: 160.0\nEpisode: 782\nEpisode reward: 117.0\nEpisode: 783\nEpisode reward: 193.0\nEpisode: 784\nEpisode reward: 119.0\nEpisode: 785\nEpisode reward: 195.0\nEpisode: 786\nEpisode reward: 118.0\nEpisode: 787\nEpisode reward: 156.0\nEpisode: 788\nEpisode reward: 195.0\nEpisode: 789\nEpisode reward: 139.0\nEpisode: 790\nEpisode reward: 188.0\nEpisode: 791\nEpisode reward: 155.0\nEpisode: 792\nEpisode reward: 113.0\nEpisode: 793\nEpisode reward: 187.0\nEpisode: 794\nEpisode reward: 126.0\nEpisode: 795\nEpisode reward: 157.0\nEpisode: 796\nEpisode reward: 181.0\nEpisode: 797\nEpisode reward: 110.0\nEpisode: 798\nEpisode reward: 200.0\nEpisode: 799\nEpisode reward: 141.0\nEpisode: 800\nEpisode reward: 170.0\nEpisode: 801\nEpisode reward: 136.0\nEpisode: 802\nEpisode reward: 153.0\nEpisode: 803\nEpisode reward: 200.0\nEpisode: 804\nEpisode reward: 115.0\nEpisode: 805\nEpisode reward: 168.0\nEpisode: 806\nEpisode reward: 165.0\nEpisode: 807\nEpisode reward: 198.0\nEpisode: 808\nEpisode reward: 146.0\nEpisode: 809\nEpisode reward: 194.0\nEpisode: 810\nEpisode reward: 152.0\nEpisode: 811\nEpisode reward: 200.0\nEpisode: 812\nEpisode reward: 162.0\nEpisode: 813\nEpisode reward: 150.0\nEpisode: 814\nEpisode reward: 140.0\nEpisode: 815\nEpisode reward: 155.0\nEpisode: 816\nEpisode reward: 200.0\nEpisode: 817\nEpisode reward: 145.0\nEpisode: 818\nEpisode reward: 181.0\nEpisode: 819\nEpisode reward: 200.0\nEpisode: 820\nEpisode reward: 104.0\nEpisode: 821\nEpisode reward: 142.0\nEpisode: 822\nEpisode reward: 107.0\nEpisode: 823\nEpisode reward: 200.0\nEpisode: 824\nEpisode reward: 147.0\nEpisode: 825\nEpisode reward: 144.0\nEpisode: 826\nEpisode reward: 167.0\nEpisode: 827\nEpisode reward: 122.0\nEpisode: 828\nEpisode reward: 127.0\nEpisode: 829\nEpisode reward: 143.0\nEpisode: 830\nEpisode reward: 113.0\nEpisode: 831\nEpisode reward: 131.0\nEpisode: 832\nEpisode reward: 120.0\nEpisode: 833\nEpisode reward: 159.0\nEpisode: 834\nEpisode reward: 200.0\nEpisode: 835\nEpisode reward: 200.0\nEpisode: 836\nEpisode reward: 193.0\nEpisode: 837\nEpisode reward: 194.0\nEpisode: 838\nEpisode reward: 119.0\nEpisode: 839\nEpisode reward: 143.0\nEpisode: 840\nEpisode reward: 141.0\nEpisode: 841\nEpisode reward: 165.0\nEpisode: 842\nEpisode reward: 84.0\nEpisode: 843\nEpisode reward: 139.0\nEpisode: 844\nEpisode reward: 130.0\nEpisode: 845\nEpisode reward: 70.0\nEpisode: 846\nEpisode reward: 200.0\nEpisode: 847\nEpisode reward: 161.0\nEpisode: 848\nEpisode reward: 142.0\nEpisode: 849\nEpisode reward: 177.0\nEpisode: 850\nEpisode reward: 133.0\nEpisode: 851\nEpisode reward: 200.0\nEpisode: 852\nEpisode reward: 134.0\nEpisode: 853\nEpisode reward: 119.0\nEpisode: 854\nEpisode reward: 200.0\nEpisode: 855\nEpisode reward: 121.0\nEpisode: 856\nEpisode reward: 183.0\nEpisode: 857\nEpisode reward: 140.0\nEpisode: 858\nEpisode reward: 196.0\nEpisode: 859\nEpisode reward: 200.0\nEpisode: 860\nEpisode reward: 110.0\nEpisode: 861\nEpisode reward: 138.0\nEpisode: 862\nEpisode reward: 200.0\nEpisode: 863\nEpisode reward: 153.0\nEpisode: 864\nEpisode reward: 161.0\nEpisode: 865\nEpisode reward: 135.0\nEpisode: 866\nEpisode reward: 169.0\nEpisode: 867\nEpisode reward: 181.0\nEpisode: 868\nEpisode reward: 112.0\nEpisode: 869\nEpisode reward: 185.0\nEpisode: 870\nEpisode reward: 147.0\nEpisode: 871\nEpisode reward: 121.0\nEpisode: 872\nEpisode reward: 118.0\nEpisode: 873\nEpisode reward: 167.0\nEpisode: 874\nEpisode reward: 184.0\nEpisode: 875\nEpisode reward: 200.0\nEpisode: 876\nEpisode reward: 146.0\nEpisode: 877\nEpisode reward: 150.0\nEpisode: 878\nEpisode reward: 149.0\nEpisode: 879\nEpisode reward: 107.0\nEpisode: 880\nEpisode reward: 151.0\nEpisode: 881\nEpisode reward: 160.0\nEpisode: 882\nEpisode reward: 153.0\nEpisode: 883\nEpisode reward: 99.0\nEpisode: 884\nEpisode reward: 119.0\nEpisode: 885\nEpisode reward: 200.0\nEpisode: 886\nEpisode reward: 158.0\nEpisode: 887\nEpisode reward: 155.0\nEpisode: 888\nEpisode reward: 143.0\nEpisode: 889\nEpisode reward: 200.0\nEpisode: 890\nEpisode reward: 188.0\nEpisode: 891\nEpisode reward: 147.0\nEpisode: 892\nEpisode reward: 155.0\nEpisode: 893\nEpisode reward: 118.0\nEpisode: 894\nEpisode reward: 113.0\nEpisode: 895\nEpisode reward: 134.0\nEpisode: 896\nEpisode reward: 118.0\nEpisode: 897\nEpisode reward: 153.0\nEpisode: 898\nEpisode reward: 112.0\nEpisode: 899\nEpisode reward: 116.0\nEpisode: 900\nEpisode reward: 120.0\nEpisode: 901\nEpisode reward: 182.0\nEpisode: 902\nEpisode reward: 149.0\nEpisode: 903\nEpisode reward: 200.0\nEpisode: 904\nEpisode reward: 200.0\nEpisode: 905\nEpisode reward: 199.0\nEpisode: 906\nEpisode reward: 143.0\nEpisode: 907\nEpisode reward: 133.0\nEpisode: 908\nEpisode reward: 126.0\nEpisode: 909\nEpisode reward: 158.0\nEpisode: 910\nEpisode reward: 144.0\nEpisode: 911\nEpisode reward: 149.0\nEpisode: 912\nEpisode reward: 173.0\nEpisode: 913\nEpisode reward: 138.0\nEpisode: 914\nEpisode reward: 159.0\nEpisode: 915\nEpisode reward: 137.0\nEpisode: 916\nEpisode reward: 169.0\nEpisode: 917\nEpisode reward: 200.0\nEpisode: 918\nEpisode reward: 134.0\nEpisode: 919\nEpisode reward: 200.0\nEpisode: 920\nEpisode reward: 165.0\nEpisode: 921\nEpisode reward: 160.0\nEpisode: 922\nEpisode reward: 142.0\nEpisode: 923\nEpisode reward: 200.0\nEpisode: 924\nEpisode reward: 159.0\nEpisode: 925\nEpisode reward: 117.0\nEpisode: 926\nEpisode reward: 145.0\nEpisode: 927\nEpisode reward: 136.0\nEpisode: 928\nEpisode reward: 149.0\nEpisode: 929\nEpisode reward: 128.0\nEpisode: 930\nEpisode reward: 200.0\nEpisode: 931\nEpisode reward: 166.0\nEpisode: 932\nEpisode reward: 153.0\nEpisode: 933\nEpisode reward: 175.0\nEpisode: 934\nEpisode reward: 111.0\nEpisode: 935\nEpisode reward: 149.0\nEpisode: 936\nEpisode reward: 118.0\nEpisode: 937\nEpisode reward: 135.0\nEpisode: 938\nEpisode reward: 117.0\nEpisode: 939\nEpisode reward: 147.0\nEpisode: 940\nEpisode reward: 134.0\nEpisode: 941\nEpisode reward: 132.0\nEpisode: 942\nEpisode reward: 151.0\nEpisode: 943\nEpisode reward: 143.0\nEpisode: 944\nEpisode reward: 138.0\nEpisode: 945\nEpisode reward: 156.0\nEpisode: 946\nEpisode reward: 142.0\nEpisode: 947\nEpisode reward: 132.0\nEpisode: 948\nEpisode reward: 175.0\nEpisode: 949\nEpisode reward: 136.0\nEpisode: 950\nEpisode reward: 145.0\nEpisode: 951\nEpisode reward: 121.0\nEpisode: 952\nEpisode reward: 149.0\nEpisode: 953\nEpisode reward: 124.0\nEpisode: 954\nEpisode reward: 132.0\nEpisode: 955\nEpisode reward: 200.0\nEpisode: 956\nEpisode reward: 200.0\nEpisode: 957\nEpisode reward: 123.0\nEpisode: 958\nEpisode reward: 200.0\nEpisode: 959\nEpisode reward: 200.0\nEpisode: 960\nEpisode reward: 136.0\nEpisode: 961\nEpisode reward: 169.0\nEpisode: 962\nEpisode reward: 151.0\nEpisode: 963\nEpisode reward: 113.0\nEpisode: 964\nEpisode reward: 148.0\nEpisode: 965\nEpisode reward: 138.0\nEpisode: 966\nEpisode reward: 200.0\nEpisode: 967\nEpisode reward: 167.0\nEpisode: 968\nEpisode reward: 200.0\nEpisode: 969\nEpisode reward: 160.0\nEpisode: 970\nEpisode reward: 157.0\nEpisode: 971\nEpisode reward: 160.0\nEpisode: 972\nEpisode reward: 143.0\nEpisode: 973\nEpisode reward: 163.0\nEpisode: 974\nEpisode reward: 110.0\nEpisode: 975\nEpisode reward: 200.0\nEpisode: 976\nEpisode reward: 113.0\nEpisode: 977\nEpisode reward: 200.0\nEpisode: 978\nEpisode reward: 135.0\nEpisode: 979\nEpisode reward: 159.0\nEpisode: 980\nEpisode reward: 118.0\nEpisode: 981\nEpisode reward: 200.0\nEpisode: 982\nEpisode reward: 122.0\nEpisode: 983\nEpisode reward: 191.0\nEpisode: 984\nEpisode reward: 149.0\nEpisode: 985\nEpisode reward: 156.0\nEpisode: 986\nEpisode reward: 119.0\nEpisode: 987\nEpisode reward: 164.0\nEpisode: 988\nEpisode reward: 112.0\nEpisode: 989\nEpisode reward: 155.0\nEpisode: 990\nEpisode reward: 148.0\nEpisode: 991\nEpisode reward: 194.0\nEpisode: 992\nEpisode reward: 112.0\nEpisode: 993\nEpisode reward: 162.0\nEpisode: 994\nEpisode reward: 160.0\nEpisode: 995\nEpisode reward: 190.0\nEpisode: 996\nEpisode reward: 178.0\nEpisode: 997\nEpisode reward: 109.0\nEpisode: 998\nEpisode reward: 145.0\nEpisode: 999\nEpisode reward: 131.0\nEpisode: 1000\nEpisode reward: 200.0\nEpisode: 1001\nEpisode reward: 160.0\nEpisode: 1002\nEpisode reward: 143.0\nEpisode: 1003\nEpisode reward: 167.0\nEpisode: 1004\nEpisode reward: 166.0\nEpisode: 1005\nEpisode reward: 183.0\nEpisode: 1006\nEpisode reward: 193.0\nEpisode: 1007\nEpisode reward: 157.0\nEpisode: 1008\nEpisode reward: 200.0\nEpisode: 1009\nEpisode reward: 151.0\nEpisode: 1010\nEpisode reward: 119.0\nEpisode: 1011\nEpisode reward: 168.0\nEpisode: 1012\nEpisode reward: 200.0\nEpisode: 1013\nEpisode reward: 130.0\nEpisode: 1014\nEpisode reward: 120.0\nEpisode: 1015\nEpisode reward: 149.0\nEpisode: 1016\nEpisode reward: 153.0\nEpisode: 1017\nEpisode reward: 121.0\nEpisode: 1018\nEpisode reward: 116.0\nEpisode: 1019\nEpisode reward: 155.0\nEpisode: 1020\nEpisode reward: 155.0\nEpisode: 1021\nEpisode reward: 90.0\nEpisode: 1022\nEpisode reward: 170.0\nEpisode: 1023\nEpisode reward: 112.0\nEpisode: 1024\nEpisode reward: 200.0\nEpisode: 1025\nEpisode reward: 172.0\nEpisode: 1026\nEpisode reward: 167.0\nEpisode: 1027\nEpisode reward: 200.0\nEpisode: 1028\nEpisode reward: 115.0\nEpisode: 1029\nEpisode reward: 155.0\nEpisode: 1030\nEpisode reward: 130.0\nEpisode: 1031\nEpisode reward: 130.0\nEpisode: 1032\nEpisode reward: 121.0\nEpisode: 1033\nEpisode reward: 117.0\nEpisode: 1034\nEpisode reward: 141.0\nEpisode: 1035\nEpisode reward: 132.0\nEpisode: 1036\nEpisode reward: 200.0\nEpisode: 1037\nEpisode reward: 177.0\nEpisode: 1038\nEpisode reward: 145.0\nEpisode: 1039\nEpisode reward: 150.0\nEpisode: 1040\nEpisode reward: 138.0\nEpisode: 1041\nEpisode reward: 121.0\nEpisode: 1042\nEpisode reward: 160.0\nEpisode: 1043\nEpisode reward: 159.0\nEpisode: 1044\nEpisode reward: 200.0\nEpisode: 1045\nEpisode reward: 132.0\nEpisode: 1046\nEpisode reward: 200.0\nEpisode: 1047\nEpisode reward: 129.0\nEpisode: 1048\nEpisode reward: 87.0\nEpisode: 1049\nEpisode reward: 146.0\nEpisode: 1050\nEpisode reward: 82.0\nEpisode: 1051\nEpisode reward: 194.0\nEpisode: 1052\nEpisode reward: 200.0\nEpisode: 1053\nEpisode reward: 121.0\nEpisode: 1054\nEpisode reward: 200.0\nEpisode: 1055\nEpisode reward: 131.0\nEpisode: 1056\nEpisode reward: 139.0\nEpisode: 1057\nEpisode reward: 190.0\nEpisode: 1058\nEpisode reward: 159.0\nEpisode: 1059\nEpisode reward: 139.0\nEpisode: 1060\nEpisode reward: 120.0\nEpisode: 1061\nEpisode reward: 189.0\nEpisode: 1062\nEpisode reward: 145.0\nEpisode: 1063\nEpisode reward: 200.0\nEpisode: 1064\nEpisode reward: 159.0\nEpisode: 1065\nEpisode reward: 112.0\nEpisode: 1066\nEpisode reward: 154.0\nEpisode: 1067\nEpisode reward: 152.0\nEpisode: 1068\nEpisode reward: 200.0\nEpisode: 1069\nEpisode reward: 178.0\nEpisode: 1070\nEpisode reward: 200.0\nEpisode: 1071\nEpisode reward: 200.0\nEpisode: 1072\nEpisode reward: 112.0\nEpisode: 1073\nEpisode reward: 178.0\nEpisode: 1074\nEpisode reward: 124.0\nEpisode: 1075\nEpisode reward: 174.0\nEpisode: 1076\nEpisode reward: 106.0\nEpisode: 1077\nEpisode reward: 180.0\nEpisode: 1078\nEpisode reward: 167.0\nEpisode: 1079\nEpisode reward: 117.0\nEpisode: 1080\nEpisode reward: 200.0\nEpisode: 1081\nEpisode reward: 190.0\nEpisode: 1082\nEpisode reward: 152.0\nEpisode: 1083\nEpisode reward: 145.0\nEpisode: 1084\nEpisode reward: 121.0\nEpisode: 1085\nEpisode reward: 129.0\nEpisode: 1086\nEpisode reward: 144.0\nEpisode: 1087\nEpisode reward: 128.0\nEpisode: 1088\nEpisode reward: 115.0\nEpisode: 1089\nEpisode reward: 142.0\nEpisode: 1090\nEpisode reward: 145.0\nEpisode: 1091\nEpisode reward: 146.0\nEpisode: 1092\nEpisode reward: 188.0\nEpisode: 1093\nEpisode reward: 136.0\nEpisode: 1094\nEpisode reward: 165.0\nEpisode: 1095\nEpisode reward: 145.0\nEpisode: 1096\nEpisode reward: 200.0\nEpisode: 1097\nEpisode reward: 200.0\nEpisode: 1098\nEpisode reward: 112.0\nEpisode: 1099\nEpisode reward: 164.0\nEpisode: 1100\nEpisode reward: 115.0\nEpisode: 1101\nEpisode reward: 105.0\nEpisode: 1102\nEpisode reward: 114.0\nEpisode: 1103\nEpisode reward: 146.0\nEpisode: 1104\nEpisode reward: 156.0\nEpisode: 1105\nEpisode reward: 189.0\nEpisode: 1106\nEpisode reward: 200.0\nEpisode: 1107\nEpisode reward: 200.0\nEpisode: 1108\nEpisode reward: 200.0\nEpisode: 1109\nEpisode reward: 144.0\nEpisode: 1110\nEpisode reward: 185.0\nEpisode: 1111\nEpisode reward: 200.0\nEpisode: 1112\nEpisode reward: 109.0\nEpisode: 1113\nEpisode reward: 115.0\nEpisode: 1114\nEpisode reward: 200.0\nEpisode: 1115\nEpisode reward: 200.0\nEpisode: 1116\nEpisode reward: 195.0\nEpisode: 1117\nEpisode reward: 200.0\nEpisode: 1118\nEpisode reward: 146.0\nEpisode: 1119\nEpisode reward: 108.0\nEpisode: 1120\nEpisode reward: 168.0\nEpisode: 1121\nEpisode reward: 117.0\nEpisode: 1122\nEpisode reward: 118.0\nEpisode: 1123\nEpisode reward: 196.0\nEpisode: 1124\nEpisode reward: 151.0\nEpisode: 1125\nEpisode reward: 154.0\nEpisode: 1126\nEpisode reward: 199.0\nEpisode: 1127\nEpisode reward: 187.0\nEpisode: 1128\nEpisode reward: 155.0\nEpisode: 1129\nEpisode reward: 200.0\nEpisode: 1130\nEpisode reward: 166.0\nEpisode: 1131\nEpisode reward: 146.0\nEpisode: 1132\nEpisode reward: 188.0\nEpisode: 1133\nEpisode reward: 154.0\nEpisode: 1134\nEpisode reward: 162.0\nEpisode: 1135\nEpisode reward: 200.0\nEpisode: 1136\nEpisode reward: 108.0\nEpisode: 1137\nEpisode reward: 177.0\nEpisode: 1138\nEpisode reward: 102.0\nEpisode: 1139\nEpisode reward: 92.0\nEpisode: 1140\nEpisode reward: 174.0\nEpisode: 1141\nEpisode reward: 112.0\nEpisode: 1142\nEpisode reward: 140.0\nEpisode: 1143\nEpisode reward: 154.0\nEpisode: 1144\nEpisode reward: 114.0\nEpisode: 1145\nEpisode reward: 136.0\nEpisode: 1146\nEpisode reward: 200.0\nEpisode: 1147\nEpisode reward: 158.0\nEpisode: 1148\nEpisode reward: 193.0\nEpisode: 1149\nEpisode reward: 103.0\nEpisode: 1150\nEpisode reward: 117.0\nEpisode: 1151\nEpisode reward: 136.0\nEpisode: 1152\nEpisode reward: 187.0\nEpisode: 1153\nEpisode reward: 108.0\nEpisode: 1154\nEpisode reward: 157.0\nEpisode: 1155\nEpisode reward: 200.0\nEpisode: 1156\nEpisode reward: 112.0\nEpisode: 1157\nEpisode reward: 181.0\nEpisode: 1158\nEpisode reward: 149.0\nEpisode: 1159\nEpisode reward: 200.0\nEpisode: 1160\nEpisode reward: 155.0\nEpisode: 1161\nEpisode reward: 138.0\nEpisode: 1162\nEpisode reward: 135.0\nEpisode: 1163\nEpisode reward: 130.0\nEpisode: 1164\nEpisode reward: 85.0\nEpisode: 1165\nEpisode reward: 101.0\nEpisode: 1166\nEpisode reward: 200.0\nEpisode: 1167\nEpisode reward: 151.0\nEpisode: 1168\nEpisode reward: 153.0\nEpisode: 1169\nEpisode reward: 117.0\nEpisode: 1170\nEpisode reward: 183.0\nEpisode: 1171\nEpisode reward: 123.0\nEpisode: 1172\nEpisode reward: 143.0\nEpisode: 1173\nEpisode reward: 126.0\nEpisode: 1174\nEpisode reward: 140.0\nEpisode: 1175\nEpisode reward: 138.0\nEpisode: 1176\nEpisode reward: 159.0\nEpisode: 1177\nEpisode reward: 184.0\nEpisode: 1178\nEpisode reward: 124.0\nEpisode: 1179\nEpisode reward: 174.0\nEpisode: 1180\nEpisode reward: 163.0\nEpisode: 1181\nEpisode reward: 200.0\nEpisode: 1182\nEpisode reward: 168.0\nEpisode: 1183\nEpisode reward: 132.0\nEpisode: 1184\nEpisode reward: 190.0\nEpisode: 1185\nEpisode reward: 167.0\nEpisode: 1186\nEpisode reward: 126.0\nEpisode: 1187\nEpisode reward: 200.0\nEpisode: 1188\nEpisode reward: 189.0\nEpisode: 1189\nEpisode reward: 169.0\nEpisode: 1190\nEpisode reward: 123.0\nEpisode: 1191\nEpisode reward: 194.0\nEpisode: 1192\nEpisode reward: 125.0\nEpisode: 1193\nEpisode reward: 153.0\nEpisode: 1194\nEpisode reward: 129.0\nEpisode: 1195\nEpisode reward: 128.0\nEpisode: 1196\nEpisode reward: 165.0\nEpisode: 1197\nEpisode reward: 173.0\nEpisode: 1198\nEpisode reward: 197.0\nEpisode: 1199\nEpisode reward: 149.0\nEpisode: 1200\nEpisode reward: 115.0\nEpisode: 1201\nEpisode reward: 135.0\nEpisode: 1202\nEpisode reward: 150.0\nEpisode: 1203\nEpisode reward: 200.0\nEpisode: 1204\nEpisode reward: 119.0\nEpisode: 1205\nEpisode reward: 122.0\nEpisode: 1206\nEpisode reward: 200.0\nEpisode: 1207\nEpisode reward: 125.0\nEpisode: 1208\nEpisode reward: 132.0\nEpisode: 1209\nEpisode reward: 122.0\nEpisode: 1210\nEpisode reward: 162.0\nEpisode: 1211\nEpisode reward: 159.0\nEpisode: 1212\nEpisode reward: 200.0\nEpisode: 1213\nEpisode reward: 126.0\nEpisode: 1214\nEpisode reward: 200.0\nEpisode: 1215\nEpisode reward: 149.0\nEpisode: 1216\nEpisode reward: 140.0\nEpisode: 1217\nEpisode reward: 200.0\nEpisode: 1218\nEpisode reward: 158.0\nEpisode: 1219\nEpisode reward: 142.0\nEpisode: 1220\nEpisode reward: 165.0\nEpisode: 1221\nEpisode reward: 147.0\nEpisode: 1222\nEpisode reward: 200.0\nEpisode: 1223\nEpisode reward: 200.0\nEpisode: 1224\nEpisode reward: 113.0\nEpisode: 1225\nEpisode reward: 200.0\nEpisode: 1226\nEpisode reward: 149.0\nEpisode: 1227\nEpisode reward: 200.0\nEpisode: 1228\nEpisode reward: 148.0\nEpisode: 1229\nEpisode reward: 189.0\nEpisode: 1230\nEpisode reward: 143.0\nEpisode: 1231\nEpisode reward: 154.0\nEpisode: 1232\nEpisode reward: 200.0\nEpisode: 1233\nEpisode reward: 179.0\nEpisode: 1234\nEpisode reward: 121.0\nEpisode: 1235\nEpisode reward: 179.0\nEpisode: 1236\nEpisode reward: 200.0\nEpisode: 1237\nEpisode reward: 188.0\nEpisode: 1238\nEpisode reward: 137.0\nEpisode: 1239\nEpisode reward: 163.0\nEpisode: 1240\nEpisode reward: 200.0\nEpisode: 1241\nEpisode reward: 159.0\nEpisode: 1242\nEpisode reward: 143.0\nEpisode: 1243\nEpisode reward: 171.0\nEpisode: 1244\nEpisode reward: 115.0\nEpisode: 1245\nEpisode reward: 155.0\nEpisode: 1246\nEpisode reward: 122.0\nEpisode: 1247\nEpisode reward: 157.0\nEpisode: 1248\nEpisode reward: 121.0\nEpisode: 1249\nEpisode reward: 147.0\nEpisode: 1250\nEpisode reward: 173.0\nEpisode: 1251\nEpisode reward: 200.0\nEpisode: 1252\nEpisode reward: 153.0\nEpisode: 1253\nEpisode reward: 155.0\nEpisode: 1254\nEpisode reward: 120.0\nEpisode: 1255\nEpisode reward: 160.0\nEpisode: 1256\nEpisode reward: 169.0\nEpisode: 1257\nEpisode reward: 200.0\nEpisode: 1258\nEpisode reward: 163.0\nEpisode: 1259\nEpisode reward: 195.0\nEpisode: 1260\nEpisode reward: 200.0\nEpisode: 1261\nEpisode reward: 118.0\nEpisode: 1262\nEpisode reward: 162.0\nEpisode: 1263\nEpisode reward: 127.0\nEpisode: 1264\nEpisode reward: 138.0\nEpisode: 1265\nEpisode reward: 157.0\nEpisode: 1266\nEpisode reward: 80.0\nEpisode: 1267\nEpisode reward: 200.0\nEpisode: 1268\nEpisode reward: 123.0\nEpisode: 1269\nEpisode reward: 186.0\nEpisode: 1270\nEpisode reward: 200.0\nEpisode: 1271\nEpisode reward: 200.0\nEpisode: 1272\nEpisode reward: 106.0\nEpisode: 1273\nEpisode reward: 193.0\nEpisode: 1274\nEpisode reward: 146.0\nEpisode: 1275\nEpisode reward: 200.0\nEpisode: 1276\nEpisode reward: 139.0\nEpisode: 1277\nEpisode reward: 131.0\nEpisode: 1278\nEpisode reward: 184.0\nEpisode: 1279\nEpisode reward: 85.0\nEpisode: 1280\nEpisode reward: 150.0\nEpisode: 1281\nEpisode reward: 131.0\nEpisode: 1282\nEpisode reward: 143.0\nEpisode: 1283\nEpisode reward: 142.0\nEpisode: 1284\nEpisode reward: 130.0\nEpisode: 1285\nEpisode reward: 150.0\nEpisode: 1286\nEpisode reward: 138.0\nEpisode: 1287\nEpisode reward: 117.0\nEpisode: 1288\nEpisode reward: 178.0\nEpisode: 1289\nEpisode reward: 163.0\nEpisode: 1290\nEpisode reward: 137.0\nEpisode: 1291\nEpisode reward: 136.0\nEpisode: 1292\nEpisode reward: 136.0\nEpisode: 1293\nEpisode reward: 120.0\nEpisode: 1294\nEpisode reward: 185.0\nEpisode: 1295\nEpisode reward: 200.0\nEpisode: 1296\nEpisode reward: 200.0\nEpisode: 1297\nEpisode reward: 200.0\nEpisode: 1298\nEpisode reward: 148.0\nEpisode: 1299\nEpisode reward: 200.0\nEpisode: 1300\nEpisode reward: 129.0\nEpisode: 1301\nEpisode reward: 177.0\nEpisode: 1302\nEpisode reward: 200.0\nEpisode: 1303\nEpisode reward: 161.0\nEpisode: 1304\nEpisode reward: 123.0\nEpisode: 1305\nEpisode reward: 200.0\nEpisode: 1306\nEpisode reward: 151.0\nEpisode: 1307\nEpisode reward: 167.0\nEpisode: 1308\nEpisode reward: 112.0\nEpisode: 1309\nEpisode reward: 200.0\nEpisode: 1310\nEpisode reward: 200.0\nEpisode: 1311\nEpisode reward: 174.0\nEpisode: 1312\nEpisode reward: 111.0\nEpisode: 1313\nEpisode reward: 200.0\nEpisode: 1314\nEpisode reward: 92.0\nEpisode: 1315\nEpisode reward: 104.0\nEpisode: 1316\nEpisode reward: 157.0\nEpisode: 1317\nEpisode reward: 125.0\nEpisode: 1318\nEpisode reward: 173.0\nEpisode: 1319\nEpisode reward: 128.0\nEpisode: 1320\nEpisode reward: 156.0\nEpisode: 1321\nEpisode reward: 175.0\nEpisode: 1322\nEpisode reward: 106.0\nEpisode: 1323\nEpisode reward: 113.0\nEpisode: 1324\nEpisode reward: 147.0\nEpisode: 1325\nEpisode reward: 138.0\nEpisode: 1326\nEpisode reward: 155.0\nEpisode: 1327\nEpisode reward: 200.0\nEpisode: 1328\nEpisode reward: 169.0\nEpisode: 1329\nEpisode reward: 200.0\nEpisode: 1330\nEpisode reward: 166.0\nEpisode: 1331\nEpisode reward: 122.0\nEpisode: 1332\nEpisode reward: 148.0\nEpisode: 1333\nEpisode reward: 140.0\nEpisode: 1334\nEpisode reward: 170.0\nEpisode: 1335\nEpisode reward: 113.0\nEpisode: 1336\nEpisode reward: 168.0\nEpisode: 1337\nEpisode reward: 122.0\nEpisode: 1338\nEpisode reward: 142.0\nEpisode: 1339\nEpisode reward: 68.0\nEpisode: 1340\nEpisode reward: 200.0\nEpisode: 1341\nEpisode reward: 138.0\nEpisode: 1342\nEpisode reward: 200.0\nEpisode: 1343\nEpisode reward: 109.0\nEpisode: 1344\nEpisode reward: 133.0\nEpisode: 1345\nEpisode reward: 200.0\nEpisode: 1346\nEpisode reward: 147.0\nEpisode: 1347\nEpisode reward: 117.0\nEpisode: 1348\nEpisode reward: 119.0\nEpisode: 1349\nEpisode reward: 112.0\nEpisode: 1350\nEpisode reward: 131.0\nEpisode: 1351\nEpisode reward: 178.0\nEpisode: 1352\nEpisode reward: 122.0\nEpisode: 1353\nEpisode reward: 152.0\nEpisode: 1354\nEpisode reward: 200.0\nEpisode: 1355\nEpisode reward: 105.0\nEpisode: 1356\nEpisode reward: 126.0\nEpisode: 1357\nEpisode reward: 146.0\nEpisode: 1358\nEpisode reward: 116.0\nEpisode: 1359\nEpisode reward: 112.0\nEpisode: 1360\nEpisode reward: 191.0\nEpisode: 1361\nEpisode reward: 144.0\nEpisode: 1362\nEpisode reward: 151.0\nEpisode: 1363\nEpisode reward: 163.0\nEpisode: 1364\nEpisode reward: 200.0\nEpisode: 1365\nEpisode reward: 181.0\nEpisode: 1366\nEpisode reward: 158.0\nEpisode: 1367\nEpisode reward: 117.0\nEpisode: 1368\nEpisode reward: 150.0\nEpisode: 1369\nEpisode reward: 112.0\nEpisode: 1370\nEpisode reward: 196.0\nEpisode: 1371\nEpisode reward: 156.0\nEpisode: 1372\nEpisode reward: 131.0\nEpisode: 1373\nEpisode reward: 200.0\nEpisode: 1374\nEpisode reward: 199.0\nEpisode: 1375\nEpisode reward: 134.0\nEpisode: 1376\nEpisode reward: 200.0\nEpisode: 1377\nEpisode reward: 154.0\nEpisode: 1378\nEpisode reward: 162.0\nEpisode: 1379\nEpisode reward: 113.0\nEpisode: 1380\nEpisode reward: 165.0\nEpisode: 1381\nEpisode reward: 136.0\nEpisode: 1382\nEpisode reward: 129.0\nEpisode: 1383\nEpisode reward: 128.0\nEpisode: 1384\nEpisode reward: 187.0\nEpisode: 1385\nEpisode reward: 140.0\nEpisode: 1386\nEpisode reward: 108.0\nEpisode: 1387\nEpisode reward: 148.0\nEpisode: 1388\nEpisode reward: 147.0\nEpisode: 1389\nEpisode reward: 121.0\nEpisode: 1390\nEpisode reward: 157.0\nEpisode: 1391\nEpisode reward: 162.0\nEpisode: 1392\nEpisode reward: 143.0\nEpisode: 1393\nEpisode reward: 200.0\nEpisode: 1394\nEpisode reward: 118.0\nEpisode: 1395\nEpisode reward: 200.0\nEpisode: 1396\nEpisode reward: 200.0\nEpisode: 1397\nEpisode reward: 200.0\nEpisode: 1398\nEpisode reward: 147.0\nEpisode: 1399\nEpisode reward: 190.0\nEpisode: 1400\nEpisode reward: 200.0\nEpisode: 1401\nEpisode reward: 183.0\nEpisode: 1402\nEpisode reward: 115.0\nEpisode: 1403\nEpisode reward: 140.0\nEpisode: 1404\nEpisode reward: 163.0\nEpisode: 1405\nEpisode reward: 123.0\nEpisode: 1406\nEpisode reward: 173.0\nEpisode: 1407\nEpisode reward: 108.0\nEpisode: 1408\nEpisode reward: 180.0\nEpisode: 1409\nEpisode reward: 189.0\nEpisode: 1410\nEpisode reward: 140.0\nEpisode: 1411\nEpisode reward: 120.0\nEpisode: 1412\nEpisode reward: 167.0\nEpisode: 1413\nEpisode reward: 187.0\nEpisode: 1414\nEpisode reward: 110.0\nEpisode: 1415\nEpisode reward: 194.0\nEpisode: 1416\nEpisode reward: 126.0\nEpisode: 1417\nEpisode reward: 130.0\nEpisode: 1418\nEpisode reward: 137.0\nEpisode: 1419\nEpisode reward: 111.0\nEpisode: 1420\nEpisode reward: 150.0\nEpisode: 1421\nEpisode reward: 178.0\nEpisode: 1422\nEpisode reward: 146.0\nEpisode: 1423\nEpisode reward: 150.0\nEpisode: 1424\nEpisode reward: 113.0\nEpisode: 1425\nEpisode reward: 200.0\nEpisode: 1426\nEpisode reward: 143.0\nEpisode: 1427\nEpisode reward: 163.0\nEpisode: 1428\nEpisode reward: 162.0\nEpisode: 1429\nEpisode reward: 148.0\nEpisode: 1430\nEpisode reward: 133.0\nEpisode: 1431\nEpisode reward: 200.0\nEpisode: 1432\nEpisode reward: 166.0\nEpisode: 1433\nEpisode reward: 137.0\nEpisode: 1434\nEpisode reward: 167.0\nEpisode: 1435\nEpisode reward: 150.0\nEpisode: 1436\nEpisode reward: 183.0\nEpisode: 1437\nEpisode reward: 200.0\nEpisode: 1438\nEpisode reward: 192.0\nEpisode: 1439\nEpisode reward: 129.0\nEpisode: 1440\nEpisode reward: 157.0\nEpisode: 1441\nEpisode reward: 131.0\nEpisode: 1442\nEpisode reward: 140.0\nEpisode: 1443\nEpisode reward: 115.0\nEpisode: 1444\nEpisode reward: 200.0\nEpisode: 1445\nEpisode reward: 187.0\nEpisode: 1446\nEpisode reward: 170.0\nEpisode: 1447\nEpisode reward: 200.0\nEpisode: 1448\nEpisode reward: 198.0\nEpisode: 1449\nEpisode reward: 200.0\nEpisode: 1450\nEpisode reward: 175.0\nEpisode: 1451\nEpisode reward: 200.0\nEpisode: 1452\nEpisode reward: 200.0\nEpisode: 1453\nEpisode reward: 108.0\nEpisode: 1454\nEpisode reward: 200.0\nEpisode: 1455\nEpisode reward: 200.0\nEpisode: 1456\nEpisode reward: 192.0\nEpisode: 1457\nEpisode reward: 200.0\nEpisode: 1458\nEpisode reward: 159.0\nEpisode: 1459\nEpisode reward: 146.0\nEpisode: 1460\nEpisode reward: 138.0\nEpisode: 1461\nEpisode reward: 150.0\nEpisode: 1462\nEpisode reward: 168.0\nEpisode: 1463\nEpisode reward: 200.0\nEpisode: 1464\nEpisode reward: 123.0\nEpisode: 1465\nEpisode reward: 131.0\nEpisode: 1466\nEpisode reward: 117.0\nEpisode: 1467\nEpisode reward: 200.0\nEpisode: 1468\nEpisode reward: 200.0\nEpisode: 1469\nEpisode reward: 200.0\nEpisode: 1470\nEpisode reward: 200.0\nEpisode: 1471\nEpisode reward: 146.0\nEpisode: 1472\nEpisode reward: 140.0\nEpisode: 1473\nEpisode reward: 131.0\nEpisode: 1474\nEpisode reward: 200.0\nEpisode: 1475\nEpisode reward: 115.0\nEpisode: 1476\nEpisode reward: 200.0\nEpisode: 1477\nEpisode reward: 125.0\nEpisode: 1478\nEpisode reward: 200.0\nEpisode: 1479\nEpisode reward: 200.0\nEpisode: 1480\nEpisode reward: 123.0\nEpisode: 1481\nEpisode reward: 200.0\nEpisode: 1482\nEpisode reward: 170.0\nEpisode: 1483\nEpisode reward: 133.0\nEpisode: 1484\nEpisode reward: 200.0\nEpisode: 1485\nEpisode reward: 141.0\nEpisode: 1486\nEpisode reward: 183.0\nEpisode: 1487\nEpisode reward: 192.0\nEpisode: 1488\nEpisode reward: 200.0\nEpisode: 1489\nEpisode reward: 153.0\nEpisode: 1490\nEpisode reward: 112.0\nEpisode: 1491\nEpisode reward: 200.0\nEpisode: 1492\nEpisode reward: 137.0\nEpisode: 1493\nEpisode reward: 190.0\nEpisode: 1494\nEpisode reward: 188.0\nEpisode: 1495\nEpisode reward: 143.0\nEpisode: 1496\nEpisode reward: 200.0\nEpisode: 1497\nEpisode reward: 180.0\nEpisode: 1498\nEpisode reward: 137.0\nEpisode: 1499\nEpisode reward: 148.0\nEpisode: 1500\nEpisode reward: 136.0\nEpisode: 1501\nEpisode reward: 200.0\nEpisode: 1502\nEpisode reward: 139.0\nEpisode: 1503\nEpisode reward: 200.0\nEpisode: 1504\nEpisode reward: 191.0\nEpisode: 1505\nEpisode reward: 144.0\nEpisode: 1506\nEpisode reward: 153.0\nEpisode: 1507\nEpisode reward: 129.0\nEpisode: 1508\nEpisode reward: 165.0\nEpisode: 1509\nEpisode reward: 121.0\nEpisode: 1510\nEpisode reward: 131.0\nEpisode: 1511\nEpisode reward: 169.0\nEpisode: 1512\nEpisode reward: 119.0\nEpisode: 1513\nEpisode reward: 158.0\nEpisode: 1514\nEpisode reward: 125.0\nEpisode: 1515\nEpisode reward: 195.0\nEpisode: 1516\nEpisode reward: 117.0\nEpisode: 1517\nEpisode reward: 174.0\nEpisode: 1518\nEpisode reward: 200.0\nEpisode: 1519\nEpisode reward: 160.0\nEpisode: 1520\nEpisode reward: 144.0\nEpisode: 1521\nEpisode reward: 113.0\nEpisode: 1522\nEpisode reward: 118.0\nEpisode: 1523\nEpisode reward: 200.0\nEpisode: 1524\nEpisode reward: 169.0\nEpisode: 1525\nEpisode reward: 63.0\nEpisode: 1526\nEpisode reward: 200.0\nEpisode: 1527\nEpisode reward: 200.0\nEpisode: 1528\nEpisode reward: 200.0\nEpisode: 1529\nEpisode reward: 163.0\nEpisode: 1530\nEpisode reward: 200.0\nEpisode: 1531\nEpisode reward: 119.0\nEpisode: 1532\nEpisode reward: 105.0\nEpisode: 1533\nEpisode reward: 145.0\nEpisode: 1534\nEpisode reward: 197.0\nEpisode: 1535\nEpisode reward: 156.0\nEpisode: 1536\nEpisode reward: 200.0\nEpisode: 1537\nEpisode reward: 125.0\nEpisode: 1538\nEpisode reward: 200.0\nEpisode: 1539\nEpisode reward: 200.0\nEpisode: 1540\nEpisode reward: 193.0\nEpisode: 1541\nEpisode reward: 200.0\nEpisode: 1542\nEpisode reward: 200.0\nEpisode: 1543\nEpisode reward: 135.0\nEpisode: 1544\nEpisode reward: 200.0\nEpisode: 1545\nEpisode reward: 124.0\nEpisode: 1546\nEpisode reward: 157.0\nEpisode: 1547\nEpisode reward: 130.0\nEpisode: 1548\nEpisode reward: 140.0\nEpisode: 1549\nEpisode reward: 121.0\nEpisode: 1550\nEpisode reward: 159.0\nEpisode: 1551\nEpisode reward: 169.0\nEpisode: 1552\nEpisode reward: 200.0\nEpisode: 1553\nEpisode reward: 196.0\nEpisode: 1554\nEpisode reward: 200.0\nEpisode: 1555\nEpisode reward: 148.0\nEpisode: 1556\nEpisode reward: 191.0\nEpisode: 1557\nEpisode reward: 140.0\nEpisode: 1558\nEpisode reward: 119.0\nEpisode: 1559\nEpisode reward: 153.0\nEpisode: 1560\nEpisode reward: 174.0\nEpisode: 1561\nEpisode reward: 131.0\nEpisode: 1562\nEpisode reward: 200.0\nEpisode: 1563\nEpisode reward: 200.0\nEpisode: 1564\nEpisode reward: 138.0\nEpisode: 1565\nEpisode reward: 200.0\nEpisode: 1566\nEpisode reward: 196.0\nEpisode: 1567\nEpisode reward: 155.0\nEpisode: 1568\nEpisode reward: 142.0\nEpisode: 1569\nEpisode reward: 145.0\nEpisode: 1570\nEpisode reward: 145.0\nEpisode: 1571\nEpisode reward: 147.0\nEpisode: 1572\nEpisode reward: 120.0\nEpisode: 1573\nEpisode reward: 156.0\nEpisode: 1574\nEpisode reward: 140.0\nEpisode: 1575\nEpisode reward: 135.0\nEpisode: 1576\nEpisode reward: 182.0\nEpisode: 1577\nEpisode reward: 127.0\nEpisode: 1578\nEpisode reward: 200.0\nEpisode: 1579\nEpisode reward: 150.0\nEpisode: 1580\nEpisode reward: 200.0\nEpisode: 1581\nEpisode reward: 153.0\nEpisode: 1582\nEpisode reward: 121.0\nEpisode: 1583\nEpisode reward: 125.0\nEpisode: 1584\nEpisode reward: 199.0\nEpisode: 1585\nEpisode reward: 115.0\nEpisode: 1586\nEpisode reward: 146.0\nEpisode: 1587\nEpisode reward: 95.0\nEpisode: 1588\nEpisode reward: 134.0\nEpisode: 1589\nEpisode reward: 120.0\nEpisode: 1590\nEpisode reward: 184.0\nEpisode: 1591\nEpisode reward: 137.0\nEpisode: 1592\nEpisode reward: 200.0\nEpisode: 1593\nEpisode reward: 151.0\nEpisode: 1594\nEpisode reward: 136.0\nEpisode: 1595\nEpisode reward: 200.0\nEpisode: 1596\nEpisode reward: 101.0\nEpisode: 1597\nEpisode reward: 134.0\nEpisode: 1598\nEpisode reward: 134.0\nEpisode: 1599\nEpisode reward: 136.0\nEpisode: 1600\nEpisode reward: 200.0\nEpisode: 1601\nEpisode reward: 139.0\nEpisode: 1602\nEpisode reward: 115.0\nEpisode: 1603\nEpisode reward: 113.0\nEpisode: 1604\nEpisode reward: 200.0\nEpisode: 1605\nEpisode reward: 200.0\nEpisode: 1606\nEpisode reward: 200.0\nEpisode: 1607\nEpisode reward: 185.0\nEpisode: 1608\nEpisode reward: 143.0\nEpisode: 1609\nEpisode reward: 200.0\nEpisode: 1610\nEpisode reward: 198.0\nEpisode: 1611\nEpisode reward: 107.0\nEpisode: 1612\nEpisode reward: 149.0\nEpisode: 1613\nEpisode reward: 200.0\nEpisode: 1614\nEpisode reward: 168.0\nEpisode: 1615\nEpisode reward: 200.0\nEpisode: 1616\nEpisode reward: 135.0\nEpisode: 1617\nEpisode reward: 126.0\nEpisode: 1618\nEpisode reward: 157.0\nEpisode: 1619\nEpisode reward: 174.0\nEpisode: 1620\nEpisode reward: 173.0\nEpisode: 1621\nEpisode reward: 200.0\nEpisode: 1622\nEpisode reward: 200.0\nEpisode: 1623\nEpisode reward: 143.0\nEpisode: 1624\nEpisode reward: 146.0\nEpisode: 1625\nEpisode reward: 200.0\nEpisode: 1626\nEpisode reward: 116.0\nEpisode: 1627\nEpisode reward: 164.0\nEpisode: 1628\nEpisode reward: 129.0\nEpisode: 1629\nEpisode reward: 146.0\nEpisode: 1630\nEpisode reward: 130.0\nEpisode: 1631\nEpisode reward: 200.0\nEpisode: 1632\nEpisode reward: 116.0\nEpisode: 1633\nEpisode reward: 200.0\nEpisode: 1634\nEpisode reward: 200.0\nEpisode: 1635\nEpisode reward: 143.0\nEpisode: 1636\nEpisode reward: 175.0\nEpisode: 1637\nEpisode reward: 157.0\nEpisode: 1638\nEpisode reward: 105.0\nEpisode: 1639\nEpisode reward: 180.0\nEpisode: 1640\nEpisode reward: 183.0\nEpisode: 1641\nEpisode reward: 119.0\nEpisode: 1642\nEpisode reward: 200.0\nEpisode: 1643\nEpisode reward: 200.0\nEpisode: 1644\nEpisode reward: 118.0\nEpisode: 1645\nEpisode reward: 187.0\nEpisode: 1646\nEpisode reward: 114.0\nEpisode: 1647\nEpisode reward: 197.0\nEpisode: 1648\nEpisode reward: 200.0\nEpisode: 1649\nEpisode reward: 156.0\nEpisode: 1650\nEpisode reward: 172.0\nEpisode: 1651\nEpisode reward: 114.0\nEpisode: 1652\nEpisode reward: 191.0\nEpisode: 1653\nEpisode reward: 136.0\nEpisode: 1654\nEpisode reward: 111.0\nEpisode: 1655\nEpisode reward: 182.0\nEpisode: 1656\nEpisode reward: 152.0\nEpisode: 1657\nEpisode reward: 191.0\nEpisode: 1658\nEpisode reward: 131.0\nEpisode: 1659\nEpisode reward: 130.0\nEpisode: 1660\nEpisode reward: 200.0\nEpisode: 1661\nEpisode reward: 189.0\nEpisode: 1662\nEpisode reward: 166.0\nEpisode: 1663\nEpisode reward: 200.0\nEpisode: 1664\nEpisode reward: 129.0\nEpisode: 1665\nEpisode reward: 200.0\nEpisode: 1666\nEpisode reward: 125.0\nEpisode: 1667\nEpisode reward: 152.0\nEpisode: 1668\nEpisode reward: 129.0\nEpisode: 1669\nEpisode reward: 162.0\nEpisode: 1670\nEpisode reward: 183.0\nEpisode: 1671\nEpisode reward: 155.0\nEpisode: 1672\nEpisode reward: 198.0\nEpisode: 1673\nEpisode reward: 162.0\nEpisode: 1674\nEpisode reward: 136.0\nEpisode: 1675\nEpisode reward: 146.0\nEpisode: 1676\nEpisode reward: 138.0\nEpisode: 1677\nEpisode reward: 184.0\nEpisode: 1678\nEpisode reward: 167.0\nEpisode: 1679\nEpisode reward: 175.0\nEpisode: 1680\nEpisode reward: 117.0\nEpisode: 1681\nEpisode reward: 200.0\nEpisode: 1682\nEpisode reward: 160.0\nEpisode: 1683\nEpisode reward: 119.0\nEpisode: 1684\nEpisode reward: 200.0\nEpisode: 1685\nEpisode reward: 158.0\nEpisode: 1686\nEpisode reward: 114.0\nEpisode: 1687\nEpisode reward: 160.0\nEpisode: 1688\nEpisode reward: 149.0\nEpisode: 1689\nEpisode reward: 175.0\nEpisode: 1690\nEpisode reward: 178.0\nEpisode: 1691\nEpisode reward: 200.0\nEpisode: 1692\nEpisode reward: 168.0\nEpisode: 1693\nEpisode reward: 116.0\nEpisode: 1694\nEpisode reward: 129.0\nEpisode: 1695\nEpisode reward: 118.0\nEpisode: 1696\nEpisode reward: 200.0\nEpisode: 1697\nEpisode reward: 131.0\nEpisode: 1698\nEpisode reward: 146.0\nEpisode: 1699\nEpisode reward: 200.0\nEpisode: 1700\nEpisode reward: 200.0\nEpisode: 1701\nEpisode reward: 146.0\nEpisode: 1702\nEpisode reward: 159.0\nEpisode: 1703\nEpisode reward: 122.0\nEpisode: 1704\nEpisode reward: 113.0\nEpisode: 1705\nEpisode reward: 200.0\nEpisode: 1706\nEpisode reward: 200.0\nEpisode: 1707\nEpisode reward: 200.0\nEpisode: 1708\nEpisode reward: 189.0\nEpisode: 1709\nEpisode reward: 108.0\nEpisode: 1710\nEpisode reward: 118.0\nEpisode: 1711\nEpisode reward: 110.0\nEpisode: 1712\nEpisode reward: 111.0\nEpisode: 1713\nEpisode reward: 149.0\nEpisode: 1714\nEpisode reward: 139.0\nEpisode: 1715\nEpisode reward: 185.0\nEpisode: 1716\nEpisode reward: 117.0\nEpisode: 1717\nEpisode reward: 162.0\nEpisode: 1718\nEpisode reward: 168.0\nEpisode: 1719\nEpisode reward: 200.0\nEpisode: 1720\nEpisode reward: 155.0\nEpisode: 1721\nEpisode reward: 200.0\nEpisode: 1722\nEpisode reward: 118.0\nEpisode: 1723\nEpisode reward: 151.0\nEpisode: 1724\nEpisode reward: 200.0\nEpisode: 1725\nEpisode reward: 153.0\nEpisode: 1726\nEpisode reward: 161.0\nEpisode: 1727\nEpisode reward: 148.0\nEpisode: 1728\nEpisode reward: 117.0\nEpisode: 1729\nEpisode reward: 142.0\nEpisode: 1730\nEpisode reward: 125.0\nEpisode: 1731\nEpisode reward: 99.0\nEpisode: 1732\nEpisode reward: 146.0\nEpisode: 1733\nEpisode reward: 166.0\nEpisode: 1734\nEpisode reward: 187.0\nEpisode: 1735\nEpisode reward: 200.0\nEpisode: 1736\nEpisode reward: 131.0\nEpisode: 1737\nEpisode reward: 169.0\nEpisode: 1738\nEpisode reward: 142.0\nEpisode: 1739\nEpisode reward: 200.0\nEpisode: 1740\nEpisode reward: 141.0\nEpisode: 1741\nEpisode reward: 136.0\nEpisode: 1742\nEpisode reward: 184.0\nEpisode: 1743\nEpisode reward: 162.0\nEpisode: 1744\nEpisode reward: 115.0\nEpisode: 1745\nEpisode reward: 126.0\nEpisode: 1746\nEpisode reward: 165.0\nEpisode: 1747\nEpisode reward: 200.0\nEpisode: 1748\nEpisode reward: 154.0\nEpisode: 1749\nEpisode reward: 192.0\nEpisode: 1750\nEpisode reward: 162.0\nEpisode: 1751\nEpisode reward: 200.0\nEpisode: 1752\nEpisode reward: 154.0\nEpisode: 1753\nEpisode reward: 152.0\nEpisode: 1754\nEpisode reward: 200.0\nEpisode: 1755\nEpisode reward: 200.0\nEpisode: 1756\nEpisode reward: 195.0\nEpisode: 1757\nEpisode reward: 200.0\nEpisode: 1758\nEpisode reward: 123.0\nEpisode: 1759\nEpisode reward: 123.0\nEpisode: 1760\nEpisode reward: 158.0\nEpisode: 1761\nEpisode reward: 115.0\nEpisode: 1762\nEpisode reward: 200.0\nEpisode: 1763\nEpisode reward: 200.0\nEpisode: 1764\nEpisode reward: 146.0\nEpisode: 1765\nEpisode reward: 158.0\nEpisode: 1766\nEpisode reward: 124.0\nEpisode: 1767\nEpisode reward: 158.0\nEpisode: 1768\nEpisode reward: 132.0\nEpisode: 1769\nEpisode reward: 199.0\nEpisode: 1770\nEpisode reward: 195.0\nEpisode: 1771\nEpisode reward: 111.0\nEpisode: 1772\nEpisode reward: 177.0\nEpisode: 1773\nEpisode reward: 114.0\nEpisode: 1774\nEpisode reward: 119.0\nEpisode: 1775\nEpisode reward: 144.0\nEpisode: 1776\nEpisode reward: 109.0\nEpisode: 1777\nEpisode reward: 200.0\nEpisode: 1778\nEpisode reward: 127.0\nEpisode: 1779\nEpisode reward: 200.0\nEpisode: 1780\nEpisode reward: 158.0\nEpisode: 1781\nEpisode reward: 114.0\nEpisode: 1782\nEpisode reward: 140.0\nEpisode: 1783\nEpisode reward: 160.0\nEpisode: 1784\nEpisode reward: 124.0\nEpisode: 1785\nEpisode reward: 175.0\nEpisode: 1786\nEpisode reward: 115.0\nEpisode: 1787\nEpisode reward: 155.0\nEpisode: 1788\nEpisode reward: 175.0\nEpisode: 1789\nEpisode reward: 129.0\nEpisode: 1790\nEpisode reward: 130.0\nEpisode: 1791\nEpisode reward: 111.0\nEpisode: 1792\nEpisode reward: 137.0\nEpisode: 1793\nEpisode reward: 200.0\nEpisode: 1794\nEpisode reward: 174.0\nEpisode: 1795\nEpisode reward: 108.0\nEpisode: 1796\nEpisode reward: 158.0\nEpisode: 1797\nEpisode reward: 145.0\nEpisode: 1798\nEpisode reward: 106.0\nEpisode: 1799\nEpisode reward: 125.0\nEpisode: 1800\nEpisode reward: 200.0\nEpisode: 1801\nEpisode reward: 149.0\nEpisode: 1802\nEpisode reward: 181.0\nEpisode: 1803\nEpisode reward: 161.0\nEpisode: 1804\nEpisode reward: 165.0\nEpisode: 1805\nEpisode reward: 173.0\nEpisode: 1806\nEpisode reward: 116.0\nEpisode: 1807\nEpisode reward: 175.0\nEpisode: 1808\nEpisode reward: 128.0\nEpisode: 1809\nEpisode reward: 132.0\nEpisode: 1810\nEpisode reward: 115.0\nEpisode: 1811\nEpisode reward: 131.0\nEpisode: 1812\nEpisode reward: 168.0\nEpisode: 1813\nEpisode reward: 111.0\nEpisode: 1814\nEpisode reward: 128.0\nEpisode: 1815\nEpisode reward: 126.0\nEpisode: 1816\nEpisode reward: 161.0\nEpisode: 1817\nEpisode reward: 200.0\nEpisode: 1818\nEpisode reward: 112.0\nEpisode: 1819\nEpisode reward: 121.0\nEpisode: 1820\nEpisode reward: 120.0\nEpisode: 1821\nEpisode reward: 153.0\nEpisode: 1822\nEpisode reward: 200.0\nEpisode: 1823\nEpisode reward: 113.0\nEpisode: 1824\nEpisode reward: 113.0\nEpisode: 1825\nEpisode reward: 119.0\nEpisode: 1826\nEpisode reward: 108.0\nEpisode: 1827\nEpisode reward: 113.0\nEpisode: 1828\nEpisode reward: 200.0\nEpisode: 1829\nEpisode reward: 134.0\nEpisode: 1830\nEpisode reward: 127.0\nEpisode: 1831\nEpisode reward: 200.0\nEpisode: 1832\nEpisode reward: 191.0\nEpisode: 1833\nEpisode reward: 142.0\nEpisode: 1834\nEpisode reward: 174.0\nEpisode: 1835\nEpisode reward: 157.0\nEpisode: 1836\nEpisode reward: 129.0\nEpisode: 1837\nEpisode reward: 150.0\nEpisode: 1838\nEpisode reward: 200.0\nEpisode: 1839\nEpisode reward: 168.0\nEpisode: 1840\nEpisode reward: 172.0\nEpisode: 1841\nEpisode reward: 172.0\nEpisode: 1842\nEpisode reward: 200.0\nEpisode: 1843\nEpisode reward: 192.0\nEpisode: 1844\nEpisode reward: 119.0\nEpisode: 1845\nEpisode reward: 134.0\nEpisode: 1846\nEpisode reward: 200.0\nEpisode: 1847\nEpisode reward: 111.0\nEpisode: 1848\nEpisode reward: 126.0\nEpisode: 1849\nEpisode reward: 160.0\nEpisode: 1850\nEpisode reward: 118.0\nEpisode: 1851\nEpisode reward: 146.0\nEpisode: 1852\nEpisode reward: 182.0\nEpisode: 1853\nEpisode reward: 111.0\nEpisode: 1854\nEpisode reward: 173.0\nEpisode: 1855\nEpisode reward: 144.0\nEpisode: 1856\nEpisode reward: 120.0\nEpisode: 1857\nEpisode reward: 169.0\nEpisode: 1858\nEpisode reward: 111.0\nEpisode: 1859\nEpisode reward: 149.0\nEpisode: 1860\nEpisode reward: 83.0\nEpisode: 1861\nEpisode reward: 143.0\nEpisode: 1862\nEpisode reward: 142.0\nEpisode: 1863\nEpisode reward: 108.0\nEpisode: 1864\nEpisode reward: 114.0\nEpisode: 1865\nEpisode reward: 140.0\nEpisode: 1866\nEpisode reward: 187.0\nEpisode: 1867\nEpisode reward: 113.0\nEpisode: 1868\nEpisode reward: 112.0\nEpisode: 1869\nEpisode reward: 155.0\nEpisode: 1870\nEpisode reward: 134.0\nEpisode: 1871\nEpisode reward: 155.0\nEpisode: 1872\nEpisode reward: 200.0\nEpisode: 1873\nEpisode reward: 199.0\nEpisode: 1874\nEpisode reward: 105.0\nEpisode: 1875\nEpisode reward: 147.0\nEpisode: 1876\nEpisode reward: 152.0\nEpisode: 1877\nEpisode reward: 117.0\nEpisode: 1878\nEpisode reward: 89.0\nEpisode: 1879\nEpisode reward: 138.0\nEpisode: 1880\nEpisode reward: 144.0\nEpisode: 1881\nEpisode reward: 136.0\nEpisode: 1882\nEpisode reward: 128.0\nEpisode: 1883\nEpisode reward: 168.0\nEpisode: 1884\nEpisode reward: 167.0\nEpisode: 1885\nEpisode reward: 121.0\nEpisode: 1886\nEpisode reward: 153.0\nEpisode: 1887\nEpisode reward: 176.0\nEpisode: 1888\nEpisode reward: 175.0\nEpisode: 1889\nEpisode reward: 200.0\nEpisode: 1890\nEpisode reward: 122.0\nEpisode: 1891\nEpisode reward: 116.0\nEpisode: 1892\nEpisode reward: 200.0\nEpisode: 1893\nEpisode reward: 154.0\nEpisode: 1894\nEpisode reward: 192.0\nEpisode: 1895\nEpisode reward: 190.0\nEpisode: 1896\nEpisode reward: 193.0\nEpisode: 1897\nEpisode reward: 200.0\nEpisode: 1898\nEpisode reward: 115.0\nEpisode: 1899\nEpisode reward: 200.0\nEpisode: 1900\nEpisode reward: 184.0\nEpisode: 1901\nEpisode reward: 123.0\nEpisode: 1902\nEpisode reward: 156.0\nEpisode: 1903\nEpisode reward: 131.0\nEpisode: 1904\nEpisode reward: 151.0\nEpisode: 1905\nEpisode reward: 144.0\nEpisode: 1906\nEpisode reward: 173.0\nEpisode: 1907\nEpisode reward: 200.0\nEpisode: 1908\nEpisode reward: 189.0\nEpisode: 1909\nEpisode reward: 136.0\nEpisode: 1910\nEpisode reward: 157.0\nEpisode: 1911\nEpisode reward: 200.0\nEpisode: 1912\nEpisode reward: 112.0\nEpisode: 1913\nEpisode reward: 123.0\nEpisode: 1914\nEpisode reward: 156.0\nEpisode: 1915\nEpisode reward: 180.0\nEpisode: 1916\nEpisode reward: 200.0\nEpisode: 1917\nEpisode reward: 146.0\nEpisode: 1918\nEpisode reward: 139.0\nEpisode: 1919\nEpisode reward: 144.0\nEpisode: 1920\nEpisode reward: 149.0\nEpisode: 1921\nEpisode reward: 200.0\nEpisode: 1922\nEpisode reward: 152.0\nEpisode: 1923\nEpisode reward: 166.0\nEpisode: 1924\nEpisode reward: 154.0\nEpisode: 1925\nEpisode reward: 200.0\nEpisode: 1926\nEpisode reward: 181.0\nEpisode: 1927\nEpisode reward: 106.0\nEpisode: 1928\nEpisode reward: 200.0\nEpisode: 1929\nEpisode reward: 116.0\nEpisode: 1930\nEpisode reward: 191.0\nEpisode: 1931\nEpisode reward: 95.0\nEpisode: 1932\nEpisode reward: 105.0\nEpisode: 1933\nEpisode reward: 156.0\nEpisode: 1934\nEpisode reward: 200.0\nEpisode: 1935\nEpisode reward: 155.0\nEpisode: 1936\nEpisode reward: 182.0\nEpisode: 1937\nEpisode reward: 200.0\nEpisode: 1938\nEpisode reward: 151.0\nEpisode: 1939\nEpisode reward: 200.0\nEpisode: 1940\nEpisode reward: 200.0\nEpisode: 1941\nEpisode reward: 66.0\nEpisode: 1942\nEpisode reward: 115.0\nEpisode: 1943\nEpisode reward: 192.0\nEpisode: 1944\nEpisode reward: 146.0\nEpisode: 1945\nEpisode reward: 200.0\nEpisode: 1946\nEpisode reward: 135.0\nEpisode: 1947\nEpisode reward: 200.0\nEpisode: 1948\nEpisode reward: 126.0\nEpisode: 1949\nEpisode reward: 143.0\nEpisode: 1950\nEpisode reward: 191.0\nEpisode: 1951\nEpisode reward: 200.0\nEpisode: 1952\nEpisode reward: 154.0\nEpisode: 1953\nEpisode reward: 200.0\nEpisode: 1954\nEpisode reward: 113.0\nEpisode: 1955\nEpisode reward: 118.0\nEpisode: 1956\nEpisode reward: 160.0\nEpisode: 1957\nEpisode reward: 151.0\nEpisode: 1958\nEpisode reward: 168.0\nEpisode: 1959\nEpisode reward: 148.0\nEpisode: 1960\nEpisode reward: 130.0\nEpisode: 1961\nEpisode reward: 152.0\nEpisode: 1962\nEpisode reward: 141.0\nEpisode: 1963\nEpisode reward: 200.0\nEpisode: 1964\nEpisode reward: 119.0\nEpisode: 1965\nEpisode reward: 107.0\nEpisode: 1966\nEpisode reward: 156.0\nEpisode: 1967\nEpisode reward: 193.0\nEpisode: 1968\nEpisode reward: 163.0\nEpisode: 1969\nEpisode reward: 164.0\nEpisode: 1970\nEpisode reward: 151.0\nEpisode: 1971\nEpisode reward: 109.0\nEpisode: 1972\nEpisode reward: 110.0\nEpisode: 1973\nEpisode reward: 198.0\nEpisode: 1974\nEpisode reward: 145.0\nEpisode: 1975\nEpisode reward: 139.0\nEpisode: 1976\nEpisode reward: 200.0\nEpisode: 1977\nEpisode reward: 141.0\nEpisode: 1978\nEpisode reward: 200.0\nEpisode: 1979\nEpisode reward: 143.0\nEpisode: 1980\nEpisode reward: 153.0\nEpisode: 1981\nEpisode reward: 124.0\nEpisode: 1982\nEpisode reward: 193.0\nEpisode: 1983\nEpisode reward: 148.0\nEpisode: 1984\nEpisode reward: 123.0\nEpisode: 1985\nEpisode reward: 150.0\nEpisode: 1986\nEpisode reward: 180.0\nEpisode: 1987\nEpisode reward: 196.0\nEpisode: 1988\nEpisode reward: 113.0\nEpisode: 1989\nEpisode reward: 200.0\nEpisode: 1990\nEpisode reward: 163.0\nEpisode: 1991\nEpisode reward: 183.0\nEpisode: 1992\nEpisode reward: 179.0\nEpisode: 1993\nEpisode reward: 141.0\nEpisode: 1994\nEpisode reward: 149.0\nEpisode: 1995\nEpisode reward: 163.0\nEpisode: 1996\nEpisode reward: 120.0\nEpisode: 1997\nEpisode reward: 200.0\nEpisode: 1998\nEpisode reward: 103.0\nEpisode: 1999\nEpisode reward: 197.0\nLearned Q-table:\ntensor([[[[[ 7.5282e-03, -5.0158e-03],\n           [ 1.8066e-04, -1.1957e-02],\n           [ 1.7809e-02,  1.9935e-02],\n           [ 1.2077e-02,  1.2135e-03]],\n\n          [[ 1.1068e-02,  1.3167e-02],\n           [-3.6065e-03, -2.3091e-02],\n           [-5.3917e-03, -3.6806e-03],\n           [-2.0194e-02,  1.4977e-02]],\n\n          [[-3.9683e-03, -1.1291e-03],\n           [ 1.6093e-03,  1.7743e-02],\n           [ 3.1133e-03, -1.3254e-02],\n           [-2.2300e-03,  1.5660e-02]],\n\n          [[-9.9277e-03, -3.0461e-03],\n           [ 1.5977e-02, -9.5863e-03],\n           [ 9.4414e-03, -4.6137e-03],\n           [-6.0294e-03,  3.8514e-03]]],\n\n\n         [[[ 3.2934e-03, -2.7038e-03],\n           [ 1.1472e-03, -7.2562e-03],\n           [ 7.2273e-03, -7.4928e-03],\n           [-3.5465e-03, -1.3511e-02]],\n\n          [[-1.1883e-02, -3.6573e-03],\n           [-9.0871e-03, -1.4479e-02],\n           [ 1.2498e-04,  2.4612e-03],\n           [-1.4339e-02, -3.3635e-03]],\n\n          [[ 1.4458e-02,  2.2707e-02],\n           [ 1.1106e-03, -1.9436e-02],\n           [ 1.7882e-02,  5.9812e-03],\n           [ 2.0743e-02, -8.5244e-03]],\n\n          [[-3.0426e-03, -1.1320e-03],\n           [-1.7067e-02,  5.2065e-03],\n           [ 5.5506e-03, -2.2826e-03],\n           [-3.7662e-03, -9.6092e-03]]],\n\n\n         [[[ 4.2712e-03, -1.7112e-02],\n           [-7.6057e-04,  1.5980e-02],\n           [ 2.6001e-03,  4.0400e-03],\n           [-1.3805e-03, -1.1307e-02]],\n\n          [[ 5.0641e-03, -1.3241e-02],\n           [ 1.7783e-03,  8.7516e-03],\n           [-9.8789e-03, -9.4022e-03],\n           [ 1.1799e-02, -8.4989e-03]],\n\n          [[-8.7781e-03, -1.9099e-02],\n           [-2.1311e-03,  1.3072e-02],\n           [-9.6554e-03, -9.8139e-03],\n           [ 1.0881e-02, -7.0734e-03]],\n\n          [[-1.2324e-02, -1.8049e-02],\n           [ 2.6147e-03,  7.3541e-03],\n           [-1.2201e-02, -2.3215e-02],\n           [ 1.8518e-02,  1.3268e-02]]],\n\n\n         [[[-3.7732e-04,  6.0749e-03],\n           [ 9.5228e-03,  1.7512e-03],\n           [-6.6485e-03, -6.8077e-04],\n           [-1.4016e-02,  4.3504e-03]],\n\n          [[-1.1826e-02,  3.7322e-03],\n           [-1.4521e-02, -5.1530e-03],\n           [-8.8820e-04,  5.4113e-03],\n           [ 1.0400e-02, -1.4762e-03]],\n\n          [[ 1.0607e-02,  6.7451e-03],\n           [ 1.0964e-02,  2.8386e-03],\n           [ 5.6247e-03,  1.0890e-02],\n           [ 4.6335e-03, -3.7274e-03]],\n\n          [[-9.0740e-03,  6.4783e-03],\n           [-1.2299e-03, -5.6999e-03],\n           [-1.6512e-02,  1.0905e-02],\n           [ 2.4370e-03, -1.5498e-02]]]],\n\n\n\n        [[[[ 8.5643e-03,  1.1855e-02],\n           [-4.0238e-03, -1.9470e-02],\n           [ 8.6876e-03, -1.3815e-03],\n           [ 1.3968e-02, -1.1944e-02]],\n\n          [[-4.9274e-03, -3.5420e-03],\n           [ 1.1639e-02, -3.9007e-03],\n           [-6.9517e-03, -9.7298e-03],\n           [-9.1168e-03,  1.6739e-03]],\n\n          [[ 9.1662e-03,  3.5723e-04],\n           [-7.4430e-04, -2.2149e-03],\n           [-3.0224e-03,  1.0551e-02],\n           [-5.0447e-03, -1.4064e-02]],\n\n          [[-3.5565e-03, -7.7704e-04],\n           [-7.0354e-03,  8.5815e-03],\n           [-8.7700e-03, -1.2051e-02],\n           [ 8.8658e-03, -2.5521e-02]]],\n\n\n         [[[-1.2974e-03, -8.8698e-03],\n           [-3.6456e-03,  1.5029e-02],\n           [-8.8230e-03,  9.4439e-03],\n           [ 2.5990e-03,  1.5128e-02]],\n\n          [[ 5.6906e-03,  4.9925e-03],\n           [ 8.7974e+00,  6.8648e+00],\n           [ 7.6102e+00,  9.6593e+00],\n           [ 7.9246e-03, -1.4221e-02]],\n\n          [[ 1.8949e-04, -9.8628e-03],\n           [ 9.7750e+00,  2.2845e+00],\n           [ 4.7479e+00,  9.7569e+00],\n           [-6.5158e-03,  1.5208e-03]],\n\n          [[ 2.0201e-04, -2.1695e-02],\n           [-2.6849e-04, -1.5498e-02],\n           [-1.1011e-02,  1.1365e-03],\n           [-7.1765e-03,  1.2924e-02]]],\n\n\n         [[[ 9.7294e-03,  2.4206e-02],\n           [-1.2685e-02, -1.0336e-03],\n           [ 8.7326e-03, -2.7275e-02],\n           [-2.1335e-02,  4.4139e-03]],\n\n          [[-1.5349e-02, -5.3750e-03],\n           [ 9.6216e+00,  6.4663e+00],\n           [ 9.2758e+00,  1.1250e+00],\n           [-2.8471e-03,  4.4822e-03]],\n\n          [[-3.5157e-03,  5.6956e-03],\n           [ 8.0273e+00,  9.5288e+00],\n           [ 6.7466e+00,  9.7377e+00],\n           [-1.5232e-02, -1.2576e-02]],\n\n          [[-1.5377e-02,  4.6587e-03],\n           [-1.2515e-02, -8.6466e-03],\n           [-3.5109e-03,  1.8327e-02],\n           [ 5.5513e-03, -7.4427e-03]]],\n\n\n         [[[-1.2366e-02, -1.8556e-02],\n           [-7.6673e-03, -6.9909e-03],\n           [-1.7524e-02, -1.2405e-02],\n           [-2.0454e-04, -1.0710e-02]],\n\n          [[-7.5223e-04,  8.1430e-03],\n           [-4.2421e-03, -2.4979e-03],\n           [-2.6400e-03, -7.0397e-03],\n           [ 7.2088e-03,  1.2598e-02]],\n\n          [[ 5.4684e-03, -2.1672e-03],\n           [ 7.8071e-04,  8.7978e-04],\n           [-4.5486e-03, -1.1562e-02],\n           [-1.2760e-02, -4.7683e-03]],\n\n          [[-5.0534e-03,  2.6844e-02],\n           [ 6.5477e-03, -2.0174e-03],\n           [-2.3228e-03, -1.9718e-03],\n           [-1.0325e-02,  1.4051e-02]]]],\n\n\n\n        [[[[ 1.2235e-02,  3.8194e-03],\n           [-1.2756e-02,  2.0048e-03],\n           [-1.0588e-02, -6.2585e-03],\n           [-1.1622e-02,  7.8146e-03]],\n\n          [[-1.3627e-02,  4.8715e-03],\n           [-2.6081e-03, -1.2547e-02],\n           [ 2.5712e-02,  6.9268e-04],\n           [ 5.7297e-03,  1.6908e-02]],\n\n          [[-6.0016e-03,  3.8388e-03],\n           [-4.2425e-03,  5.6236e-03],\n           [-2.2077e-03,  8.3500e-03],\n           [-6.5338e-03, -5.6204e-03]],\n\n          [[ 3.6226e-03,  6.5813e-03],\n           [ 8.4147e-03, -4.6316e-03],\n           [ 1.1701e-03, -3.8150e-03],\n           [ 3.4847e-03, -1.6027e-02]]],\n\n\n         [[[-1.2393e-03, -8.3570e-03],\n           [ 4.4231e-03, -6.3459e-03],\n           [-6.1139e-04,  5.3770e-03],\n           [ 5.4646e-03,  3.0140e-03]],\n\n          [[-2.6489e-04,  3.1112e-04],\n           [ 9.8092e+00,  7.6335e+00],\n           [ 8.1881e+00,  9.7766e+00],\n           [-7.3893e-03,  1.7081e-04]],\n\n          [[ 1.2995e-02,  4.9129e-03],\n           [ 9.8921e+00,  2.2475e+00],\n           [ 6.9135e+00,  9.8888e+00],\n           [-4.6639e-03,  9.7619e-03]],\n\n          [[-3.7702e-03, -1.7440e-02],\n           [ 2.7172e-03, -7.0420e-04],\n           [ 1.0267e-02,  6.5922e-03],\n           [-4.3092e-03, -6.1909e-03]]],\n\n\n         [[[ 8.2225e-03,  2.0020e-02],\n           [ 1.3149e-02, -1.5706e-02],\n           [ 1.4529e-02,  2.0051e-02],\n           [-3.3207e-03,  2.9005e-03]],\n\n          [[ 1.6814e-02, -1.1611e-02],\n           [ 9.8325e+00,  5.7229e+00],\n           [ 9.8201e+00,  2.8158e+00],\n           [-1.9186e-03, -3.3058e-03]],\n\n          [[ 1.8627e-02, -4.3313e-03],\n           [ 7.2040e+00,  9.8860e+00],\n           [ 1.7174e+00,  9.8843e+00],\n           [-4.0002e-03, -4.0428e-03]],\n\n          [[-5.8534e-03, -8.5589e-03],\n           [ 1.8699e-02,  1.4041e-02],\n           [-4.5634e-03, -1.2667e-02],\n           [ 2.9807e-03, -1.0735e-02]]],\n\n\n         [[[ 2.3185e-03, -1.1426e-02],\n           [ 1.0432e-02,  8.7466e-03],\n           [-2.0517e-02, -6.4246e-03],\n           [ 1.6325e-02, -2.2658e-03]],\n\n          [[-1.3443e-03, -7.4122e-03],\n           [ 2.6692e-03,  1.6455e-03],\n           [-1.2263e-02, -3.9807e-04],\n           [-1.1106e-02, -1.2117e-03]],\n\n          [[ 1.2348e-02, -4.9474e-03],\n           [-5.5995e-03, -2.2941e-03],\n           [-8.0381e-03,  8.6414e-03],\n           [-1.2672e-02, -8.6333e-03]],\n\n          [[ 2.2708e-03,  1.5464e-02],\n           [-6.9604e-07,  9.0496e-03],\n           [ 4.9665e-03, -1.3779e-04],\n           [ 2.5279e-03, -9.1125e-03]]]],\n\n\n\n        [[[[-4.1377e-03, -5.1594e-04],\n           [-3.2999e-03, -3.2629e-03],\n           [ 1.5395e-02, -1.9373e-03],\n           [-2.1155e-02, -2.2015e-03]],\n\n          [[-4.7272e-03,  4.2632e-03],\n           [-7.7089e-03, -4.4246e-03],\n           [ 1.1186e-02,  1.2331e-02],\n           [-8.5431e-03,  9.3936e-03]],\n\n          [[ 2.0678e-02, -1.5143e-03],\n           [ 1.1107e-03, -1.5056e-03],\n           [-1.5841e-02, -1.0837e-03],\n           [ 1.2758e-03, -1.2761e-03]],\n\n          [[-1.0277e-02, -2.0925e-02],\n           [ 2.1294e-04, -7.8277e-03],\n           [-8.0540e-04,  6.9005e-03],\n           [ 8.6584e-03, -3.0194e-03]]],\n\n\n         [[[ 1.7248e-02, -6.2072e-03],\n           [ 5.1232e-03, -8.9823e-03],\n           [-1.4095e-02, -1.8089e-02],\n           [ 8.5848e-03, -7.7452e-03]],\n\n          [[ 6.3832e-03, -9.4521e-04],\n           [-6.0866e-03, -1.7911e-02],\n           [ 7.1645e-03,  1.8826e-03],\n           [-1.1272e-03, -1.6942e-03]],\n\n          [[-1.9407e-04,  2.6855e-02],\n           [ 2.4922e-03,  4.0395e-03],\n           [-9.0179e-03,  1.1456e-02],\n           [ 6.2417e-03,  1.6225e-03]],\n\n          [[-1.3302e-02, -7.9396e-03],\n           [ 1.6342e-02, -8.3640e-04],\n           [ 8.2515e-03, -1.9994e-02],\n           [-1.5314e-02,  1.1206e-03]]],\n\n\n         [[[-1.6801e-02,  2.5082e-03],\n           [-1.2035e-02,  1.0600e-02],\n           [-3.4271e-03,  8.3387e-03],\n           [ 1.1338e-03, -1.3025e-03]],\n\n          [[-4.3297e-04,  6.9727e-03],\n           [-9.4044e-03, -1.8042e-02],\n           [-1.6318e-02, -1.8721e-03],\n           [ 9.9107e-03, -1.0611e-02]],\n\n          [[ 1.3804e-02, -5.9115e-03],\n           [-8.4717e-03,  1.2661e-02],\n           [ 5.9259e-03,  6.3610e-03],\n           [-1.8119e-03, -1.0934e-02]],\n\n          [[-6.4295e-03,  1.4941e-03],\n           [-1.3924e-02,  1.0059e-02],\n           [ 3.7694e-03,  1.3317e-02],\n           [ 7.0841e-03,  8.2705e-03]]],\n\n\n         [[[ 5.0314e-03, -1.1748e-03],\n           [-6.9476e-03, -6.9823e-05],\n           [ 3.5111e-03, -3.0028e-03],\n           [-6.3763e-03,  1.4920e-03]],\n\n          [[-9.0027e-04, -3.8365e-03],\n           [ 1.1627e-04, -4.9486e-03],\n           [ 1.3806e-02,  5.5603e-03],\n           [-1.1555e-02, -3.8007e-03]],\n\n          [[-3.6884e-04,  1.0951e-02],\n           [ 2.6923e-03,  6.7217e-04],\n           [ 1.1842e-02, -1.7159e-02],\n           [ 1.3960e-04,  8.7688e-03]],\n\n          [[-6.5861e-03,  1.1069e-03],\n           [-9.9205e-03,  1.4599e-02],\n           [-4.2275e-03, -3.8720e-03],\n           [ 1.4915e-02, -2.9827e-03]]]]])\n\n\n\nplt.plot(rewards)\n\n\n\n\n\n\n\n\n\n# Smooth the rewards and plot\ndef smooth_rewards(rewards, smoothing_factor=100):\n    smoothed_rewards = []\n    for i in range(len(rewards)):\n        smoothed_rewards.append(np.mean(rewards[max(0, i-smoothing_factor):(i+1)]))\n    return smoothed_rewards\n\nplt.plot(smooth_rewards(rewards))\n\n\n\n\n\n\n\n\n\n# Simple MLP for CartPole\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim, output_dim, hidden_dims=[32, 32]):\n        super(MLP, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.hidden_dims = hidden_dims\n\n        self.fc1 = nn.Linear(self.input_dim, self.hidden_dims[0])\n        self.fc2 = nn.Linear(self.hidden_dims[0], self.hidden_dims[1])\n        self.fc3 = nn.Linear(self.hidden_dims[1], self.output_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        q_values = self.fc3(x)\n        return q_values\n\n\nmlp = MLP(input_dim=4, output_dim=2, hidden_dims=[32, 32])\n\n\nmlp\n\nMLP(\n  (fc1): Linear(in_features=4, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=32, bias=True)\n  (fc3): Linear(in_features=32, out_features=2, bias=True)\n)\n\n\n\nmlp(torch.tensor([1, 2, 3, 4], dtype=torch.float32))\n\ntensor([-0.0455, -0.0736], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nmlp(torch.from_numpy(env.observation_space.sample()))\n\ntensor([ 3.7970e+35, -1.6602e+37], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n# Train the MLP\n\n# Hyperparameters\nlearning_rate = 0.1\ndiscount_factor = 0.9\nnum_episodes = 50\n\n# Initialize the MLP\nmlp = MLP(input_dim=4, output_dim=2, hidden_dims=[32, 32])\n\n# Define the loss function\nloss_fn = nn.MSELoss()\n\n# Define the optimizer\noptimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate)\n\n# List to store rewards for each episode\nrewards = []\n\n# Training loop\nfor episode in range(num_episodes):\n    print(\"Episode:\", episode)\n    state, info = env.reset(seed=episode)\n    state = torch.from_numpy(state).float()\n    episode_reward = 0\n\n    while True:\n        # Choose action using the current Q-table\n        q_values = mlp(state)\n        action = torch.argmax(q_values).item()\n\n        # Take the chosen action and observe the next state and reward\n        next_state, reward, terminated, truncated, info = env.step(action)\n        next_state = torch.from_numpy(next_state).float()\n\n        # Update the Q-table using the Q-learning update rule\n        q_values_next = mlp(next_state)\n        q_values_target = q_values.clone()\n        q_values_target[action] = reward + discount_factor * torch.max(q_values_next)\n        loss = loss_fn(q_values, q_values_target)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        episode_reward += reward\n        state = next_state\n\n        if terminated or truncated:\n            break\n    rewards.append(episode_reward)\n    print(\"Episode reward:\", episode_reward)\n\nEpisode: 0\nEpisode reward: 8.0\nEpisode: 1\nEpisode reward: 9.0\nEpisode: 2\nEpisode reward: 10.0\nEpisode: 3\nEpisode reward: 10.0\nEpisode: 4\nEpisode reward: 10.0\nEpisode: 5\nEpisode reward: 9.0\nEpisode: 6\nEpisode reward: 9.0\nEpisode: 7\nEpisode reward: 10.0\nEpisode: 8\nEpisode reward: 9.0\nEpisode: 9\nEpisode reward: 10.0\nEpisode: 10\nEpisode reward: 10.0\nEpisode: 11\nEpisode reward: 9.0\nEpisode: 12\nEpisode reward: 9.0\nEpisode: 13\nEpisode reward: 10.0\nEpisode: 14\nEpisode reward: 10.0\nEpisode: 15\nEpisode reward: 9.0\nEpisode: 16\nEpisode reward: 8.0\nEpisode: 17\nEpisode reward: 9.0\nEpisode: 18\nEpisode reward: 9.0\nEpisode: 19\nEpisode reward: 9.0\nEpisode: 20\nEpisode reward: 8.0\nEpisode: 21\nEpisode reward: 10.0\nEpisode: 22\nEpisode reward: 8.0\nEpisode: 23\nEpisode reward: 8.0\nEpisode: 24\nEpisode reward: 10.0\nEpisode: 25\nEpisode reward: 9.0\nEpisode: 26\nEpisode reward: 8.0\nEpisode: 27\nEpisode reward: 8.0\nEpisode: 28\nEpisode reward: 10.0\nEpisode: 29\nEpisode reward: 9.0\nEpisode: 30\nEpisode reward: 8.0\nEpisode: 31\nEpisode reward: 10.0\nEpisode: 32\nEpisode reward: 9.0\nEpisode: 33\nEpisode reward: 10.0\nEpisode: 34\nEpisode reward: 9.0\nEpisode: 35\nEpisode reward: 11.0\nEpisode: 36\nEpisode reward: 10.0\nEpisode: 37\nEpisode reward: 8.0\nEpisode: 38\nEpisode reward: 10.0\nEpisode: 39\nEpisode reward: 8.0\nEpisode: 40\nEpisode reward: 10.0\nEpisode: 41\nEpisode reward: 9.0\nEpisode: 42\nEpisode reward: 10.0\nEpisode: 43\nEpisode reward: 8.0\nEpisode: 44\nEpisode reward: 9.0\nEpisode: 45\nEpisode reward: 10.0\nEpisode: 46\nEpisode reward: 9.0\nEpisode: 47\nEpisode reward: 9.0\nEpisode: 48\nEpisode reward: 9.0\nEpisode: 49\nEpisode reward: 9.0\n\n\n\nmlp\n\nMLP(\n  (fc1): Linear(in_features=4, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=32, bias=True)\n  (fc3): Linear(in_features=32, out_features=2, bias=True)\n)\n\n\n\nmlp(torch.from_numpy(env.observation_space.sample()).float())\n\ntensor([-inf, nan], grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "posts/2019-08-20-gaussian-processes.html",
    "href": "posts/2019-08-20-gaussian-processes.html",
    "title": "Gaussian Processes",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- gaussian-processes- bayesian- uncertainty-quantification- probabilistic-models- kernel-methodsdate: ’2019-08-20’description: An interactive exploration of Gaussian processes.image: gp-learning.gifoutput-file: 2019-08-20-gaussian-processes.htmltitle: Gaussian Processestoc: true—\n\nAn example\n\nLet us look at the GIF above. It shows a non-linear fit with uncertainty on a set of points in the 2d space. The uncertainty is shown by the gray shadowed region. The animation shows how the fit and the uncertainty varies as we keep adding more points (shown as big circles). As expected, as more points are added, the uncertainty of the fit in the vicinity of the added points reduces. This is an example of Gaussian Processes (GP) regression in play.\n\n\nIntroduction\nThere exist some great online resources for Gaussian Processes (GPs) including an excellent recent Distill.Pub article. This blog post is an attempt with a programatic flavour. In this notebook, we will build the intuition and learn some basics of GPs. This notebook is heavily inspired by the awesome tutorial by Richard Turner. Here is the link to the slides and video. Lectures videos and notes from Nando De Freitas’ course are an amazing resource for GPs (and anything ML!).\n\n\nSome imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n\n\nA function to make the Matplotlib plots prettier\n\nSPINE_COLOR = 'gray'\n\ndef format_axes(ax):\n    for spine in ['top', 'right']:\n        ax.spines[spine].set_visible(False)\n\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_color(SPINE_COLOR)\n        ax.spines[spine].set_linewidth(0.5)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    for axis in [ax.xaxis, ax.yaxis]:\n        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n\n    return ax\n\n\n\nOne dimensional Gaussian/Normal\nWe will start the discussion with 1d Gaussians. Let us write some simple code to generate/sample data from \\(\\mathcal{N}(\\mu=0, \\sigma=1)\\)\n\none_dim_normal_data = np.random.normal(0, 1, size=10000)\n\nLet us now visualise the data in a 1d space using scatter plot\n\nplt.scatter(one_dim_normal_data, np.zeros_like(one_dim_normal_data), alpha=0.2, c='gray', edgecolors='k', marker='o')\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\nAs we would expect, there are a lot of samples close to zero (mean) and as we go further away from zero, the number of samples keeps reducing. We can also visualise the same phenomenon using a normed histogram shown below.\n\nplt.hist(one_dim_normal_data, density=True, bins=20, color='gray')\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\nWe can notice that there is a high probability of drawing samples close to the mean and the probability is low far from the mean.\nHowever, since histograms come with their own set of caveats, let us use kernel desnity estimation for obtaining the probability density of 1d Gaussian.\n\nfrom sklearn.neighbors import KernelDensity\n\nx_d = np.linspace(-4, 4, 100)\n\n# instantiate and fit the KDE model\nkde = KernelDensity(bandwidth=1.0, kernel='gaussian')\nkde.fit(one_dim_normal_data[:, None])\n\n# score_samples returns the log of the probability density\nlogprob = kde.score_samples(x_d[:, None])\n\nplt.fill_between(x_d, np.exp(logprob), alpha=0.2, color='gray')\nplt.plot(one_dim_normal_data, np.full_like(one_dim_normal_data, -0.01), '|k', markeredgewidth=0.1)\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\nWe can now see a smoother version of the histogram and can again verify the properties of 1D Gaussian. Let us now vary the variance of 1D Gaussian and make the same plots to enhance our understanding of the concept.\n\nfig, ax = plt.subplots(ncols=3, sharey=True, figsize=(9, 3))\nx_d = np.linspace(-6, 6, 400)\n\nfor i, var in enumerate([0.5, 1, 2]):\n    one_dim_normal_data = np.random.normal(0, var, size=10000)\n    kde = KernelDensity(bandwidth=1.0, kernel='gaussian')\n    kde.fit(one_dim_normal_data[:, None])\n\n    # score_samples returns the log of the probability density\n    logprob = kde.score_samples(x_d[:, None])\n\n    ax[i].fill_between(x_d, np.exp(logprob), alpha=0.2, color='gray')\n    ax[i].plot(one_dim_normal_data, np.full_like(one_dim_normal_data, -0.01), '|k', markeredgewidth=0.1)\n    format_axes(ax[i])\n    ax[i].set_title(f\"Variance = {var}\")\n\n\n\n\n\n\n\n\nWe can see that how increasing the variance makes the data more spread.\n\n\nBi-variate Gaussian\nHaving discussed the case of 1d Gaussian, now let us move to multivariate Gaussians. As a special case, let us first consider bi-variate or 2d Gaussian. It’s parameters are the mean vector which will have 2 elements and a covariance matrix.\nWe can write the distribution as: \\[\n\\begin{pmatrix}\nX_1 \\\\\nX_2\n\\end{pmatrix}  \\sim \\mathcal{N} \\left( \\begin{pmatrix}\n\\mu_1 \\\\\n\\mu_2\n\\end{pmatrix} , \\begin{pmatrix}\na & \\rho \\\\\n\\rho & b\n\\end{pmatrix} \\right)\n\\]\nwhere \\(\\mu_1\\), \\(\\mu_2\\) are the means for \\(X_1\\) and \\(X_2\\) respectively; \\(a\\) is the standard deviation for \\(X_1\\), \\(b\\) is the standard deviation for \\(X_2\\) and \\(\\rho\\) is the correlation between \\(X_1\\) and \\(X_2\\)\nLet us now draw some data from: \\[\n\\begin{pmatrix}\nX_1 \\\\\nX_2\n\\end{pmatrix}  \\sim \\mathcal{N} \\left( \\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix} , \\begin{pmatrix}\n1 & 0.7 \\\\\n0.7 & 1\n\\end{pmatrix} \\right)\n\\]\n\ndata = np.random.multivariate_normal(mean = np.array([0, 0]), cov = np.array([[1, 0.7], [0.7, 1]]), size=(10000, ))\n\n\nplt.scatter(data[:, 0], data[:, 1], alpha=0.05,c='gray')\nplt.axhline(0, color='k', lw=0.2)\nplt.axvline(0, color='k', lw=0.2)\nplt.xlabel(r\"$X_1$\")\nplt.ylabel(r\"$X_2$\")\n\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\nWe can see from the plot above that the data is distributed around mean [0, 0]. We can also see the positive correlation between \\(X_1\\) and \\(X_2\\)\n\n\nMarginalisation for bivariate Gaussian\nLet us look into an interesting plot provided by Seaborn.\n\nimport pandas as pd\ndata_df = pd.DataFrame(data, columns=[r'$X_1$',r'$X_2$'])\n\n\nimport seaborn as sns\ng = sns.jointplot(x= r'$X_1$', y=r'$X_2$', data=data_df, kind=\"reg\",color='gray')\n\n\n\n\n\n\n\n\nThe central plot is exactly the same as the scatter plot we made earlier. But, we see two additional 1d KDE plots at the top and the right. What do these tell us? These tell us the marginal 1d distributions of \\(X_1\\) and \\(X_2\\).\nThe marginal distribution of \\(X_1\\) is the distribution of \\(X_1\\) considering all values of \\(X_2\\) and vice versa. One of the interesting properties of Gaussian distributions is that the marginal distribution of a Gaussian is also a Gaussian distribution. MathematicalMonk on Youtube has a great set of lectures on this topic that I would highly recommend!\nWhat would you expect the marginal distribution of \\(X_1\\) to look like? No prizes for guessing.\nGiven \\[\n\\begin{pmatrix}\nX_1 \\\\\nX_2\n\\end{pmatrix}  \\sim \\mathcal{N} \\left( \\begin{pmatrix}\n\\mu_1 \\\\\n\\mu_2\n\\end{pmatrix} , \\begin{pmatrix}\na & \\rho \\\\\n\\rho & b\n\\end{pmatrix} \\right)\n\\]\nwe have the marginal distribution of: \\[X_1 \\sim \\mathcal{N}(\\mu_1, a)\\] and \\[X_2 \\sim \\mathcal{N}(\\mu_2, b)\\]\n\ndef plot_jointplot_2d(a, b, rho):\n    data = np.random.multivariate_normal(mean = np.array([0, 0]), cov = np.array([[a, rho], [rho, b]]), size=(10000, ))\n    data_df = pd.DataFrame(data, columns=[r'$X_1$',r'$X_2$'])\n    g = sns.jointplot(x= r'$X_1$', y=r'$X_2$', data=data_df, kind=\"reg\",color='gray')\n\nOk, let us know try to plot a few jointplots for different covariance matrices. We would be passing in the values of \\(a\\), \\(b\\) and \\(\\rho\\) which would make up the covariance matrix as:\n\\[\\begin{pmatrix}\na & \\rho \\\\\n\\rho & b\n\\end{pmatrix}\\]\nWe would make these plots for mean zero.\n\nplot_jointplot_2d(1, 1, -0.7)\n\n\n\n\n\n\n\n\nIn the plot above, for \\(a=1\\), \\(b=1\\) and \\(\\rho=0.7\\) we can see the negative correlation (but high) between \\(X_1\\) and \\(X_2\\).\nLet us now increase the variance in \\(X_1\\) and keep all other paramaters constant.\n\nplot_jointplot_2d(2, 1, -0.7)\n\n\n\n\n\n\n\n\nOne can see from the plot above that the variance in \\(X_1\\) is much higher now and the plot extends from -6 to +6 for \\(X_1\\) while earlier it was restricted from -4 to 4.\n\nplot_jointplot_2d(1, 1, 0.0)\n\n\n\n\n\n\n\n\nOne can see from the plot above that the correlation between \\(X_1\\) and \\(X_2\\) is zero.\n\nSurface plots for bi-variate Gaussian\nWe will now look into surface plots for bi-variate Gaussian. This is yet another way to plot and understand Gaussian distributions. I borrow code from an excellent tuorial on plotting bivariate Gaussians.\n\nfrom scipy.stats import multivariate_normal\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\n\n\ndef make_pdf_2d_gaussian(mu, sigma):\n    N = 60\n    X = np.linspace(-3, 3, N)\n    Y = np.linspace(-3, 4, N)\n    X, Y = np.meshgrid(X, Y)\n\n    # Pack X and Y into a single 3-dimensional array\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n\n    F = multivariate_normal(mu, sigma)\n    Z = F.pdf(pos)\n\n\n\n    # Create a surface plot and projected filled contour plot under it.\n    fig = plt.figure()\n    ax = fig.gca(projection='3d')\n    ax.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1, antialiased=True,\n                    cmap=cm.Greys)\n    \n    ax.set_xlabel(r\"$X_1$\")\n    ax.set_ylabel(r\"$X_2$\")\n    ax.set_zlabel(\"PDF\")\n\n    cset = ax.contourf(X, Y, Z, zdir='z', offset=-0.15, cmap=cm.Greys)\n\n    # Adjust the limits, ticks and view angle\n    ax.set_zlim(-0.15,0.25)\n    ax.set_zticks(np.linspace(0,0.2,5))\n    ax.view_init(27, -15)\n    ax.set_title(f'$\\mu$ = {mu}\\n $\\Sigma$ = {sigma}')\n\n\nmu = np.array([0., 0.])\nsigma = np.array([[ 1. , -0.5], [-0.5,  1]])\n\nmake_pdf_2d_gaussian(mu, sigma)\n\n\n\n\n\n\n\n\nFrom the plot above, we can see the surface plot showing the probability density function for the Gaussian with mean\n\\[\\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix}\\]\nand covariance matrix:\n\\[\\begin{pmatrix}\n1 & -0.5 \\\\\n-0.5 & 1\n\\end{pmatrix}\\]\nIt can be seen that the probability peaks arounds \\(X_1=0\\) and \\(X_2=0\\). The bottom plot shows the same concept using contour plots which we will heavily use from now on. The different circles in the bottom contour plot denote the loci of same probability density. Since the contour plot requires a lesser dimension, it will be easier to use in our further analysis.\nAlso, from the contour plots, we can see the correlation between \\(X_1\\) and \\(X_2\\).\n\nmu = np.array([0., 0.])\nsigma = np.array([[ 1. , 0], [0,  1]])\n\nmake_pdf_2d_gaussian(mu, sigma)\n\n\n\n\n\n\n\n\nIn the plot above, we can see that \\(X_1\\) and \\(X_2\\) are not correlated.\n\n\nContour plots for 2D Gaussians\nHaving seen the relationship between the surface plots and the contour plots, we will now exclusively focus on the contour plots. Here is a simple function to generate the contour plot for 2g gaussian with mean and covariance as the arguments.\n\ndef plot_2d_contour_pdf(mu, sigma):\n    X = np.linspace(-3, 3, 60)\n    Y = np.linspace(-3, 4, 60)\n    X, Y = np.meshgrid(X, Y)\n\n    # Pack X and Y into a single 3-dimensional array\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n\n    F = multivariate_normal(mu, sigma)\n    Z = F.pdf(pos)\n    plt.xlabel(r\"$X_1$\")\n    plt.ylabel(r\"$X_2$\")\n    \n    plt.title(f'$\\mu$ = {mu}\\n $\\Sigma$ = {sigma}')\n    plt.contourf(X, Y, Z, zdir='z', offset=-0.15, cmap=cm.Greys)\n    plt.colorbar()\n    format_axes(plt.gca())\n\n\nmu = np.array([0., 0.])\nsigma = np.array([[ 1. , 0.5], [0.5,  1.]])\nplot_2d_contour_pdf(mu, sigma)\n\n\n\n\n\n\n\n\nThe plot above shows the contour plot for 2d gaussian with mean [0, 0] and covariance [[ 1. , 0.5], [0.5, 1.]]. We can see the correlation between \\(X_1\\) and \\(X_2\\)\n\n\n\nSample from 2d gaussian and visualising it on XY plane\nWe will now sample a point from a 2d Gaussian and describe a new way of visualising it.\n\n\nThe left most plot shows the covariance matrix.\nThe middle plot shows the contour plot. The dark point marked in the contour plot is a sampled point (at random) from this 2d Gaussian distribution.\nThe right most plot is an alternative representation of the sampled point. The x-axis corresponds to the labels \\(X_1\\) and \\(X_2\\) and the corresponding y-axis are the coordinates of the point in the \\(X_1\\), \\(X_2\\) dimension shown in the contour plot.\n\nWe will now write a function to generate a random sample from a 2d gaussian given it’s mean and covariance matrix.\n\ndef plot_2d_contour_pdf_dimensions(mu, sigma, random_num):\n    fig, ax  = plt.subplots(ncols=3, figsize=(12, 4))\n\n    X = np.linspace(-3, 3, 60)\n    Y = np.linspace(-3, 3, 60)\n    X, Y = np.meshgrid(X, Y)\n\n    # Pack X and Y into a single 3-dimensional array\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n\n    F = multivariate_normal(mu, sigma)\n    Z = F.pdf(pos)\n    random_point = F.rvs(random_state=random_num)\n    \n    sns.heatmap(sigma, ax=ax[0], annot=True)\n    ax[1].contour(X, Y, Z, cmap=cm.Greys)\n    ax[1].scatter(random_point[0], random_point[1], color='k',s=100)\n    ax[1].set_xlabel(r\"$X_1$\")\n    ax[1].set_ylabel(r\"$X_2$\")\n    \n    data_array = pd.Series(random_point, index=['X1','X2'])\n    data_array.plot(ax=ax[2], kind='line', marker='o',color='k')\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    ax[2].set_ylim(-3, 3)\n    \n    format_axes(ax[0])\n    format_axes(ax[1])\n    format_axes(ax[2])\n    ax[0].set_title(\"Covariance Matrix\")\n    ax[1].set_title(\"Contour of pdf\")\n    ax[2].set_title(\"Visualising the point\")\n    plt.suptitle(f\"Random state = {random_num}\", y=1.1)\n    plt.tight_layout()\n    import os\n    if not os.path.exists(\"images\"):\n        os.makedirs(\"images\")\n    if not os.path.exists(f\"images/{sigma[0, 1]}\"):\n        os.makedirs(f\"images/{sigma[0, 1]}\")\n    plt.savefig(f\"images/{sigma[0, 1]}/{random_num}.jpg\", bbox_inches=\"tight\")\n    plt.close()\n\nWe will now create 20 such samples and animate them\n\nfor i in range(20):\n    plot_2d_contour_pdf_dimensions( mu, np.array([[ 1. , 0.1], [0.1,  1.]]), i)\n\n\n!convert -delay 20 -loop 0 images/0.1/*.jpg sigma-0-1.gif\n\n\nSince the correlation between the two variables \\(X_1\\) and \\(X_2\\) was low (0.1), we can the see that rightmost plot jumping a lot, i.e. to say that the values of \\(X_1\\) and \\(X_2\\) are not tighly constrained to move together.\n\nfor i in range(20):\n    plot_2d_contour_pdf_dimensions( mu, np.array([[ 1. , 0.7], [0.7,  1.]]), i)\n\n\n!convert -delay 20 -loop 0 images/0.7/*.jpg sigma-0-7.gif\n\n\nThe above GIF shows the same plot/animation for the 2d Gaussian where the correlation between the two variables is high (0.7). Thus, we can see that the two variables tend to move up and down together.\n\n\nConditional Bivariate Distribution\nAll excellent till now. Now, let us move to the case in which some variable’s values are known. We would then look to find the distribution of the other variables conditional on the value of the known variable. I borrow some text from Wikipedia on the subject.\n\\[\n\\begin{pmatrix}\nX_1 \\\\\nX_2\n\\end{pmatrix}  \\sim \\mathcal{N} \\left( \\begin{pmatrix}\n0 \\\\\n0\n\\end{pmatrix} , \\begin{pmatrix}\n1 & \\rho \\\\\n\\rho & 1\n\\end{pmatrix} \\right)\n\\]\nThe conditional expectation of \\(X_2\\) given \\(X_1\\) is: $(X_2 X_1=x_1)= x_1 $\nand the conditional variance is: \\(\\operatorname{var}(X_2 \\mid X_1 = x_1) = 1-\\rho^2\\)\nSo, the question now is: suppose we fix \\(X_1 = 1\\), what is the distribution of \\(X_2\\). Again, Gaussians are amazing - the conditional distributionon is again a Gaussian. Let us make some plots to understand better. The following plots would be showing the distribution of \\(X_2\\) with fixed \\(X_1\\)\n\ndef plot_2d_contour_pdf_dimensions_fixed_x1(sigma, random_num, x1 = 1):\n    mu = np.zeros(2)\n    fig, ax  = plt.subplots(ncols=3, figsize=(12, 4))\n\n    X = np.linspace(-3, 3, 60)\n    Y = np.linspace(-3, 3, 60)\n    X, Y = np.meshgrid(X, Y)\n\n    # Pack X and Y into a single 3-dimensional array\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n\n    F = multivariate_normal(mu, sigma)\n    Z = F.pdf(pos)\n    \n    rho = sigma[0, 1]\n    F_cond_x1 = multivariate_normal(rho*x1, 1-rho**2)\n    random_point_x2 = F_cond_x1.rvs(random_state=random_num)\n    sns.heatmap(sigma, ax=ax[0], annot=True)\n    ax[1].contour(X, Y, Z, cmap=cm.Greys)\n    ax[1].scatter(x1, random_point_x2, color='k',s=100)\n    ax[1].set_xlabel(r\"$X_1$\")\n    ax[1].set_ylabel(r\"$X_2$\")\n    \n    data_array = pd.Series([x1, random_point_x2], index=['X1','X2'])\n    data_array.plot(ax=ax[2], kind='line', color='k')\n    ax[2].scatter(x=0, y=x1, color='red', s=100)\n    ax[2].scatter(x=1, y=random_point_x2, color='k', s=100)\n    \n\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    ax[2].set_ylim(-3, 3)\n    format_axes(ax[0])\n    format_axes(ax[1])\n    format_axes(ax[2])\n    ax[0].set_title(\"Covariance Matrix\")\n    ax[1].set_title(\"Contour of pdf\")\n    ax[2].set_title(\"Visualising the point\")\n    plt.suptitle(f\"Random state = {random_num}\", y=1.1)\n    plt.tight_layout()\n    import os\n    if not os.path.exists(\"images/conditional/\"):\n        os.makedirs(\"images/conditional/\")\n    if not os.path.exists(f\"images/conditional/{sigma[0, 1]}\"):\n        os.makedirs(f\"images/conditional/{sigma[0, 1]}\")\n    plt.savefig(f\"images/conditional/{sigma[0, 1]}/{random_num}.jpg\", bbox_inches=\"tight\")\n    plt.close()\n\n\nfor i in range(20):\n    plot_2d_contour_pdf_dimensions_fixed_x1(np.array([[ 1. , 0.1], [0.1,  1.]]), i)\n\n\n!convert -delay 20 -loop 0 images/conditional/0.1/*.jpg conditional-sigma-0-1.gif\n\n\nThe above animation shows the movement of \\(X_2\\) with \\(X_1=1\\). The \\(X_1=1\\) is shown in red in the righmost plot. In the middle plot, we can confirm that the movement is only in the \\(X_2\\) dimension. Further, since the correlation between \\(X_1\\) and \\(X_2\\) is weak, the righmost plot seems to wiggle or jump a lot!\n\nfor i in range(20):\n    plot_2d_contour_pdf_dimensions_fixed_x1(np.array([[ 1. , 0.7], [0.7,  1.]]), i)\n\n\n!convert -delay 20 -loop 0 images/conditional/0.7/*.jpg conditional-sigma-0-7.gif\n\n\nIn the plot above, we repeat the same p|rocedure but with a covariance matrix having a much higher correlation between \\(X_1\\) and \\(X_2\\). From the righmost plot, we can clearly see that the jumps in \\(X2\\) are far lesser. This is expected, since the two variables are correlated!\n\nVisualising the same procedure for 5 dimensional Gaussian\nWe will now repeat the same procedure we did for 2d case in 5 dimensions.\n\ncovariance_5d = np.array([[1, 0.9, 0.8, 0.6, 0.4],\n                          [0.9, 1, 0.9, 0.8, 0.6],\n                          [0.8, 0.9, 1, 0.9, 0.8],\n                          [0.6, 0.8, 0.9, 1, 0.9],\n                          [0.4, 0.6, 0.8, 0.9, 1]])\n\n\ndef plot_5d_contour_pdf_dimensions(cov, random_num):\n    fig, ax  = plt.subplots(ncols=2, figsize=(6, 3))\n\n    mu = np.zeros(5)\n    F = multivariate_normal(mu, cov)\n    random_point = F.rvs(random_state=random_num)\n    \n    sns.heatmap(cov, ax=ax[0], annot=True)\n    \n    \n    data_array = pd.Series(random_point, index=['X1','X2','X3','X4', 'X5'])\n    data_array.plot(ax=ax[1], kind='line', marker='o',color='k')\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    ax[1].set_ylim(-3, 3)\n    for i in range(2):\n        format_axes(ax[i])\n    \n    ax[0].set_title(\"Covariance Matrix\")\n    ax[-1].set_title(\"Visualising the point\")\n    plt.suptitle(f\"Random state = {random_num}\", y=1.1)\n    plt.tight_layout()\n    import os\n    if not os.path.exists(\"images/5d/\"):\n        os.makedirs(\"images/5d\")\n    \n    plt.savefig(f\"images/5d/{random_num}.jpg\", bbox_inches=\"tight\")\n    plt.close()\n\n\nplot_5d_contour_pdf_dimensions(covariance_5d, 2)\n\n\nfor i in range(20):\n    plot_5d_contour_pdf_dimensions(covariance_5d, i)\n\n\n!convert -delay 20 -loop 0 images/5d/*.jpg 5d.gif\n\n\nFrom the visualisation above we can see that:\n\nsince X1 and X2 are highly correlated, they move up and down together\nbut, X1 and X5 have low correlation, thus, they can seem to wiggle almost independently of each other.\n\nWe are now getting somewhere. If the correlation between the variables is very high, we will get a smooth curve joining them. Right? Almost getting to the point where we can draw the introductory plot shown at the top of the post.\n\n\n\nConditional Multivariate Distribution\nOk, now let us draw the conditional distribution over this higher 5d space. We will fix the values of some of the variables and see the distribution of the others.\nBorrowing from Wikipedia\nIf \\(N\\)-dimensional \\(x\\) is partitioned as follows\n\\[\n\\mathbf{x}\n=\n\\begin{bmatrix}\n\\mathbf{x}_A \\\\\n\\mathbf{x}_B\n\\end{bmatrix}\n\\text{ with sizes }\\begin{bmatrix} q \\times 1 \\\\ (N-q) \\times 1 \\end{bmatrix}\n\\]\nand accordingly \\(μ\\) and \\(Σ\\) are partitioned as follows\n\\[\n\\boldsymbol\\mu\n=\n\\begin{bmatrix}\n\\boldsymbol\\mu_A \\\\\n\\boldsymbol\\mu_B\n\\end{bmatrix}\n\\text{ with sizes }\\begin{bmatrix} q \\times 1 \\\\ (N-q) \\times 1 \\end{bmatrix}\n\\]\n\\[\n\\boldsymbol\\Sigma\n=\n\\begin{bmatrix}\n\\boldsymbol\\Sigma_{AA} & \\boldsymbol\\Sigma_{AB} \\\\\n\\boldsymbol\\Sigma_{BA} & \\boldsymbol\\Sigma_{BB}\n\\end{bmatrix}\n\\text{ with sizes }\\begin{bmatrix} q \\times q & q \\times (N-q) \\\\ (N-q) \\times q & (N-q) \\times (N-q) \\end{bmatrix}\n\\]\nthen the distribution of \\(x_A\\) conditional on \\(x_B=b\\) is multivariate normal \\((x_A|x_B=b)\\sim \\mathcal{N}(\\bar{\\mu}, \\bar{\\Sigma})\\)\n\\[\n\\bar{\\boldsymbol\\mu}\n=\n\\boldsymbol\\mu_A + \\boldsymbol\\Sigma_{AB} \\boldsymbol\\Sigma_{BB}^{-1}\n\\left(\n\\mathbf{B} - \\boldsymbol\\mu_B\n\\right)\n\\]\nand covariance matrix\n\\[\n\\overline{\\boldsymbol\\Sigma}\n=\n\\boldsymbol\\Sigma_{AA} - \\boldsymbol\\Sigma_{AB} \\boldsymbol\\Sigma_{BB}^{-1} \\boldsymbol\\Sigma_{BA}.\n\\]\nLet us for our example take \\(X_5 = -2\\).\nWe have:\n\\(x_A = [x_1, x_2, x_3, x_4]\\) and \\(x_B = [x_5]\\)\nAssuming the covariance matrix of size 5 X 5 is referred as \\(C\\)\n\\[\n\\boldsymbol\\Sigma_{AA}\n=\n\\begin{bmatrix}\nC_{11} & C_{12} & C_{13} & C_{14}\\\\\nC_{21} & C_{22} & C_{23} & C_{24}\\\\\nC_{31} & C_{32} & C_{33} & C_{34}\\\\\nC_{41} & C_{42} & C_{43} & C_{44}\\\\\n\\end{bmatrix} \\\\\n\\]\n\\[\n\\boldsymbol\\Sigma_{AB}\n=\n\\begin{bmatrix}\nC_{15}\\\\\nC_{25}\\\\\nC_{35}\\\\\nC_{45}\\\\\n\\end{bmatrix}\n\\]\n\\[\n\\boldsymbol\\Sigma_{BA}\n=\n\\begin{bmatrix}\nC_{51}& C_{52} & C_{53} & C_{54}\\\\\n\\end{bmatrix}\n\\]\n\\[\n\\boldsymbol\\Sigma_{BB}\n=\n\\begin{bmatrix}\nC_{55}\\\\\n\\end{bmatrix}\n\\]\nPutting in the numbers we get:\n\nsigma_AA = covariance_5d[:4, :4]\n\n\nsigma_AA\n\narray([[1. , 0.9, 0.8, 0.6],\n       [0.9, 1. , 0.9, 0.8],\n       [0.8, 0.9, 1. , 0.9],\n       [0.6, 0.8, 0.9, 1. ]])\n\n\n\nsigma_AB = covariance_5d[:4, 4].reshape(-1, 1)\n\n\nsigma_AB\n\narray([[0.4],\n       [0.6],\n       [0.8],\n       [0.9]])\n\n\n\nsigma_BA = covariance_5d[4, :4].reshape(1, -1)\n\n\nsigma_BA\n\narray([[0.4, 0.6, 0.8, 0.9]])\n\n\n\nsigma_BB = covariance_5d[4, 4].reshape(-1, 1)\n\n\nsigma_BB\n\narray([[1.]])\n\n\nNow, calculating \\(\\bar{\\mu}\\)\n\nmu_bar = np.zeros((4, 1)) + sigma_AB@np.linalg.inv(sigma_BB)*(-2)\n\n\nmu_bar\n\narray([[-0.8],\n       [-1.2],\n       [-1.6],\n       [-1.8]])\n\n\nSince, \\(x_5\\) has highest correlation with \\(x_4\\) it makes sense for \\(x_5=-2\\) to have the mean of \\(x_4\\) to be close to -2.\nNow, calculating \\(\\bar{\\Sigma}\\)\n\nsigma_bar = sigma_AA - sigma_AB@np.linalg.inv(sigma_BB)@sigma_BA\n\n\nsigma_bar\n\narray([[0.84, 0.66, 0.48, 0.24],\n       [0.66, 0.64, 0.42, 0.26],\n       [0.48, 0.42, 0.36, 0.18],\n       [0.24, 0.26, 0.18, 0.19]])\n\n\nNow, we have the new mean and covariance matrices for \\(x_A = [x_1, x_2, x_3, x_4]\\) and \\(x_B = [x_5] = [-2]\\). Let us now draw some samples fixing \\(x_5 = -2\\)\n\ncov = sigma_bar\nmu = mu_bar.flatten()\ndef plot_5d_samples_fixed_x2(random_num):\n    fig, ax  = plt.subplots(ncols=2, figsize=(6, 3))\n    \n    \n    F = multivariate_normal(mu, cov)\n    \n    sns.heatmap(cov, ax=ax[0], annot=True)\n    random_point = F.rvs(random_state=random_num)\n    \n    \n    data_array = pd.Series(random_point, index=['X1','X2','X3','X4'])\n    data_array['X5'] = -2\n    data_array.plot(ax=ax[1], kind='line', marker='.',color='k')\n    plt.scatter([4], [-2], color='red', s=100)\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    ax[1].set_ylim(-3, 3)\n    for i in range(2):\n        format_axes(ax[i])\n    \n    ax[0].set_title(\"Covariance Matrix\")\n    ax[-1].set_title(\"Visualising the point\")\n    plt.suptitle(f\"Random state = {random_num}\", y=1.1)\n    plt.tight_layout()\n    import os\n    if not os.path.exists(\"images/5d/conditional/1\"):\n        os.makedirs(\"images/5d/conditional/1\")\n    \n    plt.savefig(f\"images/5d/conditional/1/{random_num}.jpg\", bbox_inches=\"tight\")\n    plt.close()\n    \n\n\nfor i in range(20):\n    plot_5d_samples_fixed_x2(i)\n\n\n!convert -delay 20 -loop 0 images/5d/conditional/1/*.jpg 5d-conditional-1.gif\n\n\n\n\nLet’s increase to 20 dimensions now!\nWe can not surely write the covariance matrix for 20 dimensions. Let us use a small trick called the kernel function to create this matrix. We will come it later. For now, let us think of this function as a function which:\n\noutputs low numbers for \\(x_1\\) and \\(x_2\\) if they differ by a lot\noutputs high number for \\(x_1\\) and \\(x_2\\) if they are very close\n\n\ndef rbf_kernel(x_1, x_2, sig):\n    return np.exp((-(x_1-x_2)**2)/2*(sig**2))\n\n\nrbf_kernel(1, 1, 0.4)\n\n1.0\n\n\nSince 1=1, the above function evaluates to 1 showing that 1 is similar to 1\n\nrbf_kernel(1, 2, 0.4)\n\n0.9231163463866358\n\n\nSince 1 and 2 are close, the function above evaluates to close to 1\n\nrbf_kernel(1, 2, 1)\n\n0.6065306597126334\n\n\nOk, we use the same first two arguments 1 and 2 but change the last one to 1 from 0.4 and we see that the function evaluates to a much smaller number. Thus, we can see that increase the sig parameter leads to quicker dropoff in similarity between pair of points. Or, in other words, higher sig means that the influence of a point x_1 reduces quicker.\nLet us now create the covariance matrix of size (20, 20) using this kernel function.\n\nC = np.zeros((20, 20))\n\n\nfor i in range(20):\n    for j in range(20):\n        C[i, j] = rbf_kernel(i, j, 0.5)\n\nLet us plot the heatmap of the covariance matrix\n\nsns.heatmap(C)\n\n\n\n\n\n\n\n\nThe above heatmap confirms that there is correlation between nearby points, but close to zero or zero correlation otherwise.\n\nLet us draw some samples from this 20 dimensional Gaussian\n\ndef plot_20d_samples(random_num):\n    fig, ax  = plt.subplots(figsize=(10, 3))\n    \n    \n    F = multivariate_normal(np.zeros(20), C)\n    random_point = F.rvs(random_state=random_num)\n    index = [f'X{i}' for i in range(1, 21)]\n    data_array = pd.Series(random_point, index=index)\n    data_array.plot(ax=ax, kind='line', marker='.',color='k')\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    \n    plt.suptitle(f\"Random state = {random_num}\", y=1.1)\n    plt.tight_layout()\n    import os\n    if not os.path.exists(\"images/20d/\"):\n        os.makedirs(\"images/20d/\")\n    \n    plt.ylim(-3, 3)\n    plt.savefig(f\"images/20d/{random_num}.jpg\", bbox_inches=\"tight\")\n    plt.close()\n\n\nfor i in range(50):\n    plot_20d_samples(i)\n\n\n!convert -delay 20 -loop 0 images/20d/*.jpg 20d.gif\n\n\nFrom the animation above, we can see different family of functions of mean zero across these 20 points. We’re really getting close now!\n\n\nLet us now condition on a few elements\nWe will create a new ordering of these variables such that the known variables occur towards the end. This allows for easy calculations for conditioning.\n\norder = [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 5, 10]\n\n\nnew_C = np.zeros_like(C)\n\n\nold_order = range(20)\n\n\nfor i in range(20):\n    for j in range(20):\n        new_C[i, j] = C[order[i], order[j]]\n\n\nsns.heatmap(new_C, xticklabels=order, yticklabels=order, cmap='jet')\n\n\n\n\n\n\n\n\nNow, we can condition on (x1 = 1, x2 = 3, x6 = -3, X11 = 1). We will use the same procedure we used above in the case of 5d.\n\nB = np.array([1, 3, -3, 1]).reshape(-1, 1)\nB\n\narray([[ 1],\n       [ 3],\n       [-3],\n       [ 1]])\n\n\n\nsigma_AA_20d = new_C[:-B.size, :-B.size]\nsigma_AA_20d.shape\n\n(16, 16)\n\n\n\nsigma_BB_20d = new_C[-B.size:, -B.size:]\nsigma_BB_20d.shape\n\n(4, 4)\n\n\n\nsigma_AB_20d = new_C[:-B.size, -B.size:]\nsigma_AB_20d.shape\n\n(16, 4)\n\n\n\nsigma_BA_20d = new_C[-B.size:, :-B.size]\nsigma_BA_20d.shape\n\n(4, 16)\n\n\n\nmu_bar_20d = np.zeros((20-B.size, 1)) + sigma_AB_20d@np.linalg.inv(sigma_BB_20d)@(B)\n\n\nsigma_bar_20d = sigma_AA_20d - sigma_AB_20d@np.linalg.inv(sigma_BB_20d)@sigma_BA_20d\n\n\nsns.heatmap(sigma_bar_20d, xticklabels=order[:-B.size], yticklabels=order[:-B.size], cmap='jet')\n\n\n\n\n\n\n\n\n\ndef plot_20d_samples_known_x(random_num):\n    fig, ax  = plt.subplots(figsize=(10, 3))\n    \n    \n    F = multivariate_normal(mu_bar_20d.flatten(), sigma_bar_20d)\n    random_point = F.rvs(random_state=random_num)\n    index = [f'X{i+1}' for i in order[:-B.size]]\n    data_array = pd.Series(random_point, index=index)\n    data_array['X1'] = 1\n    data_array['X2'] = 3\n    data_array['X6'] = -3\n    data_array['X11'] = -1\n    \n    data_array = data_array[[f'X{i+1}' for i in range(20)]]\n    data_array.plot(ax=ax, kind='line', marker='.',color='k')\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    plt.scatter([0, 1,5, 10], [1, 3, -3, -1], color='red',s=100)\n\n    plt.suptitle(f\"Random state = {random_num}\", y=1.1)\n    plt.tight_layout()\n    import os\n    if not os.path.exists(\"images/20d/conditional/\"):\n        os.makedirs(\"images/20d/conditional/\")\n    plt.grid()\n    plt.ylim(-4, 4)\n    plt.savefig(f\"images/20d/conditional/{random_num}.jpg\", bbox_inches=\"tight\")\n    plt.close()\n\n\nfor i in range(50):\n    plot_20d_samples_known_x(i)\n\n\n!convert -delay 20 -loop 0 images/20d/conditional/*.jpg 20d-conditional.gif\n\n\nFrom the plot above, we can see the known points in red and the other points wiggle to show the families of functions that we fit. Let us now draw a lot of samples and plot the mean and variance in these samples for the unknown X variables. We could have obtained the mean and variance directly using Gaussian marginalisation, but, for now let us just draw many samples.\n\nF = multivariate_normal(mu_bar_20d.flatten(), sigma_bar_20d)\ndfs = {}\nfor random_num in range(100):\n    random_point = F.rvs(random_state=random_num)\n    index = [f'X{i+1}' for i in order[:-B.size]]\n    data_array = pd.Series(random_point, index=index)\n    data_array['X1'] = 1\n    data_array['X2'] = 3\n    data_array['X6'] = -3\n    data_array['X11'] = -1\n    \n    data_array = data_array[[f'X{i+1}' for i in range(20)]]\n    dfs[random_num] = data_array\n\n\nfig, ax = plt.subplots(figsize=(10, 3))\npd.DataFrame(dfs).mean(axis=1).plot(yerr=pd.DataFrame(dfs).std(axis=1),marker='o', color='k')\nplt.xticks(np.arange(len(data_array.index)), data_array.index.values)\nplt.scatter([0, 1,5, 10], [1, 3, -3, -1], color='red',s=100)\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\nFrom the plot above, we can see the uncertainty (standard deviation) and the mean values for different variables. As expected, the uncertainty close to the known points (red) is low. Also, owing to the smooth nature of the covariance function we can see the means of unknown points close to known points are fairly similar.\nTo summarise: We can very clearly see that there is low variance in zones where we have the known values and high variance otherwise. The farther we go away from a known value, the more is the variance!\n\n\n\nKernels!\nWe will now take a small plunge into the world of kernels. As mentioned earlier, we will limit the discussion to generating to covariance matrix.\nWe will be redefining the function mentioned above to include two parameters l and s\n\ns is the scale of variance\nl is the influence of the point to neighbouring points\n\n\ndef sig(x1, x2, l, s):\n    return s**2*(np.exp((-1/2*(l**2))*((x1-x2)**2)))\n\n\nCov_matrix = np.zeros((100, 100))\n\n\nfig, ax = plt.subplots(ncols=4, sharex=True, sharey=True)\ns = 1\nfor ix, l in enumerate([0.001, 0.01, 0.1, 1]):\n    for i in range(100):\n        for j in range(100):\n            Cov_matrix[i, j] = sig(i, j, l, 1)\n    im = ax[ix].imshow(Cov_matrix, cmap='jet')\n    ax[ix].set_title(f\"l={l}\")\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.35, 0.05, 0.3])\nfig.colorbar(im, cax=cbar_ax)\nplt.suptitle(f\"Covariance matrix for varying l and s = {s}\")\n\nText(0.5, 0.98, 'Covariance matrix for varying l and s = 1')\n\n\n\n\n\n\n\n\n\nIn the plot above, we can the covariance matrices for fixed s=1 and varying l. It can be seen that for very low l, the correlations between far away points is also significant. At l=1, this ceases to be the case.\n\nfig, ax = plt.subplots(ncols=4, sharex=True, sharey=True, figsize=(12, 3))\nfor ix, s in enumerate([1, 10, 20, 30]):\n    for i in range(100):\n        for j in range(100):\n            Cov_matrix[i, j] = sig(i, j, 0.1, s)\n    sns.heatmap(Cov_matrix, cmap='jet', ax=ax[ix])\n    ax[ix].set_title(f\"s={s}\")\nplt.suptitle(\"Covariance matrix for varying s and l = 0.1\")\n\nText(0.5, 0.98, 'Covariance matrix for varying s and l = 0.1')\n\n\n\n\n\n\n\n\n\nOk, this is great. We can see the different scales on the colorbars with increasing s and fixing l\nNow, let us try and redo the 20 point dataset with varying kernel parameters with conditioning on some known data.\n\ndef fit_plot_gp(kernel_s, kernel_l, known_data, total_data_points, save=False):\n    \"\"\"\n    kernel_s: sigma^2 param of kernel\n    kernel_l: l (width) param of kernel\n    known_data: {pos: value}\n    total_data_points\n    \"\"\"\n    o = list(range(20))\n    for key in known_data.keys():\n        o.remove(key)\n    o.extend(list(known_data.keys()))\n    \n    C = np.zeros((total_data_points, total_data_points))\n    for i in range(total_data_points):\n        for j in range(total_data_points):\n            C[i, j] = sig(i, j, kernel_l, kernel_s)\n        \n    \n    # Making known variables shift\n    new_C = np.zeros_like(C)\n    for i in range(20):\n        for j in range(20):\n            new_C[i, j] = C[o[i], o[j]]\n    B = np.array(list(known_data.values())).reshape(-1, 1)    \n    sigma_BA_20d = new_C[-B.size:, :-B.size]\n    sigma_AB_20d = new_C[:-B.size, -B.size:]\n    sigma_BB_20d = new_C[-B.size:, -B.size:]\n    sigma_AA_20d = new_C[:-B.size, :-B.size]\n\n    mu_bar_20d = np.zeros((20-B.size, 1)) + sigma_AB_20d@np.linalg.inv(sigma_BB_20d)@(B)\n    sigma_bar_20d = sigma_AA_20d - sigma_AB_20d@np.linalg.inv(sigma_BB_20d)@sigma_BA_20d\n    F = multivariate_normal(mu_bar_20d.flatten(), sigma_bar_20d)\n    dfs = {}\n    for random_num in range(100):\n        random_point = F.rvs(random_state=random_num)\n        index = [f'X{i+1}' for i in o[:-B.size]]\n        data_array = pd.Series(random_point, index=index)\n        for k, v in known_data.items():\n            data_array[f'X{k+1}'] = v\n        \n\n        data_array = data_array[[f'X{i+1}' for i in range(20)]]\n        dfs[random_num] = data_array\n    fig, ax = plt.subplots(figsize=(10, 3))\n    mean_vector = pd.DataFrame(dfs).mean(axis=1)\n    mean_vector.plot(marker='.', color='k')\n    yerr=pd.DataFrame(dfs).std(axis=1)\n    \n    plt.fill_between(range(len(mean_vector)), mean_vector+yerr, mean_vector-yerr, color='gray',alpha=0.4)\n    plt.xticks(np.arange(len(data_array.index)), data_array.index.values)\n    plt.scatter(list(known_data.keys()), list(known_data.values()), color='gray',s=200,zorder=1)\n    format_axes(plt.gca())\n    plt.title(f\" l = {kernel_l} and s = {kernel_s}\")\n    import os\n    if save:\n        if not os.path.exists(\"images/20d/conditional-points/\"):\n            os.makedirs(\"images/20d/conditional-points/\")\n        plt.grid()\n        plt.xticks(np.arange(len(data_array.index)), np.arange(len(data_array.index)))\n        plt.ylim(-4, 4)\n        plt.title(f\"Known data: {known_data}\")\n        plt.savefig(f\"images/20d/conditional-points/{len(known_data.keys())}.jpg\", bbox_inches=\"tight\")\n        plt.close()\n        \n\n\nknown_d = {0:-2, 1:3, 9:-1, 14:-1}\n\n\nfit_plot_gp(1, 0.5, known_d, 20)\n\n\n\n\n\n\n\n\nThe above plot shows the uncertainty and the family of functions for l=0.5 and s=1.\n\nfit_plot_gp(5, 0.5, known_d, 20)\n\n\n\n\n\n\n\n\nKeeping l=0.5, the above plot shows how increasing s increases the uncertainty of estimation.\n\nfit_plot_gp(1, 1, known_d, 20)\n\n\n\n\n\n\n\n\nThe above plot shows how increasing l reduces the influence between far away points.\n\nfit_plot_gp(1, 100, known_d, 20)\n\n\n\n\n\n\n\n\nThe above plot increases l to a very large value. Seems to be just moving around the mean?\n\nnp.random.seed(0)\norder_points_added = np.random.choice(range(20), size=9, replace=False)\nk = {}\nfor i in range(9):\n    k[order_points_added[i]] = np.random.choice(range(-3, 3))\n    fit_plot_gp(1, 0.5, k, 20, True)\n\n\n!convert -delay 40 -loop 0 images/20d/conditional-points/*.jpg 20d-conditional-main.gif\n\nLet us create a small animation where we keep on adding points and see how the uncertainty and estimation changes\n\n\n\nCreating a scikit-learn like function containing fit and predict\nI’ll now bring in the formal definitions, summarise the discussion and write a function akin to scikit-learn which can accept train data to estimate for test data.\n\nFormally defining GPs\nA Gaussian process is fully specified by a mean function m(x) and covariance function K(x, x') :\n\\[\nf(x) \\sim GP (m(x),K(x, x')\n\\]\nLet us consider a case of noiseless GPs now\n\n\nNoiseless GPs\nGiven train data \\[D = {(x_i, y_i), i = 1:N}\\]\nGiven a test set \\(X_{*}\\) of size $N_* d $ containing \\(N_*\\) points in \\({\\rm I\\!R}^d\\), we want to predict function outputs \\(y_{*}\\)\nWe can write:\n\\[\n\\begin{pmatrix}\ny \\\\\ny_*\n\\end{pmatrix}  \\sim \\mathcal{N} \\left( \\begin{pmatrix}\n\\mu \\\\\n\\mu_*\n\\end{pmatrix} , \\begin{pmatrix}\nK & K_* \\\\\nK_*^T & K_{**}\n\\end{pmatrix} \\right)\n\\]\nwhere\n\\[\nK = Ker(X, X) \\in {\\rm I\\!R}^{N\\times N}\\\\\nK_* = Ker(X, X_*) \\in {\\rm I\\!R}^{N\\times N_*}\\\\\nK_{**} = Ker(X_*, X_*) \\in {\\rm I\\!R}^{N_*\\times N_*}\\\\\n\\]\nWe had previously used the kernel which we will continue to use\ndef sig(x1, x2, l, s):\n    return s**2*(np.exp((-1/2*(l**2))*((x1-x2)**2)))\nWe can then write:\n\\[\np(y_*|X_*, X, y) \\sim \\mathcal{N}(\\mu', \\Sigma') \\\\\n\\mu' = \\mu_* + K_*^TK^{-1}(x-\\mu) \\\\\n\\Sigma' = K_{**} - K_*^TK^{-1}K_*\n\\]\n\nclass NoiselessGP_inversion:\n    def __init__(self, l=0.1, s=1, prior_mean=0):\n        self.l = l\n        self.s = s     \n        self.prior_mean = prior_mean\n        \n    def prior_sample(self, x, n):\n        \"\"\"\n        Sample GP on x\n        \"\"\"\n        self.sample_k = self.create_cov_matrix(x, x, self.l, self.s)\n        for i in range(n):\n            pass\n      \n    \n    def kernel(self, a, b, l, s):\n        \"\"\"\n        Borrowed from Nando De Freita's lecture code\n        https://www.cs.ubc.ca/~nando/540-2013/lectures/gp.py\n        \"\"\"\n        sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n        return s**2*np.exp(-.5 * (1/l) * sqdist)\n    \n    def fit(self, train_x, train_y):\n        self.train_x = train_x\n        self.train_y = train_y\n        self.N = len(train_x)\n        self.K = self.kernel(train_x, train_x, self.l, self.s)\n        \n                \n    def predict(self, test_x):\n        self.N_star = len(test_x)\n        self.K_star = self.kernel(self.train_x, test_x, self.l, self.s)\n        self.K_star_star = self.kernel(test_x, test_x, self.l, self.s)\n        self.posterior_mu = self.prior_mean + self.K_star.T@np.linalg.inv(self.K)@(self.train_y-self.prior_mean)\n        self.posterior_sigma = self.K_star_star - self.K_star.T@np.linalg.inv(self.K)@self.K_star\n        return self.posterior_mu, self.posterior_sigma\n\n\nclf = NoiselessGP_inversion()\n\n\ntrain_x = np.array([-4, -3, -2, -1, 1]).reshape(5,1)\ntrain_y = np.sin(train_x)\n\ntest_x = np.linspace(-5, 5, 50).reshape(-1, 1)\ntest_y = np.sin(test_x)\n\n\nplt.plot(train_x, train_y,'ko-')\n\n\n\n\n\n\n\n\n\nclf.fit(train_x, train_y)\n\n\nposterior_mu, posterior_var = clf.predict(test_x)\n\n\nplt.plot(test_x, clf.posterior_mu,'k',label='Predicted',lw=1)\nplt.plot(test_x, test_y, 'purple',label='GT',lw=2)\nplt.plot(train_x, train_y, 'ko',label='Training Data')\n\nplt.fill_between(test_x.flatten(), \n                 (clf.posterior_mu.flatten() - clf.posterior_sigma.diagonal().flatten()),\n                 (clf.posterior_mu.flatten() + clf.posterior_sigma.diagonal().flatten()),\n                 color='gray', alpha=0.3\n                )\nplt.legend()\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\n\n\n\nCholesky decomposition\nWe had previously used matrix inversion to do the computation for computing the posterior mean and variance in our GP. However, the matrices involved may be poorly conditioned and thus Cholesky decomposition is often favoured.\nFrom Wikipedia, the Cholesky decomposition of a matrix \\(A\\) is given as: \\[\n\\mathbf{A} = \\mathbf{L L}^T\n\\]\nwhere \\(L\\) is a real lower triangular matrix.\nWe can thus re-write the posterior mean and covariance as:\n\\[\np(y_*|X_*, X, y) \\sim \\mathcal{N}(\\mu', \\Sigma') \\\\\nK = LL^T \\\\\n\\]\nWe are now going to use the \\ as follows: if \\(A\\omega = B\\), then \\(\\omega\\) = \\(A\\) \\ \\(B\\)\nWe now have: \\[\n\\alpha = K^{-1}(x-\\mu) \\\\\nor, \\alpha = {LL^T}^{-1}(x-\\mu) \\\\\nor, \\alpha = L^{-T}L^{-1}(x-\\mu) \\\\\nLet, L^{-1}(x-\\mu) = \\gamma\\\\\nThus, L\\gamma = x-\\mu \\\\\nThus, \\gamma = L \\setminus (x-\\mu)\\\\\\\nThus, \\alpha = L^{T} \\setminus (L \\setminus (x-\\mu))\n\\]\nIn Python, the same can be written as:\n    L = np.linalg.cholesky(K)\n    alpha = np.linalg.solve(L.T, np.linalg.solve(L, x-mu))\nThus, we can find the posterior mean as: \\[\n\\mu' = \\mu_* + K_*^T \\alpha \\\\\n\\]\nWe also know that \\[\n\\Sigma' = K_{**} - K_*^TK^{-1}K_*\n\\]\nLet us now define \\[\nv = L \\setminus K_{*}\\\\\nor, v = L^{-1}K_{*}\\\\\nThus, v^{T} = K_{*}^TL^{-T}\\\\\nThus, v^{T}v = K_{*}^TL^{-T}L^{-1}K_{*}\\\\\nThus, v^{T}v = K_*^TK^{-1}K_* = K_{**} - \\Sigma'\n\\]\n\\[\n\\Sigma' = K_{**} - v^{T}v\n\\]\nLet us know rewrite the code with Cholesky decomposition.\n\nclass NoiselessGP_Cholesky:\n    def __init__(self, l=0.1, s=1, prior_mean=0):\n        self.l = l\n        self.s = s     \n        self.prior_mean = prior_mean\n        \n    def prior_sample(self, x, n):\n        \"\"\"\n        Sample GP on x\n        \"\"\"\n        self.sample_k = self.create_cov_matrix(x, x, self.l, self.s)\n        for i in range(n):\n            pass\n      \n    \n    def kernel(self, a, b, l, s):\n        \"\"\"\n        Borrowed from Nando De Freita's lecture code\n        https://www.cs.ubc.ca/~nando/540-2013/lectures/gp.py\n        \"\"\"\n        sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n        return s**2*np.exp(-.5 * (1/l) * sqdist)\n    \n    def fit(self, train_x, train_y):\n        self.train_x = train_x\n        self.train_y = train_y\n        self.N = len(train_x)\n        self.K = self.kernel(train_x, train_x, self.l, self.s)\n        self.L = np.linalg.cholesky(self.K)\n        \n                \n    def predict(self, test_x):\n        self.N_star = len(test_x)\n        self.K_star = self.kernel(self.train_x, test_x, self.l, self.s)\n        self.K_star_star = self.kernel(test_x, test_x, self.l, self.s)\n        self.alpha = np.linalg.solve(self.L.T, np.linalg.solve(self.L, self.train_y-self.prior_mean))\n        self.v = np.linalg.solve(self.L, self.K_star)\n        self.posterior_mu = self.prior_mean + self.K_star.T@self.alpha\n        self.posterior_sigma = self.K_star_star - self.v.T@self.v\n        return self.posterior_mu, self.posterior_sigma\n\n\nclf = NoiselessGP_Cholesky()\nclf.fit(train_x, train_y)\nposterior_mu_cholesky, posterior_var_cholesky = clf.predict(test_x)\n\nWe will now compare our Cholesky decomposition based decompostion with the earlier one.\n\nnp.allclose(posterior_mu_cholesky, posterior_mu)\n\nTrue\n\n\n\nnp.allclose(posterior_var_cholesky, posterior_var)\n\nTrue\n\n\nOk, all looks good till now! Let us now move on to the case for Noisy GPs.\n\n\nNoisy GPs\nPreviously, we had assumed a noiseless model, which is to say, for the observed data, we had: \\[y_i = f(x_i)\\]\nWe now make the model more flexible by saying that there can be noise in the observed data as well, thus: \\[\ny_i = f(x_i) + \\epsilon \\\\\n\\epsilon \\sim \\mathcal{N}(0, \\sigma_y^2)\n\\]\nOne of the main difference compared to the noiseless model would be that in the noisy model, we will have some uncertainty even about the training points.\nEverything about our model remains the same, except for the change in the covariance matrix \\(K\\) for the training points, which is now given as:\n\\[K_y = \\sigma_y^2\\mathbf{I_n} + K\n\\]\nWe can now rewrite the function as follows:\n\nclass NoisyGP:\n    def __init__(self, l = 0.1, s = 1, prior_mean = 0, sigma_y = 1):\n        self.l = l\n        self.s = s     \n        self.prior_mean = prior_mean\n        self.sigma_y = sigma_y\n        \n    def prior_sample(self, x, n):\n        \"\"\"\n        Sample GP on x\n        \"\"\"\n        self.sample_k = self.create_cov_matrix(x, x, self.l, self.s)\n        for i in range(n):\n            pass\n      \n    \n    def kernel(self, a, b, l, s):\n        \"\"\"\n        Borrowed from Nando De Freita's lecture code\n        https://www.cs.ubc.ca/~nando/540-2013/lectures/gp.py\n        \"\"\"\n        sqdist = np.sum(a**2,1).reshape(-1,1) + np.sum(b**2,1) - 2*np.dot(a, b.T)\n        return s**2*np.exp(-.5 * (1/l) * sqdist)\n    \n    def fit(self, train_x, train_y):\n        self.train_x = train_x\n        self.train_y = train_y\n        self.N = len(train_x)\n        self.K = self.kernel(train_x, train_x, self.l, self.s) + self.sigma_y*np.eye(len(train_x))\n        self.L = np.linalg.cholesky(self.K)\n        \n                \n    def predict(self, test_x):\n        self.N_star = len(test_x)\n        self.K_star = self.kernel(self.train_x, test_x, self.l, self.s)\n        self.K_star_star = self.kernel(test_x, test_x, self.l, self.s)\n        self.alpha = np.linalg.solve(self.L.T, np.linalg.solve(self.L, self.train_y-self.prior_mean))\n        self.v = np.linalg.solve(self.L, self.K_star)\n        self.posterior_mu = self.prior_mean + self.K_star.T@self.alpha\n        self.posterior_sigma = self.K_star_star - self.v.T@self.v\n        return self.posterior_mu, self.posterior_sigma\n\n\nclf = NoisyGP(sigma_y=0.2)\nclf.fit(train_x, train_y)\nposterior_mu_noisy, posterior_var_noisy = clf.predict(test_x)\n\n\nplt.plot(test_x, clf.posterior_mu,'k',label='Predicted',lw=1)\nplt.plot(test_x, test_y, 'purple',label='GT',lw=2)\nplt.plot(train_x, train_y, 'ko',label='Training Data')\n\nplt.fill_between(test_x.flatten(), \n                 (clf.posterior_mu.flatten() - clf.posterior_sigma.diagonal().flatten()),\n                 (clf.posterior_mu.flatten() + clf.posterior_sigma.diagonal().flatten()),\n                 color='gray', alpha=0.3\n                )\nplt.legend()\nformat_axes(plt.gca())\n\n\n\n\n\n\n\n\nWe can now see that our model has some uncertainty even on the train points!"
  },
  {
    "objectID": "posts/2020-03-26-gp.html",
    "href": "posts/2020-03-26-gp.html",
    "title": "Some experiments in Gaussian Processes Regression",
    "section": "",
    "text": "youtube: https://www.youtube.com/watch?v=V1bF37-_ytQ"
  },
  {
    "objectID": "posts/2020-03-26-gp.html#air-quality-2d-map",
    "href": "posts/2020-03-26-gp.html#air-quality-2d-map",
    "title": "Some experiments in Gaussian Processes Regression",
    "section": "Air quality 2d map",
    "text": "Air quality 2d map\nNow, we will be using GPs for predicting air quality in New Delhi. See my previous post on how to get AQ data for Delhi.https://nipunbatra.github.io/blog/air%20quality/2018/06/21/aq-india-map.html\nI will be creating a function to visualise the AQ estimations using GPs based on different kernels.\nThe shapefile for Delhi can be downloaded from here.\n\nimport pandas as pd\nimport os\ndf = pd.read_csv(os.path.expanduser(\"~/Downloads/2018-04-06.csv\"))\ndf = df[(df.country=='IN')&(df.city=='Delhi')&(df.parameter=='pm25')].dropna().groupby(\"location\").mean()\n\n\ndf\n\n\n\n\n\n\n\n\nvalue\nlatitude\nlongitude\n\n\nlocation\n\n\n\n\n\n\n\nBurari Crossing, New Delhi - IMD\n245.583333\n28.725650\n77.201157\n\n\nCRRI Mathura Road, New Delhi - IMD\n265.666667\n28.551200\n77.273574\n\n\nDTU, New Delhi - CPCB\n214.333333\n28.750050\n77.111261\n\n\nIGI Airport Terminal - 3, New Delhi - IMD\n130.666667\n28.562776\n77.118005\n\n\nIHBAS, Dilshad Garden,New Delhi - CPCB\n212.583333\n28.680275\n77.201157\n\n\nITO, New Delhi - CPCB\n220.500000\n28.631694\n77.249439\n\n\nLodhi Road, New Delhi - IMD\n176.083333\n28.591825\n77.227307\n\n\nMandir Marg, New Delhi - DPCC\n82.000000\n28.637269\n77.200560\n\n\nNSIT Dwarka, New Delhi - CPCB\n184.583333\n28.609090\n77.032541\n\n\nNorth Campus, DU, New Delhi - IMD\n147.833333\n28.657381\n77.158545\n\n\nPusa, New Delhi - IMD\n112.000000\n28.610304\n77.099694\n\n\nR K Puram, New Delhi - DPCC\n103.600000\n28.564610\n77.167010\n\n\nShadipur, New Delhi - CPCB\n213.833333\n28.651478\n77.147311\n\n\nSirifort, New Delhi - CPCB\n222.250000\n28.550425\n77.215938\n\n\nUS Diplomatic Post: New Delhi\n46.625000\n28.635760\n77.224450\n\n\n\n\n\n\n\n\nimport geopandas\ngdf = geopandas.GeoDataFrame(\n    df, geometry=geopandas.points_from_xy(df.longitude, df.latitude))\n\n\ngdf.plot()\n\n\n\n\n\n\n\n\n\ndef plot_air_vis(df, k, shp, title):\n    m = GPy.models.GPRegression(df[['longitude','latitude']], df[['value']], k)\n    m.optimize(max_iters=2000)\n    y_t = np.linspace(28.38,28.9, 40)\n    x_t = np.linspace(76.82, 77.4, 40)\n\n    XX, YY = np.meshgrid(x_t, y_t)\n    Z_pred = np.zeros_like(YY)\n    Z_var = np.zeros_like(YY)\n    for i in range(40):\n        for j in range(40):\n            Z_pred[i, j], Z_var[i, j] = m.predict_noiseless(np.array([XX[i, j], YY[i, j]]).reshape(1, 2))\n    \n    data = geopandas.read_file(fp)\n    fig = plt.figure(figsize=(6, 6))\n    plt.contourf(XX, YY, Z_pred, levels=30,alpha=0.6,cmap='Purples')\n    plt.colorbar()\n    gdf.plot(ax=plt.gca(),markersize=gdf['value'],color='k')\n    data.plot(color='k',ax=plt.gca(),zorder=-1,alpha=0.4)\n    plt.gca().set_aspect(\"equal\")\n    for a in [100, 150, 200,250]:\n        plt.scatter([], [], c='k', alpha=1, s=a,\n                    label=str(a) + '$\\mu g/m^3$')\n    plt.legend(scatterpoints=1, frameon=True,\n               labelspacing=1, loc='upper left',ncol=2)\n    \n    plt.title(title+\"\\t\"+str(m.objective_function()))\n\n\nk_2d = GPy.kern.RBF(input_dim=2, lengthscale=1)\nk_2d_rbf_2 = GPy.kern.RBF(input_dim=2, lengthscale=3)*k_2d\nk_2d_rbf_3 = GPy.kern.RBF(input_dim=2, lengthscale=3) + k_2d_rbf_2\nk_matern32 = GPy.kern.Matern32(input_dim=2)\nk_matern52 = GPy.kern.Matern52(input_dim=2)\n\nk_rbf_matern = k_matern32 * k_matern52 + k_matern32*k_2d_rbf_3\n\n\nfp=os.path.expanduser(\"~/Downloads/wards delimited.shp\")\n\n\nplot_air_vis(df, k_2d, fp,\"RBF\")\nplot_air_vis(df, k_matern32, fp,\"Matern32\")\nplot_air_vis(df, k_matern52, fp,\"matern52\")\nplot_air_vis(df, k_2d_rbf_2, fp,\"RBF*RBF\")\nplot_air_vis(df, k_2d_rbf_3, fp,\"RBF*RBF+RBF\")\nplot_air_vis(df, k_rbf_matern, fp,\"Matern32*Matern52+Matern32*RBF\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere you go. Till next time!"
  },
  {
    "objectID": "posts/2017-12-18-recommend-keras.html",
    "href": "posts/2017-12-18-recommend-keras.html",
    "title": "Recommend keras",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- recommendation-systems- collaborative-filtering- deep-learning- neural-networks- keras- tensorflowdate: ’2017-12-18’output-file: 2017-12-18-recommend-keras.htmltitle: Recommend kerastoc: true—\nI have written a few posts earlier about matrix factorisation using various Python libraries. The main application I had in mind for matrix factorisation was recommender systems. In this post, I’ll write about using Keras for creating recommender systems. Various people have written excellent similar posts and code that I draw a lot of inspiration from, and give them their credit! I’m assuming that a reader has some experience with Keras, as this post is not intended to be an introduction to Keras.\nSpecifically, in this post, I’ll talk about:\n\nMatrix Factorisation in Keras\nAdding non-negativitiy constraints to solve non-negative matrix factorisation (NNMF)\nUsing neural networks for recommendations\n\nI’ll be using the Movielens-100k dataset for illustration. There are 943 users and 1682 movies. In total there are a 100k ratings in the dataset. It should be noted that the max. total number of rating for the &lt;users, movies&gt; would be 943*1682, which means that we have about 7% of the total ratings! All rating are on a scale of 1-5.\n\nTask\nGiven this set of ratings, can we recommend the next set of movies to a user? This would translate to: for every user, estimating the ratings for all the movies that (s)he hasn’t watched and maybe recommend the top-k movies by the esimtated ratings!\n\n\nPeak into the dataset\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\n\ndataset = pd.read_csv(\"/Users/nipun/Downloads/ml-100k/u.data\",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n0\n196\n242\n3\n881250949\n\n\n1\n186\n302\n3\n891717742\n\n\n2\n22\n377\n1\n878887116\n\n\n3\n244\n51\n2\n880606923\n\n\n4\n166\n346\n1\n886397596\n\n\n\n\n\n\n\nSo, each record (row) shows the rating for a user, item (movie) pair. It should be noted that I use item and movie interchangeably in this post.\n\nlen(dataset.user_id.unique()), len(dataset.item_id.unique())\n\n(943, 1682)\n\n\nWe assign a unique number between (0, #users) to each user and do the same for movies.\n\ndataset.user_id = dataset.user_id.astype('category').cat.codes.values\ndataset.item_id = dataset.item_id.astype('category').cat.codes.values\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n0\n195\n241\n3\n881250949\n\n\n1\n185\n301\n3\n891717742\n\n\n2\n21\n376\n1\n878887116\n\n\n3\n243\n50\n2\n880606923\n\n\n4\n165\n345\n1\n886397596\n\n\n\n\n\n\n\n\n\nTrain test split\nWe’ll now split our dataset of 100k ratings into train (containing 80k ratings) and test (containing 20k ratings). Given the train set, we’d like to accurately estimate the ratings in the test set.\n\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(dataset, test_size=0.2)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n90092\n832\n12\n2\n875036139\n\n\n50879\n94\n132\n3\n888954341\n\n\n67994\n436\n12\n4\n880141129\n\n\n49769\n710\n344\n4\n884485683\n\n\n11032\n121\n736\n4\n879270874\n\n\n\n\n\n\n\n\ntest.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n89284\n907\n493\n3\n879723046\n\n\n60499\n550\n25\n4\n892785056\n\n\n11090\n373\n222\n5\n880394520\n\n\n36096\n199\n140\n4\n884129346\n\n\n21633\n71\n317\n5\n880037702\n\n\n\n\n\n\n\n\n\nMatrix factorisation\nOne popular recommender systems approach is called Matrix Factorisation. It works on the principle that we can learn a low-dimensional representation (embedding) of user and movie. For example, for each movie, we can have how much action it has, how long it is, and so on. For each user, we can encode how much they like action, or how much they like long movies, etc. Thus, we can combine the user and the movie embeddings to estimate the ratings on unseen movies. This approach can also be viewed as: given a matrix (A [M X N]) containing users and movies, we want to estimate low dimensional matrices (W [M X k] and H [M X k]), such that: \\(A \\approx W.H^T\\)\n\n\nMatrix factorisation in Keras\nWe’ll now write some code to solve the recommendation problem by matrix factorisation in Keras. We’re trying to learn two low-dimensional embeddings of users and items.\n\nimport keras\nfrom IPython.display import SVG\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import model_to_dot\nn_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\nn_latent_factors = 3\n\nUsing TensorFlow backend.\n\n\nThe key thing is to learn an embedding for movies and users, and then combine them using the dot product! For estimating the rating, for each user, movie pair of interest, we’d take the dot product of the respective user and item embedding. As an example, if we have 2 dimensions in our user and item embedding, which say correspond to [how much user likes action, how much user likes long movies], and the item embedding is [how much action is in the movie, how long is the movie]. Then, we can predict for a user u, and movie m as how much u likes action \\(\\times\\) how much action is there in m \\(+\\) how much u likes long movies \\(\\times\\) how long is m.\nOur model would optimise the emebedding such that we minimise the mean squared error on the ratings from the train set.\n\nmovie_input = keras.layers.Input(shape=[1],name='Item')\nmovie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\nmovie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n\nuser_input = keras.layers.Input(shape=[1],name='User')\nuser_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n\nprod = keras.layers.merge([movie_vec, user_vec], mode='dot',name='DotProduct')\nmodel = keras.Model([user_input, movie_input], prod)\nmodel.compile('adam', 'mean_squared_error')\n\nHere’s a visualisation of our model for a better understanding.\n\nSVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))\n\n\n\n\n\n\n\n\nWe can see that in the Merge layer, we take the dot product of the user and the item embeddings to obtain the rating.\nWe can also summarise our model as follows:\n\nmodel.summary()\n\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nItem (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nUser (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nMovie-Embedding (Embedding)     (None, 1, 3)         5049        Item[0][0]                       \n__________________________________________________________________________________________________\nUser-Embedding (Embedding)      (None, 1, 3)         2832        User[0][0]                       \n__________________________________________________________________________________________________\nFlattenMovies (Flatten)         (None, 3)            0           Movie-Embedding[0][0]            \n__________________________________________________________________________________________________\nFlattenUsers (Flatten)          (None, 3)            0           User-Embedding[0][0]             \n__________________________________________________________________________________________________\nDotProduct (Merge)              (None, 1)            0           FlattenMovies[0][0]              \n                                                                 FlattenUsers[0][0]               \n==================================================================================================\nTotal params: 7,881\nTrainable params: 7,881\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\nSo, we have 7881 parameters to learn! Let’s train our model now!\n\nhistory = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=0)\n\n\nTrain error v/s epoch number\nBefore we test how well our model does in the test setting, we can visualise the train loss with epoch number.\n\npd.Series(history.history['loss']).plot(logy=True)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Train Error\")\n\n\n\n\n\n\n\n\n\n\nPrediction error\nLet’s now see how our model does! I’ll do a small post-processing step to round off our prediction to the nearest integer. This is usually not done, and thus just a whimsical step, since the training ratings are all integers! There are better ways to encode this intger requirement (one-hot encoding!), but we won’t discuss them in this post.\n\ny_hat = np.round(model.predict([test.user_id, test.item_id]),0)\ny_true = test.rating\n\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_true, y_hat)\n\n0.6915\n\n\nNot bad! We’re able to get a \\(MAE\\) of 0.69! I’m sure with a bit of parameter/hyper-parameter optimisation, we may be able to improve the results. However, I won’t talk about these optimisations in this post.\n\n\nExtracting the learnt embeddings\nWe can extract the learnt movie and item embeddings as follows:\n\nmovie_embedding_learnt = model.get_layer(name='Movie-Embedding').get_weights()[0]\npd.DataFrame(movie_embedding_learnt).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\ncount\n1683.000000\n1683.000000\n1683.000000\n\n\nmean\n-0.935420\n0.857862\n0.954169\n\n\nstd\n0.517458\n0.447439\n0.458095\n\n\nmin\n-2.524487\n-0.459752\n-0.989537\n\n\n25%\n-1.323431\n0.546364\n0.642444\n\n\n50%\n-0.949188\n0.851243\n0.993619\n\n\n75%\n-0.550862\n1.159588\n1.283555\n\n\nmax\n0.500618\n2.140607\n2.683658\n\n\n\n\n\n\n\n\nuser_embedding_learnt = model.get_layer(name='User-Embedding').get_weights()[0]\npd.DataFrame(user_embedding_learnt).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\ncount\n944.000000\n944.000000\n944.000000\n\n\nmean\n-1.126231\n1.171609\n1.109131\n\n\nstd\n0.517478\n0.409016\n0.548384\n\n\nmin\n-2.883226\n-0.500010\n-0.415373\n\n\n25%\n-1.458197\n0.903574\n0.735729\n\n\n50%\n-1.159480\n1.199517\n1.084089\n\n\n75%\n-0.836746\n1.456610\n1.468611\n\n\nmax\n0.899436\n2.605330\n2.826109\n\n\n\n\n\n\n\nWe can see that both the user and the item embeddings have negative elements. There are some applications which require that the learnt embeddings be non-negative. This approach is also called non-negative matrix factorisation, which we’ll workout now.\n\n\n\nNon-negative Matrix factorisation (NNMF) in Keras\nThe code for NNMF remains exactly the same as the code for matrix factorisation. The only change is that we add non-negativity constraints on the learnt embeddings. This is done as follows:\n\nfrom keras.constraints import non_neg\nmovie_input = keras.layers.Input(shape=[1],name='Item')\nmovie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='NonNegMovie-Embedding', embeddings_constraint=non_neg())(movie_input)\nmovie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n\nuser_input = keras.layers.Input(shape=[1],name='User')\nuser_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='NonNegUser-Embedding',embeddings_constraint=non_neg())(user_input))\n\nprod = keras.layers.merge([movie_vec, user_vec], mode='dot',name='DotProduct')\nmodel = keras.Model([user_input, movie_input], prod)\nmodel.compile('adam', 'mean_squared_error')\n\nWe now verify if we are indeed able to learn non-negative embeddings. I’ll not compare the performance of NNMF on the test set, in the interest of space.\n\nhistory_nonneg = model.fit([train.user_id, train.item_id], train.rating, epochs=10, verbose=0)\n\n\nmovie_embedding_learnt = model.get_layer(name='NonNegMovie-Embedding').get_weights()[0]\npd.DataFrame(movie_embedding_learnt).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\ncount\n1683.000000\n1683.000000\n1683.000000\n\n\nmean\n0.838450\n0.840330\n0.838066\n\n\nstd\n0.301618\n0.301529\n0.301040\n\n\nmin\n-0.000000\n-0.000000\n-0.000000\n\n\n25%\n0.657749\n0.663951\n0.656453\n\n\n50%\n0.901495\n0.904192\n0.895934\n\n\n75%\n1.072706\n1.073591\n1.072926\n\n\nmax\n1.365719\n1.379006\n1.373672\n\n\n\n\n\n\n\nLooks good!\n\n\nNeural networks for recommendation\nWe’ll now create a simple neural network for recommendation, or for estimating rating! This model is very similar to the earlier matrix factorisation models, but differs in the following ways:\n\nInstead of taking a dot product of the user and the item embedding, we concatenate them and use them as features for our neural network. Thus, we are not constrained to the dot product way of combining the embeddings, and can learn complex non-linear relationships.\nDue to #1, we can now have a different dimension of user and item embeddings. This can be useful if one dimension is larger than the other.\n\n\nn_latent_factors_user = 5\nn_latent_factors_movie = 8\n\nmovie_input = keras.layers.Input(shape=[1],name='Item')\nmovie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding')(movie_input)\nmovie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\nmovie_vec = keras.layers.Dropout(0.2)(movie_vec)\n\n\nuser_input = keras.layers.Input(shape=[1],name='User')\nuser_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors_user,name='User-Embedding')(user_input))\nuser_vec = keras.layers.Dropout(0.2)(user_vec)\n\n\nconcat = keras.layers.merge([movie_vec, user_vec], mode='concat',name='Concat')\nconcat_dropout = keras.layers.Dropout(0.2)(concat)\ndense = keras.layers.Dense(200,name='FullyConnected')(concat)\ndropout_1 = keras.layers.Dropout(0.2,name='Dropout')(dense)\ndense_2 = keras.layers.Dense(100,name='FullyConnected-1')(concat)\ndropout_2 = keras.layers.Dropout(0.2,name='Dropout')(dense_2)\ndense_3 = keras.layers.Dense(50,name='FullyConnected-2')(dense_2)\ndropout_3 = keras.layers.Dropout(0.2,name='Dropout')(dense_3)\ndense_4 = keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n\n\nresult = keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\nadam = Adam(lr=0.005)\nmodel = keras.Model([user_input, movie_input], result)\nmodel.compile(optimizer=adam,loss= 'mean_absolute_error')\n\nLet’s now see how our model looks like:\n\nSVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))\n\n\n\n\n\n\n\n\nIt should be noted that we use a different number of embeddings for user (3) and items (5)! These combine to form a vector of length (5+3 = 8), which is then fed into the neural network. We also add a dropout layer to prevent overfitting!\n\nmodel.summary()\n\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nItem (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nUser (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nMovie-Embedding (Embedding)     (None, 1, 8)         13464       Item[0][0]                       \n__________________________________________________________________________________________________\nUser-Embedding (Embedding)      (None, 1, 5)         4720        User[0][0]                       \n__________________________________________________________________________________________________\nFlattenMovies (Flatten)         (None, 8)            0           Movie-Embedding[0][0]            \n__________________________________________________________________________________________________\nFlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 8)            0           FlattenMovies[0][0]              \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 5)            0           FlattenUsers[0][0]               \n__________________________________________________________________________________________________\nConcat (Merge)                  (None, 13)           0           dropout_1[0][0]                  \n                                                                 dropout_2[0][0]                  \n__________________________________________________________________________________________________\nFullyConnected-1 (Dense)        (None, 100)          1400        Concat[0][0]                     \n__________________________________________________________________________________________________\nFullyConnected-2 (Dense)        (None, 50)           5050        FullyConnected-1[0][0]           \n__________________________________________________________________________________________________\nFullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           \n__________________________________________________________________________________________________\nActivation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           \n==================================================================================================\nTotal params: 25,675\nTrainable params: 25,675\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n\nWe can see that the number of parameters is more than what we had in the Matrix Factorisation case. Let’s see how this model works. I’ll run it for more epochs given that we have more parameters.\n\nhistory = model.fit([train.user_id, train.item_id], train.rating, epochs=250, verbose=0)\n\n\nPrediction performance of Neural Network based recommender system\n\ny_hat_2 = np.round(model.predict([test.user_id, test.item_id]),0)\nprint(mean_absolute_error(y_true, y_hat_2))\n\nprint(mean_absolute_error(y_true, model.predict([test.user_id, test.item_id])))\n\n\n0.6957\n0.708807692927\n\n\nPretty similar to the result we got using matrix factorisation. Maybe, we need to tweak around a lot more with the neural network to get better results?\nThanks for reading. This post has been a good learning experience for me. Hope you enjoyed too!"
  },
  {
    "objectID": "posts/transcript.html",
    "href": "posts/transcript.html",
    "title": "YouTube video to transcript using openAI whisper and summary using OLLama",
    "section": "",
    "text": "References\n\nWhisper\nLangchain and LLama\n\n\nBasic Imports\n\nimport yt_dlp\n\n\ndef download(video_id: str) -&gt; str:\n    video_url = f'https://www.youtube.com/watch?v={video_id}'\n    ydl_opts = {\n        'format': 'm4a/bestaudio/best',\n        'paths': {'home': 'audio/'},\n        'outtmpl': {'default': '%(id)s.%(ext)s'},\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'm4a',\n        }]\n    }\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        error_code = ydl.download([video_url])\n        if error_code != 0:\n            raise Exception('Failed to download video')\n\n    return f'audio/{video_id}.m4a'\n\n\ndownload('CuBzyh4Xmvk')\n\n[youtube] Extracting URL: https://www.youtube.com/watch?v=CuBzyh4Xmvk\n[youtube] CuBzyh4Xmvk: Downloading webpage\n[youtube] CuBzyh4Xmvk: Downloading ios player API JSON\n[youtube] CuBzyh4Xmvk: Downloading android player API JSON\n[youtube] CuBzyh4Xmvk: Downloading m3u8 information\n[info] CuBzyh4Xmvk: Downloading 1 format(s): 140\n[download] audio/CuBzyh4Xmvk.m4a has already been downloaded\n[download] 100% of   72.26MiB\n[ExtractAudio] Not converting audio audio/CuBzyh4Xmvk.m4a; file is already in target format m4a\n\n\n'audio/CuBzyh4Xmvk.m4a'\n\n\n\nimport whisper\n\n\nwhisper_model = whisper.load_model(\"base.en\")\n\n\ntranscription = whisper_model.transcribe(\"audio/CuBzyh4Xmvk.m4a\", fp16=True, verbose=False)\n\n100%|██████████| 468481/468481 [02:05&lt;00:00, 3720.37frames/s]\n\n\n\ntranscription[\"text\"][:100]\n\n\" Please look at the code mentioned above and please sign up on the Google Cloud. We've already start\"\n\n\n\ntranscription.keys()\n\ndict_keys(['text', 'segments', 'language'])\n\n\n\ndef create_srt_from_transcription(transcription_objects, srt_file_path):\n    with open(srt_file_path, 'w') as srt_file:\n        index = 1  # SRT format starts with index 1\n\n        for entry in transcription_objects['segments']:\n            start_time = entry['start']\n            end_time = entry['end']\n            text = entry['text']\n\n            # Convert time to SRT format\n            start_time_str = format_time(start_time)\n            end_time_str = format_time(end_time)\n\n            # Write entry to SRT file\n            srt_file.write(f\"{index}\\n\")\n            srt_file.write(f\"{start_time_str} --&gt; {end_time_str}\\n\")\n            srt_file.write(f\"{text}\\n\\n\")\n\n            index += 1\n\ndef format_time(time_seconds):\n    minutes, seconds = divmod(time_seconds, 60)\n    hours, minutes = divmod(minutes, 60)\n    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},000\"\n\n\ncreate_srt_from_transcription(transcription, \"audio/CuBzyh4Xmvk.srt\")\n\n\n!head audio/CuBzyh4Xmvk.srt\n\n1\n00:00:00,000 --&gt; 00:00:05,000\n Please look at the code mentioned above and please sign up on the Google Cloud.\n\n2\n00:00:05,000 --&gt; 00:00:08,000\n We've already started making some announcements.\n\n3\n00:00:08,000 --&gt; 00:00:14,000\n\n\n\nfrom langchain.llms import Ollama\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler \n                                 \n\n\nllm = Ollama(model=\"mistral\", \n             callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))\n\n\nprompt_qs = [\"Please provide a bullet-point summary for the given text:\",\n             \"Summarize the following in Markdown bullets:\",\n             \"Highlight the important topics and subtopics in the given lecture:\",\n             \"Give us some question for a quiz based on the following text:\"]\n\nprompts = [q + \"\\n\" + transcription[\"text\"] for q in prompt_qs]\n\nfor prompt, prompt_qs in zip(prompts, prompt_qs):\n    print(prompt_qs, end=\"\\n\\n\")\n    output = llm(prompt)\n    print(output, end=\"\\n\\n\")\n    print(\"==\"*50, end=\"\\n\\n\")\n\nPlease provide a bullet-point summary for the given text:\n\n * The text asks for attention to the code and signing up on Google Cloud, as well as an announcement of an extra lecture\n* Machine learning definition: ability for computers to learn without being explicitly programmed\n* The example task is to write a program to recognize digits from a dataset\n* Rules for recognizing digits include vertical and horizontal lines, similar height of vertical lines, and no star or other mark on the digit\n* Slides and videos from first lecture have been put on Google Cloud\n* Previous lecture covered definition of machine learning and difference between explicit and implicit programming\n* Decision trees will be used to predict whether a day is good for playing tennis based on weather conditions\n* Decision trees involve creating rules based on attributes (in this case, outlook and humidity) and choosing the attribute that gives the best performance gain\n* Entropy is a measure of disorder or uncertainty in a system and is used to quantify the performance gain of an attribute. Information gain is the difference between the entropy of a set and the weighted entropy of its subsets based on an attribute. * The text asks for attention to the code and signing up on Google Cloud, as well as an announcement of an extra lecture\n* Machine learning definition: ability for computers to learn without being explicitly programmed\n* The example task is to write a program to recognize digits from a dataset\n* Rules for recognizing digits include vertical and horizontal lines, similar height of vertical lines, and no star or other mark on the digit\n* Slides and videos from first lecture have been put on Google Cloud\n* Previous lecture covered definition of machine learning and difference between explicit and implicit programming\n* Decision trees will be used to predict whether a day is good for playing tennis based on weather conditions\n* Decision trees involve creating rules based on attributes (in this case, outlook and humidity) and choosing the attribute that gives the best performance gain\n* Entropy is a measure of disorder or uncertainty in a system and is used to quantify the performance gain of an attribute. Information gain is the difference between the entropy of a set and the weighted entropy of its subsets based on an attribute.\n\n====================================================================================================\n\nSummarize the following in Markdown bullets:\n\n * Please sign up on Google Cloud for the course\n* Announcements: extra lecture on Saturday, 11th Jan at 11am in 1.101\n* FAQ and projects shared on Google Docs, comment access given for questions\n* First lecture video and slides now available on Google Cloud\n* Review of previous lecture: machine learning defined as ability for computers to learn without explicit programming\n* Discussion on recognizing digits using a program and rules\n* Need to consider constraints such as similar height of vertical lines, no long or short lines dominating the digit shape\n* Slides refer to visuals with some angle or inclination, but in this context they mean features or attributes of data points\n* Example: predicting quality or condition of computer tomatoes using image features and machine learning algorithms\n* Data collected with human expert annotations for each tomato's quality (good or bad)\n* Features: color, size, texture\n* Training set: X (input features matrix), Y (output vector of labels)\n* Test set: unseen samples without labels, trying to predict their quality based on input features\n* Prediction tasks in machine learning: given input features, estimate the output using algorithms and models\n* Metrics for evaluating performance: accuracy, precision, recall, F-score, Matthew's correlation coefficient * Please sign up on Google Cloud for the course\n* Announcements: extra lecture on Saturday, 11th Jan at 11am in 1.101\n* FAQ and projects shared on Google Docs, comment access given for questions\n* First lecture video and slides now available on Google Cloud\n* Review of previous lecture: machine learning defined as ability for computers to learn without explicit programming\n* Discussion on recognizing digits using a program and rules\n* Need to consider constraints such as similar height of vertical lines, no long or short lines dominating the digit shape\n* Slides refer to visuals with some angle or inclination, but in this context they mean features or attributes of data points\n* Example: predicting quality or condition of computer tomatoes using image features and machine learning algorithms\n* Data collected with human expert annotations for each tomato's quality (good or bad)\n* Features: color, size, texture\n* Training set: X (input features matrix), Y (output vector of labels)\n* Test set: unseen samples without labels, trying to predict their quality based on input features\n* Prediction tasks in machine learning: given input features, estimate the output using algorithms and models\n* Metrics for evaluating performance: accuracy, precision, recall, F-score, Matthew's correlation coefficient\n\n====================================================================================================\n\nHighlight the important topics and subtopics in the given lecture:\n\n Important topics and subtopics in the given lecture:\n\n1. Machine Learning Basics\n    * Definition of machine learning\n    * Explicit vs implicit programming\n    * Brief history of machine learning\n2. Recognizing Digits using Machine Learning\n    * Rules for recognizing digits\n3. Traditional Programming vs Machine Learning\n    * Explicit programming vs machine learning\n    * Example: Predicting tomato quality using computer vision\n4. Performance Measures in Machine Learning\n    * Accuracy, precision, recall, F-score, Matthew's correlation coefficient\n5. Decision Trees\n    * Introduction to decision trees\n    * Building a decision tree for predicting whether to play tennis or not based on weather conditions\n6. ID3 Algorithm\n    * Recursive algorithm for building decision trees\n7. Entropy and Information Gain\n    * Definition of entropy\n    * Choosing the best attribute for information gain\n8. Future lectures\n    * Additional lecture on Saturday, 11th Jan at 11am in 1.101\n    * FAQs and projects available on Google Docs\n    * Sharing video and slides from the first lecture on code translate and course website. Important topics and subtopics in the given lecture:\n\n1. Machine Learning Basics\n    * Definition of machine learning\n    * Explicit vs implicit programming\n    * Brief history of machine learning\n2. Recognizing Digits using Machine Learning\n    * Rules for recognizing digits\n3. Traditional Programming vs Machine Learning\n    * Explicit programming vs machine learning\n    * Example: Predicting tomato quality using computer vision\n4. Performance Measures in Machine Learning\n    * Accuracy, precision, recall, F-score, Matthew's correlation coefficient\n5. Decision Trees\n    * Introduction to decision trees\n    * Building a decision tree for predicting whether to play tennis or not based on weather conditions\n6. ID3 Algorithm\n    * Recursive algorithm for building decision trees\n7. Entropy and Information Gain\n    * Definition of entropy\n    * Choosing the best attribute for information gain\n8. Future lectures\n    * Additional lecture on Saturday, 11th Jan at 11am in 1.101\n    * FAQs and projects available on Google Docs\n    * Sharing video and slides from the first lecture on code translate and course website.\n\n====================================================================================================\n\nGive us some question for a quiz based on the following text:\n\n 1. What is the purpose of the announcement about signing up on Google Cloud and missing announcements?\n2. What is the second quick logistical announcement regarding?\n3. In what room will there be an extra lecture on Saturday, 11th Jan at 11am?\n4. Who is Arthur Sandler and when did he first mention machine learning?\n5. What does being explicitly programmed mean in machine learning?\n6. Can you explain the difference between explicit programming and machine learning?\n7. How can you recognize a digit '4' based on the rules given in the text?\n8. What are some other rules that could be used to recognize the digit '4' from the dataset mentioned?\n9. What is meant by the term \"slides\" in the context of this machine learning course?\n10. What is the name of the business use case for this machine learning project and what is its goal?\n11. What data does the company have for this machine learning project?\n12. Which visual features are expected to be useful for characterizing tomatoes in this project?\n13. What is the difference between a training set and a test set in machine learning?\n14. What is the role of experience P, task P, and performance measure P in machine learning?\n15. Can you explain what is meant by the term \"precision\" in machine learning?\n16. What is the difference between precision and recall in machine learning?\n17. What is Matthew's correlation coefficient and why is it useful in machine learning?\n18. What are some common metrics used to evaluate the performance of machine learning models?\n19. What is the difference between mean squared error and mean absolute error as evaluation metrics in machine learning?\n20. What is a decision tree and how is it used in machine learning for classification problems? 1. What is the purpose of the announcement about signing up on Google Cloud and missing announcements?\n2. What is the second quick logistical announcement regarding?\n3. In what room will there be an extra lecture on Saturday, 11th Jan at 11am?\n4. Who is Arthur Sandler and when did he first mention machine learning?\n5. What does being explicitly programmed mean in machine learning?\n6. Can you explain the difference between explicit programming and machine learning?\n7. How can you recognize a digit '4' based on the rules given in the text?\n8. What are some other rules that could be used to recognize the digit '4' from the dataset mentioned?\n9. What is meant by the term \"slides\" in the context of this machine learning course?\n10. What is the name of the business use case for this machine learning project and what is its goal?\n11. What data does the company have for this machine learning project?\n12. Which visual features are expected to be useful for characterizing tomatoes in this project?\n13. What is the difference between a training set and a test set in machine learning?\n14. What is the role of experience P, task P, and performance measure P in machine learning?\n15. Can you explain what is meant by the term \"precision\" in machine learning?\n16. What is the difference between precision and recall in machine learning?\n17. What is Matthew's correlation coefficient and why is it useful in machine learning?\n18. What are some common metrics used to evaluate the performance of machine learning models?\n19. What is the difference between mean squared error and mean absolute error as evaluation metrics in machine learning?\n20. What is a decision tree and how is it used in machine learning for classification problems?\n\n===================================================================================================="
  },
  {
    "objectID": "posts/2020-04-16-inverse-transform.html",
    "href": "posts/2020-04-16-inverse-transform.html",
    "title": "Sampling from common distributions",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nPRNG\n\nUniform distribution\nI am pasting the code from vega-vis\nexport default function(seed) {\n  // Random numbers using a Linear Congruential Generator with seed value\n  // Uses glibc values from https://en.wikipedia.org/wiki/Linear_congruential_generator\n  return function() {\n    seed = (1103515245 * seed + 12345) % 2147483647;\n    return seed / 2147483647;\n  };\n}\n\ndef random_gen(seed, num):\n    out = np.zeros(num)\n    out[0] =  (1103515245 * seed + 12345) % 2147483647\n    for i in range(1, num):\n        out[i] = (1103515245 * out[i-1] + 12345) % 2147483647\n    return out/2147483647\n        \n        \n\n\nplt.hist(random_gen(0, 5000), density=True, alpha=0.5, label='Our implementation');\n\n\n\n\n\n\n\n\n\nplt.hist(random_gen(0, 5000), density=True, alpha=0.5, label='Our implementation');\nplt.hist(np.random.random(5000), density=True, alpha=0.4, label='Numpy implementation');\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\nInverse transform sampling\n\nExponential distribution\nBorrowing from Wikipedia.\nThe probability density function (pdf) of an exponential distribution is \\[\nf(x ; \\lambda)=\\left\\{\\begin{array}{ll}\n\\lambda e^{-\\lambda x} & x \\geq 0 \\\\\n0 & x \\leq 0\n\\end{array}\\right.\n\\]\nThe exponential distribution is sometimes parametrized in terms of the scale parameter \\(\\beta=1 / \\lambda:\\) \\[\nf(x ; \\beta)=\\left\\{\\begin{array}{ll}\n\\frac{1}{\\beta} e^{-x / \\beta} & x \\geq 0 \\\\\n0 & x&lt;0\n\\end{array}\\right.\n\\]\nThe cumulative distribution function is given by \\[\nF(x ; \\lambda)=\\left\\{\\begin{array}{ll}\n1-e^{-\\lambda x} & x \\geq 0 \\\\\n0 & x&lt;0\n\\end{array}\\right.\n\\]\n\nfrom scipy.stats import expon\nrvs = [expon(scale=s) for s in [1/1., 1/2., 1/3.]]\n\n\nx = np.arange(0, 10, 0.1)\nfor i, lambda_val in enumerate([1, 2, 3]):\n    plt.plot(x, rvs[i].pdf(x), lw=2, label=r'$\\lambda=%s$' %lambda_val)\nplt.legend()\n\n\n\n\n\n\n\n\nFor the purposes of this notebook, I will be looking only at the standard exponential or set the scale to 1.\nLet us now view the CDF of the standard exponential.\n\nfig, ax = plt.subplots(nrows=2, sharex=True)\nax[0].plot(x, expon().pdf(x), lw=2)\nax[0].set_title(\"PDF\")\nax[1].set_title(\"CDF\")\nax[1].plot(x, expon().cdf(x), lw=2,)\n\n\n\n\n\n\n\n\n\nr = expon.rvs(size=1000)\n\n\nplt.hist(r, normed=True, bins=100)\nplt.plot(x, expon().pdf(x), lw=2)\n\n/home/nipunbatra-pc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: MatplotlibDeprecationWarning: \nThe 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\n\n\n\n\n\n\nInverse of the CDF of exponential\nThe cumulative distribution function is given by \\[\nF(x ; \\lambda)=\\left\\{\\begin{array}{ll}\n1-e^{-\\lambda x} & x \\geq 0 \\\\\n0 & x&lt;0\n\\end{array}\\right.\n\\]\nLet us consider only \\(x \\geq 0\\).\nLet \\(u = F^{-1}\\) be the inverse of the CDF of \\(F\\).\n\\[\nu = 1-e^{-\\lambda x} \\\\\n1- u = e^{-\\lambda x} \\\\\n\\log(1-u) = -\\lambda x\\\\\nx = -\\frac{\\log(1-u)}{\\lambda}\n\\]\n\ndef inverse_transform(lambda_val, num_samples):\n    u = np.random.random(num_samples)\n    x = -np.log(1-u)/lambda_val\n    return x\n\n\nplt.hist(inverse_transform(1, 5000), bins=100, normed=True,label='Generated using our function');\nplt.plot(x, expon().pdf(x), lw=4, label='Generated using scipy')\nplt.legend()\n\n/home/nipunbatra-pc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: MatplotlibDeprecationWarning: \nThe 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\n\n\n\n\n\n\n\n\nDrawing samples from Laplace distribution\nA random variable has a Laplace \\((\\mu, b)\\) distribution if its probability density function is \\[\nf(x | \\mu, b)=\\frac{1}{2 b} \\exp \\left(-\\frac{|x-\\mu|}{b}\\right)\n\\]\n\\[F^{-1}(u)=\\mu-b \\operatorname{sgn}(u-0.5) \\ln (1-2|u-0.5|)\\]\n\ndef inverse_transform_laplace(b, mu, num_samples):\n    u = np.random.random(num_samples)\n    x = mu-b*np.sign(u-0.5)*np.log(1-2*np.abs(u-0.5))\n    return x\n\n\nfrom scipy.stats import laplace\nplt.hist(inverse_transform_laplace(1, 0, 5000),bins=100, density=True, label='Generated using \\nour function');\nx_n = np.linspace(-10, 10, 100)\nplt.plot(x_n, laplace().pdf(x_n), lw=4, label='Generated from\\n scipy')\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\nBox-Muller transform"
  },
  {
    "objectID": "posts/bald.html",
    "href": "posts/bald.html",
    "title": "Bayesian Active Learning with Disagreement (BALD)",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\n\ndist =torch.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\npt1 = torch.tensor([[1.0, 0.0],\n                    [1.0, 0.0],\n                    [1.0, 0.0],\n                    [1.0, 0.0]\n                    ])\npt2 = torch.tensor([[0.5, 0.5],\n                    [0.5, 0.5],\n                    [0.5, 0.5],\n                    [0.5, 0.5]\n                    ])\npt3 = torch.tensor([[0.0, 1.0],\n                    [1.0, 0.0],\n                    [0.0, 1.0],\n                    [1.0, 0.0]\n                    ])\n\n\ndef avg_prob(pt):\n    return torch.mean(pt, dim=0)\n\navg_prob(pt1), avg_prob(pt2), avg_prob(pt3)\n\n(tensor([1., 0.]), tensor([0.5000, 0.5000]), tensor([0.5000, 0.5000]))\n\n\n\ndef predictive_entropy(pt):\n    avg = avg_prob(pt)\n    return -torch.sum(avg * torch.log2(avg))\n\n\npredictive_entropy(pt1), predictive_entropy(pt2), predictive_entropy(pt3)\n\n(tensor(nan), tensor(1.), tensor(1.))\n\n\n\n# Numerically stable version to compute entropy by avoiding log(0)\ndef predictive_entropy(pt):\n    avg = avg_prob(pt)\n    return -torch.sum(avg * torch.log2(avg + 1e-8))\n\npredictive_entropy(pt1), predictive_entropy(pt2), predictive_entropy(pt3)\n\n(tensor(-0.), tensor(1.), tensor(1.))\n\n\n\ndef expected_entropy(pt):\n    return torch.mean(torch.sum(-pt * torch.log2(pt + 1e-8), dim=1))\n\nexpected_entropy(pt1), expected_entropy(pt2), expected_entropy(pt3)\n\n(tensor(0.), tensor(1.), tensor(0.))\n\n\n\ndef mutual_information(pt):\n    return predictive_entropy(pt) - expected_entropy(pt)\n\nmutual_information(pt1), mutual_information(pt2), mutual_information(pt3)\n\n(tensor(-0.), tensor(0.), tensor(1.))\n\n\n\n\nExample from Gal et al.\n\n# Training data\n\n# Between -5 and -3, y = 0, and we have n1 = 100\n# Between -3 and -2, y = 1, and we have n2 = 50\n# Between 1 and 2.5, y = 0, and we have n3 = 75\n# Between 2.5 and 5, y = 1, and we have n4 = 125\n\nfac = 30\n# Generate data\nn1 = 1000//fac\nn2 = 500//fac\nn3 = 750//fac\nn4 = 1250//fac\n\nx1 = dist.Uniform(-5, -3).sample((n1,))\nx2 = dist.Uniform(-3, -2.5).sample((n2,))\nx3 = dist.Uniform(1.5, 2.5).sample((n3,))\nx4 = dist.Uniform(2.5, 5).sample((n4,))\n\nx = torch.cat([x1, x2, x3, x4])\ny = torch.cat([torch.zeros(n1), torch.ones(n2), torch.zeros(n3), torch.ones(n4)])\n\nplt.figure(figsize=(8, 6))\nplt.scatter(x, y, s=1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n\n# Move to GPU\nx = x.cuda()\ny = y.cuda()\n\n\n\n\n\n\n\n\n\n# Simple MLP with 4 layers and dropout in between\nimport torch.functional as F\n\nclass MLP(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout_prob):\n        super().__init__()\n        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = torch.nn.Linear(hidden_dim, output_dim)\n        self.dropout = torch.nn.Dropout(dropout_prob)\n\n    def forward(self, x):\n        x = torch.nn.GELU()(self.fc1(x))\n        x = self.dropout(x)\n        x = torch.nn.GELU()(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n\n\n# Training loop\n\ndef train(model, x, y, optimizer, loss_fn, num_epochs):\n    for epoch in range(num_epochs):\n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = loss_fn(y_pred.squeeze(), y)\n        loss.backward()\n        optimizer.step()\n        if epoch % 300 == 0:\n            print(f\"Epoch {epoch}, loss {loss.item():.4f}\")\n\n# Train the model\nmodel = MLP(1, 16, 1, 0.2).cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nloss_fn = torch.nn.BCEWithLogitsLoss()\ntrain(model, x.unsqueeze(1), y, optimizer, loss_fn, 4000)\n\nEpoch 0, loss 0.7011\nEpoch 300, loss 0.0829\nEpoch 600, loss 0.0474\nEpoch 900, loss 0.0192\n\n\n\n# At test time, we want to use MC dropout to get the predictive distribution\n\ndef predict(model, x, num_mc_samples):\n    model.train()\n    y_preds = []\n    for _ in range(num_mc_samples):\n        y_pred = torch.sigmoid(model(x.unsqueeze(1)))\n        y_preds.append(y_pred.detach().cpu().numpy())\n    return np.concatenate(y_preds, axis=1)\n\n# Plot the predictive distribution\nx_test = torch.linspace(-7, 7, 1000).cuda()\ny_test = predict(model, x_test, 2000) # 500 MC samples\n\n\ny_test_orig = torch.from_numpy(y_test)\ny_test_orig.shape\n\ntorch.Size([1000, 2000])\n\n\n\nplt.figure(figsize=(8, 6))\nplt.scatter(x.cpu(), y.cpu(), s=50, alpha=0.5)\nplt.plot(x_test.cpu(), torch.mean(y_test_orig, axis=1).cpu(), color=\"black\", label=\"Mean prediction\")\nplt.fill_between(x_test.cpu(), np.percentile(y_test_orig.cpu(), 2.5, axis=1), np.percentile(y_test_orig.cpu(), 97.5, axis=1), alpha=0.3, color=\"black\", label=\"95% CI\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n# Legend outside the plot\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n\n\n\n\n\n\n\n\ny_test_orig\n\ntensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0430e-26, 0.0000e+00,\n         0.0000e+00],\n        ...,\n        [5.0677e-01, 1.0000e+00, 2.8454e-01,  ..., 1.0000e+00, 1.0000e+00,\n         1.0000e+00],\n        [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 6.4444e-01, 1.0000e+00,\n         1.0000e+00],\n        [9.9873e-01, 1.4383e-01, 3.9857e-01,  ..., 1.0000e+00, 1.0000e+00,\n         1.0000e+00]])\n\n\n\n# Convert y_test to (n_samples, n_mc_samples, n_classes)\ny_test = torch.stack([1 - y_test_orig, y_test_orig], axis=2)\n\ny_test.shape\n\ntorch.Size([1000, 2000, 2])\n\n\n\n# Compute the predictive entropy for a single example\npredictive_entropy(y_test[0])\n\ntensor(0.0214)\n\n\n\n# Find MI for a single example\nmutual_information(y_test[0])\n\ntensor(0.0182)\n\n\n\nplt.figure(figsize=(8, 6))\nplt.scatter(x.cpu(), y.cpu(), s=10, alpha=0.5)\nplt.plot(x_test.cpu(), torch.mean(y_test_orig, axis=1).cpu(), color=\"black\", label=\"Mean prediction\")\nplt.fill_between(x_test.cpu(), np.percentile(y_test_orig.cpu(), 2.5, axis=1), np.percentile(y_test_orig.cpu(), 97.5, axis=1), alpha=0.3, color=\"black\", label=\"95% CI\")\n# Use vmap from torch to compute the predictive entropy for all examples\npred_entropy_vals = torch.func.vmap(predictive_entropy)(y_test)\nplt.plot(x_test.cpu(), pred_entropy_vals, color=\"red\", label=\"Predictive entropy\")\n\n# Use vmap from torch to compute the mutual information for all examples\nmi_vals = torch.func.vmap(mutual_information)(y_test)\nplt.plot(x_test.cpu(), mi_vals, color=\"blue\", label=\"Mutual information\")\n\n# Legend outside the plot\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
  },
  {
    "objectID": "posts/2013-05-01-aggregation-timeseries.html",
    "href": "posts/2013-05-01-aggregation-timeseries.html",
    "title": "Aggregation timeseries",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- time-series- data-aggregation- data-analysis- pandas- visualizationdate: ’2013-05-01’output-file: 2013-05-01-aggregation-timeseries.htmltitle: Aggregation timeseriestoc: true—\nWe’ve all grown up studying groupy by and aggregations in SQL. Pandas provides excellent functionality for group by and aggregations. However, for time series data, we need a bit of manipulation. In this post, I’ll take a small example of weather time series data.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\n\ndf = pd.read_csv(\"weather.csv\", index_col=0, parse_dates=True).tz_localize(\"UTC\").tz_convert(\"US/Central\")\n\n\ndf.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\n\n\n\n\n2015-01-01 00:00:00-06:00\n0.73\n38.74\n\n\n2015-01-01 01:00:00-06:00\n0.74\n38.56\n\n\n2015-01-01 02:00:00-06:00\n0.75\n38.56\n\n\n2015-01-01 03:00:00-06:00\n0.79\n37.97\n\n\n2015-01-01 04:00:00-06:00\n0.80\n37.78\n\n\n\n\n\n\n\n\nQuestion 1: What is the mean temperature and humidity per hour of the day?\nWe’ll create a new column in the df containing the hour information from the index.\n\ndf[\"hour\"] = df.index.hour\n\n\ndf.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\nhour\n\n\n\n\n2015-01-01 00:00:00-06:00\n0.73\n38.74\n0\n\n\n2015-01-01 01:00:00-06:00\n0.74\n38.56\n1\n\n\n2015-01-01 02:00:00-06:00\n0.75\n38.56\n2\n\n\n2015-01-01 03:00:00-06:00\n0.79\n37.97\n3\n\n\n2015-01-01 04:00:00-06:00\n0.80\n37.78\n4\n\n\n\n\n\n\n\n\nmean_temp_humidity = df.groupby(\"hour\").mean()\nmean_temp_humidity.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\n\n\nhour\n\n\n\n\n\n\n0\n0.779322\n45.976441\n\n\n1\n0.803898\n44.859492\n\n\n2\n0.812203\n44.244407\n\n\n3\n0.819153\n43.724068\n\n\n4\n0.832712\n43.105763\n\n\n\n\n\n\n\n\nmean_temp_humidity.plot(subplots=True);\n\n\n\n\n\n\n\n\nWe can use pivoting to achieve the same dataframe.\n\nmean_temp_humidity_pivoting = pd.pivot_table(df, index=[\"hour\"], values=[\"temperature\", \"humidity\"])\n\n\nmean_temp_humidity_pivoting.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\n\n\nhour\n\n\n\n\n\n\n0\n0.779322\n45.976441\n\n\n1\n0.803898\n44.859492\n\n\n2\n0.812203\n44.244407\n\n\n3\n0.819153\n43.724068\n\n\n4\n0.832712\n43.105763\n\n\n\n\n\n\n\nBy default the aggregation function used in pivoting is mean.\n\n\nQuestion 2: Can we plot the daily variation in temperature per hour of the day?\nFor this, we want to have a dataframe with hour of day as the index and the different days as the different columns.\n\ndf[\"day\"] = df.index.dayofyear\n\n\ndf.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\nhour\nday\n\n\n\n\n2015-01-01 00:00:00-06:00\n0.73\n38.74\n0\n1\n\n\n2015-01-01 01:00:00-06:00\n0.74\n38.56\n1\n1\n\n\n2015-01-01 02:00:00-06:00\n0.75\n38.56\n2\n1\n\n\n2015-01-01 03:00:00-06:00\n0.79\n37.97\n3\n1\n\n\n2015-01-01 04:00:00-06:00\n0.80\n37.78\n4\n1\n\n\n\n\n\n\n\n\ndaily_temp = pd.pivot_table(df, index=[\"hour\"], columns=[\"day\"], values=[\"temperature\"])\n\n\ndaily_temp.head()\n\n\n\n\n\n\n\ntemperature\n\n\nday\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n...\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\nhour\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n38.74\n39.94\n39.57\n41.83\n33.95\n36.98\n46.93\n29.95\n36.57\n36.19\n...\n46.17\n54.01\n66.57\n55.49\n37.68\n30.34\n34.97\n39.93\n36.19\n32.25\n\n\n1\n38.56\n39.76\n39.75\n40.85\n32.29\n35.89\n45.33\n28.55\n37.31\n36.40\n...\n41.38\n54.56\n66.57\n55.49\n36.76\n30.04\n34.97\n36.37\n36.38\n32.25\n\n\n2\n38.56\n39.58\n39.94\n39.73\n31.59\n36.44\n44.51\n27.44\n37.78\n36.59\n...\n39.99\n55.81\n66.57\n55.34\n35.56\n30.57\n34.75\n34.74\n36.20\n32.25\n\n\n3\n37.97\n38.83\n40.16\n38.78\n30.48\n36.85\n43.92\n25.97\n37.97\n36.38\n...\n39.05\n57.14\n66.38\n55.27\n34.94\n30.59\n35.15\n34.31\n36.20\n32.52\n\n\n4\n37.78\n39.02\n40.65\n39.74\n29.89\n35.72\n44.37\n24.74\n37.82\n35.49\n...\n37.99\n57.51\n66.57\n55.49\n34.04\n30.38\n35.15\n33.02\n34.49\n32.52\n\n\n\n\n5 rows × 59 columns\n\n\n\n\ndaily_temp.plot(style='k-', alpha=0.3, legend=False)\nplt.ylabel(\"Temp\");\n\n\n\n\n\n\n\n\nSo, we can see some pattern up there! Around 15 hours, the temperature usually peaks.\nThere you go! Some recipes for aggregation and plotting of time series data."
  },
  {
    "objectID": "posts/2021-06-16-shortcuts-ipad.html",
    "href": "posts/2021-06-16-shortcuts-ipad.html",
    "title": "Some of my shortcuts on the iPad",
    "section": "",
    "text": "Combine some random images from internet and display on a grid\nCombine Images GAN Shortcut link\nThe end result\n\nIn this shortcut I mainly do the following: - loop N number of times - Each time, get the content of URL https://thispersondoesnotexist.com/image that produces a “fake” image from a GAN - Resize this image and add to a list - Use the combine images in a grid tool from ToolboxPro and create a grid\nA screenshot of the shortcut is below\n\n\n\nCreate a simple chart in Charty"
  },
  {
    "objectID": "posts/np.html",
    "href": "posts/np.html",
    "title": "Basic Neural Process",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n%config InlineBackend.figure_format = 'retina'\n\n\n# task \ndef task(amplitude=1.0, frequency=1.0, n_points=400):\n    x = torch.linspace(-2.0, 2.0, n_points)\n    y = amplitude*torch.sin(2*torch.pi*frequency*x)\n    return x.reshape(-1, 1), y\n    \n\n\nx, y = task()\nplt.plot(x, y)\n\n\n\n\n\n\n\n\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size = 1, hidden_size=10, representation_size=5):\n        super(Encoder, self).__init__()\n\n        self.fc1 = nn.Linear(input_size + 1, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, hidden_size)\n        self.fc3 = nn.Linear(hidden_size, representation_size)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n        return x\n\n\ndef create_context(x, y):\n    \"\"\"\n    x: (n, d)\n    y: (n,)\n    ---\n    output:\n    c: (n, d+1)\n    \"\"\"\n    return torch.cat((x, y.reshape(-1, 1)), dim=1)\n\n\nctx = create_context(x, y)\n\n\nrepresentation_size = 5\n\n\nenc = Encoder(representation_size=representation_size)\nrepresentation = enc(ctx)\nrepresentation_mean = representation.mean(dim=0)\nprint(representation_mean.shape)\n\ntorch.Size([5])\n\n\n\nclass Decoder(nn.Module):\n    def __init__(self, input_size = 1, hidden_size=10, representation_size=5):\n        super(Decoder, self).__init__()\n\n        self.fc1 = nn.Linear(representation_size + input_size, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, hidden_size)\n        self.fc3 = nn.Linear(hidden_size, 1)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n        x = x.ravel()\n        return x\n\n\ndec = Decoder(representation_size=representation_size)\n\n\nrepeated_representation = representation_mean.repeat(len(x), 1)\nrepeated_representation\n\ntensor([[-0.1554,  0.1063, -0.0408, -0.1532, -0.0355],\n        [-0.1554,  0.1063, -0.0408, -0.1532, -0.0355],\n        [-0.1554,  0.1063, -0.0408, -0.1532, -0.0355],\n        ...,\n        [-0.1554,  0.1063, -0.0408, -0.1532, -0.0355],\n        [-0.1554,  0.1063, -0.0408, -0.1532, -0.0355],\n        [-0.1554,  0.1063, -0.0408, -0.1532, -0.0355]],\n       grad_fn=&lt;RepeatBackward0&gt;)\n\n\n\ndecoder_inp = torch.cat((x, repeated_representation), dim=1)\ndecoder_inp.shape\n\ntorch.Size([400, 6])\n\n\n\ndec(decoder_inp).shape\n\ntorch.Size([400])\n\n\n\n# Train/test split\n\nx, y = task(n_points=2000)\n\n\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y)\n\n\ntrain_x.shape, test_x.shape\n\n(torch.Size([1500, 1]), torch.Size([500, 1]))\n\n\n\ndef get_context_target(train_x, train_y, ctx_points):\n    #torch.manual_seed(0)\n    idx = torch.randperm(len(train_x))\n    context_idx = idx[:ctx_points]\n    context_x = train_x[context_idx]\n    context_y = train_y[context_idx]\n    \n    target_idx = idx[ctx_points:]\n    \n    target_x = train_x[target_idx]\n    target_y = train_y[target_idx]\n    return context_x, context_y, target_x, target_y\n\n\nn_epochs = 2000\nctx_points = 1000\ntarget_points = len(x)*0.25\nrepresentation_size = 4\nhidden_size = 30\nenc = Encoder(representation_size=representation_size, hidden_size=hidden_size)\ndec = Decoder(representation_size=representation_size, hidden_size=hidden_size)\n\n\nparams = list(enc.parameters()) + list(dec.parameters())\n\noptimizer = torch.optim.Adam(params, lr=3e-3)\n\nfor i in range(n_epochs):\n    context_x, context_y, target_x, target_y = get_context_target(train_x, train_y, ctx_points)\n    ctx = create_context(context_x, context_y)\n    representation = enc(ctx)\n    representation_mean = representation.mean(dim=0)\n    \n    repeated_representation = representation_mean.repeat(len(target_x), 1)\n    decoder_inp = torch.cat((target_x, repeated_representation), dim=1)\n    \n    yhat = dec(decoder_inp)\n    \n    loss = nn.MSELoss()(yhat, target_y)\n    if i%100==0:\n        print(i, loss.item())\n    loss.backward()\n    optimizer.step()\n    \n    optimizer.zero_grad()\n\n0 0.5121781229972839\n100 0.39759519696235657\n200 0.25660619139671326\n300 0.14657656848430634\n400 0.06448779255151749\n500 0.04326537624001503\n600 0.021076882258057594\n700 0.015273225493729115\n800 0.010952409356832504\n900 0.009423683397471905\n1000 0.006264188792556524\n1100 0.0054198820143938065\n1200 0.004422122146934271\n1300 0.0035493236500769854\n1400 0.0030960990116000175\n1500 0.0022987055126577616\n1600 0.0020124774891883135\n1700 0.002914207987487316\n1800 0.003236218122765422\n1900 0.002254761289805174\n\n\n\nplt.scatter(target_x.detach().numpy(), yhat.detach().numpy() )\nplt.scatter(target_x.detach().numpy(), target_y.detach().numpy())\n\n\n\n\n\n\n\n\n\nrepresentation_mean\n\ntensor([-0.7204, -0.9697, -1.2259, -0.3359], grad_fn=&lt;MeanBackward1&gt;)"
  },
  {
    "objectID": "posts/2021-09-03-param-learning-sgd.html",
    "href": "posts/2021-09-03-param-learning-sgd.html",
    "title": "Learning Gaussian Process regression parameters using mini-batch stochastic gradient descent",
    "section": "",
    "text": "In our previous post we had mentioned (for the noiseless case):\nGiven train data \\[\nD=\\left(x_{i}, y_{i}\\right), i=1: N\n\\] Given a test set \\(X_{*}\\) of size \\(N_{*} \\times d\\) containing \\(N_{*}\\) points in \\(\\mathbb{R}^{d},\\) we want to predict function outputs \\(y_{*}\\) We can write: \\[\n\\left(\\begin{array}{l}\ny \\\\\ny_{*}\n\\end{array}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{array}{l}\n\\mu \\\\\n\\mu_{*}\n\\end{array}\\right),\\left(\\begin{array}{cc}\nK & K_{*} \\\\\nK_{*}^{T} & K_{* *}\n\\end{array}\\right)\\right)\n\\] where \\[\n\\begin{aligned}\nK &=\\operatorname{Ker}(X, X) \\in \\mathbb{R}^{N \\times N} \\\\\nK_{*} &=\\operatorname{Ker}\\left(X, X_{*}\\right) \\in \\mathbb{R}^{N \\times N} \\\\\nK_{* *} &=\\operatorname{Ker}\\left(X_{*}, X_{*}\\right) \\in \\mathbb{R}^{N_{*} \\times N_{*}}\n\\end{aligned}\n\\]\nThus, from the property of conditioning of multivariate Gaussian, we know that:\n\\[y \\sim \\mathcal{N}_N(\\mu, K)\\]\nWe will assume \\(\\mu\\) to be zero. Thus, we have for the train data, the following expression:\n\\[y \\sim \\mathcal{N}_N(0, K)\\]\nFor the noisy case, we have:\n\\[y \\sim \\mathcal{N}_N(0, K + \\sigma_{noise}^2\\mathcal{I}_N)\\]\nFrom this expression, we can write the log-likelihood of data computed over the kernel parameters \\(\\theta\\) as:\n\\[\\mathcal{LL}(\\theta) = \\log(\\frac{\\exp((-1/2)(y-0)^T (K+\\sigma_{noise}^2\\mathcal{I}_N)^{-1}(y-0))}{(2\\pi)^{N/2}|(K+\\sigma_{noise}^2\\mathcal{I}_N)|^{1/2}})\\]\nThus, we can write:\n\\[\\mathcal{LL}(\\theta) =\\log P(\\mathbf{y} | X, \\theta)=-\\frac{1}{2} \\mathbf{y}^{\\top} M^{-1} \\mathbf{y}-\\frac{1}{2} \\log |M|-\\frac{N}{2} \\log 2 \\pi\\]\nwhere \\[M = K + \\sigma_{noise}^2\\mathcal{I}_N\\]"
  },
  {
    "objectID": "posts/2021-09-03-param-learning-sgd.html#choosing-n-neighbors-for-sgd-batch",
    "href": "posts/2021-09-03-param-learning-sgd.html#choosing-n-neighbors-for-sgd-batch",
    "title": "Learning Gaussian Process regression parameters using mini-batch stochastic gradient descent",
    "section": "Choosing N-Neighbors for SGD batch",
    "text": "Choosing N-Neighbors for SGD batch\n\nsigma = 2.\nl = 2.\nnoise = 0.5\nlr = 1e-2\nnum_iter = 1500\nnp.random.seed(0)\nnll_arr = np.zeros(num_iter)\nfor iteration in range(num_iter):\n    # Sample 1 point\n    idx = np.random.randint(X.shape[0], size=1)\n    x_val = X[idx]\n\n    K = batch_size \n    a = np.abs(X - x_val).flatten()\n    idx = np.argpartition(a,K)[:K] \n    X_subset = X[idx, :]\n    Y_subset = Y[idx, :]\n     \n    nll_arr[iteration] = nll(X_subset, Y_subset, sigma, l, noise)\n    del_sigma, del_l, del_noise = grad_objective(X_subset, Y_subset, sigma, l, noise)\n    sigma = sigma - lr*del_sigma\n    l = l - lr*del_l\n    noise = noise - lr*del_noise\n    \n    lr = lr/(iteration+1)\n\n\nplt.plot(nll_arr)\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"NLL\")\n\nText(0, 0.5, 'NLL')\n\n\n\n\n\n\n\n\n\n\nApplying gradient descent and visualising the learnt function\n\nsigma = 2.\nl = 2.\nnoise = 0.5\nlr = 1e-2\nnum_iter = 100\nbatch_size = 5\nnll_arr = np.zeros(num_iter)\nfig, ax = plt.subplots()\nnp.random.seed(0)\nfor iteration in range(num_iter):\n    # Sample 1 point\n    idx = np.random.randint(X.shape[0], size=1)\n    x_val = X[idx]\n\n    K = batch_size \n    a = np.abs(X - x_val).flatten()\n    idx = np.argpartition(a,K)[:K] \n    X_subset = X[idx, :]\n    Y_subset = Y[idx, :]\n     \n    nll_arr[iteration] = nll(X_subset, Y_subset, sigma, l, noise)\n    del_sigma, del_l, del_noise = grad_objective(X_subset, Y_subset, sigma, l, noise)\n    sigma = sigma - lr*del_sigma\n    l = l - lr*del_l\n    noise = noise - lr*del_noise\n    k.lengthscale = l\n    k.variance = sigma**2\n    m = GPy.models.GPRegression(X, Y, k, normalizer=False)\n    m.Gaussian_noise = noise**2\n    m.plot(ax=ax, alpha=0.2)['dataplot'];\n    ax.scatter(X_subset, Y_subset, color='green', marker='*', s = 50)\n    plt.ylim((0, 6))\n    #plt.title(f\"Iteration: {iteration:04}, Objective :{nll_arr[iteration]:04.2f}\")\n    plt.savefig(f\"/Users/nipun/Desktop/gp_learning/{iteration:04}.png\")\n    ax.clear()\n    lr = lr/(iteration+1)\nplt.clf()\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\nprint(sigma**2, l, noise)\n\n4.239252534833201 2.0031950532157596 0.30136335707188894\n\n\n\n!convert -delay 40 -loop 0 /Users/nipun/Desktop/gp_learning/*.png gp-learning-new.gif"
  },
  {
    "objectID": "posts/2017-04-19-nmf-out-matrix.html",
    "href": "posts/2017-04-19-nmf-out-matrix.html",
    "title": "Out of matrix non-negative matrix factorisation",
    "section": "",
    "text": "I have written a bunch of posts on this blog about non-negative matrix factorisation (NNMF). However, all of them involved the test user to be a part of the matrix that we factorise to learn the latent factors. Is that always the case? Read on to find more!\n\nStandard Problem\nOur goal is given a matrix A, decompose it into two non-negative factors, as follows:\n$ A_{M N} W_{M K} H_{K N} $, such that $ W_{M K} $ and $ H_{K N} $\n\n\n\nOur Problem- Out of matrix factorisation\nImagine that we have trained the model for M-1 users on N movies. Now, the \\(M^{th}\\) user has rated some movies. Do we retrain the model from scratch to consider \\(M^{th}\\) user? This can be a very expensive operation!\n\nInstead, as shown in above figure, we will learn the user factor for the \\(M^{th}\\) user. We can do this the shared movie factor (H) has already been learnt.\nWe can formulate as follows:\n\\[\nA[M,:] = W[M,:]H\n\\]\nTaking transpose both sides\n\\[\nA[M,:]^T = H^T W[M,:]^T\n\\]\nHowever, \\(A[M,:]^T\\) will have missing entries. Thus, we can mask those entries from the calculation as shown below.\n\nThus, we can write\n\\[\nW[M,:]^T = \\mathrm{Least Squares} (H^T[Mask], A[M,:]^T[Mask])\n\\]\nIf instead we want the factors to be non-negative, we can use non-negative least squares instead of usual least squares for this estimation.\n\n\nCode example\nI’ll now present a simple code example to illustrate the procedure.\n\nDefining matrix A\n\nimport numpy as np\nimport pandas as pd\n\nM, N = 20, 10\n\nnp.random.seed(0)\nA_orig = np.abs(np.random.uniform(low=0.0, high=1.0, size=(M,N)))\npd.DataFrame(A_orig).head()\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n0\n0.548814\n0.715189\n0.602763\n0.544883\n0.423655\n0.645894\n0.437587\n0.891773\n0.963663\n0.383442\n\n\n1\n0.791725\n0.528895\n0.568045\n0.925597\n0.071036\n0.087129\n0.020218\n0.832620\n0.778157\n0.870012\n\n\n2\n0.978618\n0.799159\n0.461479\n0.780529\n0.118274\n0.639921\n0.143353\n0.944669\n0.521848\n0.414662\n\n\n3\n0.264556\n0.774234\n0.456150\n0.568434\n0.018790\n0.617635\n0.612096\n0.616934\n0.943748\n0.681820\n\n\n4\n0.359508\n0.437032\n0.697631\n0.060225\n0.666767\n0.670638\n0.210383\n0.128926\n0.315428\n0.363711\n\n\n\n\n\n\n\n\n\nMasking a few entries\n\nA = A_orig.copy()\nA[0, 0] = np.NAN\nA[3, 1] = np.NAN\nA[6, 3] = np.NAN\n\n# Masking for last user. \nA[19, 2] = np.NAN\nA[19, 7] = np.NAN\n\nWe will be using A2 (first 19 users) matrix for learning the movie factors and the user factors for the 19 users\n\nA2 = A[:-1,:]\nA2.shape\n\n(19, 10)\n\n\n\nA_df = pd.DataFrame(A)\nA_df.head()\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n0\nNaN\n0.715189\n0.602763\n0.544883\n0.423655\n0.645894\n0.437587\n0.891773\n0.963663\n0.383442\n\n\n1\n0.791725\n0.528895\n0.568045\n0.925597\n0.071036\n0.087129\n0.020218\n0.832620\n0.778157\n0.870012\n\n\n2\n0.978618\n0.799159\n0.461479\n0.780529\n0.118274\n0.639921\n0.143353\n0.944669\n0.521848\n0.414662\n\n\n3\n0.264556\nNaN\n0.456150\n0.568434\n0.018790\n0.617635\n0.612096\n0.616934\n0.943748\n0.681820\n\n\n4\n0.359508\n0.437032\n0.697631\n0.060225\n0.666767\n0.670638\n0.210383\n0.128926\n0.315428\n0.363711\n\n\n\n\n\n\n\n\n\nDefining matrices W and H (learning on M-1 users and N movies)\n\nK = 4\nW = np.abs(np.random.uniform(low=0, high=1, size=(M-1, K)))\nH = np.abs(np.random.uniform(low=0, high=1, size=(K, N)))\nW = np.divide(W, K*W.max())\nH = np.divide(H, K*H.max())\n\n\npd.DataFrame(W).head()\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n0.078709\n0.175784\n0.095359\n0.045339\n\n\n1\n0.006230\n0.016976\n0.171505\n0.114531\n\n\n2\n0.135453\n0.226355\n0.250000\n0.054753\n\n\n3\n0.167387\n0.066473\n0.005213\n0.191444\n\n\n4\n0.080785\n0.096801\n0.148514\n0.209789\n\n\n\n\n\n\n\n\npd.DataFrame(H).head()\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n0\n0.239700\n0.203498\n0.160529\n0.222617\n0.074611\n0.216164\n0.157328\n0.003370\n0.088415\n0.037721\n\n\n1\n0.250000\n0.121806\n0.126649\n0.162827\n0.093851\n0.034858\n0.209333\n0.048340\n0.130195\n0.057117\n\n\n2\n0.024914\n0.219537\n0.247731\n0.244654\n0.230833\n0.197093\n0.084828\n0.020651\n0.103694\n0.059133\n\n\n3\n0.033735\n0.013604\n0.184756\n0.002910\n0.196210\n0.037417\n0.020248\n0.022815\n0.171121\n0.062477\n\n\n\n\n\n\n\n\n\nDefining the cost that we want to minimise\n\ndef cost(A, W, H):\n    from numpy import linalg\n    WH = np.dot(W, H)\n    A_WH = A-WH\n    return linalg.norm(A_WH, 'fro')\n\nHowever, since A has missing entries, we have to define the cost in terms of the entries present in A\n\ndef cost(A, W, H):\n    from numpy import linalg\n    mask = pd.DataFrame(A).notnull().values\n    WH = np.dot(W, H)\n    WH_mask = WH[mask]\n    A_mask = A[mask]\n    A_WH_mask = A_mask-WH_mask\n    # Since now A_WH_mask is a vector, we use L2 instead of Frobenius norm for matrix\n    return linalg.norm(A_WH_mask, 2)\n\nLet us just try to see the cost of the initial set of values of W and H we randomly assigned. Notice, we pass A2!\n\ncost(A2, W, H)\n\n7.2333001567031294\n\n\n\n\nAlternating NNLS procedure\n\nnum_iter = 1000\nnum_display_cost = max(int(num_iter/10), 1)\nfrom scipy.optimize import nnls\n\nfor i in range(num_iter):\n    if i%2 ==0:\n        # Learn H, given A and W\n        for j in range(N):\n            mask_rows = pd.Series(A2[:,j]).notnull()\n            H[:,j] = nnls(W[mask_rows], A2[:,j][mask_rows])[0]\n    else:\n        for j in range(M-1):\n            mask_rows = pd.Series(A2[j,:]).notnull()\n            W[j,:] = nnls(H.transpose()[mask_rows], A2[j,:][mask_rows])[0]\n    WH = np.dot(W, H)\n    c = cost(A2, W, H)\n    if i%num_display_cost==0:\n        print i, c\n        \n\n0 3.74162948918\n100 2.25416363991\n200 2.25258698617\n300 2.25229707846\n400 2.25131714233\n500 2.24968386447\n600 2.24967129897\n700 2.24965023589\n800 2.24961410381\n900 2.24955008837\n\n\n\nA_pred = pd.DataFrame(np.dot(W, H))\nA_pred.head()\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n0\n0.590301\n0.653038\n0.531940\n0.623272\n0.584763\n0.630835\n0.574041\n0.700139\n0.841706\n0.565808\n\n\n1\n0.802724\n0.532299\n0.482430\n1.017968\n0.149923\n0.449312\n0.097775\n0.708727\n0.506595\n0.846219\n\n\n2\n0.764296\n0.563711\n0.527292\n0.905236\n0.306275\n0.505674\n0.223192\n0.705882\n0.604356\n0.757878\n\n\n3\n0.373539\n0.745239\n0.334948\n0.663219\n0.132686\n0.551844\n0.760420\n0.598546\n0.808108\n0.627732\n\n\n4\n0.467623\n0.331457\n0.617263\n0.239449\n0.634455\n0.370041\n0.294412\n0.288539\n0.484822\n0.126945\n\n\n\n\n\n\n\n\n\nLearning home factors for \\(M^{th}\\) home\n\nA_m = A[-1,:]\nA_m_transpose = A_m.T\nmask = ~np.isnan(A_m_transpose)\nW_m = nnls(H.T[mask], A_m_transpose[mask])[0]\n\n\nW_m\n\narray([ 0.12248095,  0.20778687,  0.15185613,  0.        ])\n\n\n\n\nPredicting for \\(M^{th}\\) home\n\nratings_m_home = np.dot(H.T, W_m)\n\n\nratings_m_home[~mask]\n\narray([ 0.4245947 ,  0.57447552])\n\n\n\nA_orig[-1,:][~mask]\n\narray([ 0.18619301,  0.25435648])\n\n\nThere you go, we are able to get ratings for the \\(M^{th}\\) user for the movies that they have not seen. We only trained the model on the other users! Ofcourse, these numbers might not look so impressive. However, this was just a toy example based on random data. In reality, we could expect better results!"
  },
  {
    "objectID": "posts/2022-02-04-sampling-normal.html",
    "href": "posts/2022-02-04-sampling-normal.html",
    "title": "Sampling from univariate and multivariate normal distributions using Box-Muller transform",
    "section": "",
    "text": "In this notebook I’ll talk about sampling from univariate and multivariate normal distributions. I’ll mostly directly write the code and show the output. The excellent linked references provide the background.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\ntfd = tfp.distributions\ntfl = tfp.layers\ntfb = tfp.bijectors\n\nsns.reset_defaults()\nsns.set_context(context='talk',font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nSampling from a univariate normal\nThe goal here is to sample from \\(\\mathcal{N}(\\mu, \\sigma^2)\\). The key idea is to use samples from a uniform distribution to first get samples for a standard normal \\(\\mathcal{N}(0, 1)\\) and then apply an affine transformation to get samples for \\(\\mathcal{N}(\\mu, \\sigma^2)\\).\n\nSampling from uniform distribution\n\nU = tf.random.uniform((1000, 2))\nU1, U2 = U[:, 0], U[:, 1]\n\n2022-02-04 12:00:15.559198: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n\n\nApplying the Box-Muller transform\n\nX1 = tf.sqrt(-2*tf.math.log(U1))*tf.cos(2*np.pi*U2)\nX2 = tf.sqrt(-2*tf.math.log(U1))*tf.sin(2*np.pi*U2)\n\n\nX = tf.concat((X1, X2), axis=0)\nX.shape\n\nTensorShape([2000])\n\n\n\n\nPlotting the obtained standard normal\n\nsns.kdeplot(X, bw_adjust=2)\nsns.despine()\n\n\n\n\n\n\n\n\n\nplt.hist(X.numpy(), bins=20, density=True)\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nSampling from \\(\\mathcal{N}(\\mu, \\sigma^2)\\)\nWe apply the affine transformation.\n\\(X \\sim \\mathcal{N}(0, 1)\\)\n\\(Y \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) is equivalent to \\(Y \\sim \\mu + \\sigma X\\)\n\nmu = 2.\nsigma = 2.\nY = mu + sigma*X\n\n\nax = sns.kdeplot(X, label=r'$\\mathcal{N}(0, 1)$', bw_adjust=2)\nsns.kdeplot(Y, label=r'$\\mathcal{N}(2, 4)$', bw_adjust=2)\nsns.despine()\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\nSampling from multivariate normal\nLike before, we first sample from standard multivariate normal and then apply an affine transformation to get for our desired multivariate normal.\nThe important thing to note in the generation of the standard multivariate normal samples is that the individial random variables are independent of each other given the identity covariance matrix. Thus, we can independently generate the samples for individual random variable.\n\nU_2D_Samples = tf.random.uniform((2, 1000, 2))\n\n\nU11, U12, U21, U22 = U_2D_Samples[0, :, 0], U_2D_Samples[0, :, 1],U_2D_Samples[1, :, 0],U_2D_Samples[1, :, 1]\n\n\ndef generate(U1, U2):\n    X1 = tf.sqrt(-2*tf.math.log(U1))*tf.cos(2*np.pi*U2)\n    X2 = tf.sqrt(-2*tf.math.log(U1))*tf.sin(2*np.pi*U2)\n    X = tf.concat((X1, X2), axis=0)\n    return X\n\n\nX_1 = tf.reshape(generate(U11, U12), (-1, 1))\nX_2 = tf.reshape(generate(U21, U22), (-1, 1))\n\n\nX = tf.concat((X_1, X_2), axis=1)\n\n\nX\n\n&lt;tf.Tensor: shape=(2000, 2), dtype=float32, numpy=\narray([[-1.2652589 , -1.4106055 ],\n       [ 0.09925841, -0.12048604],\n       [ 0.73987466,  1.8815755 ],\n       ...,\n       [-0.05203251,  1.1814289 ],\n       [-0.04060707, -0.14595209],\n       [-0.7659936 ,  1.505757  ]], dtype=float32)&gt;\n\n\n\nPlotting samples from generated standard 2d normal\n\nsns.kdeplot(x=X[:, 0],\n            y = X[:, 1],zorder=0, n_levels=10, shade=True, \n    cbar=True, thresh=0.001, cmap='viridis',bw_adjust=5,  cbar_kws={'format': '%.3f', })\n\nplt.gca().set_aspect('equal')\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nApplying the affine transformation\nThe main difference in the 1d and multivariate case is that instead of using \\(\\sigma\\), we use the \\(L\\) cholesky matrix.\n\nmean_2d = tf.constant([3., -1.])\ncov = tf.constant([[2., 0.5],\n                  [0.5, 1.]])\n\n\nL = tf.linalg.cholesky(cov)\n\n\nY_2d = mean_2d + X@tf.transpose(L)\n\n\nY_2d.shape\n\nTensorShape([2000, 2])\n\n\n\nfig, ax = plt.subplots(ncols=2, sharey=True, figsize=(8, 4))\nsns.kdeplot(x=Y_2d[:, 0],\n            y = Y_2d[:, 1],zorder=0, n_levels=10, shade=True, \n    cbar=True, thresh=0.001, cmap='viridis',bw_adjust=5, ax=ax[0], cbar_kws={'format': '%.3f', })\n\nsns.kdeplot(x=X[:, 0],\n            y = X[:, 1],zorder=0, n_levels=10, shade=True, \n    cbar=True, thresh=0.001, cmap='viridis',bw_adjust=5, ax=ax[1], cbar_kws={'format': '%.3f', })\n\nax[0].set_aspect('equal')\nax[1].set_aspect('equal')\n\nsample_mean_tr = tf.reduce_mean(Y_2d, axis=0).numpy()\nsample_mean_tr_rounded  = np.around(sample_mean_tr, 2)\n\ncov_tr = tfp.stats.covariance(Y_2d).numpy()\ncov_tr_rounded =np.around(cov_tr, 2)\n\n\nsample_mean = tf.reduce_mean(X, axis=0).numpy()\nsample_mean_rounded  = np.around(sample_mean, 2)\n\ncov = tfp.stats.covariance(X).numpy()\ncov_rounded =np.around(cov, 2)\n\n\nax[0].set_title(fr\"$\\mu$ = {sample_mean_tr_rounded}\"+\"\\n\"+ fr\"$\\Sigma$ = {cov_tr_rounded}\")\nax[1].set_title(fr\"$\\mu$ = {sample_mean_rounded}\"+\"\\n\"+ fr\"$\\Sigma$ = {cov_rounded}\")\n\n\n\nsns.despine()\nfig.tight_layout()\n\n\n\n\n\n\n\n\nReferences\n\nhttps://www.youtube.com/watch?v=DSWM7-9gK7s&list=PLISXH-iEM4Jm5B_J9p1oUNGDAUeCFZLkJ&index=38\nhttps://www.youtube.com/watch?v=4fVQrH65aWU\nhttps://en.wikipedia.org/wiki/Box–Muller_transform\nhttps://en.wikipedia.org/wiki/Affine_transformation"
  },
  {
    "objectID": "posts/2022-02-21-coordinate-descent-failure.html",
    "href": "posts/2022-02-21-coordinate-descent-failure.html",
    "title": "Coordinate descent failure example",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nfrom functools import partial\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nX = torch.linspace(-5, 5, 200).unsqueeze(-1)\nY = torch.linspace(-5, 5, 200).unsqueeze(0)\nshape = torch.Size((X.shape[0], Y.shape[1]))\nX = X.expand(shape)\nY = Y.expand(shape)\n\n\ndef f(x, y):\n    return torch.abs(x+y) + 3*torch.abs(y-x)\n\nplt.contourf(X.numpy(), Y.numpy(), f(X, Y).numpy(), [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31])\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.colorbar()\n\n\nplt.gca().set_aspect(\"equal\")\n\n\n\n\n\n\n\n\n\ndef plot_point(x, y):\n    plt.contour(X.numpy(), Y.numpy(), f(X, Y).numpy(), levels=[1, 4, 7, 10, 13, 16, 19] )\n\n    plt.scatter(x, y, zorder=5, color='k', s=100)\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    plt.gca().set_aspect(\"equal\")\n\n\nx_start, y_start = -4, 2\nplot_point(x_start, y_start)\n\n\n\n\n\n\n\n\nFix x2 = 2\n\nx_start, y_start = -4, 2\nplot_point(x_start, y_start)\nplt.axhline(2, color='red')\n\n\n\n\n\n\n\n\n\ng = partial(f, y=2)\ng\n\nfunctools.partial(&lt;function f at 0x136323310&gt;, y=2)\n\n\n\nx_learn = torch.tensor(0., requires_grad = True)\noptim = torch.optim.Adam([x_learn], lr=0.0005)\n\nfor i in range(3000):\n    loss = g(x_learn)\n    loss.backward()\n    optim.step()\n    if i%100==0:\n        print(i, x_learn.item(), loss.item())\n\n0 0.0004999999655410647 8.0\n100 0.06779850274324417 7.865949630737305\n200 0.14714795351028442 7.707312107086182\n300 0.22784578800201416 7.545924663543701\n400 0.3085353970527649 7.384539604187012\n500 0.38880792260169983 7.223984718322754\n600 0.4684963822364807 7.0645952224731445\n700 0.5475249886512756 6.906523704528809\n800 0.6258596777915955 6.74984073638916\n900 0.7034878730773926 6.594569683074951\n1000 0.7804093360900879 6.440712928771973\n1100 0.8566311597824097 6.288255214691162\n1200 0.9321646094322205 6.137174606323242\n1300 1.0070239305496216 5.987442493438721\n1400 1.0812252759933472 5.839026927947998\n1500 1.1547856330871582 5.691894054412842\n1600 1.2277231216430664 5.546006679534912\n1700 1.3000539541244507 5.401332855224609\n1800 1.371799349784851 5.257830619812012\n1900 1.4429757595062256 5.115466594696045\n2000 1.5136009454727173 4.974205493927002\n2100 1.583693265914917 4.834010124206543\n2200 1.6532690525054932 4.694848537445068\n2300 1.7223458290100098 4.556684970855713\n2400 1.7909395694732666 4.419487953186035\n2500 1.8590670824050903 4.283223628997803\n2600 1.926743507385254 4.147861957550049\n2700 1.9939842224121094 4.01337194442749\n2800 2.058466672897339 4.231417655944824\n2900 2.11668062210083 4.464505195617676\n\n\nHard to optimize!\n\nx_dummy = torch.linspace(-5, 5, 400)\nplt.plot(x_dummy, g(x_dummy))\nplt.ylabel(f\"f(x, 2)\")\nplt.xlabel(\"x\")\n\nText(0.5, 0, 'x')\n\n\n\n\n\n\n\n\n\n\nx_start, y_start = 2, 2\nplot_point(x_start, y_start)\nplt.axvline(2, color='red')\n\n\n\n\n\n\n\n\nhttps://stats.stackexchange.com/questions/146317/coordinate-vs-gradient-descent"
  },
  {
    "objectID": "posts/2017-12-29-neural-collaborative-filtering.html",
    "href": "posts/2017-12-29-neural-collaborative-filtering.html",
    "title": "Neural Networks for Collaborative Filtering",
    "section": "",
    "text": "Recently, I had a chance to read an interesting WWW 2017 paper entitled: Neural Collaborative Filtering. The first paragraph of the abstract reads as follows:\n\nIn recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation — collaborative filtering — on the basis of implicit feedback.\n\nI’d recently written a blog post on using Keras (deep learning library) for implementing traditional matrix factorization based collaborative filtering. So, I thought to get my hands dirty with building a prototype for the paper mentioned above. The authors have already provided their code on Github, which should serve as a reference for the paper and not my post, whose purpose is merely educational!\nHere’s how the proposed network architecture looks in the paper:\n\nThere are a few terms that we need to understand:\n\nUser (u) and Item (i) are used to create embeddings (low-dimensional) for user and item\nGeneralized Matrix Factorisation (GMF) combines the two embeddings using the dot product. This is our regular matrix factorisation.\nMulti-layer perceptron can also create embeddings for user and items. However, instead of taking a dot product of these to obtain the rating, we can concatenate them to create a feature vector which can be passed on to the further layers.\nNeural MF can then combine the predictions from MLP and GMF to obtain the following prediction.\n\nAs done in my previous post, I’ll use the MovieLens-100k dataset for illustration. Please refer to my previous post for more details.\n\nPeak into the dataset\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\n\ndataset = pd.read_csv(\"/Users/nipun/Downloads/ml-100k/u.data\",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n0\n196\n242\n3\n881250949\n\n\n1\n186\n302\n3\n891717742\n\n\n2\n22\n377\n1\n878887116\n\n\n3\n244\n51\n2\n880606923\n\n\n4\n166\n346\n1\n886397596\n\n\n\n\n\n\n\nSo, each record (row) shows the rating for a user, item (movie) pair. It should be noted that I use item and movie interchangeably in this post.\n\nlen(dataset.user_id.unique()), len(dataset.item_id.unique())\n\n(943, 1682)\n\n\nWe assign a unique number between (0, #users) to each user and do the same for movies.\n\ndataset.user_id = dataset.user_id.astype('category').cat.codes.values\ndataset.item_id = dataset.item_id.astype('category').cat.codes.values\n\n\ndataset.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n0\n195\n241\n3\n881250949\n\n\n1\n185\n301\n3\n891717742\n\n\n2\n21\n376\n1\n878887116\n\n\n3\n243\n50\n2\n880606923\n\n\n4\n165\n345\n1\n886397596\n\n\n\n\n\n\n\n\n\nTrain test split\nWe’ll now split our dataset of 100k ratings into train (containing 80k ratings) and test (containing 20k ratings). Given the train set, we’d like to accurately estimate the ratings in the test set.\n\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(dataset, test_size=0.2)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n13185\n71\n95\n5\n880037203\n\n\n23391\n144\n509\n4\n882181859\n\n\n90744\n895\n50\n2\n887159951\n\n\n3043\n255\n279\n5\n882151167\n\n\n8932\n55\n94\n4\n892683274\n\n\n\n\n\n\n\n\ntest.head()\ny_true = test.rating\n\n\n\nCreating the model\n\nimport keras\nn_latent_factors_user = 8\nn_latent_factors_movie = 10\nn_latent_factors_mf = 3\nn_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\n\nmovie_input = keras.layers.Input(shape=[1],name='Item')\nmovie_embedding_mlp = keras.layers.Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding-MLP')(movie_input)\nmovie_vec_mlp = keras.layers.Flatten(name='FlattenMovies-MLP')(movie_embedding_mlp)\nmovie_vec_mlp = keras.layers.Dropout(0.2)(movie_vec_mlp)\n\nmovie_embedding_mf = keras.layers.Embedding(n_movies + 1, n_latent_factors_mf, name='Movie-Embedding-MF')(movie_input)\nmovie_vec_mf = keras.layers.Flatten(name='FlattenMovies-MF')(movie_embedding_mf)\nmovie_vec_mf = keras.layers.Dropout(0.2)(movie_vec_mf)\n\n\nuser_input = keras.layers.Input(shape=[1],name='User')\nuser_vec_mlp = keras.layers.Flatten(name='FlattenUsers-MLP')(keras.layers.Embedding(n_users + 1, n_latent_factors_user,name='User-Embedding-MLP')(user_input))\nuser_vec_mlp = keras.layers.Dropout(0.2)(user_vec_mlp)\n\nuser_vec_mf = keras.layers.Flatten(name='FlattenUsers-MF')(keras.layers.Embedding(n_users + 1, n_latent_factors_mf,name='User-Embedding-MF')(user_input))\nuser_vec_mf = keras.layers.Dropout(0.2)(user_vec_mf)\n\n\nconcat = keras.layers.merge([movie_vec_mlp, user_vec_mlp], mode='concat',name='Concat')\nconcat_dropout = keras.layers.Dropout(0.2)(concat)\ndense = keras.layers.Dense(200,name='FullyConnected')(concat_dropout)\ndense_batch = keras.layers.BatchNormalization(name='Batch')(dense)\ndropout_1 = keras.layers.Dropout(0.2,name='Dropout-1')(dense_batch)\ndense_2 = keras.layers.Dense(100,name='FullyConnected-1')(dropout_1)\ndense_batch_2 = keras.layers.BatchNormalization(name='Batch-2')(dense_2)\n\n\ndropout_2 = keras.layers.Dropout(0.2,name='Dropout-2')(dense_batch_2)\ndense_3 = keras.layers.Dense(50,name='FullyConnected-2')(dropout_2)\ndense_4 = keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n\npred_mf = keras.layers.merge([movie_vec_mf, user_vec_mf], mode='dot',name='Dot')\n\n\npred_mlp = keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n\ncombine_mlp_mf = keras.layers.merge([pred_mf, pred_mlp], mode='concat',name='Concat-MF-MLP')\nresult_combine = keras.layers.Dense(100,name='Combine-MF-MLP')(combine_mlp_mf)\ndeep_combine = keras.layers.Dense(100,name='FullyConnected-4')(result_combine)\n\n\nresult = keras.layers.Dense(1,name='Prediction')(deep_combine)\n\n\nmodel = keras.Model([user_input, movie_input], result)\nopt = keras.optimizers.Adam(lr =0.01)\nmodel.compile(optimizer='adam',loss= 'mean_absolute_error')\n\nUsing TensorFlow backend.\n\n\nLet’s now see how our model looks like:\n\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nSVG(model_to_dot(model,  show_shapes=False, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))\n\n\n\n\n\n\n\n\nSo, it wasn’t very complicated to set up. Courtesy Keras, we can do even more complex stuff!\n\nmodel.summary()\n\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nItem (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nUser (InputLayer)               (None, 1)            0                                            \n__________________________________________________________________________________________________\nMovie-Embedding-MLP (Embedding) (None, 1, 10)        16830       Item[0][0]                       \n__________________________________________________________________________________________________\nUser-Embedding-MLP (Embedding)  (None, 1, 8)         7552        User[0][0]                       \n__________________________________________________________________________________________________\nFlattenMovies-MLP (Flatten)     (None, 10)           0           Movie-Embedding-MLP[0][0]        \n__________________________________________________________________________________________________\nFlattenUsers-MLP (Flatten)      (None, 8)            0           User-Embedding-MLP[0][0]         \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 10)           0           FlattenMovies-MLP[0][0]          \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 8)            0           FlattenUsers-MLP[0][0]           \n__________________________________________________________________________________________________\nConcat (Merge)                  (None, 18)           0           dropout_1[0][0]                  \n                                                                 dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 18)           0           Concat[0][0]                     \n__________________________________________________________________________________________________\nFullyConnected (Dense)          (None, 200)          3800        dropout_5[0][0]                  \n__________________________________________________________________________________________________\nBatch (BatchNormalization)      (None, 200)          800         FullyConnected[0][0]             \n__________________________________________________________________________________________________\nDropout-1 (Dropout)             (None, 200)          0           Batch[0][0]                      \n__________________________________________________________________________________________________\nFullyConnected-1 (Dense)        (None, 100)          20100       Dropout-1[0][0]                  \n__________________________________________________________________________________________________\nBatch-2 (BatchNormalization)    (None, 100)          400         FullyConnected-1[0][0]           \n__________________________________________________________________________________________________\nMovie-Embedding-MF (Embedding)  (None, 1, 3)         5049        Item[0][0]                       \n__________________________________________________________________________________________________\nUser-Embedding-MF (Embedding)   (None, 1, 3)         2832        User[0][0]                       \n__________________________________________________________________________________________________\nDropout-2 (Dropout)             (None, 100)          0           Batch-2[0][0]                    \n__________________________________________________________________________________________________\nFlattenMovies-MF (Flatten)      (None, 3)            0           Movie-Embedding-MF[0][0]         \n__________________________________________________________________________________________________\nFlattenUsers-MF (Flatten)       (None, 3)            0           User-Embedding-MF[0][0]          \n__________________________________________________________________________________________________\nFullyConnected-2 (Dense)        (None, 50)           5050        Dropout-2[0][0]                  \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 3)            0           FlattenMovies-MF[0][0]           \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 3)            0           FlattenUsers-MF[0][0]            \n__________________________________________________________________________________________________\nFullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           \n__________________________________________________________________________________________________\nDot (Merge)                     (None, 1)            0           dropout_2[0][0]                  \n                                                                 dropout_4[0][0]                  \n__________________________________________________________________________________________________\nActivation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           \n__________________________________________________________________________________________________\nConcat-MF-MLP (Merge)           (None, 2)            0           Dot[0][0]                        \n                                                                 Activation[0][0]                 \n__________________________________________________________________________________________________\nCombine-MF-MLP (Dense)          (None, 100)          300         Concat-MF-MLP[0][0]              \n__________________________________________________________________________________________________\nFullyConnected-4 (Dense)        (None, 100)          10100       Combine-MF-MLP[0][0]             \n__________________________________________________________________________________________________\nPrediction (Dense)              (None, 1)            101         FullyConnected-4[0][0]           \n==================================================================================================\nTotal params: 73,955\nTrainable params: 73,355\nNon-trainable params: 600\n__________________________________________________________________________________________________\n\n\nWe can see that the number of parameters is more than what we had in the Matrix Factorisation case. Let’s see how this model works. I’ll run it for more epochs given that we have more parameters.\n\nhistory = model.fit([train.user_id, train.item_id], train.rating, epochs=25, verbose=0, validation_split=0.1)\n\n\n\nPrediction performance of Neural Network based recommender system\n\nfrom sklearn.metrics import mean_absolute_error\ny_hat_2 = np.round(model.predict([test.user_id, test.item_id]),0)\nprint(mean_absolute_error(y_true, y_hat_2))\n\nprint(mean_absolute_error(y_true, model.predict([test.user_id, test.item_id])))\n\n\n0.716\n0.737380115688\n\n\nPretty similar to the result we got using matrix factorisation. This isn’t very optimised, and I am sure doing so, we can make this approach perform much better than GMF!\nThanks for reading. This post has been a good learning experience for me. Hope you enjoyed too!"
  },
  {
    "objectID": "posts/2021-06-19-blur-affinity.html",
    "href": "posts/2021-06-19-blur-affinity.html",
    "title": "Blurring an image selectively using Affinity Photo",
    "section": "",
    "text": "In this post (video recording), I selectively blur an image using Affinity Photo on the iPad. I used the following command (borrowed from: https://stackoverflow.com/a/63575228/743775)\n\nconvert -append Image-1.png blurred.jpg  -resize x500x new_image_conbined.png"
  },
  {
    "objectID": "posts/2018-01-13-denoising.html",
    "href": "posts/2018-01-13-denoising.html",
    "title": "Signal denoising using RNNs in PyTorch",
    "section": "",
    "text": "In this post, I’ll use PyTorch to create a simple Recurrent Neural Network (RNN) for denoising a signal. I started learning RNNs using PyTorch. However, I felt that many of the examples were fairly complex. So, here’s an attempt to create a simple educational example.\n\nProblem description\nGiven a noisy sine wave as an input, we want to estimate the denoised signal. This is shown in the figure below.\n\n\n\nCustomary imports\n\nimport numpy as np\nimport math, random\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nnp.random.seed(0)\n\n\n\nCreating noisy and denoised signals\nLet’s now write functions to cerate a sine wave, add some noise on top of it. This way we’re able to create a noisy verison of the sine wave.\n\n# Generating a clean sine wave \ndef sine(X, signal_freq=60.):\n    return np.sin(2 * np.pi * (X) / signal_freq)\n\n# Adding uniform noise\ndef noisy(Y, noise_range=(-0.35, 0.35)):\n    noise = np.random.uniform(noise_range[0], noise_range[1], size=Y.shape)\n    return Y + noise\n\n# Create a noisy and clean sine wave \ndef sample(sample_size):\n    random_offset = random.randint(0, sample_size)\n    X = np.arange(sample_size)\n    out = sine(X + random_offset)\n    inp = noisy(out)\n    return inp, out\n\nLet’s now invoke the functions we defined to generate the figure we saw in the problem description.\n\ninp, out = sample(100)\nplt.plot(inp, label='Noisy')\nplt.plot(out, label ='Denoised')\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nCreating dataset\nNow, let’s write a simple function to generate a dataset of such noisy and denoised samples.\n\ndef create_dataset(n_samples=10000, sample_size=100):\n    data_inp = np.zeros((n_samples, sample_size))\n    data_out = np.zeros((n_samples, sample_size))\n    \n    for i in range(n_samples):\n        sample_inp, sample_out = sample(sample_size)\n        data_inp[i, :] = sample_inp\n        data_out[i, :] = sample_out\n    return data_inp, data_out\n\nNow, creating the dataset, and dividing it into train and test set.\n\ndata_inp, data_out = create_dataset()\ntrain_inp, train_out = data_inp[:8000], data_out[:8000]\ntest_inp, test_out = data_inp[8000:], data_out[8000:]\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\n\nCreating RNN\nWe have 1d sine waves, which we want to denoise. Thus, we have input dimension of 1. Let’s create a simple 1-layer RNN with 30 hidden units.\n\ninput_dim = 1\nhidden_size = 30\nnum_layers = 1\n\nclass CustomRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(CustomRNN, self).__init__()\n        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n        self.linear = nn.Linear(hidden_size, output_size, )\n        self.act = nn.Tanh()\n    def forward(self, x):\n        pred, hidden = self.rnn(x, None)\n        pred = self.act(self.linear(pred)).view(pred.data.shape[0], -1, 1)\n        return pred\n\nr= CustomRNN(input_dim, hidden_size, 1)\n\n\nr\n\nCustomRNN (\n  (rnn): RNN(1, 30, batch_first=True)\n  (linear): Linear (30 -&gt; 1)\n  (act): Tanh ()\n)\n\n\n\n\nTraining\n\n# Storing predictions per iterations to visualise later\npredictions = []\n\noptimizer = torch.optim.Adam(r.parameters(), lr=1e-2)\nloss_func = nn.L1Loss()\n\nfor t in range(301):\n    hidden = None\n    inp = Variable(torch.Tensor(train_inp.reshape((train_inp.shape[0], -1, 1))), requires_grad=True)\n    out = Variable(torch.Tensor(train_out.reshape((train_out.shape[0], -1, 1))) )\n    pred = r(inp)\n    optimizer.zero_grad()\n    predictions.append(pred.data.numpy())\n    loss = loss_func(pred, out)\n    if t%20==0:\n        print(t, loss.data[0])\n    loss.backward()\n    optimizer.step()\n\n0 0.5774930715560913\n20 0.12028147280216217\n40 0.11251863092184067\n60 0.10834833979606628\n80 0.11243857443332672\n100 0.11533079296350479\n120 0.09951132535934448\n140 0.078636534512043\n160 0.08674494177103043\n180 0.07217984646558762\n200 0.06266186386346817\n220 0.05793667957186699\n240 0.0723448321223259\n260 0.05628745257854462\n280 0.050240203738212585\n300 0.06297950446605682\n\n\nGreat. As expected, the loss reduces over time.\n\n\nGenerating prediction on test set\n\nt_inp = Variable(torch.Tensor(test_inp.reshape((test_inp.shape[0], -1, 1))), requires_grad=True)\npred_t = r(t_inp)\n\n\n# Test loss\nprint(loss_func(pred_t, Variable(torch.Tensor(test_out.reshape((test_inp.shape[0], -1, 1))))).data[0])\n\n0.06105425953865051\n\n\n\n\nVisualising sample denoising\n\nsample_num = 23\nplt.plot(pred_t[sample_num].data.numpy(), label='Pred')\nplt.plot(test_out[sample_num], label='GT')\nplt.legend()\nplt.title(\"Sample num: {}\".format(sample_num))\n\n\n\n\n\n\n\n\n\n\nBidirectional RNN\nSeems reasonably neat to me! If only the first few points were better esimtated. Any idea why they’re not? Maybe, we need a bidirectional RNN? Let’s try one, and I’ll also add dropout to prevent overfitting.\n\nbidirectional = True\nif bidirectional:\n    num_directions = 2\nelse:\n    num_directions = 1\nclass CustomRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(CustomRNN, self).__init__()\n        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, \n                          batch_first=True, bidirectional=bidirectional, dropout=0.1)\n        self.linear = nn.Linear(hidden_size*num_directions, output_size, )\n        self.act = nn.Tanh()\n    def forward(self, x):\n        pred, hidden = self.rnn(x, None)\n        pred = self.act(self.linear(pred)).view(pred.data.shape[0], -1, 1)\n        return pred\n\nr= CustomRNN(input_dim, hidden_size, 1)\nr\n\nCustomRNN (\n  (rnn): RNN(1, 30, batch_first=True, dropout=0.1, bidirectional=True)\n  (linear): Linear (60 -&gt; 1)\n  (act): Tanh ()\n)\n\n\n\n# Storing predictions per iterations to visualise later\npredictions = []\n\noptimizer = torch.optim.Adam(r.parameters(), lr=1e-2)\nloss_func = nn.L1Loss()\n\nfor t in range(301):\n    hidden = None\n    inp = Variable(torch.Tensor(train_inp.reshape((train_inp.shape[0], -1, 1))), requires_grad=True)\n    out = Variable(torch.Tensor(train_out.reshape((train_out.shape[0], -1, 1))) )\n    pred = r(inp)\n    optimizer.zero_grad()\n    predictions.append(pred.data.numpy())\n    loss = loss_func(pred, out)\n    if t%20==0:\n        print(t, loss.data[0])\n    loss.backward()\n    optimizer.step()\n\n0 0.6825199127197266\n20 0.11104971915483475\n40 0.07732641696929932\n60 0.07210152596235275\n80 0.06964801251888275\n100 0.06717491149902344\n120 0.06266810745000839\n140 0.06302479654550552\n160 0.05954732000827789\n180 0.05402040109038353\n200 0.05266999825835228\n220 0.06145058199763298\n240 0.0500367134809494\n260 0.05388529226183891\n280 0.053044941276311874\n300 0.046826526522636414\n\n\n\nt_inp = Variable(torch.Tensor(test_inp.reshape((test_inp.shape[0], -1, 1))), requires_grad=True)\npred_t = r(t_inp)\n\n\n# Test loss\nprint(loss_func(pred_t, Variable(torch.Tensor(test_out.reshape((test_inp.shape[0], -1, 1))))).data[0])\n\n0.050666142255067825\n\n\n\nsample_num = 23\nplt.plot(pred_t[sample_num].data.numpy(), label='Pred')\nplt.plot(test_out[sample_num], label='GT')\nplt.legend()\nplt.title(\"Sample num: {}\".format(sample_num))\n\n\n\n\n\n\n\n\nHmm. The estimated signal looks better for the initial few points. But, gets worse for the final few points. Oops! Guess, now the reverse RNN causes problems for its first few points!\n\n\nFrom RNNs to GRU\nLet’s now replace our RNN with GRU to see if the model improves.\n\nbidirectional = True\nif bidirectional:\n    num_directions = 2\nelse:\n    num_directions = 1\nclass CustomRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(CustomRNN, self).__init__()\n        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, \n                          batch_first=True, bidirectional=bidirectional, dropout=0.1)\n        self.linear = nn.Linear(hidden_size*num_directions, output_size, )\n        self.act = nn.Tanh()\n    def forward(self, x):\n        pred, hidden = self.rnn(x, None)\n        pred = self.act(self.linear(pred)).view(pred.data.shape[0], -1, 1)\n        return pred\n\nr= CustomRNN(input_dim, hidden_size, 1)\nr\n\nCustomRNN (\n  (rnn): GRU(1, 30, batch_first=True, dropout=0.1, bidirectional=True)\n  (linear): Linear (60 -&gt; 1)\n  (act): Tanh ()\n)\n\n\n\n# Storing predictions per iterations to visualise later\npredictions = []\n\noptimizer = torch.optim.Adam(r.parameters(), lr=1e-2)\nloss_func = nn.L1Loss()\n\nfor t in range(201):\n    hidden = None\n    inp = Variable(torch.Tensor(train_inp.reshape((train_inp.shape[0], -1, 1))), requires_grad=True)\n    out = Variable(torch.Tensor(train_out.reshape((train_out.shape[0], -1, 1))) )\n    pred = r(inp)\n    optimizer.zero_grad()\n    predictions.append(pred.data.numpy())\n    loss = loss_func(pred, out)\n    if t%20==0:\n        print(t, loss.data[0])\n    loss.backward()\n    optimizer.step()\n\n0 0.6294281482696533\n20 0.11452394723892212\n40 0.08548719435930252\n60 0.07101015746593475\n80 0.05964939296245575\n100 0.053830236196517944\n120 0.06312716007232666\n140 0.04494623467326164\n160 0.04309168830513954\n180 0.04010637104511261\n200 0.035212572664022446\n\n\n\nt_inp = Variable(torch.Tensor(test_inp.reshape((test_inp.shape[0], -1, 1))), requires_grad=True)\npred_t = r(t_inp)\n\n\n# Test loss\nprint(loss_func(pred_t, Variable(torch.Tensor(test_out.reshape((test_inp.shape[0], -1, 1))))).data[0])\n\n0.03618593513965607\n\n\n\nsample_num = 23\nplt.plot(pred_t[sample_num].data.numpy(), label='Pred')\nplt.plot(test_out[sample_num], label='GT')\nplt.legend()\nplt.title(\"Sample num: {}\".format(sample_num))\n\n\n\n\n\n\n\n\nThe GRU prediction seems to far better! Maybe, the RNNs suffer from the vanishing gradients problem?\n\n\nVisualising estimations as model improves\nLet’s now write a simple function to visualise the estimations as a function of iterations. We’d expect the estimations to improve over time.\n\nplt.rcParams['animation.ffmpeg_path'] = './ffmpeg'\nfrom matplotlib.animation import FuncAnimation\n\nfig, ax = plt.subplots(figsize=(4, 3))\nfig.set_tight_layout(True)\n\n# Query the figure's on-screen size and DPI. Note that when saving the figure to\n# a file, we need to provide a DPI for that separately.\nprint('fig size: {0} DPI, size in inches {1}'.format(\n    fig.get_dpi(), fig.get_size_inches()))\n\ndef update(i):\n    label = 'Iteration {0}'.format(i)\n    ax.cla()\n    ax.plot(np.array(predictions)[i, 0, :, 0].T, label='Pred')\n    ax.plot(train_out[0, :], label='GT')\n    ax.legend()\n    ax.set_title(label)\n \n\nanim = FuncAnimation(fig, update, frames=range(0, 201, 4), interval=20)\nanim.save('learning.mp4',fps=20)\nplt.close()\n\nfig size: 72.0 DPI, size in inches [ 4.  3.]\n\n\n\nfrom IPython.display import Video\nVideo(\"learning.mp4\")\n\n\n      Your browser does not support the video element.\n    \n\n\nThis looks great! We can see how our model learns to learn reasonably good denoised signals over time. It doesn’t start great though. Would a better initialisation help? I certainly feel that for this particular problem it would, as predicting the output the same as input is a good starting point!\n\n\nBonus: Handling missing values in denoised training data\nThe trick to handling missing values in the denoised training data (the quantity we wish to estimate) is to compute the loss only over the present values. This requires creating a mask for finding all entries except missing.\nOne such way to do so would be: mask = out &gt; -1* 1e8 where out is the tensor containing missing values.\nLet’s first add some unknown values (np.NaN) in the training output data.\n\nfor num_unknown_values in range(50):\n    train_out[np.random.choice(list(range(0, 8000))), np.random.choice(list(range(0, 100)))] = np.NAN\n\n\nnp.isnan(train_out).sum()\n\n50\n\n\nTesting using a network with few parameters.\n\nr= CustomRNN(input_dim, 2, 1)\nr\n\nCustomRNN (\n  (rnn): GRU(1, 30, batch_first=True, dropout=0.1, bidirectional=True)\n  (linear): Linear (60 -&gt; 1)\n  (act): Tanh ()\n)\n\n\n\n# Storing predictions per iterations to visualise later\npredictions = []\n\noptimizer = torch.optim.Adam(r.parameters(), lr=1e-2)\nloss_func = nn.L1Loss()\n\nfor t in range(20):\n    hidden = None\n    inp = Variable(torch.Tensor(train_inp.reshape((train_inp.shape[0], -1, 1))), requires_grad=True)\n    out = Variable(torch.Tensor(train_out.reshape((train_out.shape[0], -1, 1))) )\n    pred = r(inp)\n    optimizer.zero_grad()\n    predictions.append(pred.data.numpy())\n    # Create a mask to compute loss only on defined quantities\n    mask = out &gt; -1* 1e8\n    loss = loss_func(pred[mask], out[mask])\n    if t%20==0:\n        print(t, loss.data[0])\n    loss.backward()\n    optimizer.step()\n\n0 0.6575785279273987\n\n\nThere you go! We’ve also learnt how to handle missing values!\nI must thank Simon Wang and his helpful inputs on the PyTorch discussion forum."
  },
  {
    "objectID": "posts/networkx-trees.html",
    "href": "posts/networkx-trees.html",
    "title": "Trees using NetworkX",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n%matplotlib inline\n\n# Retina display\n%config InlineBackend.figure_format = 'retina'\n\n\n%pip install pydot\n\nRequirement already satisfied: pydot in /home/nipun.batra/miniforge3/lib/python3.9/site-packages (1.4.2)\nRequirement already satisfied: pyparsing&gt;=2.1.4 in /home/nipun.batra/miniforge3/lib/python3.9/site-packages (from pydot) (3.0.7)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nfrom tueplots import bundles\nplt.rcParams.update(bundles.icml2022())\n\n# Also add despine to the bundle using rcParams\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.spines.top'] = False\n\n# Increase font size to match Beamer template\nplt.rcParams['font.size'] = 16\n# Make background transparent\nplt.rcParams['figure.facecolor'] = 'none'\n\n\n# Create a simple binary tree in networkx and plot it with dot layout\n\n# +\nG = nx.Graph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2), (1, 3), (2, 4), (2, 5), (3, 6), (3, 7)])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\nnx.draw(G, pos, with_labels=True, node_size=1000, node_color='white')\n\n/home/nipun.batra/miniforge3/lib/python3.9/site-packages/IPython/core/pylabtools.py:151: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\n\nG = nx.Graph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2), (1, 3), (2, 4), (2, 5), (3, 6), (3, 7)])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\nnx.draw(G, pos, with_labels=True, node_size=500, node_color='white', node_shape='s', edgecolors='black', linewidths=2)\n# Show circle around root node\nplt.tight_layout()\n\n/tmp/ipykernel_2537678/3260582450.py:8: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n# Edges have string labels\nG = nx.DiGraph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2, {'label': '0'}), (1, 3, {'label': '1'}), (2, 4, {'label': '0'}), (2, 5, {'label': '1'}), (3, 6, {'label': '0'}), (3, 7, {'label': '1'})])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\nnx.draw(G, pos, with_labels=True, node_size=500, node_color='white', node_shape='s', edgecolors='black', linewidths=2)\n\n# Print edge labels\nlabels = nx.get_edge_attributes(G, 'label')\n_ = nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n\n\n\n\n\n\n\n\n\n\n\n# Colour 0 edges red and 1 edges blue\nG = nx.DiGraph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2, {'label': '0'}), (1, 3, {'label': '1'}), (2, 4, {'label': '0'}), (2, 5, {'label': '1'}), (3, 6, {'label': '0'}), (3, 7, {'label': '1'})])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n#nx.draw(G, pos, with_labels=True, node_size=500, node_color='white', node_shape='s', edgecolors='black', linewidths=2)\n\n# Print edge labels\nlabels = nx.get_edge_attributes(G, 'label')\nedge_colors = ['red' if label == '0' else 'blue' for label in labels.values()]\nnx.draw(G, pos, with_labels=True, node_size=500, node_color='white', node_shape='s', edgecolors='black', linewidths=2, edge_color=edge_colors)\n\n_ = nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n\n\n\n\n\n\n\n\n\n\n# Colour odd nodes as black and even nodes as magenta with alpha=0.2\nG = nx.DiGraph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2, {'label': '0'}), (1, 3, {'label': '1'}), (2, 4, {'label': '0'}), (2, 5, {'label': '1'}), (3, 6, {'label': '0'}), (3, 7, {'label': '1'})])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n\n# Print edge labels\nlabels = nx.get_edge_attributes(G, 'label')\nedge_colors = ['red' if label == '0' else 'blue' for label in labels.values()]\nnode_colors = ['black' if node % 2 == 1 else 'magenta' for node in G.nodes]\n\n#nx.draw(G, pos, with_labels=True, node_size=500, node_color=node_colors, node_shape='s', edgecolors='black', linewidths=2, edge_color=edge_colors, alpha=0.6)\n\n\n# Make edge lines dashed and weight 2\nnx.draw(G, pos, with_labels=True, node_size=500, node_color=node_colors, node_shape='s',\n         edgecolors='black', linewidths=2, edge_color=edge_colors, alpha=0.6, style='dashed', width=2)\n\n# Make text labels white\n\n_ = nx.draw_networkx_labels(G, pos, font_color='white')\n\n\n\n\n\n\n\n\n\nG = nx.DiGraph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2, {'label': '0'}), (1, 3, {'label': '1'}), (2, 4, {'label': '0'}), (2, 5, {'label': '1'}), (3, 6, {'label': '0'}), (3, 7, {'label': '1'})])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n\n# Print edge labels\nlabels = nx.get_edge_attributes(G, 'label')\nedge_colors = ['red' if label == '0' else 'blue' for label in labels.values()]\nnode_colors = ['green' if node % 2 == 1 else 'magenta' for node in G.nodes]\n\nfig = plt.figure()\n# Make edge lines dashed and weight 2\nnx.draw(G, pos, with_labels=True, node_size=500, node_color=node_colors, node_shape='s',\n        edgecolors='white', linewidths=2, edge_color=edge_colors, alpha=0.6, style='dashed', width=2)\n\nfig.set_facecolor(\"#00000F\")\n\n# Make text labels white\n_ = nx.draw_networkx_labels(G, pos, font_color='white')\n\n\n\n\n\n\n\n\n\n\nG = nx.DiGraph()\nG.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\nG.add_edges_from([(1, 2, {'label': '0'}), (1, 3, {'label': '1'}), (2, 4, {'label': '0'}), (2, 5, {'label': '1'}), (3, 6, {'label': '0'}), (3, 7, {'label': '1'})])\n\npos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n\n# Print edge labels\nlabels = nx.get_edge_attributes(G, 'label')\nedge_colors = ['red' if label == '0' else 'blue' for label in labels.values()]\nnode_colors = ['green' if node % 2 == 1 else 'magenta' for node in G.nodes]\n\nfig = plt.figure()\n# Make edge lines dashed and weight 2\nnx.draw(G, pos, with_labels=True, node_size=500, node_color=node_colors, node_shape='s',\n        edgecolors='white', linewidths=2, edge_color=edge_colors, alpha=0.6, style='dashed', width=2)\n\nfig.set_facecolor(\"#000001\")\n\n\n\n# Make text labels white\n_ = nx.draw_networkx_labels(G, pos, font_color='white')\n\n# Put coding for each node. Each red appends 0 and each blue appends 1\n# codings[1] = '0'\n# codings[2] = '00'\n# codings[3] = '01'\n# codings[4] = '000' and so on\n\ncodings = {}\ncodings[1] = '0'\ncodings[2] = '00'\ncodings[3] = '01'\ncodings[4] = '000'\ncodings[5] = '001'\ncodings[6] = '010'\ncodings[7] = '011'\n\n# Put codings on the left of each node in white\nfor node, coding in codings.items():\n    plt.text(pos[node][0] - 40, pos[node][1], coding, color='white', fontsize=12)"
  },
  {
    "objectID": "posts/siren-paper-impl.html",
    "href": "posts/siren-paper-impl.html",
    "title": "SIREN paper implementation",
    "section": "",
    "text": "TLDR: Sine activation function is better than ReLU for reconstructing images\n\n\n\n\n\n\nReconstruction from ReLU\n\n\n\n\n\n\n\nReconstruction from Sine\n\n\n\n\n\n\n\nAnimation of the training process\n\n\n\n\n\n\nReconstruction from ReLU\n\n\n\n\n\n\n\nReconstruction from Sine\n\n\n\n\n\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Remove all the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set env CUDA_LAUNCH_BLOCKING=1\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n\n!wget https://segment-anything.com/assets/gallery/AdobeStock_94274587_welsh_corgi_pembroke_CD.jpg -O dog.jpg\n\n--2023-04-27 17:21:53--  https://segment-anything.com/assets/gallery/AdobeStock_94274587_welsh_corgi_pembroke_CD.jpg\nResolving segment-anything.com (segment-anything.com)... 108.138.128.23, 108.138.128.8, 108.138.128.34, ...\nConnecting to segment-anything.com (segment-anything.com)|108.138.128.23|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 221810 (217K) [image/jpeg]\nSaving to: ‘dog.jpg’\n\ndog.jpg             100%[===================&gt;] 216.61K   400KB/s    in 0.5s    \n\n2023-04-27 17:21:55 (400 KB/s) - ‘dog.jpg’ saved [221810/221810]\n\n\n\n\n# Read in a image from torchvision\nimg = torchvision.io.read_image(\"dog.jpg\")\n\n\nplt.imshow(img.permute(1, 2, 0))\n\n\n\n\n\n\n\n\n\n# Normalize the image\nimg = img / 255.0\n\n\nimg.shape\n\ntorch.Size([3, 1365, 2048])\n\n\n\n# Take a random 224x224 crop of the image\ncrop = torchvision.transforms.functional.crop(img, 600, 750, 400, 400)\n\n\n# Plot the crop\nplt.imshow(crop.permute(1, 2, 0))\n\n\n\n\n\n\n\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Get the dimensions of the image tensor\nnum_channels, height, width = crop.shape\n\n# Create a 2D grid of (x,y) coordinates\nx_coords = torch.arange(width).repeat(height, 1)\ny_coords = torch.arange(height).repeat(width, 1).t()\nx_coords = x_coords.reshape(-1)\ny_coords = y_coords.reshape(-1)\n\n# Combine the x and y coordinates into a single tensor\nX = torch.stack([x_coords, y_coords], dim=1).float()\n\n# Move X to GPU if available\nX = X.to(device)\n\n\nnum_xy = height * width\nnum_xy\n\n160000\n\n\n\nX.shape, X\n\n(torch.Size([160000, 2]),\n tensor([[  0.,   0.],\n         [  1.,   0.],\n         [  2.,   0.],\n         ...,\n         [397., 399.],\n         [398., 399.],\n         [399., 399.]], device='cuda:0'))\n\n\n\n# Extract pixel values from image tensor\npixel_values = crop.reshape(num_channels, -1).float().to(device)\n\n# Transpose the pixel values to be (num_xy, num_channels)\npixel_values = pixel_values.transpose(0, 1)\n\ny = pixel_values.to(device)\n\n\n# Create a MLP with 5 hidden layers with 256 neurons each and ReLU activations.\n# Input is (x, y) and output is (r, g, b)\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(2, 256)\n        self.fc2 = nn.Linear(256, 256)\n        self.fc3 = nn.Linear(256, 256)\n        self.fc4 = nn.Linear(256, 256)\n        self.fc5 = nn.Linear(256, 256)\n        self.fc6 = nn.Linear(256, 3)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = F.relu(self.fc5(x))\n        return self.fc6(x)\n\n\n# Training loop function to train the model\n# X: (num_xy, 2) tensor of (x, y) coordinates\n# y: (num_xy, 3) tensor of (r, g, b) pixel values\n# model: MLP model\n# lr: learning rate\n# epochs: number of epochs to train for\n# bs: batch size\n# print_every: print loss every print_every epochs\n# Logs losses\n# Saves the prediction frmo model every print_every epochs\n\ndef train(X, y, model, lr=0.01, epochs=1000, bs=1000, print_every=100):\n    losses = []\n    imgs = []\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = nn.MSELoss()\n    for epoch in range(epochs):\n        # Get a random batch of (x, y) coordinates\n        idxs = torch.randperm(num_xy)[:bs]\n        batch_X = X[idxs]\n        batch_y = y[idxs]\n\n        # Predict the (r, g, b) values\n        pred_y = model(batch_X)\n\n        # Compute the loss\n        loss = criterion(pred_y, batch_y)\n\n        # Zero gradients, perform a backward pass, and update the weights\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n\n        # Print loss every print_every epochs\n        if epoch % print_every == 0:\n            print(f\"Epoch {epoch} loss: {loss.item()}\")\n            with torch.no_grad():\n                # Predict the (r, g, b) values\n                pred_y = model(X)\n\n                # Reshape the predictions to be (3, height, width)\n                pred_y = pred_y.transpose(0, 1).reshape(num_channels, height, width)\n                imgs.append(pred_y.permute(1, 2, 0).detach().cpu())\n                \n    return losses, imgs\n\n\nm1 = MLP()\nm1 = m1.to(device)\nlosses_mlp, imgs = train(X, y, m1, lr=0.001, epochs=4000, bs=2000, print_every=100)\n\nEpoch 0 loss: 1.5234602689743042\nEpoch 100 loss: 0.0640626773238182\nEpoch 200 loss: 0.04388527199625969\nEpoch 300 loss: 0.03277464583516121\nEpoch 400 loss: 0.03183111175894737\nEpoch 500 loss: 0.02485758438706398\nEpoch 600 loss: 0.023289738222956657\nEpoch 700 loss: 0.024606380611658096\nEpoch 800 loss: 0.023782318457961082\nEpoch 900 loss: 0.026350615546107292\nEpoch 1000 loss: 0.025088826194405556\nEpoch 1100 loss: 0.023389095440506935\nEpoch 1200 loss: 0.02370390295982361\nEpoch 1300 loss: 0.023111725226044655\nEpoch 1400 loss: 0.023864751681685448\nEpoch 1500 loss: 0.021725382655858994\nEpoch 1600 loss: 0.021787280216813087\nEpoch 1700 loss: 0.021760988980531693\nEpoch 1800 loss: 0.021614212542772293\nEpoch 1900 loss: 0.020562106743454933\nEpoch 2000 loss: 0.019880816340446472\nEpoch 2100 loss: 0.01901845820248127\nEpoch 2200 loss: 0.018372364342212677\nEpoch 2300 loss: 0.01828525774180889\nEpoch 2400 loss: 0.018451901152729988\nEpoch 2500 loss: 0.01738181710243225\nEpoch 2600 loss: 0.01698809117078781\nEpoch 2700 loss: 0.01643018051981926\nEpoch 2800 loss: 0.01669265516102314\nEpoch 2900 loss: 0.01664060726761818\nEpoch 3000 loss: 0.01606595516204834\nEpoch 3100 loss: 0.01667209528386593\nEpoch 3200 loss: 0.015133237466216087\nEpoch 3300 loss: 0.014814447611570358\nEpoch 3400 loss: 0.01538220327347517\nEpoch 3500 loss: 0.01484852284193039\nEpoch 3600 loss: 0.01589234732091427\nEpoch 3700 loss: 0.014897373504936695\nEpoch 3800 loss: 0.014240250922739506\nEpoch 3900 loss: 0.015261288732290268\n\n\n\ndef plot_image(model, name=None):\n    # Predict the (r, g, b) values\n    pred_y = model(X)\n\n    # Reshape the predictions to be (3, height, width)\n    pred_y = pred_y.transpose(0, 1).reshape(num_channels, height, width)\n\n    # plot the image\n    plt.imshow(pred_y.permute(1, 2, 0).detach().cpu())\n    if name:\n        plt.savefig(name)\n\n\nplot_image(m1, \"mlp_dog.png\")\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# Create the animation from imgs and save it as a gif\n\nimport imageio\nimageio.mimsave('mlp.gif', imgs, fps=10)\n\nLossy conversion from float32 to uint8. Range [-13.466928482055664, 2.713646650314331]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.18658676743507385, 1.3069090843200684]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.18308542668819427, 1.0001248121261597]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.07874367386102676, 1.0167515277862549]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.09477106481790543, 1.0060935020446777]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.033188510686159134, 1.0109848976135254]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.0989738255739212, 1.0007272958755493]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.04943906515836716, 1.0269501209259033]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.02097826451063156, 1.0289174318313599]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.029821299016475677, 1.0194318294525146]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.016834549605846405, 1.0527536869049072]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.008144930005073547, 1.0191292762756348]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.009020708501338959, 1.0909096002578735]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.017141804099082947, 1.0371521711349487]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.013367637991905212, 1.0438421964645386]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0.0005456805229187012, 1.0179295539855957]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.011109575629234314, 1.0290166139602661]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.020140215754508972, 1.078523874282837]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.0396433025598526, 1.0415352582931519]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.015714898705482483, 1.0283904075622559]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.04321514815092087, 1.0413591861724854]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.04679575562477112, 1.067355990409851]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.003602549433708191, 1.0755447149276733]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.007610529661178589, 1.052262306213379]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.033921219408512115, 1.0815953016281128]. Convert image to uint8 prior to saving to suppress this warning.\n\n\n\n\n# Create a MLP with 5 hidden layers with 256 neurons each and sine activations.\n# Input is (x, y) and output is (r, g, b)\n\nclass MLP_sin(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(2, 256)\n        self.fc2 = nn.Linear(256, 256)\n        self.fc3 = nn.Linear(256, 256)\n        self.fc4 = nn.Linear(256, 256)\n        self.fc5 = nn.Linear(256, 256)\n        self.fc6 = nn.Linear(256, 3)\n\n    def forward(self, x):\n        x = torch.sin(self.fc1(x))\n        x = torch.sin(self.fc2(x))\n        x = torch.sin(self.fc3(x))\n        x = torch.sin(self.fc4(x))\n        x = torch.sin(self.fc5(x))\n        return self.fc6(x)\n\n\nm2 = MLP_sin()\nm2 = m2.to(device)\nlosses_mlp_sin, imgs = train(X, y, m2, lr=0.001, epochs=4000, bs=1000, print_every=100)\n\nEpoch 0 loss: 0.40150442719459534\nEpoch 100 loss: 0.03298206627368927\nEpoch 200 loss: 0.033279214054346085\nEpoch 300 loss: 0.03175220638513565\nEpoch 400 loss: 0.03205806389451027\nEpoch 500 loss: 0.03196191042661667\nEpoch 600 loss: 0.02972976118326187\nEpoch 700 loss: 0.029925711452960968\nEpoch 800 loss: 0.02968132309615612\nEpoch 900 loss: 0.028653116896748543\nEpoch 1000 loss: 0.02474542148411274\nEpoch 1100 loss: 0.020879685878753662\nEpoch 1200 loss: 0.019819265231490135\nEpoch 1300 loss: 0.016965048387646675\nEpoch 1400 loss: 0.013934656977653503\nEpoch 1500 loss: 0.011689499020576477\nEpoch 1600 loss: 0.010081701911985874\nEpoch 1700 loss: 0.007140354719012976\nEpoch 1800 loss: 0.006480662152171135\nEpoch 1900 loss: 0.005266484338790178\nEpoch 2000 loss: 0.004757172428071499\nEpoch 2100 loss: 0.003453798359259963\nEpoch 2200 loss: 0.0032651633955538273\nEpoch 2300 loss: 0.0028410402592271566\nEpoch 2400 loss: 0.0026403532829135656\nEpoch 2500 loss: 0.0019292739452794194\nEpoch 2600 loss: 0.0021367412991821766\nEpoch 2700 loss: 0.0020427301060408354\nEpoch 2800 loss: 0.0017756932647898793\nEpoch 2900 loss: 0.0016549285501241684\nEpoch 3000 loss: 0.0016728530172258615\nEpoch 3100 loss: 0.001471961266361177\nEpoch 3200 loss: 0.0014844941906630993\nEpoch 3300 loss: 0.0014798615593463182\nEpoch 3400 loss: 0.0012664658715948462\nEpoch 3500 loss: 0.0012708695139735937\nEpoch 3600 loss: 0.0012460555881261826\nEpoch 3700 loss: 0.0012855605455115438\nEpoch 3800 loss: 0.001190435141324997\nEpoch 3900 loss: 0.0011714434949681163\n\n\n\nplot_image(m2, \"mlp_sin_dog.png\")\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\nimageio.mimsave('mlp_sin.gif', imgs, fps=10)\n\nLossy conversion from float32 to uint8. Range [-0.1441832184791565, 0.3080734610557556]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.056166477501392365, 0.9270500540733337]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.04645712673664093, 0.9617018103599548]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.08092432469129562, 0.9469475746154785]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.13254448771476746, 1.0228846073150635]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.18537408113479614, 1.0271779298782349]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.15940740704536438, 1.069307804107666]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.1629665046930313, 1.0901581048965454]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.17787247896194458, 1.164113163948059]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.23600360751152039, 1.1689845323562622]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.1829279065132141, 1.1432479619979858]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.12739746272563934, 1.1281737089157104]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.11645704507827759, 1.1141674518585205]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.11797109246253967, 1.1277530193328857]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.09862736612558365, 1.0859858989715576]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.1146015003323555, 1.099491834640503]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.09405502676963806, 1.1023061275482178]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.132747620344162, 1.0877472162246704]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.11511929333209991, 1.0887328386306763]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.11015606671571732, 1.0807398557662964]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.09713895618915558, 1.087331771850586]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.0733504444360733, 1.0549205541610718]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.07674040645360947, 1.0766404867172241]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.07997756451368332, 1.0550076961517334]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.09363748133182526, 1.056591510772705]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.08970168232917786, 1.0528484582901]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.08736599236726761, 1.04934561252594]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.08859498053789139, 1.0708154439926147]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.08006224036216736, 1.0856648683547974]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.08170387893915176, 1.071043610572815]. Convert image to uint8 prior to saving to suppress this warning.\nLossy conversion from float32 to uint8. Range [-0.06969650834798813, 1.0583616495132446]. Convert image to uint8 prior to saving to suppress this warning.\n\n\n\n\n# Audio\n!wget https://www.vincentsitzmann.com/siren/img/audio/gt_bach.wav\n\n--2023-04-28 14:24:10--  https://www.vincentsitzmann.com/siren/img/audio/gt_bach.wav\nResolving www.vincentsitzmann.com (www.vincentsitzmann.com)... 185.199.111.153, 185.199.108.153, 185.199.110.153, ...\nConnecting to www.vincentsitzmann.com (www.vincentsitzmann.com)|185.199.111.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1232886 (1.2M) [audio/wav]\nSaving to: ‘gt_bach.wav.3’\n\ngt_bach.wav.3       100%[===================&gt;]   1.17M  --.-KB/s    in 0.06s   \n\n2023-04-28 14:24:10 (19.7 MB/s) - ‘gt_bach.wav.3’ saved [1232886/1232886]\n\n\n\n\n# CLear CUDA cache\ntorch.cuda.empty_cache()\n\n\nfrom IPython.display import Audio\nAudio('gt_bach.wav')\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n# Read the audio file\nimport torchaudio\naudio, sr = torchaudio.load('gt_bach.wav')\n\n\nsr\n\n44100\n\n\n\naudio.shape\naudio = audio[0]\naudio = audio.to(device)\n\n\n# use last 2 seconds of audio\naudio = audio[-2 * sr:]\nX = torch.arange(0, len(audio)).unsqueeze(1).float().to(device)\n\n# Rescale X between -10 and 10\nX = X / X.max() * 20 - 10\nX.min(), X.max()\n\n(tensor(-10., device='cuda:0'), tensor(10., device='cuda:0'))\n\n\n\nX.shape, audio.shape, X\n\n(torch.Size([88200, 1]),\n torch.Size([88200]),\n tensor([[-10.0000],\n         [ -9.9998],\n         [ -9.9995],\n         ...,\n         [  9.9995],\n         [  9.9998],\n         [ 10.0000]], device='cuda:0'))\n\n\n\nAudio(audio.cpu(), rate=sr)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nclass SinActivation(torch.nn.Module):\n    def __init__(self):\n        super(SinActivation, self).__init__()\n        return\n    def forward(self, x):\n        return torch.sin(x)\n    \n\nclass SinActivation30(torch.nn.Module):\n    def __init__(self):\n        super(SinActivation30, self).__init__()\n        return\n    def forward(self, x):\n        return torch.sin(30*x)\n\n\nimport torch.nn as nn\n\ndef create_mlp(n, m, f):\n    \"\"\"\n    n: number of hidden layers\n    m: number of neurons in each hidden layer\n    f: activation function\n    ---\n    Weighing initialization: \n    uniform distribution between -30/input_dim and 30/input_dim for first layer\n    -sqrt(6/input_dim) and sqrt(6/input_dim) for the rest\n\n    Weight init is done in the forward pass\n    \"\"\"\n\n    layers = []\n    layer1 = nn.Linear(1, m)\n    torch.nn.init.uniform_(layer1.weight, a=-1/1, b=1/1)\n    #torch.nn.init.uniform_(layer1.bias, a=-1/1, b=1/1)\n    layers.append(layer1)\n    layers.append(SinActivation30())\n    for i in range(n):\n        layer_i = nn.Linear(m, m)\n        # Uniform distribution between -sqrt(6/input_dim) and sqrt(6/input_dim)\n        torch.nn.init.uniform_(layer_i.weight, a=-np.sqrt(6/m), b=np.sqrt(6/m))\n        torch.nn.init.uniform_(layer_i.bias, a=-np.sqrt(6/m), b=np.sqrt(6/m))\n        layers.append(layer_i)\n        layers.append(f)\n    layers.append(nn.Linear(m, 1))\n\n    return nn.Sequential(*layers)\n\n\nmlp_audio_sin_5_256 = create_mlp(5, 256, SinActivation()).to(device)\n#mlp_audio_sin_8_512 = create_mlp(8, 512, SinActivation()).to(device)\n#mlp_audio_sin_3_128 = create_mlp(3, 128, SinActivation()).to(device)\n\n\nmlp_audio_sin_5_128\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb Cell 39 in &lt;module&gt;\n----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'&gt;1&lt;/a&gt; mlp_audio_sin_5_128\n\nNameError: name 'mlp_audio_sin_5_128' is not defined\n\n\n\n\ndef train_audio(X, y, model, lr=0.01, epochs=1000, bs=1000, print_every=100):\n    losses = []\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = nn.MSELoss()\n    for epoch in range(epochs):\n        num_rows = X.shape[0]\n        idx = torch.randperm(num_rows)[:bs]\n        batch_X = X[idx]\n        batch_y = y[idx]\n        pred_y = model(batch_X)\n\n        # Compute the loss\n        loss = criterion(pred_y, batch_y)\n\n        # Zero gradients, perform a backward pass, and update the weights\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n\n        # Print loss every print_every epochs\n        if epoch % print_every == 0:\n            print(f\"Epoch {epoch} loss: {loss.item()}\")\n\n    return losses\n\n\n#losses_mlp_sin_3_128 = train_audio(X, audio, mlp_audio_sin_3_128, lr=0.0001,\n#                                    epochs=5000, bs=len(X)//2, print_every=100)\n\nlosses_mlp_sin_5_256 = train_audio(X, audio, mlp_audio_sin_5_256, lr=0.0001,\n                                    epochs=5000, bs=len(X)//2, print_every=100)\n\nEpoch 0 loss: 0.210729718208313\n\n\n\n---------------------------------------------------------------------------\nOutOfMemoryError                          Traceback (most recent call last)\n/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb Cell 41 in &lt;module&gt;\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'&gt;1&lt;/a&gt; #losses_mlp_sin_3_128 = train_audio(X, audio, mlp_audio_sin_3_128, lr=0.0001,\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'&gt;2&lt;/a&gt; #                                    epochs=5000, bs=len(X)//2, print_every=100)\n----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'&gt;4&lt;/a&gt; losses_mlp_sin_5_256 = train_audio(X, audio, mlp_audio_sin_5_256, lr=0.0001,\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'&gt;5&lt;/a&gt;                                     epochs=5000, bs=len(X)//2, print_every=100)\n\n/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb Cell 41 in train_audio(X, y, model, lr, epochs, bs, print_every)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'&gt;10&lt;/a&gt; pred_y = model(batch_X)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'&gt;12&lt;/a&gt; # Compute the loss\n---&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'&gt;13&lt;/a&gt; loss = criterion(pred_y, batch_y)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'&gt;15&lt;/a&gt; # Zero gradients, perform a backward pass, and update the weights\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'&gt;16&lt;/a&gt; optimizer.zero_grad()\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536, in MSELoss.forward(self, input, target)\n    535 def forward(self, input: Tensor, target: Tensor) -&gt; Tensor:\n--&gt; 536     return F.mse_loss(input, target, reduction=self.reduction)\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:3295, in mse_loss(input, target, size_average, reduce, reduction)\n   3292     reduction = _Reduction.legacy_get_string(size_average, reduce)\n   3294 expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n-&gt; 3295 return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n\nOutOfMemoryError: CUDA out of memory. Tried to allocate 7.25 GiB (GPU 0; 79.18 GiB total capacity; 63.06 GiB already allocated; 7.88 MiB free; 74.24 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\n\n\nX\n\ntensor([[-1.7320],\n        [-1.7320],\n        [-1.7319],\n        ...,\n        [ 1.7319],\n        [ 1.7320],\n        [ 1.7320]], device='cuda:0')\n\n\n\nimport time\n\n\na = time.time()\nlosses_mlp_sin_8_512 = train_audio(X, audio, mlp_audio_sin_8_512, \n                                   lr=0.0001, epochs=10, bs=len(X), print_every=1)\nb = time.time()\nprint(b-a)\n\n\n---------------------------------------------------------------------------\nOutOfMemoryError                          Traceback (most recent call last)\n/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb Cell 43 in &lt;module&gt;\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'&gt;1&lt;/a&gt; a = time.time()\n----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'&gt;2&lt;/a&gt; losses_mlp_sin_8_512 = train_audio(X, audio, mlp_audio_sin_8_512, \n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'&gt;3&lt;/a&gt;                                    lr=0.0001, epochs=10, bs=len(X), print_every=1)\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'&gt;4&lt;/a&gt; b = time.time()\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'&gt;5&lt;/a&gt; print(b-a)\n\n/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb Cell 43 in train_audio(X, y, model, lr, epochs, bs, print_every)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'&gt;10&lt;/a&gt; pred_y = model(batch_X)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'&gt;12&lt;/a&gt; # Compute the loss\n---&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'&gt;13&lt;/a&gt; loss = criterion(pred_y, batch_y)\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'&gt;15&lt;/a&gt; # Zero gradients, perform a backward pass, and update the weights\n     &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'&gt;16&lt;/a&gt; optimizer.zero_grad()\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536, in MSELoss.forward(self, input, target)\n    535 def forward(self, input: Tensor, target: Tensor) -&gt; Tensor:\n--&gt; 536     return F.mse_loss(input, target, reduction=self.reduction)\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:3295, in mse_loss(input, target, size_average, reduce, reduction)\n   3292     reduction = _Reduction.legacy_get_string(size_average, reduce)\n   3294 expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n-&gt; 3295 return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n\nOutOfMemoryError: CUDA out of memory. Tried to allocate 28.98 GiB (GPU 0; 79.18 GiB total capacity; 33.40 GiB already allocated; 14.51 GiB free; 59.74 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\n\n\nmlp_audio_sin_8_512 = torch.compile(mlp_audio_sin_8_512)\n\n\na = time.time()\nlosses_mlp_sin_8_512 = train_audio(X, audio, mlp_audio_sin_8_512, \n                                   lr=0.0001, epochs=10, bs=len(X), print_every=1)\nb = time.time()\nprint(b-a)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb Cell 44 in &lt;module&gt;\n----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'&gt;1&lt;/a&gt; a = time.time()\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'&gt;2&lt;/a&gt; losses_mlp_sin_8_512 = train_audio(X, audio, mlp_audio_sin_8_512, \n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'&gt;3&lt;/a&gt;                                    lr=0.0001, epochs=10, bs=len(X), print_every=1)\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/siren-paper-implementation.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'&gt;4&lt;/a&gt; b = time.time()\n\nNameError: name 'time' is not defined\n\n\n\n\n# Plot the reconstruction\nwith torch.no_grad():\n    #pred_y_5_256 = mlp_audio_sin_5_256(X)\n    #pred_y_8_512 = mlp_audio_sin_8_512(X)\n    pred_y_3_128 = mlp_audio_sin_3_128(X)\n    plt.plot(audio.cpu().numpy(), label=\"Ground truth\")\n    #plt.plot(pred_y_5_256.cpu().numpy(), label=\"MLP 5 layers 256 neurons\")\n    plt.plot(pred_y_3_128.cpu().numpy(), label=\"MLP 8 layers 512 neurons\")\n    plt.legend()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({\"GT audio\": audio.cpu().numpy(), \n                   \"MLP 5 layers 256 neurons\": pred_y_5_256.cpu().numpy().flatten(), \n                   \"MLP 8 layers 512 neurons\": pred_y_8_512.cpu().numpy().flatten()})\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nGT audio\nMLP 5 layers 256 neurons\nMLP 8 layers 512 neurons\n\n\n\n\ncount\n88200.000000\n88200.000000\n88200.000000\n\n\nmean\n0.000127\n-0.013929\n-0.010819\n\n\nstd\n0.208728\n0.025773\n0.156109\n\n\nmin\n-0.868308\n-0.083747\n-0.710084\n\n\n25%\n-0.130095\n-0.030821\n-0.116540\n\n\n50%\n-0.002093\n-0.011080\n-0.010339\n\n\n75%\n0.130701\n0.002974\n0.094733\n\n\nmax\n1.000000\n0.051832\n0.658187\n\n\n\n\n\n\n\n\naudio.shape, pred_y_8_512.shape\n\n(torch.Size([88200]), torch.Size([88200, 1]))\n\n\n\n# Play the reconstruction\nAudio(pred_y_8_512.cpu().T, rate=sr)\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n\nTODO\n\nShow the gradient of the reconstructed image for different activation functions"
  },
  {
    "objectID": "posts/2018-06-16-active-committee.html",
    "href": "posts/2018-06-16-active-committee.html",
    "title": "Active Learning",
    "section": "",
    "text": "We all get it - AI is the new electricity. Deep neural nets are everywhere around us. But you know what, getting labelled training data can still be a big issue in many domains. This is where active learning comes in - given that we only have a small amount of labelled data, do we randomly get labels for other samples, or can we create a smarter strategy for the same? Active learning deals with the latter.\nVarious strategies for active learning have been proposed in the past. In this post, I’ll work out a trivial example of what is called query by committee. The key idea is that we create a committee of learners and choose to acquire labels for the unlabelled points for which there is maximum disaggrement amongst the committee.\nI’d recommend the new readers to go through this survey.\nIn this particular post, I’d be looking at active learning via query by committee, where the committee members are trained on different subsets of the train data. In a future post, I’ll write about active learning via query by committee, where the committee members are trained on the same data, but with different parameters.\n\nStandard imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.random.seed(0)\n%matplotlib inline\n\n\n\nCreating dataset\n\nX = np.arange(1, 1001, 1)\nY = 10*X + 4 + 400* np.random.randn(1000, ) \n\n\nplt.scatter(X, Y, s=0.1)\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\n\nText(0, 0.5, 'Y')\n\n\n\n\n\n\n\n\n\n\n\nLearning a linear regression model on the entire data\n\nfrom sklearn.linear_model import LinearRegression\nclf = LinearRegression()\n\n\nclf.fit(X.reshape(-1,1), Y)\n\nLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n\n\n\nclf.intercept_\n\n-10.370897712972692\n\n\n\nclf.coef_\n\narray([9.99254389])\n\n\n\n\nVisualising the fit\n\nplt.scatter(X, Y, s=0.1)\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.plot(X, clf.coef_[0]*X + clf.intercept_, color='k', label='Best fit on all data')\nplt.legend()\nplt.text(500, clf.coef_[0]*500 + clf.intercept_ +4000, \"Y = {0:0.2f} X + {1:0.2f}\".format(clf.coef_[0], clf.intercept_) )\n\nText(500, 8985.90104506115, 'Y = 9.99 X + -10.37')\n\n\n\n\n\n\n\n\n\n\n\nCreating the initial train set, the test set and the pool\n\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_pool_X, test_X, train_pool_Y, test_Y = train_test_split(X, Y, test_size = 0.5)\n\n\ntrain_X, pool_X, train_Y, pool_Y = train_test_split(train_pool_X, train_pool_Y, test_size=495)\n\n\nplt.scatter(train_X, train_Y)\n\n\n\n\n\n\n\n\n\n\nCreating a committee each learnt on different subset of the data\n\ncommittee_size = 5\n\n\ntrain_X_com = {0:{}}\ntrain_Y_com = {0:{}}\nmodels_com = {0:{}}\n\niteration = 0\n\nfor cur_committee in range(committee_size):\n    train_X_com[iteration][cur_committee], _, train_Y_com[iteration][cur_committee], _ = train_test_split(train_X, train_Y, train_size=0.5, \n                                                                              random_state=cur_committee)\n    models_com[iteration][cur_committee] = LinearRegression()\n    models_com[iteration][cur_committee].fit(train_X_com[iteration][cur_committee].reshape(-1,1), train_Y_com[iteration][cur_committee])\n\n\n\nPlotting the fit of the committee on the entire dataset\n\nplt.scatter(X, Y, s=0.2)\nfor cur_committee in range(committee_size):\n    plt.plot(X, models_com[0][cur_committee].coef_[0]*X + models_com[0][cur_committee].intercept_,\n             label='Model {0}\\nY = {1:0.2f} X + {2:0.2f}'.format(cur_committee,\n                                                                 models_com[0][cur_committee].coef_[0],\n                                                                models_com[0][cur_committee].intercept_))\n    plt.legend()\n\n\n\n\n\n\n\n\n\n\nEvaluate the performance on the test set\n\nestimations_com = {0:{}}\nfor cur_committee in range(committee_size):\n    estimations_com[0][cur_committee] = models_com[0][cur_committee].predict(test_X.reshape(-1, 1))\n\n\ntest_mae_error = {0:(pd.DataFrame(estimations_com[0]).mean(axis=1) - test_Y).abs().mean()}\n\nThe MAE on the test set is:\n\ntest_mae_error[0]\n\n565.8837967341798\n\n\n\n\nActive learning procedure\n\nnum_iterations = 20\npoints_added_x=[]\n\npoints_added_y=[]\n\nprint(\"Iteration, Cost\\n\")\nprint(\"-\"*40)\n\nfor iteration in range(1, num_iterations):\n    # For each committee: making predictions on the pool set based on model learnt in the respective train set \n    estimations_pool = {cur_committee: models_com[iteration-1][cur_committee].predict(pool_X.reshape(-1, 1)) for cur_committee in range(committee_size)}\n    # Finding points from the pool with highest disagreement among the committee - highest standard deviation\n    in_var = pd.DataFrame(estimations_pool).std(axis=1).argmax()\n    \n    to_add_x = pool_X[in_var]\n    to_add_y = pool_Y[in_var]\n    points_added_x.append(to_add_x)\n    points_added_y.append(to_add_y)\n    \n    # For each committee - Adding the point where the committe most disagrees\n    for com in range(committee_size):\n        if iteration not in train_X_com:\n            train_X_com[iteration] = {}\n            train_Y_com[iteration] = {}\n            models_com[iteration] = {}\n        train_X_com[iteration][com] = np.append(train_X_com[iteration-1][com], to_add_x)\n        train_Y_com[iteration][com] = np.append(train_Y_com[iteration-1][com], to_add_y)\n    \n    # Deleting the point from the pool\n    pool_X = np.delete(pool_X, in_var)\n    pool_Y = np.delete(pool_Y, in_var)\n    \n    # Training on the new set for each committee\n    for cur_committee in range(committee_size):\n        models_com[iteration][cur_committee] = LinearRegression()\n        models_com[iteration][cur_committee].fit(train_X_com[iteration][cur_committee].reshape(-1,1), train_Y_com[iteration][cur_committee])\n    \n    estimations_com[iteration] = {}\n    for cur_committee in range(committee_size):\n        estimations_com[iteration][cur_committee] = models_com[iteration][cur_committee].predict(test_X.reshape(-1, 1))\n    test_mae_error[iteration]=(pd.DataFrame(estimations_com[iteration]).mean(axis=1) - test_Y).abs().mean()\n    print(iteration, (test_mae_error[iteration]))\n\nIteration, Cost\n\n----------------------------------------\n1 406.17664898054875\n2 402.9897752715986\n3 348.45182739054235\n4 348.49519515039907\n5 349.04197938475716\n6 348.68188577804807\n7 352.40882668573266\n8 373.60417208279864\n9 377.25044571705723\n10 372.5302143045216\n11 335.30243056115603\n12 336.6073606660666\n13 343.2867837998923\n14 347.0491266373306\n15 349.7464195274436\n16 351.5990833631039\n17 349.21957548034976\n18 338.8765223206476\n19 337.0132510959355\n\n\n\npd.Series(test_mae_error).plot(style='ko-')\nplt.xlim((-0.5, num_iterations+0.5))\nplt.ylabel(\"MAE on test set\")\nplt.xlabel(\"# Points Queried\")\n\nText(0.5, 0, '# Points Queried')\n\n\n\n\n\n\n\n\n\nAs expected, the error goes down as we increase the number of points queried\n\nfig, ax = plt.subplots()\nimport os\nfrom matplotlib.animation import FuncAnimation\nplt.rcParams['animation.ffmpeg_path'] = os.path.expanduser('/Users/nipun/ffmpeg')\ndef update(iteration):\n    ax.cla()\n    ax.scatter(X, Y, s=0.2)\n    ax.set_title(\"Iteration: {} \\n MAE = {:0.2f}\".format(iteration, test_mae_error[iteration]))\n    for cur_committee in range(committee_size):\n        ax.plot(X, models_com[iteration][cur_committee].coef_[0]*X + models_com[iteration][cur_committee].intercept_,\n             label='Model {0}\\nY = {1:0.2f} X + {2:0.2f}'.format(cur_committee,\n                                                                 models_com[iteration][cur_committee].coef_[0],\n                                                                models_com[iteration][cur_committee].intercept_))\n        \n        ax.scatter(points_added_x[iteration], points_added_y[iteration],s=100, color='red')\n    ax.legend()\n    \n    fig.tight_layout()\n\nanim = FuncAnimation(fig, update, frames=np.arange(0, num_iterations-1, 1), interval=1000)\nplt.close()\n\n\nfrom IPython.display import HTML\nHTML(anim.to_html5_video())\n\n\n  \n  Your browser does not support the video tag.\n\n\n\nFrom the animation, we can see that how adding a new point to the train set (shown in red) reduces the variation in prediction amongst the different committee members."
  },
  {
    "objectID": "posts/2017-04-20-parafac-out-tensor.html",
    "href": "posts/2017-04-20-parafac-out-tensor.html",
    "title": "Out of Tensor factorisation",
    "section": "",
    "text": "In a previous post, we had looked at predicting for users who weren’t a part of the original matrix factorisation. In this post, we’ll look at the same for 3-d tensors. In case you want to learn more about tensor factorisations, look at my earlier post.\n\nGeneral Tensor Factorisation\n\nGeneral tensor factorisation for a 3d tensor A (M X N X O) would produce 3 factors- X (M X K), Y (N X K) and Z (O X K). The \\(A_{ijl}\\) entry can be found as (Khatri product) :\n\\[ A_{ijl} = \\sum_k{X_{ik}Y_{jk}Z_{lk}}\\]\n\n\nLearning \\(X_M\\) factor\nHowever, we’d assume that the \\(M^{th}\\) entry isn’t a part of this decomposition. So, how do we obtain the X factors correspondonding to \\(M^{th}\\) entry? We learn the Y and Z factors from the tensor A (excluding the \\(M^{th}\\) row entries). We assume the Y and Z learnt to be shared across the entries across rows of A (1 through M).\n\nThe above figure shows the latent factor for X (\\(X_{M}\\)) corresponding to the \\(M^{th}\\) entry of X that we wish to learn. On the LHS, we see the matrix corresponding to \\(A_{M}\\). The highlighted entry of \\(A_{M}\\) is created by element-wise multiplication of \\(X_M, Y_0, Z_0\\) and then summing. Thus, each of the N X O entries of \\(A_M\\) are created by multiplying \\(X_M\\) with a row from Y and a row from Z. In general,\n\\[A_{M, n, o}  = \\sum_k{X_{M, k} \\times Y_{n, k} \\times Z_{o, k}}\\]\nNow, to learn \\(X_M\\), we plan to use least squares. For that, we need to reduce the problem into \\(\\alpha x = \\beta\\) We do this as follows:\n\nWe flatten out the A_M matrix into a vector containing N X O entries and call it \\(\\beta\\)\nWe create a matrix by element-wise multiplication of each row of Y with each row of Z to create \\(\\alpha\\) of shape (N X O, K)\n\nWe can now write,\n\\[ \\alpha X_M^T \\approx \\beta \\] Thus, X_M^T = Least Squares (\\(\\alpha, \\beta\\))\nOfcourse, \\(\\beta\\) can have missing entries, which we mask out. Thus, we can write:\n\\(X_M^T\\) = Least Squares (\\(\\alpha [Mask], \\beta [Mask]\\))\nIn case we’re doing a non-negative tensor factorisation, we can instead learn \\(X_M^T\\) as follows: \\(X_M^T\\) = Non-negative Least Squares (\\(\\alpha [Mask], \\beta [Mask]\\))\n\n\nCode example\n\nimport tensorly\nfrom tensorly.decomposition import parafac, non_negative_parafac\nimport numpy as np\n\n\nCreating the tensor to be decomposed\n\nM, N, O = 10, 4, 3 #user, movie, feature\nt = np.arange(M*N*O).reshape(M, N, O).astype('float32')\nt[0] #First entry\n\narray([[  0.,   1.,   2.],\n       [  3.,   4.,   5.],\n       [  6.,   7.,   8.],\n       [  9.,  10.,  11.]], dtype=float32)\n\n\n\n\nSetting a few entries of the last user to be unavailable/unknown\n\nt_orig = t.copy() # creating a copy\nt[-1,:,:][0, 0] = np.NAN\nt[-1,:,:][2, 2] = np.NAN\nt[-1,:,:]\n\narray([[  nan,  109.,  110.],\n       [ 111.,  112.,  113.],\n       [ 114.,  115.,   nan],\n       [ 117.,  118.,  119.]], dtype=float32)\n\n\n\n\nStandard Non-negative PARAFAC decomposition\n\nK = 2\n# Notice, we factorise a tensor with one less user. thus, t[:-1, :, :]\nX, Y, Z = non_negative_parafac(t[:-1,:,:], rank=K)\n\n\nX.shape, Y.shape, Z.shape\n\n((9, 2), (4, 2), (3, 2))\n\n\n\nY\n\narray([[ 0.48012616,  1.13542261],\n       [ 0.49409014,  2.98947262],\n       [ 0.5072998 ,  5.03375154],\n       [ 0.52051081,  7.07682331]])\n\n\n\nZ\n\narray([[ 0.57589198,  1.55655956],\n       [ 0.58183329,  1.7695134 ],\n       [ 0.58778163,  1.98182137]])\n\n\n\n\nCreating \\(\\alpha\\) by element-wise multiplication of Y, Z and reshaping\n\nalpha = np.einsum('nk, ok -&gt; nok', Y, Z).reshape((N*O, K))\nprint alpha\n\nprint \"\\nShape of alpha = \", alpha.shape\n\n[[  0.27650081   1.76735291]\n [  0.27935339   2.00914552]\n [  0.28220934   2.25020479]\n [  0.28454255   4.65329218]\n [  0.28747809   5.28991186]\n [  0.29041711   5.92460074]\n [  0.29214989   7.83533407]\n [  0.29516391   8.9072908 ]\n [  0.29818151   9.9759964 ]\n [  0.299758    11.01549695]\n [  0.30285052  12.52253365]\n [  0.30594669  14.02499969]]\n\nShape of alpha =  (12, 2)\n\n\n\nfrom scipy.optimize import nnls\n\n\n\nCreating \\(\\beta\\)\n\nbeta = t[-1,:,:].reshape(N*O, 1)\nmask = ~np.isnan(beta).flatten()\nbeta[mask].reshape(-1, 1)\n\narray([[ 109.],\n       [ 110.],\n       [ 111.],\n       [ 112.],\n       [ 113.],\n       [ 114.],\n       [ 115.],\n       [ 117.],\n       [ 118.],\n       [ 119.]], dtype=float32)\n\n\n\n\nLearning \\(X_M\\)\n\nX_M = nnls(alpha[mask], beta[mask].reshape(-1, ))[0].reshape((1, K))\nX_M\n\narray([[ 389.73825036,    0.        ]])\n\n\n\n\nComparing X_M with other entries from X\n\nX\n\narray([[  7.40340055e-01,   7.62705972e-01],\n       [  4.14288653e+01,   7.57249713e-01],\n       [  8.51282259e+01,   6.56239315e-01],\n       [  1.29063811e+02,   5.46019997e-01],\n       [  1.73739412e+02,   4.06496594e-01],\n       [  2.19798887e+02,   2.11453297e-01],\n       [  2.64609697e+02,   6.54705290e-02],\n       [  3.01392149e+02,   2.39700484e-01],\n       [  3.39963876e+02,   3.41824756e-01]])\n\n\nIt seems that the first column captures the increasing trend of values in the tensor\n\n\nPredicting missing entries using tensor multiplication\n\nnp.round(np.einsum('ir, jr, kr -&gt; ijk', X_M, Y, Z))\n\narray([[[ 108.,  109.,  110.],\n        [ 111.,  112.,  113.],\n        [ 114.,  115.,  116.],\n        [ 117.,  118.,  119.]]])\n\n\n\n\nActual entries\n\nt_orig[-1, :, :]\n\narray([[ 108.,  109.,  110.],\n       [ 111.,  112.,  113.],\n       [ 114.,  115.,  116.],\n       [ 117.,  118.,  119.]], dtype=float32)\n\n\nNot bad! We’re exactly there!"
  },
  {
    "objectID": "posts/2021-05-31-gan.html",
    "href": "posts/2021-05-31-gan.html",
    "title": "GAN",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- deep-learning- generative-models- adversarial-networks- neural-networks- keras- tensorflowdate: ’2021-05-31’description: Implementation and visualization of Generative Adversarial Networksimage: GAN-1.jpgoutput-file: 2021-05-31-gan.htmltitle: GANtoc: true—"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#introduction",
    "href": "posts/2021-05-31-gan.html#introduction",
    "title": "GAN",
    "section": "Introduction",
    "text": "Introduction\nThis is a post about Generative Adversarial Networks (GANs). This post is very heavily influenced and borrows code from:\n\nVideo from Luis Serrano\nHeavily borrowed code from this article on machine learning mastery\n\nThese folks deserve all the credit! I am writing this post mostly for my learning.\nI’d highly recommend reading the above two mentioned resources."
  },
  {
    "objectID": "posts/2021-05-31-gan.html#goal",
    "href": "posts/2021-05-31-gan.html#goal",
    "title": "GAN",
    "section": "Goal",
    "text": "Goal\nThe goal of GANs is to generate realistic data, i.e. data with similar statistics as the training data.\nSee below a “generated” face on https://thispersondoesnotexist.com\nRefresh this page to get a new face each time!\nThese are people that do not exist but their faces have been generated using GANs.\n\nfrom IPython.display import HTML, IFrame\nIFrame(\"https://thispersondoesnotexist.com\", 400, 400)"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#overall-block-diagram",
    "href": "posts/2021-05-31-gan.html#overall-block-diagram",
    "title": "GAN",
    "section": "Overall Block Diagram",
    "text": "Overall Block Diagram\nConceptually, GANs are simple.They have two main components:\n\nA discriminator: that tries to accurately tell generated and real data (from training data) apart\nA generator: that generates data given some random numbers\n\nThe goal of GANs is to use the generator to create realistic data such that the discriminator thinks it is real (coming from the training dataset)\n\nThe two components discriminator and generator are “fighting” where:\n\nthe goal of the discriminator is to tell apart fake (generated) data from true data (from training set) even when the generator is fairly good\nthe goal of the generator is to generate realistics data such that the discriminator thinks it is real data"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#creating-true-distribution",
    "href": "posts/2021-05-31-gan.html#creating-true-distribution",
    "title": "GAN",
    "section": "Creating “true” distribution",
    "text": "Creating “true” distribution\nLet us now create some data from the true/known distribution. We will be essentially creating a 2x2 matrix (image) as explained in Luis Serrano’s tutorial. The (0, 0) and (1, 1) position will be a high number between 0.8 and 1 whereas the other two positions (0, 1) and (1, 0) have values between 0 and 0.1\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport mediapy as media\n\n%matplotlib inline\nnp.random.seed(40)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport logging\nimport os\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\nlogging.getLogger('tensorflow').setLevel(logging.FATAL)\nimport tensorflow as tf   \ntf.get_logger().setLevel('ERROR')\n\ntf.random.set_seed(42)\n\n\nSIZE = 5000\nfaces = np.vstack((np.random.uniform(0.8, 1, SIZE), \n                   np.random.uniform(0., 0.1, SIZE),\n                  np.random.uniform(0., 0.1, SIZE),\n                  np.random.uniform(0.8, 1, SIZE))).T\nfaces.shape\n\n(5000, 4)\n\n\n\ndef plot_face(f):\n    f_reshape = f.reshape(2, 2)\n    plt.imshow(f_reshape, cmap=\"Greys\")\n\n\ndef plot_faces(faces, subset=1):\n    images = {\n        f'Image={im}': faces[im].reshape(2, 2)\n        for im in range(len(faces))[::subset]\n    }\n    media.show_images(images, border=True, columns=8, height=80, cmap='Greys')\n\nplot_faces(faces, subset=700)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=0\n\n\n\n\n\n\n\n\n\nImage=700\n\n\n\n\n\n\n\n\n\nImage=1400\n\n\n\n\n\n\n\n\n\nImage=2100\n\n\n\n\n\n\n\n\n\nImage=2800\n\n\n\n\n\n\n\n\n\nImage=3500\n\n\n\n\n\n\n\n\n\nImage=4200\n\n\n\n\n\n\n\n\n\nImage=4900\n\n\n\n\n\n\n\n\n\n\n\nThe above shows some samples drawn from the true distibution. Let us also now create some random/noisy samples. These samples do not have any relationship between the 4 positions.\n\n# Examples of noisy images\nnoise = np.random.randn(40, 4)\nnoise = np.abs(noise)\nnoise = noise/noise.max()\n\n\nplot_faces(noise)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=0\n\n\n\n\n\n\n\n\n\nImage=1\n\n\n\n\n\n\n\n\n\nImage=2\n\n\n\n\n\n\n\n\n\nImage=3\n\n\n\n\n\n\n\n\n\nImage=4\n\n\n\n\n\n\n\n\n\nImage=5\n\n\n\n\n\n\n\n\n\nImage=6\n\n\n\n\n\n\n\n\n\nImage=7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=8\n\n\n\n\n\n\n\n\n\nImage=9\n\n\n\n\n\n\n\n\n\nImage=10\n\n\n\n\n\n\n\n\n\nImage=11\n\n\n\n\n\n\n\n\n\nImage=12\n\n\n\n\n\n\n\n\n\nImage=13\n\n\n\n\n\n\n\n\n\nImage=14\n\n\n\n\n\n\n\n\n\nImage=15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=16\n\n\n\n\n\n\n\n\n\nImage=17\n\n\n\n\n\n\n\n\n\nImage=18\n\n\n\n\n\n\n\n\n\nImage=19\n\n\n\n\n\n\n\n\n\nImage=20\n\n\n\n\n\n\n\n\n\nImage=21\n\n\n\n\n\n\n\n\n\nImage=22\n\n\n\n\n\n\n\n\n\nImage=23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=24\n\n\n\n\n\n\n\n\n\nImage=25\n\n\n\n\n\n\n\n\n\nImage=26\n\n\n\n\n\n\n\n\n\nImage=27\n\n\n\n\n\n\n\n\n\nImage=28\n\n\n\n\n\n\n\n\n\nImage=29\n\n\n\n\n\n\n\n\n\nImage=30\n\n\n\n\n\n\n\n\n\nImage=31\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=32\n\n\n\n\n\n\n\n\n\nImage=33\n\n\n\n\n\n\n\n\n\nImage=34\n\n\n\n\n\n\n\n\n\nImage=35\n\n\n\n\n\n\n\n\n\nImage=36\n\n\n\n\n\n\n\n\n\nImage=37\n\n\n\n\n\n\n\n\n\nImage=38\n\n\n\n\n\n\n\n\n\nImage=39"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#creating-the-discriminator",
    "href": "posts/2021-05-31-gan.html#creating-the-discriminator",
    "title": "GAN",
    "section": "Creating the discriminator",
    "text": "Creating the discriminator\nOur discriminator is simple.\n\nIt accepts as input a 4 dimensional input (the 2x2 image)\nIt outputs a single number with sigmoid activation denoting the probability of:\nimage being fake or generated by generator or belonging to class 0\nimage being real or sampled from training dataset or belonging to class 1\nWe use the binary cross entropy loss\n\nTo make the above crystal clear, I’ll use the following gist to draw this NN\n\nfrom draw_nn import draw_neural_net\n\n\nfig = plt.figure(figsize=(4, 4))\nax = fig.gca()\nax.axis('off')\ndraw_neural_net(ax, .1, 0.9, .1, .6, [4, 1])\nplt.tight_layout()\nplt.title(\"Discriminator NN\");\n\n\n\n\n\n\n\n\n\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam\n\ndiscriminator = Sequential([\n  Dense(1,activation='sigmoid', input_shape=(4, )),\n])\n\ndiscriminator._name = \"Discriminator\"\n\ndiscriminator.compile(\n    optimizer=Adam(0.001),\n    loss='binary_crossentropy'\n)\n\n\ndiscriminator.summary()\n\nModel: \"Discriminator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 1)                 5         \n=================================================================\nTotal params: 5\nTrainable params: 5\nNon-trainable params: 0\n_________________________________________________________________\n\n\nAs expected, the discriminator has 5 parameters (4 weights coming from the 4 inputs to the output node and 1 bias term added). Now, let us create the generator."
  },
  {
    "objectID": "posts/2021-05-31-gan.html#creating-the-generator",
    "href": "posts/2021-05-31-gan.html#creating-the-generator",
    "title": "GAN",
    "section": "Creating the generator",
    "text": "Creating the generator\nLet us now create the generator model. We create a very simple one\n\nIt accepts as input a single random number\nIt creates a vector of size 4\n\nThe illustration below shows this network. It should be noted that the single random input is an arbitrary choice. We could use any number really!\n\nfig = plt.figure(figsize=(4, 4))\nax = fig.gca()\nax.axis('off')\ndraw_neural_net(ax, .1, 0.9, .1, .6, [1, 4])\nplt.tight_layout()\nplt.title(\"Generator NN\");\n\n\n\n\n\n\n\n\n\nfrom keras.layers import ReLU\ngenerator = Sequential([\n  Dense(4, input_shape=(1, )),\n   ReLU(max_value=1.0) \n\n])\n\ngenerator._name = \"Generator\"\n\ngenerator.compile(\n    optimizer=Adam(0.001),\n    loss='binary_crossentropy'\n)\n\n\ngenerator.summary()\n\nModel: \"Generator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 4)                 8         \n_________________________________________________________________\nmodule_wrapper (ModuleWrappe (None, 4)                 0         \n=================================================================\nTotal params: 8\nTrainable params: 8\nNon-trainable params: 0\n_________________________________________________________________\n\n\nWe can verify that the network has 8 parameters (4 weights and one bias value per output node)"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#generating-samples-from-generator",
    "href": "posts/2021-05-31-gan.html#generating-samples-from-generator",
    "title": "GAN",
    "section": "Generating samples from Generator",
    "text": "Generating samples from Generator\nWe can now use our generator to generate some samples and plot them.\n\ndef gen_fake(n_samples):\n    x_input = np.random.randn(n_samples, 1)\n    X = generator.predict(x_input)\n    y = np.zeros((n_samples, 1))\n    return X, y\n\nAs expected, the samples look random, without any specific pattern and do not resemble the training data as our generator is untrained. Further, it is important to reiterate that the class associated with the fake samples generated from the generator is 0. Thus, we have the line np.zeros((n_samples, 1)) in the code above.\n\nplot_faces(gen_fake(20)[0])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=0\n\n\n\n\n\n\n\n\n\nImage=1\n\n\n\n\n\n\n\n\n\nImage=2\n\n\n\n\n\n\n\n\n\nImage=3\n\n\n\n\n\n\n\n\n\nImage=4\n\n\n\n\n\n\n\n\n\nImage=5\n\n\n\n\n\n\n\n\n\nImage=6\n\n\n\n\n\n\n\n\n\nImage=7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=8\n\n\n\n\n\n\n\n\n\nImage=9\n\n\n\n\n\n\n\n\n\nImage=10\n\n\n\n\n\n\n\n\n\nImage=11\n\n\n\n\n\n\n\n\n\nImage=12\n\n\n\n\n\n\n\n\n\nImage=13\n\n\n\n\n\n\n\n\n\nImage=14\n\n\n\n\n\n\n\n\n\nImage=15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=16\n\n\n\n\n\n\n\n\n\nImage=17\n\n\n\n\n\n\n\n\n\nImage=18\n\n\n\n\n\n\n\n\n\nImage=19"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#sampling-from-the-real-train-dataset",
    "href": "posts/2021-05-31-gan.html#sampling-from-the-real-train-dataset",
    "title": "GAN",
    "section": "Sampling from the Real (Train) Dataset",
    "text": "Sampling from the Real (Train) Dataset\n\ndef gen_real(n_samples):\n    ix = np.random.randint(0, faces.shape[0], n_samples)\n    X = faces[ix]\n    y = np.ones((n_samples, 1))\n    return X, y\n\n\nplot_faces(gen_real(20)[0])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=0\n\n\n\n\n\n\n\n\n\nImage=1\n\n\n\n\n\n\n\n\n\nImage=2\n\n\n\n\n\n\n\n\n\nImage=3\n\n\n\n\n\n\n\n\n\nImage=4\n\n\n\n\n\n\n\n\n\nImage=5\n\n\n\n\n\n\n\n\n\nImage=6\n\n\n\n\n\n\n\n\n\nImage=7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=8\n\n\n\n\n\n\n\n\n\nImage=9\n\n\n\n\n\n\n\n\n\nImage=10\n\n\n\n\n\n\n\n\n\nImage=11\n\n\n\n\n\n\n\n\n\nImage=12\n\n\n\n\n\n\n\n\n\nImage=13\n\n\n\n\n\n\n\n\n\nImage=14\n\n\n\n\n\n\n\n\n\nImage=15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=16\n\n\n\n\n\n\n\n\n\nImage=17\n\n\n\n\n\n\n\n\n\nImage=18\n\n\n\n\n\n\n\n\n\nImage=19\n\n\n\n\n\n\n\n\n\n\n\nWe can clearly see the pattern in the images coming from the training dataset."
  },
  {
    "objectID": "posts/2021-05-31-gan.html#training-the-gan",
    "href": "posts/2021-05-31-gan.html#training-the-gan",
    "title": "GAN",
    "section": "Training the GAN",
    "text": "Training the GAN\nThe block diagram below shows the main idea behind training GANs. The procedure is similar to alternative least squares.\n\n\ndef define_gan(g_model, d_model):\n    d_model.trainable = False\n    model = Sequential()\n    model.add(g_model)\n    model.add(d_model)\n    opt = Adam(lr=0.001)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model\n\n\ngan_model = define_gan(generator, discriminator)\n\nIt is important to note that we will train two networks:\n\nDiscriminator on\nFake data (class 0)\nReal data (class 1)\nCombined model consisting og Generator + Discriminator (where the Discriminator is is fixed) on\nFake data (class 0) posing as real data (class 1) to the model\n\nThus, we do not train on the generator separately.\n\nsamples_saved = {}\nlosses = {}\nN_ITER = 1000\nSTEP = N_ITER//10\nfor i in range(N_ITER):\n    # Generate some fake data\n    X_fake, y_fake = gen_fake(2)\n    X_real, y_real = gen_real(2)\n    \n    X, y = np.vstack((X_fake, X_real)), np.vstack((y_fake, y_real))\n    \n    # Discriminator \n    d_loss = discriminator.train_on_batch(X, y)\n        \n    # Generator\n    n_samples = 4\n    g_loss= gan_model.train_on_batch(np.random.randn(n_samples, 1), np.ones(n_samples))\n    losses[i] = {'Gen. loss':g_loss, 'Disc. loss':d_loss}\n    \n    # Save 5 samples\n    samples_saved[i]= gen_fake(5)[0]\n    \n    if i%STEP==0:\n        # Save model\n        generator.save(f\"models/gen-{i}\")\n        print(\"\")\n        print(\"Iteration: {}\".format(i))\n        \n        print(\"Discriminator loss: {:0.2f}\".format(d_loss))\n\n\n        print(\"Generator loss: {:0.2f}\".format(g_loss))\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 0\nDiscriminator loss: 0.61\nGenerator loss: 0.72\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 100\nDiscriminator loss: 0.61\nGenerator loss: 0.75\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 200\nDiscriminator loss: 0.59\nGenerator loss: 0.76\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 300\nDiscriminator loss: 0.57\nGenerator loss: 0.72\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 400\nDiscriminator loss: 0.60\nGenerator loss: 0.77\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 500\nDiscriminator loss: 0.61\nGenerator loss: 0.68\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 600\nDiscriminator loss: 0.64\nGenerator loss: 0.66\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 700\nDiscriminator loss: 0.60\nGenerator loss: 0.71\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 800\nDiscriminator loss: 0.65\nGenerator loss: 0.66\n\n\nWARNING:absl:Found untraced functions such as re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_fn, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n\n\n\nIteration: 900\nDiscriminator loss: 0.70\nGenerator loss: 0.63"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#convergence",
    "href": "posts/2021-05-31-gan.html#convergence",
    "title": "GAN",
    "section": "Convergence",
    "text": "Convergence\n\nimport pandas as pd\nlosses_df = pd.DataFrame(losses)\nlosses_df.T.plot();\nplt.xlabel(\"Iteration Number\");\n\n\n\n\n\n\n\n\nYou might epxect that over time the generator loss reduces as it becomes better and correspodingly the discriminator has a harder time!"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#generating-some-fake-images-from-the-trained-generator",
    "href": "posts/2021-05-31-gan.html#generating-some-fake-images-from-the-trained-generator",
    "title": "GAN",
    "section": "Generating some “fake” images from the trained generator",
    "text": "Generating some “fake” images from the trained generator\n\nplot_faces(gen_fake(20)[0])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=0\n\n\n\n\n\n\n\n\n\nImage=1\n\n\n\n\n\n\n\n\n\nImage=2\n\n\n\n\n\n\n\n\n\nImage=3\n\n\n\n\n\n\n\n\n\nImage=4\n\n\n\n\n\n\n\n\n\nImage=5\n\n\n\n\n\n\n\n\n\nImage=6\n\n\n\n\n\n\n\n\n\nImage=7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=8\n\n\n\n\n\n\n\n\n\nImage=9\n\n\n\n\n\n\n\n\n\nImage=10\n\n\n\n\n\n\n\n\n\nImage=11\n\n\n\n\n\n\n\n\n\nImage=12\n\n\n\n\n\n\n\n\n\nImage=13\n\n\n\n\n\n\n\n\n\nImage=14\n\n\n\n\n\n\n\n\n\nImage=15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage=16\n\n\n\n\n\n\n\n\n\nImage=17\n\n\n\n\n\n\n\n\n\nImage=18\n\n\n\n\n\n\n\n\n\nImage=19\n\n\n\n\n\n\n\n\n\n\n\nYou could not tell, right! The generator has been trained well!"
  },
  {
    "objectID": "posts/2021-05-31-gan.html#visualising-evolution-of-generator",
    "href": "posts/2021-05-31-gan.html#visualising-evolution-of-generator",
    "title": "GAN",
    "section": "Visualising evolution of generator",
    "text": "Visualising evolution of generator\nLet us now visualise the evolution of the generator. To do so, we use the already saved generator models at different iterations and feed them the same “random” input.\n\no = {}\nfor i in range(0, N_ITER, STEP):\n    for inp in [0., 0.2, 0.4, 0.6, 1.]:\n        o[f'It:{i}-Inp:{inp}'] = load_model(f\"models/gen-{i}\").predict(np.array([inp])).reshape(2, 2)\n\n\nmedia.show_images(o,  border=True, columns=5, height=80, cmap='Greys')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:0-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:0-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:0-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:0-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:0-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:100-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:100-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:100-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:100-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:100-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:200-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:200-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:200-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:200-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:200-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:300-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:300-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:300-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:300-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:300-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:400-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:400-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:400-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:400-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:400-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:500-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:500-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:500-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:500-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:500-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:600-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:600-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:600-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:600-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:600-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:700-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:700-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:700-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:700-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:700-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:800-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:800-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:800-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:800-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:800-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt:900-Inp:0.0\n\n\n\n\n\n\n\n\n\nIt:900-Inp:0.2\n\n\n\n\n\n\n\n\n\nIt:900-Inp:0.4\n\n\n\n\n\n\n\n\n\nIt:900-Inp:0.6\n\n\n\n\n\n\n\n\n\nIt:900-Inp:1.0\n\n\n\n\n\n\n\n\n\n\n\nWe can see above the improvement of the generation over the different iterations and different inputs! That is it for this article. Happing GANning."
  },
  {
    "objectID": "posts/logo.html",
    "href": "posts/logo.html",
    "title": "Logo",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\n# Linear classification plot\nx = np.linspace(0, 2, 100)\ny = 0.1 * x**2 + 2\nplt.plot(x, y, label='Linear Classification', color='navy', lw=3)\n\n# Scattered points for two different classes\nrandom_idx = np.random.randint(0, 100, 10)\nclass_1_points = y - 0.7*np.random.rand(100)\nclass_2_points = y + 0.7*np.random.rand(100)\n\n# Scatter circles for Class 1 (hollow)\nplt.scatter(x[random_idx], class_1_points[random_idx],\n            edgecolors='black', facecolors='none', marker='o', label='Class 1', lw=2)\n\n# Scatter diamonds for Class 2 (hollow)\nplt.scatter(x[random_idx], class_2_points[random_idx], \n            edgecolors='black', facecolors='none', marker='D', label='Class 2', lw=2)\n\n# Adding text in black\nplt.text(1, 1, 'Sustainability Lab', fontsize=36, ha='center', color='black')\nplt.text(1, 0.3, 'AI for Sustainability', fontsize=16, ha='center', color='black')\n\nplt.axis('off')\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Create a grey background for the entire figure\nfig, ax = plt.subplots(figsize=(4, 5))\nfig.patch.set_facecolor('#F4F4F0')  # Light grey background color\n\n# Quadratic classification plot with a curved line\nx = np.linspace(0, 2, 100)\ny = 0.1 * x**2 + 2\nax.plot(x, y, label='Quadratic Classification', color='navy', linewidth=3)\n\n# Scattered points for two different classes\nnp.random.seed(42)\nrandom_idx = np.random.randint(0, 100, 10)\nclass_1_points = y - 0.7 * np.random.rand(100)\nclass_2_points = y + 0.7 * np.random.rand(100)\n\n# Scatter circles for Class 1 (hollow)\nax.scatter(x[random_idx], class_1_points[random_idx],\n           edgecolors='navy', facecolors='none', marker='o', label='Class 1', linewidth=2)\n\n# Scatter diamonds for Class 2 (hollow)\nax.scatter(x[random_idx], class_2_points[random_idx], \n           edgecolors='navy', facecolors='none', marker='D', label='Class 2', linewidth=2)\n\n# Adding text in black with adjusted positions\nax.text(1, 0.7, 'Sustainability Lab', fontsize=24, ha='center', color='navy')\nax.text(1, 0.3, 'AI for Sustainability', fontsize=14, ha='center', color='navy')\n\n# Remove x and y-axis ticks and labels for a cleaner look\nax.set_xticks([])\nax.set_yticks([])\n\n# Show the legend\n#ax.legend()\n\n# Remove top and right spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Set the face color of the plot area to grey\nax.set_facecolor('#F4F4F0')\n\n# Set the width of the axes\nax.spines['bottom'].set_linewidth(3)\nax.spines['left'].set_linewidth(3)\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Draw sigmoid function to write S and write L besides it\nimport matplotlib.patches as patches\n\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\nx_range = np.linspace(-20, 20, 800)\n\nplt.plot(x_range, sigmoid(x_range), label='Sigmoid Function', color='navy',\n          lw=30, alpha=0.8)\n\n# Draw \"X\" around x = 13, 17, 19\nxs_plus = np.array([13, 17, 19])\nplt.scatter(xs_plus, sigmoid(xs_plus), color='white', marker='X', s=250, zorder=3)\n\nxs_o = np.array([-10, -14, -18])\nplt.scatter(xs_o, sigmoid(xs_o), color='white', marker='o', s=250, zorder=3)\n\nax = plt.gca()\n\nax.set_xticks([])\nax.set_yticks([])\n\n# Show the legend\n#ax.legend()\n\n# Remove top and right spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['bottom'].set_visible(False)\n\n\n# Set the face color of the plot area to grey\nax.set_facecolor('#F4F4F0')\n\n# Draw L-shaped figure from x = 25 onwards to match sigmoid height\n# The height of the sigmoid function is between 0 and 1\nl_height = sigmoid(25)\nvertical_part = patches.Rectangle((25, -0.05), 5, l_height + 0.05, facecolor='navy')\nhorizontal_part = patches.Rectangle((25, -0.05), 15, 0.1, facecolor='navy')\n\n# Add the L-shape to the plot\nax.add_patch(vertical_part)\nax.add_patch(horizontal_part)\n\nx_start = 25\ny_start = 0\nx_end = 40\n\n# add resistor symbol\nx_resistor = np.linspace(x_start + 1, x_end - 1, (x_end - x_start - 2)*2)\ny_resistor = np.zeros_like(x_resistor)\n# odd places are +0.05 and even places are -0.05\ny_resistor[1::2] += 0.03\ny_resistor[::2] -= 0.03\nplt.plot(x_resistor, y_resistor, color='white', lw=2)\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import FancyBboxPatch\n\n# Sigmoid function\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# Generate data\nx_range = np.linspace(-20, 20, 1200)\ny_range = sigmoid(x_range)\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Plot sigmoid function with shadow\nax.plot(x_range, y_range, label='Sigmoid Function', color='navy', lw=10, zorder=3)\nax.plot(x_range, y_range - 0.03, color='grey', lw=10, alpha=0.4, zorder=2)\n\n# Draw 'S' using 'X' markers\nxs_plus = np.array([13, 17, 19])\nys_plus = sigmoid(xs_plus)\nax.scatter(xs_plus, ys_plus, color='white', edgecolor='black', marker='X', s=300, zorder=4)\n\n# Draw 'S' using 'o' markers\nxs_o = np.array([-10, -14, -18])\nys_o = sigmoid(xs_o)\nax.scatter(xs_o, ys_o, color='white', edgecolor='black', marker='o', s=300, zorder=4)\n\n# Draw 'L' shape\nl_height = sigmoid(7)\nvertical_part = FancyBboxPatch((7, 0), 0.5, l_height, boxstyle=\"round,pad=0.1\", facecolor='navy', edgecolor='black', lw=2)\nhorizontal_part = FancyBboxPatch((7, 0), 3, 0.5, boxstyle=\"round,pad=0.1\", facecolor='navy', edgecolor='black', lw=2)\n\n# Add the L-shape to the plot\nax.add_patch(vertical_part)\nax.add_patch(horizontal_part)\n\n# Add shadow to 'L' shape\nvertical_shadow = FancyBboxPatch((7.05, -0.05), 0.5, l_height, boxstyle=\"round,pad=0.1\", facecolor='grey', alpha=0.3, zorder=1)\nhorizontal_shadow = FancyBboxPatch((7.05, -0.05), 3, 0.5, boxstyle=\"round,pad=0.1\", facecolor='grey', alpha=0.3, zorder=1)\n\nax.add_patch(vertical_shadow)\nax.add_patch(horizontal_shadow)\n\n# Set the face color of the plot area to grey\nax.set_facecolor('#F4F4F0')\n\n# Remove ticks and labels\nax.set_xticks([])\nax.set_yticks([])\n\n# Remove spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['bottom'].set_visible(False)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef make_logo(fig_size=(10, 5), color='navy'):\n    # Sigmoid function\n    def sigmoid(x):\n        return 1 / (1 + np.exp(-x))\n\n    # Generate data\n    x_range = np.linspace(-20, 20, 1200)\n    y_range = sigmoid(x_range)\n\n    fig, ax = plt.subplots(figsize=fig_size)\n\n    # Plot sigmoid function with shadow\n    ax.plot(x_range, y_range, label='Sigmoid Function', color=color, lw=10, zorder=3)\n    ax.plot(x_range, y_range - 0.03, color='grey', lw=10, alpha=0.4, zorder=2)\n\n    # Draw 'S' using 'X' markers\n    xs_plus = np.array([13, 17, 19])\n    ys_plus = sigmoid(xs_plus)\n    ax.scatter(xs_plus, ys_plus, color='white', edgecolor='black', marker='X', s=300, zorder=4)\n\n    # Draw 'S' using 'o' markers\n    xs_o = np.array([-10, -14, -18])\n    ys_o = sigmoid(xs_o)\n    ax.scatter(xs_o, ys_o, color='white', edgecolor='black', marker='o', s=300, zorder=4)\n\n    # Draw thick 'L' shaped coordinate axes\n    ax.plot([0, 20], [0, 0], color=color, lw=8, zorder=3)  # Positive x-axis\n    ax.plot([0, 0], [0, 1], color=color, lw=8, zorder=3)   # Positive y-axis\n\n    # Draw shadow for 'L' shaped coordinate axes\n    ax.plot([0, 20], [-0.02, -0.02], color='grey', lw=8, alpha=0.4, zorder=2)  # Shadow for x-axis\n    ax.plot([0.05, 0.05], [0, 1], color='grey', lw=8, alpha=0.4, zorder=2)    # Shadow for y-axis\n\n    # Set the face color of the plot area to grey\n    ax.set_facecolor('#F4F4F0')\n\n    # Remove ticks and labels\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    # Remove spines\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n\n\n\nmake_logo()\n\n\n\n\n\n\n\n\n\nmake_logo(fig_size=(8, 4), color='green')\n\n\n\n\n\n\n\n\n\nmake_logo(fig_size=(8, 4), color='red')\n\n\n\n\n\n\n\n\n\nmake_logo(fig_size=(8, 4), color='black')\n\n\n\n\n\n\n\n\n\nmake_logo(fig_size=(8, 4), color='navy')\n\n\n\n\n\n\n\n\n\nmake_logo(color='#4169E1')\n\n\n\n\n\n\n\n\n\nmake_logo(color='#9932CC')\n\n\n\n\n\n\n\n\n\nmake_logo(color='#DAA520')\n\n\n\n\n\n\n\n\n\nmake_logo(color='#B22222')\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import font_manager as fm\n\ndef make_logo(fig_size=(10, 5), color='navy'):\n    # Sigmoid function\n    def sigmoid(x):\n        return 1 / (1 + np.exp(-x))\n\n    # Generate data\n    x_range = np.linspace(-20, 20, 1200)\n    y_range = sigmoid(x_range)\n\n    fig, ax = plt.subplots(figsize=fig_size)\n\n    # Plot sigmoid function with shadow\n    ax.plot(x_range, y_range, label='Sigmoid Function', color=color, lw=10, zorder=3)\n    ax.plot(x_range, y_range - 0.03, color='grey', lw=10, alpha=0.4, zorder=2)\n\n    # Draw 'S' using 'X' markers\n    xs_plus = np.array([13, 17, 19])\n    ys_plus = sigmoid(xs_plus)\n    ax.scatter(xs_plus, ys_plus, color='white', edgecolor='black', marker='X', s=300, zorder=4)\n\n    # Draw 'S' using 'o' markers\n    xs_o = np.array([-10, -14, -18])\n    ys_o = sigmoid(xs_o)\n    ax.scatter(xs_o, ys_o, color='white', edgecolor='black', marker='o', s=300, zorder=4)\n\n    # Draw thick 'L' shaped coordinate axes\n    ax.plot([0, 20], [0, 0], color=color, lw=8, zorder=3)  # Positive x-axis\n    ax.plot([0, 0], [0, 1], color=color, lw=8, zorder=3)   # Positive y-axis\n\n    # Draw shadow for 'L' shaped coordinate axes\n    ax.plot([0, 20], [-0.02, -0.02], color='grey', lw=8, alpha=0.4, zorder=2)  # Shadow for x-axis\n    ax.plot([0.05, 0.05], [0, 1], color='grey', lw=8, alpha=0.4, zorder=2)    # Shadow for y-axis\n\n    # Set the face color of the plot area to grey\n    ax.set_facecolor('#F4F4F0')\n\n    # Remove ticks and labels\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    # Remove spines\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n\n    # Add text in beautiful font\n    prop = fm.FontProperties(fname=fm.findSystemFonts(fontpaths=None, fontext='ttf')[0], size=20)\n    ax.text(1.02, 0.7, 'Sustainability Lab', ha='center', va='center', transform=ax.transAxes, fontproperties=prop, fontsize=64, color=color, fontweight='bold')\n    ax.text(1.02, 0.5, 'AI and Sensing for Sustainability', ha='center', va='center', transform=ax.transAxes, fontproperties=prop, fontsize=36, color=color)\n\n    fig.patch.set_facecolor('#F4F4F0')\n    \n\n\n# Example usage with 'Royal Blue'\nmake_logo(color='tomato')\n\n\n\n\n\n\n\n\n\nmake_logo(color='navy')"
  },
  {
    "objectID": "posts/siren-paper.html",
    "href": "posts/siren-paper.html",
    "title": "SIREN paper",
    "section": "",
    "text": "Introduction\nIn this post, I’m noting some observations from the SIREN paper.\nThis is based on some quick experiments with their awesome fork of TFPlayground here\n\n\nOOD\n\n\n\n\n\n\nReLU does better in OOD\n\n\n\n\n\n\n\nSine Activation does “bad” in OOD regions\n\n\n\n\n\n\n\nAbility to learn with simple networks\n\n\n\n\n\n\nSimple Network with ReLU unable to learn\n\n\n\n\n\n\n\nSimple Network with Sine activation can learn well\n\n\n\n\n\n\n\nAbility to fit complex functions\n\n\n\n\n\n\nOn very complicated datasets, ReLU is not able to drive the train loss low\n\n\n\n\n\n\n\nOn very complicated datasets, Sine is able to drive the train and test loss very low!\n\n\n\n\n\n\n\nFitting “speed”\n\n\n\n\n\n\nReLU is slow\n\n\n\n\n\n\n\nSine is fast"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html",
    "href": "posts/2021-08-20-bayesian.html",
    "title": "Probabilistic Programming in Pyro",
    "section": "",
    "text": "In this post, I will look at a simple application:\nIs the number of COVID cases changing over time?\n\nI will not be using real data and this post will be purely educational in nature.\nThe main aim of this post is to review some distributions and concepts in probabilistic programming.\nThe post is heavily inspired (copied and modified) by the excellent book called Bayesian Methods for Hackers (BMH). I am also borrowing a small subset of code from a forked repository for BMF containing some code in Pyro.\nEventually, we should be able to learn something like the following image, where we detect the changepoint and also the values before and after the change.\n\n\nimport torch\nimport pyro\nimport numpy as np\n\npyro.set_rng_seed(101)\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pyro.infer import MCMC, NUTS, HMC\nimport pyro.distributions as dist\nplt.style.use('seaborn-colorblind')"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html#introduction",
    "href": "posts/2021-08-20-bayesian.html#introduction",
    "title": "Probabilistic Programming in Pyro",
    "section": "",
    "text": "In this post, I will look at a simple application:\nIs the number of COVID cases changing over time?\n\nI will not be using real data and this post will be purely educational in nature.\nThe main aim of this post is to review some distributions and concepts in probabilistic programming.\nThe post is heavily inspired (copied and modified) by the excellent book called Bayesian Methods for Hackers (BMH). I am also borrowing a small subset of code from a forked repository for BMF containing some code in Pyro.\nEventually, we should be able to learn something like the following image, where we detect the changepoint and also the values before and after the change.\n\n\nimport torch\nimport pyro\nimport numpy as np\n\npyro.set_rng_seed(101)\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pyro.infer import MCMC, NUTS, HMC\nimport pyro.distributions as dist\nplt.style.use('seaborn-colorblind')"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html#distributions-in-pyro",
    "href": "posts/2021-08-20-bayesian.html#distributions-in-pyro",
    "title": "Probabilistic Programming in Pyro",
    "section": "Distributions in Pyro",
    "text": "Distributions in Pyro\nWe will first look at some distributions in Pyro to understand the task better.\nWe first start with the unfirom distribution between 0 and 100 and generate 1000 samples.\n\nu = torch.distributions.Uniform(0, 100)\n\n\nn=1000\ns = pd.Series(u.sample((n, )))\ns.hist(density=True, grid=False, bins=10 )\nplt.ylabel(\"PDF at z\")\nplt.xlabel(\"z\")\nplt.title(\"Uniform Distribution\")\n\nText(0.5, 0, 'z')\n\n\n\n\n\n\n\n\n\nAs expected, all values in [0, 100] are equally likely.\nWe next look at the Categorical distribution which is a discrete distribution. Using it, we can create a discrete uniform distribution over [0, 10].\n\ndu = torch.distributions.Categorical(torch.tensor([1./n for _ in range(10)]))\n\n\nn = 1000\ndu_samples = du.sample((n, ))\n\n\ndu_series = pd.Series(du_samples).value_counts().sort_index()\ndu_prop = du_series/n\ndu_prop.plot(kind='bar',rot=0, color='green')\nplt.ylabel(\"PMF at k\")\nplt.xlabel(\"k\")\nplt.title(\"Discrete Uniform Distribution\")\n\nText(0.5, 1.0, 'Discrete Uniform Distribution')\n\n\n\n\n\n\n\n\n\nWe next look at the exponential distribution. It is controlled by a parameter \\(\\lambda\\) with the expected value of the random variable being \\(\\dfrac{1}{\\lambda}\\)\n\nexp1 = torch.distributions.Exponential(1)\nexp2 = torch.distributions.Exponential(5)\n\n\ns1 = pd.Series(exp1.sample((5000, )))\ns2 = pd.Series(exp2.sample((5000, )))\n\n\ns1.hist(density=True, alpha=0.3, bins=20, color='g', label=r'$\\lambda = 1$')\ns2.hist(density=True, alpha=0.6, bins=20, color='orange',label=r'$\\lambda = 5$')\nplt.xlim((0, 5))\n\nplt.ylabel(\"PDF at z\")\nplt.xlabel(\"z\")\nplt.title(\"Exponential distribution\")\nplt.legend()\n\n\n\n\n\n\n\n\nWe finally look at the Poisson distribution. It is controlled by a parameter \\(\\lambda\\) with the expected value of the random variable being \\({\\lambda}\\). Poisson is a discrete distribution often used for modelling count data.\n\np1 = torch.distributions.Poisson(4)\np2 = torch.distributions.Poisson(8)\n\n\ns1 = pd.Series(p1.sample((5000, )))\ns2 = pd.Series(p2.sample((5000, )))\n\ns1 = s1.astype('int').value_counts().sort_index()\ns1 = s1/5000\n\ns2 = s2.astype('int').value_counts().sort_index()\ns2 = s2/5000\n\ns1.plot.bar(color='g', alpha=0.5, label=r'$\\lambda = 4$', rot=0)\ns2.plot.bar(color='orange', alpha=0.3, label=r'$\\lambda = 8$', rot=0)\n\nplt.legend()\nplt.ylabel(\"PMF at k\")\nplt.xlabel(\"k\")\nplt.title(\"Poisson Distribution\")\n\nText(0.5, 1.0, 'Poisson Distribution')"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html#creating-the-dataset",
    "href": "posts/2021-08-20-bayesian.html#creating-the-dataset",
    "title": "Probabilistic Programming in Pyro",
    "section": "Creating the dataset",
    "text": "Creating the dataset\nWe will be creating the dataset for daily COVID count with\n\nBefore day number 30, the cases are Poisson distributed with mean of 30\nAfter day number 30, the cases are Poisson distributed with mean of 40\nWe have data for a total of 50 days\n\n\ngt_tau = 30\ngt_lambda_1 = 30\ngt_lambda_2 = 40\n\ndef sample(day):\n    if day &lt; gt_tau:\n        l = gt_lambda_1\n    else:\n        l = gt_lambda_2\n    \n    return torch.distributions.Poisson(l).sample()\n\n\ndata = np.array([sample(day) for day in range(50)])\n\n\nplt.bar(range(50), data, color='orange')\nplt.xlabel(\"Day\")\nplt.ylabel(\"Number of daily cases\")\nplt.savefig(\"cases-raw.png\")\n\n\n\n\n\n\n\n\n\nplt.bar(range(50), data, color='orange')\nplt.xlabel(\"Day\")\nplt.ylabel(\"Number of daily cases\")\nplt.axhline(30, 0, 30/50, label='Before changepoint', lw=3, color='green')\nplt.axhline(40, 30/50, 1, label='After changepoint', lw=3, color='red')\nplt.axvline(30, label='Changepoint', lw=5, color='black', alpha=0.8, linestyle='--')\n\n\nplt.legend()\nplt.savefig(\"cases-annotated.png\")"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html#modelling",
    "href": "posts/2021-08-20-bayesian.html#modelling",
    "title": "Probabilistic Programming in Pyro",
    "section": "Modelling",
    "text": "Modelling\nWe will now assume that we received the data and need to create a model.\nWe choose the following model\n\\[C_{i} \\sim \\operatorname{Poisson}(\\lambda)\\]\n\\[\\lambda= \\begin{cases}\\lambda_{1} & \\text { if } t&lt;\\tau \\\\ \\lambda_{2} & \\text { if } t \\geq \\tau\\end{cases}\\]\n\\[\\begin{aligned}\n&\\lambda_{1} \\sim \\operatorname{Exp}(\\alpha) \\\\\n&\\lambda_{2} \\sim \\operatorname{Exp}(\\alpha)\n\\end{aligned}\n\\]\n\ndef model(data):\n    alpha = 1.0 / data.mean()\n    lambda_1 = pyro.sample(\"lambda_1\", dist.Exponential(alpha))\n    lambda_2 = pyro.sample(\"lambda_2\", dist.Exponential(alpha))\n    \n    tau = pyro.sample(\"tau\", dist.Uniform(0, 1))\n    lambda1_size = (tau * data.size(0) + 1).long()\n    lambda2_size = data.size(0) - lambda1_size\n    lambda_ = torch.cat([lambda_1.expand((lambda1_size,)),\n                         lambda_2.expand((lambda2_size,))])\n\n    with pyro.plate(\"data\", data.size(0)):\n        pyro.sample(\"obs\",dist.Poisson(lambda_), obs=data)"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html#inference-button",
    "href": "posts/2021-08-20-bayesian.html#inference-button",
    "title": "Probabilistic Programming in Pyro",
    "section": "Inference button",
    "text": "Inference button\n\nkernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True, max_tree_depth=3)\nposterior = MCMC(kernel, num_samples=5000, warmup_steps=2000)\nposterior.run(torch.from_numpy(data));\n\nSample: 100%|██████████| 7000/7000 [00:33, 210.22it/s, step size=1.06e-02, acc. prob=0.963]"
  },
  {
    "objectID": "posts/2021-08-20-bayesian.html#obtaining-and-plotting-the-posteriors",
    "href": "posts/2021-08-20-bayesian.html#obtaining-and-plotting-the-posteriors",
    "title": "Probabilistic Programming in Pyro",
    "section": "Obtaining and plotting the posteriors",
    "text": "Obtaining and plotting the posteriors\n\nhmc_samples = {k: v.detach().cpu().numpy() for k, v in posterior.get_samples().items()}\nlambda_1_samples = hmc_samples['lambda_1']\nlambda_2_samples = hmc_samples['lambda_2']\ntau_samples = (hmc_samples['tau'] * torch.from_numpy(data).size(0) + 1).astype(int)\n\n\nfig, ax  = plt.subplots(nrows=2, sharex=True)\nax[0].hist(lambda_1_samples, density=True)\nax[1].hist(lambda_2_samples, density=True)\nplt.suptitle(r\"Posterior distribution for $\\lambda$\")\nax[0].set_title(r\"$\\lambda_1$\")\nax[1].set_title(r\"$\\lambda_2$\")\n\nText(0.5, 1.0, '$\\\\lambda_2$')\n\n\n\n\n\n\n\n\n\n\n(pd.Series(tau_samples).value_counts()/5000).sort_index().plot(kind='bar',rot=0)\nplt.suptitle(r\"Posterior distribution for $\\tau$\")\nplt.xlabel(r\"$\\tau=k$\")\nplt.ylabel(r\"$P(\\tau=k)$\")\n\nText(0, 0.5, '$P(\\\\tau=k)$')\n\n\n\n\n\n\n\n\n\n\nIt seems from our posterior that we have obtained a fairly good estimate our simulation parameters."
  },
  {
    "objectID": "posts/2022-02-09-pytorch-learn-normal.html",
    "href": "posts/2022-02-09-pytorch-learn-normal.html",
    "title": "Maximum Likelihood Estimation (MLE) for parameters of univariate and multivariate normal distribution in PyTorch",
    "section": "",
    "text": "import torch\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\ndist = torch.distributions\n\n\nCreating a 1d normal distribution\n\nuv_normal = dist.Normal(loc=0.0, scale=1.0)\n\n\n\nSampling from the distribution\n\nsamples = uv_normal.sample(sample_shape=[1000])\n\n\nsns.histplot(samples)\nsns.despine()\n\n\n\n\n\n\n\n\n\nsns.kdeplot(samples, bw_adjust=2)\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nComputing logprob and prob at a given x\n\nsns.kdeplot(samples, bw_adjust=2)\nplt.axvline(0.5, color=\"k\", linestyle=\"--\")\nlog_pdf_05 = uv_normal.log_prob(torch.Tensor([0.5]))\n\n\npdf_05 = torch.exp(log_pdf_05)\n\n\nplt.title(\n    \"Density at x = 0.5 is {:.2f}\\n Logprob at x = 0.5 is {:.2f}\".format(\n        pdf_05.numpy()[0], log_pdf_05.numpy()[0]\n    )\n)\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nLearning parameters via MLE\nLet us generate some normally distributed data and see if we can learn the mean.\n\ntrain_data = uv_normal.sample([10000])\n\n\nuv_normal.loc, uv_normal.scale\n\n(tensor(0.), tensor(1.))\n\n\n\ntrain_data.mean(), train_data.std()\n\n(tensor(-0.0174), tensor(1.0049))\n\n\nThe above is the analytical MLE solution\n\nSetting 1: Fixed scale, learning only location\n\nloc = torch.tensor(-10.0, requires_grad=True)\nopt = torch.optim.Adam([loc], lr=0.01)\nfor i in range(3100):\n    to_learn = torch.distributions.Normal(loc=loc, scale=1.0)\n    loss = -torch.sum(to_learn.log_prob(train_data))\n    loss.backward()\n    if i % 500 == 0:\n        print(f\"Iteration: {i}, Loss: {loss.item():0.2f}, Loc: {loc.item():0.2f}\")\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 512500.16, Loc: -10.00\nIteration: 500, Loss: 170413.53, Loc: -5.61\nIteration: 1000, Loss: 47114.50, Loc: -2.58\nIteration: 1500, Loss: 18115.04, Loc: -0.90\nIteration: 2000, Loss: 14446.38, Loc: -0.22\nIteration: 2500, Loss: 14242.16, Loc: -0.05\nIteration: 3000, Loss: 14238.12, Loc: -0.02\n\n\n\nprint(\n    f\"MLE location gradient descent: {loc:0.2f}, MLE location analytical: {train_data.mean().item():0.2f}\"\n)\n\nMLE location gradient descent: -0.02, MLE location analytical: -0.02\n\n\n\n\nSetting 2: Learning location and scale\nAn important difference from the previous code is that we need to use a transformed variable to ensure scale is positive. We do so by using softplus.\n\nloc = torch.tensor(-10.0, requires_grad=True)\nscale = torch.tensor(2.0, requires_grad=True)\n\nopt = torch.optim.Adam([loc, scale], lr=0.01)\nfor i in range(5100):\n    scale_softplus = torch.functional.F.softplus(scale)\n\n    to_learn = torch.distributions.Normal(loc=loc, scale=scale_softplus)\n    loss = -torch.sum(to_learn.log_prob(train_data))\n    loss.backward()\n    if i % 500 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss.item():0.2f}, Loc: {loc.item():0.2f}, Scale: {scale_softplus.item():0.2f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 127994.02, Loc: -10.00, Scale: 2.13\nIteration: 500, Loss: 37320.10, Loc: -6.86, Scale: 4.15\nIteration: 1000, Loss: 29944.32, Loc: -4.73, Scale: 4.59\nIteration: 1500, Loss: 26326.08, Loc: -2.87, Scale: 4.37\nIteration: 2000, Loss: 22592.90, Loc: -1.19, Scale: 3.46\nIteration: 2500, Loss: 15968.47, Loc: -0.06, Scale: 1.63\nIteration: 3000, Loss: 14237.87, Loc: -0.02, Scale: 1.01\nIteration: 3500, Loss: 14237.87, Loc: -0.02, Scale: 1.00\nIteration: 4000, Loss: 14237.87, Loc: -0.02, Scale: 1.00\nIteration: 4500, Loss: 14237.87, Loc: -0.02, Scale: 1.00\nIteration: 5000, Loss: 14237.87, Loc: -0.02, Scale: 1.00\n\n\n\nprint(\n    f\"MLE loc gradient descent: {loc:0.2f}, MLE loc analytical: {train_data.mean().item():0.2f}\"\n)\nprint(\n    f\"MLE scale gradient descent: {scale_softplus:0.2f}, MLE scale analytical: {train_data.std().item():0.2f}\"\n)\n\nMLE loc gradient descent: -0.02, MLE loc analytical: -0.02\nMLE scale gradient descent: 1.00, MLE scale analytical: 1.00\n\n\n\nmvn = dist.MultivariateNormal(\n    loc=torch.zeros(2), covariance_matrix=torch.tensor([[1.0, 0.5], [0.5, 2.0]])\n)\n\n\nmvn_samples = mvn.sample([1000])\n\n\nsns.kdeplot(\n    x=mvn_samples[:, 0],\n    y=mvn_samples[:, 1],\n    zorder=0,\n    n_levels=10,\n    shade=True,\n    cbar=True,\n    thresh=0.001,\n    cmap=\"viridis\",\n    bw_adjust=5,\n    cbar_kws={\n        \"format\": \"%.3f\",\n    },\n)\n\nplt.gca().set_aspect(\"equal\")\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nSetting 1: Fixed scale, learning only location\n\nloc = torch.tensor([-10.0, 5.0], requires_grad=True)\nopt = torch.optim.Adam([loc], lr=0.01)\nfor i in range(4100):\n    to_learn = dist.MultivariateNormal(\n        loc=loc, covariance_matrix=torch.tensor([[1.0, 0.5], [0.5, 2.0]])\n    )\n    loss = -torch.sum(to_learn.log_prob(mvn_samples))\n    loss.backward()\n    if i % 500 == 0:\n        print(f\"Iteration: {i}, Loss: {loss.item():0.2f}, Loc: {loc}\")\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 81817.08, Loc: tensor([-10.,   5.], requires_grad=True)\nIteration: 500, Loss: 23362.23, Loc: tensor([-5.6703,  0.9632], requires_grad=True)\nIteration: 1000, Loss: 7120.20, Loc: tensor([-2.7955, -0.8165], requires_grad=True)\nIteration: 1500, Loss: 3807.52, Loc: tensor([-1.1763, -0.8518], requires_grad=True)\nIteration: 2000, Loss: 3180.41, Loc: tensor([-0.4009, -0.3948], requires_grad=True)\nIteration: 2500, Loss: 3093.31, Loc: tensor([-0.0965, -0.1150], requires_grad=True)\nIteration: 3000, Loss: 3087.07, Loc: tensor([-0.0088, -0.0259], requires_grad=True)\nIteration: 3500, Loss: 3086.89, Loc: tensor([ 0.0073, -0.0092], requires_grad=True)\nIteration: 4000, Loss: 3086.88, Loc: tensor([ 0.0090, -0.0075], requires_grad=True)\n\n\n\nloc, mvn_samples.mean(axis=0)\n\n(tensor([ 0.0090, -0.0075], requires_grad=True), tensor([ 0.0090, -0.0074]))\n\n\nWe can see that our approach yields the same results as the analytical MLE\n\n\nSetting 2: Learning scale and location\nWe need to now choose the equivalent of standard deviation in MVN case, this is the Cholesky matrix which should be a lower triangular matrix\n\nloc = torch.tensor([-10.0, 5.0], requires_grad=True)\ntril = torch.autograd.Variable(torch.tril(torch.ones(2, 2)), requires_grad=True)\nopt = torch.optim.Adam([loc, tril], lr=0.01)\n\nfor i in range(8100):\n    to_learn = dist.MultivariateNormal(loc=loc, covariance_matrix=tril @ tril.t())\n    loss = -torch.sum(to_learn.log_prob(mvn_samples))\n    loss.backward()\n    if i % 500 == 0:\n        print(f\"Iteration: {i}, Loss: {loss.item():0.2f}, Loc: {loc}\")\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 166143.42, Loc: tensor([-10.,   5.], requires_grad=True)\nIteration: 500, Loss: 9512.82, Loc: tensor([-7.8985,  3.2943], requires_grad=True)\nIteration: 1000, Loss: 6411.09, Loc: tensor([-6.4121,  2.5011], requires_grad=True)\nIteration: 1500, Loss: 5248.90, Loc: tensor([-5.0754,  1.8893], requires_grad=True)\nIteration: 2000, Loss: 4647.84, Loc: tensor([-3.8380,  1.3627], requires_grad=True)\nIteration: 2500, Loss: 4289.96, Loc: tensor([-2.6974,  0.9030], requires_grad=True)\nIteration: 3000, Loss: 4056.93, Loc: tensor([-1.6831,  0.5176], requires_grad=True)\nIteration: 3500, Loss: 3885.87, Loc: tensor([-0.8539,  0.2273], requires_grad=True)\nIteration: 4000, Loss: 3722.92, Loc: tensor([-0.2879,  0.0543], requires_grad=True)\nIteration: 4500, Loss: 3495.34, Loc: tensor([-0.0310, -0.0046], requires_grad=True)\nIteration: 5000, Loss: 3145.29, Loc: tensor([ 0.0089, -0.0075], requires_grad=True)\nIteration: 5500, Loss: 3080.54, Loc: tensor([ 0.0090, -0.0074], requires_grad=True)\nIteration: 6000, Loss: 3080.53, Loc: tensor([ 0.0090, -0.0074], requires_grad=True)\nIteration: 6500, Loss: 3080.53, Loc: tensor([ 0.0090, -0.0074], requires_grad=True)\nIteration: 7000, Loss: 3080.53, Loc: tensor([ 0.0090, -0.0074], requires_grad=True)\nIteration: 7500, Loss: 3080.53, Loc: tensor([ 0.0090, -0.0074], requires_grad=True)\nIteration: 8000, Loss: 3080.53, Loc: tensor([ 0.0090, -0.0074], requires_grad=True)\n\n\n\nto_learn.loc, to_learn.covariance_matrix\n\n(tensor([ 0.0090, -0.0074], grad_fn=&lt;AsStridedBackward0&gt;),\n tensor([[1.0582, 0.4563],\n         [0.4563, 1.7320]], grad_fn=&lt;ExpandBackward0&gt;))\n\n\n\nmle_loc = mvn_samples.mean(axis=0)\nmle_loc\n\ntensor([ 0.0090, -0.0074])\n\n\n\nmle_covariance = (\n    (mvn_samples - mle_loc).t() @ ((mvn_samples - mle_loc)) / mvn_samples.shape[0]\n)\nmle_covariance\n\ntensor([[1.0582, 0.4563],\n        [0.4563, 1.7320]])\n\n\nWe can see that our gradient based methods parameters match those of the MLE computed analytically.\nReferences\n\nhttps://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian\nhttps://forum.pyro.ai/t/mle-for-normal-distribution-parameters/3861/3\nhttps://ericmjl.github.io/notes/stats-ml/estimating-a-multivariate-gaussians-parameters-by-gradient-descent/"
  },
  {
    "objectID": "posts/2022-02-14-gmm.html",
    "href": "posts/2022-02-14-gmm.html",
    "title": "GMM",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- mixture-models- clustering- expectation-maximization- probabilistic-models- unsupervised-learningdate: ’2022-02-14’output-file: 2022-02-14-gmm.htmltitle: GMMtoc: true—\n\nimport torch\ndist = torch.distributions\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\n\n\nfrom wand.image import Image as WImage\nfrom wand.color import Color\nimg = WImage(filename='../pgm/gmm.pdf', resolution=400)\nimg.crop(500, 600, 2680, 1600)\nimg\n\n\n\n\n\n\n\n\n\nK = 3\n\nmu_1 = -1.\nmu_2 = 4.\nmu_3 = 10.\n\nsigma_1 = 2.\nsigma_2 = 1.\nsigma_3 = 1.5\n\nmu = torch.tensor([mu_1, mu_2, mu_3])\nsigma = torch.tensor([sigma_1, sigma_2, sigma_3])\n\n\ndists = dist.Normal(loc = mu, scale = sigma)\n\n\npi = torch.tensor([0.5, 0.25, 0.25])\nz = dist.Categorical(probs=pi)\n\n\nN = 1000\nsamples = {0: [], 1: [], 2: []}\nall_samples = []\nfor n in range(N):\n    z_n = z.sample()\n    mu_n = mu[z_n]\n    sigma_n = sigma[z_n]\n    x = dist.Normal(loc = mu_n, scale= sigma_n).sample()\n    samples[z_n.item()].append(x.item())\n    all_samples.append(x.item())\n\n\nfor k, v in samples.items():\n    print(k, len(v))\n\n0 502\n1 252\n2 246\n\n\n\nsns.kdeplot(samples[0], bw_adjust=2, color='red', label='Component 1')\nsns.kdeplot(samples[1], bw_adjust=2, color='green', label='Component 2')\nsns.kdeplot(samples[2], bw_adjust=2, color='blue', label='Component 3')\n\nsns.kdeplot(all_samples, bw_adjust=2, color='black', label='Mixture')\nsns.despine()\nplt.legend()\n#sns.kdeplot(samples_n, bw_adjust=2)\n\n\n\n\n\n\n\n\n\nmixture = dist.MixtureSameFamily(mixture_distribution=z, component_distribution=dists)\n\n\nsamples_n = mixture.sample([1000])\n\n\nmixture.mixture_distribution\n\nCategorical(probs: torch.Size([3]), logits: torch.Size([3]))\n\n\n\nsns.kdeplot(samples[0], bw_adjust=2, color='red', label='Component 1')\nsns.kdeplot(samples[1], bw_adjust=2, color='green', label='Component 2')\nsns.kdeplot(samples[2], bw_adjust=2, color='blue', label='Component 3')\n\nsns.kdeplot(all_samples, bw_adjust=2, color='black', label='Our Mixture')\nsns.despine()\nsns.kdeplot(samples_n, bw_adjust=2, color='purple', lw = 10, alpha=0.5, label='PyTorch Mixture')\nplt.legend()\n\n\n\n\n\n\n\n\n\nto_learn_locs = torch.tensor([0.0, 1.0, 2.0], requires_grad=True)\nto_learn_scales = torch.tensor([1.0, 1.0, 1.0], requires_grad=True)\nto_learn_scales_softplus = torch.functional.F.softplus(to_learn_scales)\nto_learn_dists = dist.Normal(loc=to_learn_locs, scale=to_learn_scales_softplus)\n\nto_learn_mix = torch.tensor([0.3, 0.4, 0.2], requires_grad=True)\n\nto_learn_mixture = dist.Categorical(probs=to_learn_mix)\noverall = dist.MixtureSameFamily(\n    mixture_distribution=to_learn_mixture, component_distribution=to_learn_dists\n)\n\n\ndef nll(loc, scale, mix):\n    to_learn_scales_softplus = torch.functional.F.softplus(scale)\n    to_learn_dists = dist.Normal(loc=loc, scale=to_learn_scales_softplus)\n    mix_softmax = torch.functional.F.softmax(mix)\n    to_learn_mixture = dist.Categorical(probs=mix_softmax)\n    overall = dist.MixtureSameFamily(\n        mixture_distribution=to_learn_mixture, component_distribution=to_learn_dists\n    )\n    return -torch.sum(overall.log_prob(samples))\n\n\nopt = torch.optim.Adam([to_learn_locs, to_learn_scales, to_learn_mix], lr=0.05)\nfor i in range(101):\n    loss =nll(to_learn_locs, to_learn_scales, to_learn_mix)\n    if i % 10 == 0:\n        print(f\"Iteration: {i}, Loss: {loss.item():0.2f}\")\n    loss.backward()\n    # loc_array.append(theta_learn_loc)\n    # loss_array.append(loss_val.item())\n\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 16368.27\nIteration: 10, Loss: 10628.43\nIteration: 20, Loss: 8328.17\nIteration: 30, Loss: 7339.84\nIteration: 40, Loss: 6849.51\nIteration: 50, Loss: 6566.24\nIteration: 60, Loss: 6376.24\nIteration: 70, Loss: 6226.55\nIteration: 80, Loss: 6086.78\nIteration: 90, Loss: 5958.18\nIteration: 100, Loss: 5888.01\n\n\n/var/folders/1x/wmgn24mn1bbd2vgbqlk98tbc0000gn/T/ipykernel_48017/2345747116.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  mix_softmax = torch.functional.F.softmax(mix)\n\n\n\nto_learn_locs\n\ntensor([-1.6593,  6.8915,  4.1946], requires_grad=True)\n\n\n\nto_learn_scales\n\ntensor([1.4718, 3.8919, 2.9224], requires_grad=True)\n\n\n\ns\n\ntensor([0.3407, 0.3356, 0.1757], requires_grad=True)\n\n\n\ntorch.functional.F.softmax(to_learn_mix)\n\n/var/folders/1x/wmgn24mn1bbd2vgbqlk98tbc0000gn/T/ipykernel_48017/1334526509.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  torch.functional.F.softmax(to_learn_mix)\n\n\ntensor([0.3518, 0.3500, 0.2983], grad_fn=&lt;SoftmaxBackward0&gt;)"
  },
  {
    "objectID": "posts/2022-02-11-pytorch-learn-normal-map.html",
    "href": "posts/2022-02-11-pytorch-learn-normal-map.html",
    "title": "Maximum A-Posteriori (MAP) for parameters of univariate and multivariate normal distribution in PyTorch",
    "section": "",
    "text": "import torch\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\ndist = torch.distributions\n\n\nCreating a 1d normal distribution\n\nuv_normal = dist.Normal(loc=0.0, scale=1.0)\n\n\n\nSampling from the distribution\n\nsamples = uv_normal.sample(sample_shape=[100])\n\n\nsns.kdeplot(samples, bw_adjust=2)\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nDefining the prior\n\nprior_mu = torch.tensor(5.0, requires_grad=True)\nprior = dist.Normal(loc=prior_mu, scale=1.0)\nprior\n\nNormal(loc: 5.0, scale: 1.0)\n\n\n\n\nComputing logprob of prior for a mu\n\ndef logprob_prior(mu):\n    return -prior.log_prob(mu)\n\n\n\nComputing logprob of observing data given a mu\n\nstdev_likelihood = 1.0\n\n\ndef log_likelihood(mu, samples):\n\n    to_learn = torch.distributions.Normal(loc=mu, scale=stdev_likelihood)\n    return -torch.sum(to_learn.log_prob(samples))\n\n\nmu = torch.tensor(-2.0, requires_grad=True)\n\nlog_likelihood(mu, samples), logprob_prior(mu)\nlog_likelihood(mu, samples).item()\n\n305.98101806640625\n\n\n\nout = {\"Logprob_Prior\": {}, \"LogLikelihood\": {}}\nfor mu_s in torch.linspace(-10, 10, 100):\n    t = mu_s.item()\n    mu = torch.tensor(mu_s)\n    out[\"Logprob_Prior\"][t] = logprob_prior(mu).item()\n    out[\"LogLikelihood\"][t] = log_likelihood(mu, samples).item()\n\n/var/folders/1x/wmgn24mn1bbd2vgbqlk98tbc0000gn/T/ipykernel_73152/3102909564.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  mu = torch.tensor(mu_s)\n\n\n\npd.DataFrame(out).plot(subplots=True)\n\narray([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\n\ndef loss(mu):\n    return log_likelihood(mu, samples) + logprob_prior(mu)\n\n\nmu = torch.tensor(2.0, requires_grad=True)\n\nopt = torch.optim.Adam([mu], lr=0.01)\nfor i in range(1500):\n    loss_val = loss(mu)\n    loss_val.backward()\n    if i % 100 == 0:\n        print(f\"Iteration: {i}, Loss: {loss_val.item():0.2f}, Loc: {mu.item():0.6f}\")\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 374.37, Loc: 2.000000\nIteration: 100, Loss: 222.93, Loc: 1.092788\nIteration: 200, Loss: 166.98, Loc: 0.468122\nIteration: 300, Loss: 152.88, Loc: 0.119012\nIteration: 400, Loss: 150.57, Loc: -0.034995\nIteration: 500, Loss: 150.33, Loc: -0.088207\nIteration: 600, Loss: 150.31, Loc: -0.102667\nIteration: 700, Loss: 150.31, Loc: -0.105761\nIteration: 800, Loss: 150.31, Loc: -0.106279\nIteration: 900, Loss: 150.31, Loc: -0.106346\nIteration: 1000, Loss: 150.31, Loc: -0.106352\nIteration: 1100, Loss: 150.31, Loc: -0.106353\nIteration: 1200, Loss: 150.31, Loc: -0.106353\nIteration: 1300, Loss: 150.31, Loc: -0.106353\nIteration: 1400, Loss: 150.31, Loc: -0.106353\n\n\n\n\nAnalytical MAP estimate of location\n\\(\\hat{\\theta}_{MAP}=\\dfrac{n}{n+\\sigma^{2}} \\bar{x}+\\dfrac{\\sigma^{2}}{n+\\sigma^{2}} \\mu\\)\n\nprior_mu\n\ntensor(5., requires_grad=True)\n\n\n\nn = samples.shape[0]\nsample_mean = samples.mean()\nn_plus_variance = n + stdev_likelihood**2\n\nloc_map = ((n * sample_mean) / n_plus_variance) + (\n    (stdev_likelihood**2) / (n_plus_variance)\n) * prior_mu\nloc_map.item()\n\n-0.1063527911901474\n\n\n\ntorch.allclose(loc_map, mu)\n\nTrue\n\n\n\nSetting 2: Learning location and scale\nAn important difference from the previous code is that we need to use a transformed variable to ensure scale is positive. We do so by using softplus.\n\nmu = torch.tensor(1.0, requires_grad=True)\nscale = torch.tensor(2.0, requires_grad=True)\n\n\ndef log_likelihood(mu, scale, samples):\n    scale_softplus = torch.functional.F.softplus(scale)\n    to_learn = torch.distributions.Normal(loc=mu, scale=scale_softplus)\n    return -torch.sum(to_learn.log_prob(samples))\n\n\ndef loss(mu, scale):\n    return log_likelihood(mu, scale, samples) + logprob_prior(mu)\n\n\nopt = torch.optim.Adam([mu, scale], lr=0.01)\nfor i in range(1500):\n    loss_val = loss(mu, scale)\n    loss_val.backward()\n    if i % 100 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss_val.item():0.2f}, Loc: {mu.item():0.3f}, Scale: {torch.functional.F.softplus(scale).item():0.3f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 200.89, Loc: 1.000, Scale: 2.127\nIteration: 100, Loss: 158.51, Loc: 0.086, Scale: 1.282\nIteration: 200, Loss: 149.98, Loc: -0.112, Scale: 0.942\nIteration: 300, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 400, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 500, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 600, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 700, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 800, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 900, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 1000, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 1100, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 1200, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 1300, Loss: 149.98, Loc: -0.112, Scale: 0.943\nIteration: 1400, Loss: 149.98, Loc: -0.112, Scale: 0.943\n\n\nWe can see that our gradient based methods parameters match those of the MLE computed analytically.\n\nmvn = dist.MultivariateNormal(\n    loc=torch.tensor([1.0, 1.0]),\n    covariance_matrix=torch.tensor([[2.0, 0.5], [0.5, 0.4]]),\n)\n\n\nmle_mvn_loc = mvn_samples = mvn.sample([1000])\n\n\nloss\n\n\nloc = torch.tensor([-1.0, 1.0], requires_grad=True)\ntril = torch.autograd.Variable(torch.tril(torch.ones(2, 2)), requires_grad=True)\nopt = torch.optim.Adam([loc, tril], lr=0.01)\n\nprior = dist.MultivariateNormal(\n    loc=torch.tensor([0.0, 0.0]),\n    covariance_matrix=torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n)\n\n\ndef log_likelihood(loc, tril, samples):\n    cov = tril @ tril.t()\n    to_learn = torch.distributions.MultivariateNormal(loc=loc, covariance_matrix=cov)\n    return -torch.sum(to_learn.log_prob(samples))\n\n\ndef logprob_prior(loc):\n    return -prior.log_prob(loc)\n\n\ndef loss(loc, tril, samples):\n    return log_likelihood(loc, tril, samples) + logprob_prior(loc)\n\n\nfor i in range(8100):\n    to_learn = dist.MultivariateNormal(loc=loc, covariance_matrix=tril @ tril.t())\n    loss_value = loss(loc, tril, mvn_samples)\n    loss_value.backward()\n    if i % 500 == 0:\n        print(f\"Iteration: {i}, Loss: {loss_value.item():0.2f}, Loc: {loc}\")\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 7663.86, Loc: tensor([-1.,  1.], requires_grad=True)\nIteration: 500, Loss: 2540.96, Loc: tensor([0.8229, 0.9577], requires_grad=True)\nIteration: 1000, Loss: 2526.40, Loc: tensor([1.0300, 1.0076], requires_grad=True)\nIteration: 1500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 2000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 2500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 3000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 3500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 4000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 4500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 5000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 5500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 6000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 6500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 7000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 7500, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\nIteration: 8000, Loss: 2526.40, Loc: tensor([1.0308, 1.0077], requires_grad=True)\n\n\n\ntril@tril.t(),mvn.covariance_matrix, prior.covariance_matrix\n\n(tensor([[1.9699, 0.4505],\n         [0.4505, 0.3737]], grad_fn=&lt;MmBackward0&gt;),\n tensor([[2.0000, 0.5000],\n         [0.5000, 0.4000]]),\n tensor([[1., 0.],\n         [0., 1.]]))\n\n\n\nTodo\n\n1. Expand on MVN case\n2. Clean up code\n3. Visualize, prior, likelihood, MLE, MAP \n4. Shrinkage estimation (reference Murphy book)\n5. Inverse Wishart distribution\n\nReferences\n\nhttps://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian\nhttps://forum.pyro.ai/t/mle-for-normal-distribution-parameters/3861/3\nhttps://ericmjl.github.io/notes/stats-ml/estimating-a-multivariate-gaussians-parameters-by-gradient-descent/\nhttps://www.youtube.com/watch?v=KogqeZ_88-g&list=PLD0F06AA0D2E8FFBA&index=32"
  },
  {
    "objectID": "posts/2024-forecast.html",
    "href": "posts/2024-forecast.html",
    "title": "Time Series Forecasting - Comparing MLP and Transformer Models",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange, reduce, repeat\nimport time\n\n\n# sine dataset\nX_whole = torch.linspace(0, 100, 10000)\ny_whole = torch.sin(X_whole)\n\n# split into train and test\nX_train = X_whole[:8000]\ny_train = y_whole[:8000]\n\nX_test = X_whole[8000:]\ny_test = y_whole[8000:]\n\n# plot\nplt.figure(figsize=(6, 4))\nplt.plot(X_train, y_train, label='train')\nplt.plot(X_test, y_test, label='test')\n\n\n\n\n\n\n\n\n\ny_train.shape\n\ntorch.Size([8000])\n\n\n\ncontext_length = 100 # history\nprediction_length = 10 # future to predict\n\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim, prediction_length):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.fc2 = nn.Linear(128, 128)\n        self.fc3 = nn.Linear(128, 128)\n        self.fc4 = nn.Linear(128, prediction_length)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n    \n\n\ni = 0\ny_train[i:i+context_length].shape, y_train[i+context_length:i+context_length+prediction_length].shape\n\n(torch.Size([100]), torch.Size([10]))\n\n\n\n# create training data\ndef create_train_data(X, y, context_length, prediction_length):\n    Xs, ys = [], []\n    for i in range(len(X) - context_length - prediction_length):\n        Xs.append(y[i:i+context_length])\n        ys.append(y[i+context_length:i+context_length+prediction_length])\n    return torch.stack(Xs), torch.stack(ys)\n\n\nXs, ys = create_train_data(X_train, y_train, context_length, prediction_length)\n\n\n# Plot the first training data example\nplt.figure(figsize=(6, 4))\nplt.plot(Xs[0], label='context (history)')\nplt.plot(range(context_length, context_length+prediction_length), ys[0], label='prediction (future)')\n\n\n\n\n\n\n\n\n\nmlp = MLP(context_length, prediction_length)\nprint(\"Number of parameters:\", sum(p.numel() for p in mlp.parameters()))\n\noptimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()\n\n# training loop\nn_epochs = 100\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n    y_pred = mlp(Xs)\n    loss = criterion(y_pred, ys)\n    loss.backward()\n    optimizer.step()\n    if epoch % 10 == 0:\n        print(f'Epoch {epoch} - Loss {loss.item():.4f} Time (s) {time.time() - start_time: .2f}')\n\nNumber of parameters: 47242\nEpoch 0 - Loss 0.4968 Time (s)  0.02\nEpoch 10 - Loss 0.1697 Time (s)  0.15\nEpoch 20 - Loss 0.0666 Time (s)  0.28\nEpoch 30 - Loss 0.0046 Time (s)  0.41\nEpoch 40 - Loss 0.0038 Time (s)  0.54\nEpoch 50 - Loss 0.0019 Time (s)  0.64\nEpoch 60 - Loss 0.0004 Time (s)  0.74\nEpoch 70 - Loss 0.0002 Time (s)  0.84\nEpoch 80 - Loss 0.0001 Time (s)  0.97\nEpoch 90 - Loss 0.0001 Time (s)  1.12\n\n\n\nX_test.shape, y_test.shape\n\n(torch.Size([2000]), torch.Size([2000]))\n\n\n\n# Test data\nXs_test, ys_test = create_train_data(X_test, y_test, context_length, prediction_length)\n\n\nXs_test.shape, ys_test.shape\n\n(torch.Size([1890, 100]), torch.Size([1890, 10]))\n\n\n\ny_hat = mlp(Xs_test)\n\n# compute the loss\nwith torch.no_grad():\n    loss = criterion(y_hat, ys_test)\nprint(f'Test Loss: {loss.item():0.4f}')\n\nTest Loss: 5.9333124227123335e-05\n\n\n\nXs_test.shape, y_hat.shape\n\n(torch.Size([1890, 100]), torch.Size([1890, 10]))\n\n\n\n# Plot the first test data example\ndef plot_prediction(i):\n    plt.figure(figsize=(6, 4))\n    plt.plot(Xs_test[i], label='context (history)')\n    plt.plot(range(context_length, context_length+prediction_length), ys_test[i], label='ground truth (future)')\n    plt.plot(range(context_length, context_length+prediction_length), y_hat[i].detach().numpy(), label='prediction (future)')\n    plt.legend()\n\nplot_prediction(0)\n\n\n\n\n\n\n\n\n\n# Simple Transformer\n\nclass Transformer(nn.Module):\n    def __init__(self, input_dim, prediction_length, num_heads=8, num_layers=3):\n        super(Transformer, self).__init__()\n        self.prediction_length = prediction_length\n        self.num_heads = num_heads\n        self.num_layers = num_layers\n        self.emb = nn.Linear(input_dim, 32)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=32, nhead=num_heads)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.fc = nn.Linear(32, prediction_length)\n        \n    def forward(self, x):\n        x = self.emb(x)\n        x = self.transformer_encoder(x)\n        x = self.fc(x)\n        return x\n\n\ntransormer = Transformer(context_length, prediction_length, num_heads=4, num_layers=3)\nprint(\"Number of parameters:\", sum(p.numel() for p in transormer.parameters()))\noptimizer = torch.optim.Adam(transormer.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()\n\n# training loop\nn_epochs = 100\n\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n    y_pred = transormer(Xs)\n    loss = criterion(y_pred, ys)\n    loss.backward()\n    optimizer.step()\n    if epoch % 10 == 0:\n        print(f'Epoch {epoch} - Loss {loss.item():.4f} Time {time.time() - start_time: .2f}')\n    \n\nNumber of parameters: 416074\nEpoch 0 - Loss 1.0997 Time  22.90\nEpoch 10 - Loss 0.0648 Time  181.78\nEpoch 20 - Loss 0.0348 Time  292.99\nEpoch 30 - Loss 0.0191 Time  410.26\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[110], line 14\n     12 y_pred = transormer(Xs)\n     13 loss = criterion(y_pred, ys)\n---&gt; 14 loss.backward()\n     15 optimizer.step()\n     16 if epoch % 10 == 0:\n\nFile ~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:487, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)\n    477 if has_torch_function_unary(self):\n    478     return handle_torch_function(\n    479         Tensor.backward,\n    480         (self,),\n   (...)\n    485         inputs=inputs,\n    486     )\n--&gt; 487 torch.autograd.backward(\n    488     self, gradient, retain_graph, create_graph, inputs=inputs\n    489 )\n\nFile ~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:200, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n    195     retain_graph = create_graph\n    197 # The reason we repeat same the comment below is that\n    198 # some Python versions print out the first line of a multi-line function\n    199 # calls in the traceback and some print out the last line\n--&gt; 200 Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n    201     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n    202     allow_unreachable=True, accumulate_grad=True)\n\nKeyboardInterrupt: \n\n\n\n\n# Prediction \n\nwith torch.no_grad():\n    y_hat = transormer(Xs_test)\n    loss = criterion(y_hat, ys_test)\n    print(f'Test Loss: {loss.item()}')  \n\nTest Loss: 0.017046289518475533\n\n\n\n# Plot the first test data example\nplot_prediction(0)\n\n\n\n\n\n\n\n\n\nfrom transformers import InformerForPrediction, InformerConfig\n\nconfig = InformerConfig(\n    input_dim=context_length,\n    prediction_length=prediction_length,\n    num_heads=4,\n    encoder_layers=2,\n    decoder_layers=2,\n    use_mask=True,\n    forecast=True\n)\n\ninformer = InformerForPrediction(config)\n\n\nsum(p.numel() for p in informer.parameters())\n\n134531\n\n\n\n# training loop\nn_epochs = 100\n\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n    y_pred = informer(Xs, past\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[117], line 7\n      5 for epoch in range(n_epochs):\n      6     optimizer.zero_grad()\n----&gt; 7     y_pred = informer(Xs)\n      8     loss = criterion(y_pred, ys)\n      9     loss.backward()\n\nFile ~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n\nTypeError: forward() missing 2 required positional arguments: 'past_time_features' and 'past_observed_mask'"
  },
  {
    "objectID": "posts/2022-10-27-calibration.html",
    "href": "posts/2022-10-27-calibration.html",
    "title": "Calibration",
    "section": "",
    "text": "import numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\n\nhttps://towardsdatascience.com/introduction-to-reliability-diagrams-for-probability-calibration-ed785b3f5d44\n\np = np.array([0.9, 0.2, 0.7, 0.4, 0.8, 0.1, 0.2, 0.8, 0.5, 0.9])\n\n\ntrue_labels = np.ones_like(p)\ntrue_labels[[1, 6, 7, 8]] = 0\ntrue_labels\n\narray([1., 0., 1., 1., 1., 1., 0., 0., 0., 1.])\n\n\n\nnum_splits = 3\n\n\nsplits_arr = np.linspace(0, 1, num_splits + 1)\nsplits = [(x, y) for (x, y) in zip(splits_arr[:-1], splits_arr[1:])]\nsplits\n\n[(0.0, 0.3333333333333333),\n (0.3333333333333333, 0.6666666666666666),\n (0.6666666666666666, 1.0)]\n\n\n\npd.cut(pd.Series(p), bins=splits_arr)\n\n0      (0.667, 1.0]\n1      (0.0, 0.333]\n2      (0.667, 1.0]\n3    (0.333, 0.667]\n4      (0.667, 1.0]\n5      (0.0, 0.333]\n6      (0.0, 0.333]\n7      (0.667, 1.0]\n8    (0.333, 0.667]\n9      (0.667, 1.0]\ndtype: category\nCategories (3, interval[float64, right]): [(0.0, 0.333] &lt; (0.333, 0.667] &lt; (0.667, 1.0]]\n\n\n\nsplits = np.digitize(p, splits_arr)\nsplits\n\narray([3, 1, 3, 2, 3, 1, 1, 3, 2, 3])\n\n\n\np_group = {}\nlabels_pos = {}\nfor group in np.unique(splits):\n    p_group[group] = p[splits==group]\n    #frac_pos[group] = true_labels[splits==group].sum()*1.0/len(p_group[group])\n    labels_pos[group] = true_labels[splits==group]\n    #print(np.arange(10)[splits==group])\n\n\np_group\n\n{1: array([0.2, 0.1, 0.2]),\n 2: array([0.4, 0.5]),\n 3: array([0.9, 0.7, 0.8, 0.8, 0.9])}\n\n\n\nlabels_pos\n\n{1: array([0., 1., 0.]), 2: array([1., 0.]), 3: array([1., 1., 1., 0., 1.])}\n\n\n\np_group_mean = {k:np.mean(v) for k, v in p_group.items()}\np_group_mean\n\n{1: 0.16666666666666666, 2: 0.45, 3: 0.8200000000000001}\n\n\n\nfracs = {k:np.sum(v)*1.0/len(v) for k, v in labels_pos.items()}\nfracs\n\n{1: 0.3333333333333333, 2: 0.5, 3: 0.8}\n\n\n\nplt.plot(p_group_mean.values(), fracs.values(), marker='*')\nplt.xlim((-0.05, 1.05))\nplt.ylim((-0.05, 1.05))\nplt.gca().set_aspect(\"equal\")\nplt.xlabel(\"p\")\nplt.ylabel(\"Relative frequency\")\n\nplt.plot([0, 1], [0, 1], color='k', ls='--', label='Ideal')\nplt.legend()\n\n\n\n\n\n\n\n\nLet us wrap into a function\n\ndef calib_curve(true, pred, n_bins = 10):\n    splits_arr = np.linspace(0, 1, n_bins + 1)\n    splits = np.digitize(pred, splits_arr)\n    p_group = {}\n    labels_pos = {}\n    for group in np.unique(splits):\n        p_group[group] = pred[splits==group]\n        labels_pos[group] = true[splits==group]\n    p_group_mean = {k:np.mean(v) for k, v in p_group.items()}\n    fracs = {k:np.sum(v)*1.0/len(v) for k, v in labels_pos.items()}\n    counts = np.array([len(v) for v in labels_pos.values()])\n    return  np.array(list(p_group_mean.values())), np.array(list(fracs.values())), counts\n\n\nfrom sklearn.calibration import calibration_curve, CalibrationDisplay\n\nprob_true, prob_pred = calibration_curve(true_labels, p, n_bins=3)\n\n\nprob_true\n\narray([0.33333333, 0.5       , 0.8       ])\n\n\n\nprob_pred\n\narray([0.16666667, 0.45      , 0.82      ])\n\n\n\np_ours, p_hat_ours, count = calib_curve(true_labels, p, 3)\np_ours\n\narray([0.16666667, 0.45      , 0.82      ])\n\n\nExpected Calibration Error\n\n(np.abs(p_ours-p_hat_ours)*count).mean()\n\n0.23333333333333336\n\n\n\nfrom sklearn.datasets import make_classification\n\n\nX, y = make_classification(n_features=2, n_informative=2, n_redundant=0, random_state=0)\n\n\nplt.scatter(X[:, 0], X[:, 1], c = y)\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LogisticRegression\n\n\nlr = LogisticRegression()\n\n\nlr.fit(X, y)\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\ndisplay = CalibrationDisplay.from_estimator(\n        lr,\n        X,\n        y,\n        n_bins=11,\n)\n\n\n\n\n\n\n\n\n\npred_p = lr.predict_proba(X)[:, 1]\n\n\nprobs, fractions, counts  = calib_curve(y, pred_p, 11)\n\n\nplt.plot(probs, fractions, marker='^')\nplt.xlabel(\"p\")\nplt.ylabel(\"Relative frequency\")\n\nplt.plot([0, 1], [0, 1], color='k', ls='--', label='Ideal')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.hist(pred_p);\n\n\n\n\n\n\n\n\n\n(np.abs(probs-fractions)*counts).mean()\n\n0.9530316314463302\n\n\n\ncounts\n\narray([18, 14, 13,  4,  2,  4,  2,  2,  6,  7, 28])"
  },
  {
    "objectID": "posts/2017-06-14-widgets-matplotlib.html",
    "href": "posts/2017-06-14-widgets-matplotlib.html",
    "title": "Data exploration using widgets in Matplotlib",
    "section": "",
    "text": "Imagine that you have to do data cleaning on 10s or 100s of sample points (akin to a row in a 2d matrix). For the purposes of data cleaning, you’d also need to zoom/pan at the data correpsonding to each sample point. Would you create 100s of static plots? We lose the zoom/pan ability there. How about we write a simple function and manually change the argument to reflect the sample #.\nIn this post, I’ll be looking at a simple Matplotlib widget to sift through the samples and retain the ability to pan and zoom. This post is heavily inspired by Jake Vanderplas’ PyData 2013 Matplotlib tutorial. I would be creating 15 timeseries having recorded daily for an year for illustration purposes.\n\nSetting the backend to TK.\nFor some reasons, it works better than the default OSX one.\n\n%matplotlib tk\n\n\n\nCustomary imports\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sys\n\n\n\nCreating the data\n\n# Fixing the seed for reproducibility\nnp.random.seed(0)\ndf = pd.DataFrame(np.random.randn(365, 15), index=pd.DatetimeIndex(start='2017',freq='D', periods=365))\n\n\ndf.head()[range(5)]\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\n2017-01-01\n1.764052\n0.400157\n0.978738\n2.240893\n1.867558\n\n\n2017-01-02\n0.333674\n1.494079\n-0.205158\n0.313068\n-0.854096\n\n\n2017-01-03\n0.154947\n0.378163\n-0.887786\n-1.980796\n-0.347912\n\n\n2017-01-04\n-0.438074\n-1.252795\n0.777490\n-1.613898\n-0.212740\n\n\n2017-01-05\n-0.672460\n-0.359553\n-0.813146\n-1.726283\n0.177426\n\n\n\n\n\n\n\n\nfig, ax  = plt.subplots()\ndf.plot(ax=ax)\n\nNotice, that since I used %matplotlib TK backend, I don’t see the plot embedded in the notebook. Thus I’ll save the current figure as an image and then link it here.\n\nplt.savefig(\"all_data.png\")\n\n\nThis sure does not look pretty.\n\n\nProposed solution\n\nGreat. It seems to do the intended job. Let us now look at the individual pieces and how we can tie them up.\n\n\nCreating the initial frame\nIn the first frame we would like to plot the data for the first sample.\nfig, ax = plt.subplots()\ndf[0].plot(ax=ax, title=\"Sample number: 0\")\n\n\nCreating the buttons at the bottom\nFirst, we’d want to make space for the button at the bottom and place them there. We can do this as follows:\nfrom matplotlib.widgets import Button\n\nfig.subplots_adjust(bottom=0.2)\n\naxprev = plt.axes([0.7, 0.05, 0.1, 0.075])\naxnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n\nbnext = Button(axnext, '&gt;')\nbprev = Button(axprev, '&lt;')\n\n\nLinking the buttons to functions\nWe’d next want to call some function each time either of the two buttons are pressed. We would also need a notion of currently selected data point. The idea would be that each time, &gt; is pressed, we advance the currently selected point and plot correspondingly.\nWe’d have to define next() and prev() where we increment and decrement the selected data point.\n\nclass Index:\n    data = df\n    selected = 0\n    \n    def next(self, event):\n        self.selected += 1\n        ax.cla()\n        df[self.selected].plot(ax=ax)\n        ax.set_title(\"Sample number: %d\" %self.selected)\n\n    def prev(self, event):\n        self.selected -= 1\n        ax.cla()\n        df[self.selected].plot(ax=ax)\n        ax.set_title(\"Sample number: %d\" %self.selected)\nHere, ax.cla() clears the data for the current data point before drawing for the next one. df[self.selected].plot(ax=ax) plots for the newly selected data. ax.set_title(\"Sample number: %d\" %self.selected) would change the title to reflect the currently used data point.\nWe can link to callback as follows:\ncallback = Index()\n\nbnext.on_clicked(callback.next)\nbprev.on_clicked(callback.prev)\n\n\nEnsuring we do not select data point out of range\nIf you notice, we simply incremented and decremented the selected data point without considering going beyond (0, number of data points). So, we need to change the call back functions to check that we do not go beyond the range. This would require the following changes to next() with the changes to prev() being similar.\ndata_min = 0\ndata_max = data.shape[1]-1\nselected = 0\ndef next(self, event):\n    if self.selected &gt;=self.data_max:\n        self.selected = self.data_max\n        ax.set_title('Last sample reached. Cannot go forwards')\n    else:\n        self.selected += 1\n        ax.cla()\n        df[self.selected].plot(ax=ax)\n        ax.set_title(\"Sample number: %d\" %self.selected)\nThere you go. This was fairly simple and fun to do, and yet can be very helpful!\n\n\nComplete code\n\nfrom matplotlib.widgets import Button\n\nfig, ax = plt.subplots()\nfig.subplots_adjust(bottom=0.2)\n\ndf[0].plot(ax=ax, title=\"Sample number: 0\")\n\nclass Index:\n    data = df\n    data_min = 0\n    data_max = data.shape[1]-1\n    selected = 0\n    def next(self, event):\n        if self.selected &gt;=self.data_max:\n            self.selected = self.data_max\n            ax.set_title('Last sample reached. Cannot go forwards')\n        else:\n            self.selected += 1\n            ax.cla()\n            df[self.selected].plot(ax=ax)\n            ax.set_title(\"Sample number: %d\" %self.selected)\n\n    def prev(self, event):\n        if self.selected &lt;=self.data_min:\n            self.selected = 0\n            ax.set_title('First sample reached. Cannot go backwards')\n        else:\n            self.selected -= 1\n            ax.cla()\n            df[self.selected].plot(ax=ax)\n            ax.set_title(\"Sample number: %d\" %self.selected)\n        \n\ncallback = Index()\naxprev = plt.axes([0.7, 0.05, 0.1, 0.075])\naxnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n\nbnext = Button(axnext, '&gt;')\nbnext.on_clicked(callback.next)\n\nbprev = Button(axprev, '&lt;')\nbprev.on_clicked(callback.prev)\n\n0\n\n\n\n\nAdvanced example\nHere is another slightly more advanced wideget use case in action.\n\nI will just put the code up here and leave the understanding upto the reader as an exercise.\n\nwith pd.HDFStore('temp-store.h5', mode='w') as st:\n\n    # 15 home-&gt; 2 columns, 365 rows (daily one reading)\n    for home in range(15):\n        df = pd.DataFrame(np.random.randn(365, 2), columns=['fridge','microwave'],\n                          index=pd.DatetimeIndex(start='2017',freq='D', periods=365))\n        df = df.abs()\n        st['/home_%d' %home] = df\n\n\nst = pd.HDFStore('temp-store.h5', mode='r')\n\n\nfrom matplotlib.widgets import Button, CheckButtons\n\nfig, ax = plt.subplots()\nfig.subplots_adjust(bottom=0.2)\nfig.subplots_adjust(left=0.2)\n\nhome_0 = st['/home_0']\n\nrax = plt.axes([0.02, 0.4, 0.13, 0.2], aspect='equal')\n\nlabels = tuple(home_0.columns)\nstates = tuple([True]*len(labels))\ncheck = CheckButtons(rax, labels, states)\n\n\nst['/home_0'].plot(ax=ax, title=\"Sample number: 0\").legend(loc=2)\nlines = ax.get_lines()\n\nclass Index:\n    store = st\n    data_min = 0\n    data_max = len(store.keys())-1\n    selected = 0\n    st, la = states, labels\n    states_dict = dict(zip(la, st))\n    def selected_column(self, label):\n        self.states_dict[label] = not self.states_dict[label]\n        self.plot()\n    \n    def plot(self):\n        ax.cla()\n        st['/home_%d' %self.selected].plot(ax=ax, title=\"Sample number: %d\" %self.selected).legend(loc=2)\n        lines = ax.get_lines()\n        for i ,(l, s) in enumerate(self.states_dict.items()):\n            lines[i].set_visible(s)\n        plt.legend(loc=1)\n        \n        \n    def next(self, event):\n        if self.selected &gt;=self.data_max:\n            self.selected = self.data_max\n            ax.set_title('Last sample reached. Cannot go forwards')\n        else:\n            self.selected += 1\n            self.plot()\n            \n\n    def prev(self, event):\n        if self.selected &lt;=self.data_min:\n            self.selected = 0\n            ax.set_title('First sample reached. Cannot go backwards')\n        else:\n            self.selected -= 1\n            self.plot()\n        \n\ncallback = Index()\naxprev = plt.axes([0.7, 0.05, 0.1, 0.075])\naxnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n\nbnext = Button(axnext, '&gt;')\nbnext.on_clicked(callback.next)\n\nbprev = Button(axprev, '&lt;')\nbprev.on_clicked(callback.prev)\n\ncheck.on_clicked(callback.selected_column);"
  },
  {
    "objectID": "posts/2022-11-20-binomial-poisson-distribution.html",
    "href": "posts/2022-11-20-binomial-poisson-distribution.html",
    "title": "Binomial and Poisson distribution",
    "section": "",
    "text": "import jax.numpy as jnp\nimport jax\nfrom jax import random\nimport tensorflow_probability.substrates.jax as tfp\ntfd = tfp.distributions\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nrandom.bernoulli(key=random.PRNGKey(0), p=0.6, shape=(10,)).astype(int).sum()\n\nWARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\nDeviceArray(7, dtype=int32)\n\n\n\nProbability of getting X heads\n\nfrom itertools import permutations\n\n\nset(permutations(['H', 'H', 'H', 'T'], 4 ))\n\n{('H', 'H', 'H', 'T'),\n ('H', 'H', 'T', 'H'),\n ('H', 'T', 'H', 'H'),\n ('T', 'H', 'H', 'H')}\n\n\n\nfrom sympy.utilities.iterables import multiset_permutations\n\n\nlist(multiset_permutations([True, True, False], 3))\n\n[[False, True, True], [True, False, True], [True, True, False]]\n\n\n\ndef print_permutations(n_heads=1, n_total=10):\n    init = ['H']*n_heads\n    init.extend(['T']*(n_total-n_heads))\n    permutations = list(multiset_permutations(init, n_total))\n    return permutations, len(permutations)\n\n\nperm, l = print_permutations()\n\n\nperm\n\n[['H', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T'],\n ['T', 'H', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T'],\n ['T', 'T', 'H', 'T', 'T', 'T', 'T', 'T', 'T', 'T'],\n ['T', 'T', 'T', 'H', 'T', 'T', 'T', 'T', 'T', 'T'],\n ['T', 'T', 'T', 'T', 'H', 'T', 'T', 'T', 'T', 'T'],\n ['T', 'T', 'T', 'T', 'T', 'H', 'T', 'T', 'T', 'T'],\n ['T', 'T', 'T', 'T', 'T', 'T', 'H', 'T', 'T', 'T'],\n ['T', 'T', 'T', 'T', 'T', 'T', 'T', 'H', 'T', 'T'],\n ['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'H', 'T'],\n ['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'H']]\n\n\n\nl\n\n10\n\n\n\nnum_sequences = {}\nfor n_heads in range(0, 11, 1):\n    _, num_sequences[n_heads] = print_permutations(n_heads=n_heads, n_total=10)\n\n\nnum_sequences = pd.Series(num_sequences)\nnum_sequences\n\n0       1\n1      10\n2      45\n3     120\n4     210\n5     252\n6     210\n7     120\n8      45\n9      10\n10      1\ndtype: int64\n\n\n\nnum_sequences.plot(xlabel=\"Heads\", ylabel=\"Permutations\")\n\n\n\n\n\n\n\n\n\nfrom math import comb\ncomb(10, 3)\n\n120\n\n\n\npd.Series(list(map(partial(comb, 10), range(0, 11))))\n\n0       1\n1      10\n2      45\n3     120\n4     210\n5     252\n6     210\n7     120\n8      45\n9      10\n10      1\ndtype: int64\n\n\n\n### Probability of given sequence\n\n\ndef prob_sequence(n_heads = 5, n_total = 10, p_head = 0.3):\n    return (p_head**n_heads)*(1-p_head)**(n_total-n_heads)\n\n\nfrom functools import partial\n\n\nprob_sequence(0, 10, 0.3)\n\n0.02824752489999998\n\n\n\nprob_sequence_fixed_p = partial(prob_sequence, n_total=10, p_head=0.3)\n\n\nprobs = prob_sequence_fixed_p(num_sequences.index)*num_sequences\nprobs\n\n0     0.028248\n1     0.121061\n2     0.233474\n3     0.266828\n4     0.200121\n5     0.102919\n6     0.036757\n7     0.009002\n8     0.001447\n9     0.000138\n10    0.000006\ndtype: float64\n\n\n\nprobs.plot()\n\n\n\n\n\n\n\n\n\nimport rich\n\n\nrich.inspect(tfd.Binomial)\n\n╭───── &lt;class 'tensorflow_probability.substrates.jax.distributions.binomial.Binomial'&gt; ─────╮\n│ class Binomial(total_count, logits=None, probs=None, validate_args=False,                 │\n│ allow_nan_stats=True, name=None):                                                         │\n│                                                                                           │\n│ Binomial distribution.                                                                    │\n│                                                                                           │\n│               allow_nan_stats = &lt;property object at 0x1a7594310&gt;                          │\n│                   batch_shape = &lt;property object at 0x1a7594400&gt;                          │\n│                         dtype = &lt;property object at 0x1a7594220&gt;                          │\n│                   event_shape = &lt;property object at 0x1a7594450&gt;                          │\n│ experimental_shard_axis_names = &lt;property object at 0x1a75943b0&gt;                          │\n│                        logits = &lt;property object at 0x1a75f79a0&gt;                          │\n│                          name = &lt;property object at 0x1a75941d0&gt;                          │\n│                    parameters = &lt;property object at 0x1a7594270&gt;                          │\n│                         probs = &lt;property object at 0x1a75f79f0&gt;                          │\n│       reparameterization_type = &lt;property object at 0x1a75942c0&gt;                          │\n│                   total_count = &lt;property object at 0x1a75f7950&gt;                          │\n│           trainable_variables = &lt;property object at 0x115bf0f40&gt;                          │\n│                 validate_args = &lt;property object at 0x1a7594360&gt;                          │\n│                     variables = &lt;property object at 0x115bf0f90&gt;                          │\n╰───────────────────────────────────────────────────────────────────────────────────────────╯\n\n\n\n\nfrom scipy.special import comb as scomb\n\n\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass OurBinomial:\n    total_count: int = 10\n    probs: float = 0.5\n\n    def __repr__(self):\n        return (\n            \"Binomial distribution\"\n            + \"\\n\"\n            + \"---------------------\\n\"\n            + f\"P(H) = {self.probs}\\nTotal Count = {self.total_count}\"\n        )\n\n    def mode(self):\n        return self.probs * self.total_count\n\n    def prob(self, observed_num_heads):\n        # (N choose K)*(p**n_h)*(1-p)**n_t\n        return (\n            comb(self.total_count, observed_num_heads)\n            * (self.probs**observed_num_heads)\n            * (1 - self.probs) ** (self.total_count - observed_num_heads)\n        )\n\n    def logprob(self, observed_num_heads):\n        return (\n            jnp.log(comb(self.total_count, observed_num_heads))\n            + observed_num_heads * jnp.log(self.probs)\n            + (self.total_count - observed_num_heads) * jnp.log(1 - self.probs)\n        )\n\n\nc = OurBinomial(probs=0.3)\nc\n\nBinomial distribution\n---------------------\nP(H) = 0.3\nTotal Count = 10\n\n\n\nc.total_count\n\n10\n\n\n\ntfp_bin = tfd.Binomial(total_count=10, probs=0.3)\n\n\ntfp_bin.mode()\n\nDeviceArray(3., dtype=float32)\n\n\n\nc.mode()\n\n3.0\n\n\n\ntfp_bin.prob(2)\n\nDeviceArray(0.23347428, dtype=float32)\n\n\n\ncomb(10, 3)\n\n120\n\n\n\nc.prob(2)\n\n0.23347444049999988\n\n\n\njnp.allclose(c.prob(2), tfp_bin.prob(2))\n\nDeviceArray(True, dtype=bool)\n\n\n\ntfp_bin.log_prob(2)\n\nDeviceArray(-1.4546833, dtype=float32)\n\n\n\nc.logprob(2)\n\nDeviceArray(-1.4546828, dtype=float32)\n\n\n\nbinomial_dict = {}\n# Divide hour in 10 intervals\n\nbinomial_dict[10] = OurBinomial(total_count=10, probs=0.3).prob(5)\n\n\nbinomial_dict\n\n{10: 0.10291934519999994}\n\n\n\nfor interval in [10, 20, 60, 1000, 10000]:\n    binomial_dict[interval] = OurBinomial(total_count=interval, probs=3.0/interval).prob(5)\n\n\nbinomial_dict\n\n{10: 0.10291934519999994,\n 20: 0.10284517954557212,\n 60: 0.10161579161609695,\n 1000: 0.10086908328293617,\n 10000: 0.10082385299843205}\n\n\n\npd.Series(binomial_dict).plot(logx=True)"
  },
  {
    "objectID": "posts/positional-encoding.html",
    "href": "posts/positional-encoding.html",
    "title": "Positional Encoding",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\n\ndist =torch.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n# Generate complex data\nx = np.linspace(-2, 2, 100)\nfreq = lambda x: x**2\nf = lambda x: np.sin(2 * np.pi * x * freq(x))\ny = f(x) + np.random.randn(x.shape[0]) * 0.1\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.plot(x, y, 'o', label='data')\nplt.plot(x, f(x), label='true function')\nplt.legend()\n\n\n\n\n\n\n\n\n\n# Learn linear model on data\nfrom sklearn.linear_model import LinearRegression, Ridge\n\nlr1 = Ridge()\nlr1.fit(x.reshape(-1, 1), y.reshape(-1, 1))\n\n# Predict on linspace and plot\ny_pred = lr1.predict(x.reshape(-1, 1))\nplt.figure(figsize=(8, 5))\nplt.plot(x, y, 'o', label='data')\nplt.plot(x, f(x), label='true function')\nplt.plot(x, y_pred, label='linear model')\n\n\n\n\n\n\n\n\n\n# Add position encoding\n# Gamma(x) = [sin(2^0*pi*x), cos(2^0*pi*x), sin(2^1*pi*x), cos(2^1*pi*x), ..., sin(2^k*pi*x), cos(2^k*pi*x)]\n\ndef gamma(x, k):\n    \"\"\"\n    x: (N, 1)\n    k: int\n    Output: (N, 2k)\n    \"\"\"\n    x = x.reshape(-1, 1)\n    x = np.repeat(x, k, axis=1)\n    x = x * (2 ** np.arange(k) * np.pi)\n    z = np.concatenate([np.sin(x), np.cos(x)], axis=1)\n    # Concatenate x and z\n    z = np.concatenate([x, z], axis=1)\n    return z\n\n\nplt.plot(x, gamma(x, 2), alpha=0.2, color='k')\n\n\n\n\n\n\n\n\n\n# Fit linear model with position encoding for k\n\ndef fit_plot(x, k):\n    lr = Ridge()\n    X_new = gamma(x, k)\n    lr.fit(X_new, y.reshape(-1, 1))\n    y_pred = lr.predict(X_new)\n    plt.figure(figsize=(8, 5))\n    plt.plot(x, y, 'o', label='data')\n    plt.plot(x, f(x), label='true function')\n    plt.plot(x, y_pred, label='linear model with position encoding of order {}'.format(k), lw=3)\n    # Legend outside plot\n    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n    # Title is the score\n    plt.title('Score: {:.2f}'.format(lr.score(X_new, y.reshape(-1, 1))))\n\n    # Show extrapolation also\n    # extrapolation points are set difference between linspace and data points\n    \n    x_extra = np.linspace(-3, 3, 100)\n    X_extra = gamma(x_extra, k)\n    y_extra = lr.predict(X_extra)\n    plt.plot(x_extra, y_extra, '--', label='extrapolation', alpha=0.2)\n    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    \n    \n\n\nfit_plot(x, 1)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/home/nipun.batra/git/blog/posts/positional-encoding.ipynb Cell 8 in &lt;module&gt;\n----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/positional-encoding.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'&gt;1&lt;/a&gt; fit_plot(x, 1)\n\n/home/nipun.batra/git/blog/posts/positional-encoding.ipynb Cell 8 in fit_plot(x, k)\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/positional-encoding.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'&gt;4&lt;/a&gt; lr = Ridge()\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/positional-encoding.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'&gt;5&lt;/a&gt; X_new = gamma(x, k)\n----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/positional-encoding.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'&gt;6&lt;/a&gt; lr.fit(X_new, y.reshape(-1, 1))\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/positional-encoding.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'&gt;7&lt;/a&gt; y_pred = lr.predict(X_new)\n      &lt;a href='vscode-notebook-cell://ssh-remote%2B10.0.62.168/home/nipun.batra/git/blog/posts/positional-encoding.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'&gt;8&lt;/a&gt; plt.figure(figsize=(8, 5))\n\nFile ~/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:1003, in Ridge.fit(self, X, y, sample_weight)\n    983 \"\"\"Fit Ridge regression model.\n    984 \n    985 Parameters\n   (...)\n   1000     Fitted estimator.\n   1001 \"\"\"\n   1002 _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X), self.solver)\n-&gt; 1003 X, y = self._validate_data(\n   1004     X,\n   1005     y,\n   1006     accept_sparse=_accept_sparse,\n   1007     dtype=[np.float64, np.float32],\n   1008     multi_output=True,\n   1009     y_numeric=True,\n   1010 )\n   1011 return super().fit(X, y, sample_weight=sample_weight)\n\nFile ~/miniforge3/lib/python3.9/site-packages/sklearn/base.py:581, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)\n    579         y = check_array(y, **check_y_params)\n    580     else:\n--&gt; 581         X, y = check_X_y(X, y, **check_params)\n    582     out = X, y\n    584 if not no_val_X and check_params.get(\"ensure_2d\", True):\n\nFile ~/miniforge3/lib/python3.9/site-packages/sklearn/utils/validation.py:981, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\n    964 X = check_array(\n    965     X,\n    966     accept_sparse=accept_sparse,\n   (...)\n    976     estimator=estimator,\n    977 )\n    979 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric)\n--&gt; 981 check_consistent_length(X, y)\n    983 return X, y\n\nFile ~/miniforge3/lib/python3.9/site-packages/sklearn/utils/validation.py:332, in check_consistent_length(*arrays)\n    330 uniques = np.unique(lengths)\n    331 if len(uniques) &gt; 1:\n--&gt; 332     raise ValueError(\n    333         \"Found input variables with inconsistent numbers of samples: %r\"\n    334         % [int(l) for l in lengths]\n    335     )\n\nValueError: Found input variables with inconsistent numbers of samples: [100, 768]\n\n\n\n\nfit_plot(x, 2)\n\n\n\n\n\n\n\n\n\nfit_plot(x, 3)\n\n\n\n\n\n\n\n\n\nfit_plot(x, 7)\n\n\n\n\n\n\n\n\n\nfit_plot(x, 10)\n\n\n\n\n\n\n\n\n\nfit_plot(x, 70)\n\n\n\n\n\n\n\n\n\n!wget https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv\n\n--2023-06-09 15:39:49--  https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv\nResolving gml.noaa.gov (gml.noaa.gov)... 140.172.200.41, 2610:20:8800:6101::29\nConnecting to gml.noaa.gov (gml.noaa.gov)|140.172.200.41|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 38018 (37K) [text/csv]\nSaving to: ‘co2_mm_mlo.csv’\n\nco2_mm_mlo.csv      100%[===================&gt;]  37.13K   146KB/s    in 0.3s    \n\n2023-06-09 15:39:51 (146 KB/s) - ‘co2_mm_mlo.csv’ saved [38018/38018]\n\n\n\n\ndf = pd.read_csv('co2_mm_mlo.csv', header=None, skiprows=72)\n\n\nX = df.index.values\ny = df[3].values.reshape(-1, 1)\n\n\nplt.plot(X, y)"
  },
  {
    "objectID": "posts/2023-12-21-towards-transformers.html",
    "href": "posts/2023-12-21-towards-transformers.html",
    "title": "Towards Transformers",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- transformers- attention-mechanism- deep-learning- neural-networks- nlp- sequence-modeling- pytorchdate: ’2023-12-21’title: Towards Transformerstoc: true—\n\nBasic Imports\n\nimport tiktoken\n\n\nencoding = tiktoken.get_encoding(\"cl100k_base\")\n\n\nencoding.encode(\"Hello World! This is a simple notebook\")\n\n[9906, 4435, 0, 1115, 374, 264, 4382, 38266]\n\n\n\nencoding.decode([9906, 4435, 0, 1115])\n\n'Hello World! This'\n\n\n\nser = {}\nn =20\nfor i in range(n**2):\n    ser[i] = encoding.decode([i])\n\n\nimport pandas as pd\n\n\npd.DataFrame(pd.Series(ser).values.reshape(n,n))\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n\n0\n!\n\"\n#\n$\n%\n&\n'\n(\n)\n*\n+\n,\n-\n.\n/\n0\n1\n2\n3\n4\n\n\n1\n5\n6\n7\n8\n9\n:\n;\n&lt;\n=\n&gt;\n?\n@\nA\nB\nC\nD\nE\nF\nG\nH\n\n\n2\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\nU\nV\nW\nX\nY\nZ\n[\n\\\n\n\n3\n]\n^\n_\n`\na\nb\nc\nd\ne\nf\ng\nh\ni\nj\nk\nl\nm\nn\no\np\n\n\n4\nq\nr\ns\nt\nu\nv\nw\nx\ny\nz\n{\n|\n}\n~\n�\n�\n�\n�\n�\n�\n\n\n5\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n\n\n6\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n\n\n7\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n\n\n8\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n\n\n9\n�\n�\n�\n�\n�\n�\n�\n�\n\n\u0001\n\u0002\n\u0003\n\u0004\n\u0005\n\u0006\n\u0007\n\b\n\\t\n\\n\n\n\n\n10\n\n\\r\n\u000e\n\u000f\n\u0010\n\u0011\n\u0012\n\u0013\n\u0014\n\u0015\n\u0016\n\u0017\n\u0018\n\u0019\n\u001a\n\u001b\n\n\n\n\n\n\n11\n\n\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n\n\n12\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n\n\nin\nt\n\n\n13\n\ner\n\non\na\nre\nat\nst\nen\nor\nth\n\\n\\n\nc\nle\ns\nit\nan\nar\nal\nthe\n\n\n14\n;\\n\np\nf\nou\n=\nis\n\ning\nes\nw\nion\ned\nic\nb\nd\net\nm\no\n\\t\\t\nro\n\n\n15\nas\nel\nct\nnd\nin\nh\nent\nid\nn\nam\n\nto\nre\n--\n{\nof\nom\n);\\n\nim\n\\r\\n\n\n\n16\n(\nil\n//\nand\nur\nse\nl\nex\nS\nad\n\"\nch\nut\nif\n**\n}\nem\nol\n\nth\n\n\n17\n)\\n\n{\\n\ng\nig\niv\n,\\n\nce\nod\nv\nate\nT\nag\nay\n*\not\nus\nC\nst\nI\nun\n\n\n18\nul\nue\nA\now\n'\new\n&lt;\nation\n()\nfor\nab\nort\num\name\nis\npe\ntr\nck\n�\ny\n\n\n19\nist\n----\n.\\n\\n\nhe\ne\nlo\nM\nbe\ners\non\ncon\nap\nub\nP\n\nass\nint\n&gt;\\n\nly\nurn"
  },
  {
    "objectID": "posts/2022-02-09-autograd-pytorch-jax.html",
    "href": "posts/2022-02-09-autograd-pytorch-jax.html",
    "title": "Autograd in JAX and PyTorch",
    "section": "",
    "text": "Basic Imports\n\nimport torch\nfrom jax import grad\nimport jax.numpy as jnp\n\n\n\nCreating scalar variables in PyTorch\n\nx_torch = torch.autograd.Variable(torch.tensor(1.), requires_grad=True)\ny_torch = torch.autograd.Variable(torch.tensor(1.), requires_grad=True)\n\n\n\nCreating scalar variables in JAX\n\nx_jax = jnp.array(1.)\ny_jax = jnp.array(1.)\n\nWARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\n\n\nDefining a loss on scalar inputs\n\ndef loss(x, y):\n    return x*x + y*y\n\n\n\nComputing the loss on PyTorch input\n\nl_torch  = loss(x_torch, y_torch)\nl_torch\n\ntensor(2., grad_fn=&lt;AddBackward0&gt;)\n\n\n\n\nComputing the loss on JAX input\n\nl_jax = loss(x_jax, y_jax)\n\n\n\nComputing the gradient on PyTorch input\n\nl_torch.backward()\nx_torch.grad, y_torch.grad\n\n(tensor(2.), tensor(2.))\n\n\n\n\nComputing the gradient on JAX input\n\ngrad_loss = grad(loss, argnums=[0, 1])\ngrad_loss(x_jax, y_jax)\n\n(DeviceArray(2., dtype=float32, weak_type=True),\n DeviceArray(2., dtype=float32, weak_type=True))\n\n\n\n\nRepeating the same procedure as above for both libraries but instead using vector function\n\ndef loss(theta):\n    return theta.T@theta\n\n\ntheta_torch = torch.autograd.Variable(torch.tensor([1., 1.]), requires_grad=True)\n\n\ntheta_torch\n\ntensor([1., 1.], requires_grad=True)\n\n\n\nl = loss(theta_torch)\nl\n\ntensor(2., grad_fn=&lt;DotBackward0&gt;)\n\n\n\nl.backward()\ntheta_torch.grad\n\ntensor([2., 2.])\n\n\n\ntheta_jax = jnp.array([1., 1.])\n\n\nloss(theta_jax)\n\nDeviceArray(2., dtype=float32)\n\n\n\ngrad_loss = grad(loss, argnums=[0])\n\n\ngrad_loss(theta_jax)\n\n(DeviceArray([2., 2.], dtype=float32),)"
  },
  {
    "objectID": "posts/2022-02-17-pyro-linreg.html",
    "href": "posts/2022-02-17-pyro-linreg.html",
    "title": "Linear Regression using Pyro",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\n\nt_dist =torch.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n\nCreating dataset\n\nx = torch.linspace(-5, 5, 200)\ntrue_y = 3*x + 4 \nobserved_y = true_y+ 2*torch.randn(200)\n\nplt.scatter(x, observed_y, s = 30, alpha=0.5)\nplt.plot(x, true_y, color = 'k')\n\n\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nMLE\n\nimport pyro\nimport pyro.distributions as dist\nimport pyro.distributions.constraints as constraints\n\npyro.clear_param_store()\n\n\ndef mle_model(x, y=None):\n    theta_0 = pyro.param(\"theta_0\", torch.randn(1))\n    theta_1 = pyro.param(\"theta_1\", torch.randn(1))\n    y_hat_mean = theta_0 + theta_1*x\n\n    with pyro.plate(\"data\", len(x)):\n        return pyro.sample(\"obs\", dist.Normal(y_hat_mean, 1), obs=y)\n\n#pyro.render_model(mle_model, model_args=(x, observed_y))\n\n\nm = mle_model(x)\npyro.param(\"theta_0\").item(), pyro.param(\"theta_1\").item()\n\n(-0.100727379322052, 1.5172470808029175)\n\n\n\nfor i in range(5):\n    plt.scatter(x, mle_model(x).detach(), s = 5, alpha = 0.4)\n    plt.plot(x, )\n\n\n\n\n\n\n\n\n\ndef guide(x, y):\n    # register the two variational parameters with Pyro.\n    pyro.sample(\"theta_0\", dist.Normal(0., 1.))\n    pyro.sample(\"theta_1\", dist.Normal(0., 1.))\n\n\npyro.render_model(guide, model_args=(x, observed_y))\n\n\n\n\n\n\n\n\n\nfrom pyro.optim import Adam\nfrom pyro.infer import SVI, Trace_ELBO\nadam_params = {\"lr\": 0.005, \"betas\": (0.90, 0.999)}\noptimizer = Adam(adam_params)\n\n# setup the inference algorithm\nsvi = SVI(mle_model, guide, optimizer, loss=Trace_ELBO())\n\nn_steps = 5000\n# do gradient steps\nfor step in range(n_steps):\n    svi.step(x, y)\n    if step%110==0:\n        print(pyro.param(\"theta_0\").item(), pyro.param(\"theta_1\").item())\n\n/Users/nipun/miniforge3/lib/python3.9/site-packages/pyro/util.py:288: UserWarning: Found non-auxiliary vars in guide but not model, consider marking these infer={'is_auxiliary': True}:\n{'theta_1', 'theta_0'}\n  warnings.warn(\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/poutine/trace_struct.py:230, in Trace.compute_log_prob(self, site_filter)\n    229 try:\n--&gt; 230     log_p = site[\"fn\"].log_prob(\n    231         site[\"value\"], *site[\"args\"], **site[\"kwargs\"]\n    232     )\n    233 except ValueError as e:\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/distributions/normal.py:73, in Normal.log_prob(self, value)\n     72 if self._validate_args:\n---&gt; 73     self._validate_sample(value)\n     74 # compute the variance\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/distributions/distribution.py:276, in Distribution._validate_sample(self, value)\n    275     if i != 1 and j != 1 and i != j:\n--&gt; 276         raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\n    277                          format(actual_shape, expected_shape))\n    278 try:\n\nValueError: Value is not broadcastable with batch_shape+event_shape: torch.Size([100]) vs torch.Size([200]).\n\nThe above exception was the direct cause of the following exception:\n\nValueError                                Traceback (most recent call last)\nInput In [117], in &lt;module&gt;\n     10 # do gradient steps\n     11 for step in range(n_steps):\n---&gt; 12     svi.step(x, y)\n     13     if step%110==0:\n     14         print(pyro.param(\"theta_0\").item(), pyro.param(\"theta_1\").item())\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/svi.py:145, in SVI.step(self, *args, **kwargs)\n    143 # get loss and compute gradients\n    144 with poutine.trace(param_only=True) as param_capture:\n--&gt; 145     loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\n    147 params = set(\n    148     site[\"value\"].unconstrained() for site in param_capture.trace.nodes.values()\n    149 )\n    151 # actually perform gradient steps\n    152 # torch.optim objects gets instantiated for any params that haven't been seen yet\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:140, in Trace_ELBO.loss_and_grads(self, model, guide, *args, **kwargs)\n    138 loss = 0.0\n    139 # grab a trace from the generator\n--&gt; 140 for model_trace, guide_trace in self._get_traces(model, guide, args, kwargs):\n    141     loss_particle, surrogate_loss_particle = self._differentiable_loss_particle(\n    142         model_trace, guide_trace\n    143     )\n    144     loss += loss_particle / self.num_particles\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/elbo.py:182, in ELBO._get_traces(self, model, guide, args, kwargs)\n    180 else:\n    181     for i in range(self.num_particles):\n--&gt; 182         yield self._get_trace(model, guide, args, kwargs)\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/trace_elbo.py:57, in Trace_ELBO._get_trace(self, model, guide, args, kwargs)\n     52 def _get_trace(self, model, guide, args, kwargs):\n     53     \"\"\"\n     54     Returns a single trace from the guide, and the model that is run\n     55     against it.\n     56     \"\"\"\n---&gt; 57     model_trace, guide_trace = get_importance_trace(\n     58         \"flat\", self.max_plate_nesting, model, guide, args, kwargs\n     59     )\n     60     if is_validation_enabled():\n     61         check_if_enumerated(guide_trace)\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/enum.py:75, in get_importance_trace(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\n     72 guide_trace = prune_subsample_sites(guide_trace)\n     73 model_trace = prune_subsample_sites(model_trace)\n---&gt; 75 model_trace.compute_log_prob()\n     76 guide_trace.compute_score_parts()\n     77 if is_validation_enabled():\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/poutine/trace_struct.py:236, in Trace.compute_log_prob(self, site_filter)\n    234     _, exc_value, traceback = sys.exc_info()\n    235     shapes = self.format_shapes(last_site=site[\"name\"])\n--&gt; 236     raise ValueError(\n    237         \"Error while computing log_prob at site '{}':\\n{}\\n{}\".format(\n    238             name, exc_value, shapes\n    239         )\n    240     ).with_traceback(traceback) from e\n    241 site[\"unscaled_log_prob\"] = log_p\n    242 log_p = scale_and_mask(log_p, site[\"scale\"], site[\"mask\"])\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/poutine/trace_struct.py:230, in Trace.compute_log_prob(self, site_filter)\n    228 if \"log_prob\" not in site:\n    229     try:\n--&gt; 230         log_p = site[\"fn\"].log_prob(\n    231             site[\"value\"], *site[\"args\"], **site[\"kwargs\"]\n    232         )\n    233     except ValueError as e:\n    234         _, exc_value, traceback = sys.exc_info()\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/distributions/normal.py:73, in Normal.log_prob(self, value)\n     71 def log_prob(self, value):\n     72     if self._validate_args:\n---&gt; 73         self._validate_sample(value)\n     74     # compute the variance\n     75     var = (self.scale ** 2)\n\nFile ~/miniforge3/lib/python3.9/site-packages/torch/distributions/distribution.py:276, in Distribution._validate_sample(self, value)\n    274 for i, j in zip(reversed(actual_shape), reversed(expected_shape)):\n    275     if i != 1 and j != 1 and i != j:\n--&gt; 276         raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\n    277                          format(actual_shape, expected_shape))\n    278 try:\n    279     support = self.support\n\nValueError: Error while computing log_prob at site 'obs':\nValue is not broadcastable with batch_shape+event_shape: torch.Size([100]) vs torch.Size([200]).\nTrace Shapes:      \n Param Sites:      \n      theta_0     1\n      theta_1     1\nSample Sites:      \n     obs dist 200 |\n        value 100 |\n\n\n\n\nx = torch.linspace(-5, 5, 100)\npredicted_y = pyro.param(\"theta_1\").item()*x + pyro.param(\"theta_0\").item()\n#observed_y = true_y+ 2*torch.randn(100)\n\nplt.scatter(x, observed_y, s = 30, alpha=0.5)\nplt.plot(x, predicted_y, color = 'k')\nplt.plot(x, true_y, color = 'k')\n\n\n\nsns.despine()\n\n\n\n\n\n\n\n\n\ndata_dim = 2\nlatent_dim = 1\nnum_datapoints = 100\nz = dist.Normal(\n    loc=torch.zeros([latent_dim, num_datapoints]),\n    scale=torch.ones([latent_dim, num_datapoints]),)\n\nw = dist.Normal(\n    loc=torch.zeros([data_dim, latent_dim]),\n    scale=5.0 * torch.ones([data_dim, latent_dim]),\n)\n\n\nw_sample= w.sample()\nz_sample = z.sample()\n\n\nx = dist.Normal(loc = w_sample@z_sample, scale=2)\nx_sample = x.sample([100])\nplt.scatter(x_sample[:, 0], x_sample[:, 1], alpha=0.2, s=30)\n\n\n\n\n\n\n\n\n\n\nGenerative model for PPCA in Pyro\n\nimport pyro.distributions as dist\nimport pyro.distributions.constraints as constraints\nimport pyro\npyro.clear_param_store()\n\ndef ppca_model(data, latent_dim):\n    N, data_dim = data.shape\n    W = pyro.param(\"W\", torch.zeros((data_dim, latent_dim)))\n    #print(W.shape, data_dim, (data_dim, latent_dim))\n    \n    for i in range(N):\n        z_vec = pyro.sample(\"z_{}\".format(i), dist.Normal(loc = torch.zeros(latent_dim), scale = 1.))\n        #print(W.shape, z.shape, W@z)\n        pyro.sample(fr\"\\$x_{i}\\$\", dist.Normal(W@z_vec, 2.), obs=data[i])\n\n\npyro.render_model(ppca_model, model_args=(torch.randn(150, 3), 1))\n\n\n\n\n\n\n\n\n\npyro.clear_param_store()\n\ndef ppca_model2(data, latent_dim):\n    N, data_dim = data.shape\n    W = pyro.param(\"W\", torch.zeros((data_dim, latent_dim)))\n    #print(W.shape, data_dim, (data_dim, latent_dim))\n    z_vec = pyro.sample(\"z\", dist.Normal(loc = torch.zeros([latent_dim, N]), scale = 1.))\n    \n    print(W.shape, z_vec.shape, (W@z_vec).t().shape, data.shape)\n    return pyro.sample(\"obs\", (W@z_vec).t(), obs=data)\n    \npyro.render_model(ppca_model2, model_args=(torch.randn(150, 3), 1))\n\ntorch.Size([3, 1]) torch.Size([1, 150]) torch.Size([150, 3]) torch.Size([150, 3])\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nInput In [110], in &lt;module&gt;\n      9     print(W.shape, z_vec.shape, (W@z_vec).t().shape, data.shape)\n     10     return pyro.sample(\"obs\", (W@z_vec).t(), obs=data)\n---&gt; 12 pyro.render_model(ppca_model2, model_args=(torch.randn(150, 3), 1))\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/inspect.py:494, in render_model(model, model_args, model_kwargs, filename, render_distributions)\n    471 def render_model(\n    472     model: Callable,\n    473     model_args: Optional[tuple] = None,\n   (...)\n    476     render_distributions: bool = False,\n    477 ) -&gt; \"graphviz.Digraph\":\n    478     \"\"\"\n    479     Renders a model using `graphviz &lt;https://graphviz.org&gt;`_ .\n    480 \n   (...)\n    492     :rtype: graphviz.Digraph\n    493     \"\"\"\n--&gt; 494     relations = get_model_relations(model, model_args, model_kwargs)\n    495     graph_spec = generate_graph_specification(relations)\n    496     graph = render_graph(graph_spec, render_distributions=render_distributions)\n\nFile ~/miniforge3/lib/python3.9/site-packages/pyro/infer/inspect.py:287, in get_model_relations(model, model_args, model_kwargs)\n    283 if site[\"type\"] != \"sample\" or site_is_subsample(site):\n    284     continue\n    285 sample_sample[name] = [\n    286     upstream\n--&gt; 287     for upstream in get_provenance(site[\"fn\"].log_prob(site[\"value\"]))\n    288     if upstream != name\n    289 ]\n    290 sample_dist[name] = _get_dist_name(site[\"fn\"])\n    291 for frame in site[\"cond_indep_stack\"]:\n\nAttributeError: 'ProvenanceTensor' object has no attribute 'log_prob'\n\n\n\n\ndist.Normal(loc = torch.tensor([0.]), scale = 1.).sample()\n\ntensor([-1.2529])\n\n\n\npyro.clear_param_store()\n\nD = 2\nd = 1\n\ndata = torch.zeros(100, D)\n\ndef ppca(data):\n    A = pyro.param(\"A\", torch.zeros((D, d)))\n    mu = pyro.param(\"mu\", torch.zeros(D))\n\n    for i in pyro.plate(\"data\", len(data)):\n        z = pyro.sample(\"latent_{}\".format(i), dist.Normal(torch.zeros(d), 1.0).to_event(1))\n        pyro.sample(\"observed_{}\".format(i), dist.Normal(A @ z + mu, 1.0).to_event(1), obs=data[i])\n\npyro.render_model(ppca, model_kwargs={'data':data})\n\n\n\n\n\n\n\n\n\nppca(data)\n\n\ndata.shape\n\ntorch.Size([100, 2])\n\n\n\nN = 1000\nx = np.random.normal(loc = 5, scale = 1., size = N)\n\n\no = {}\nfor i in range(N-2):\n    o[i] = x[:i+2].std()\n\n\npd.Series(o).plot()\nplt.axhline(y=1)\nsns.despine()\n\n\n\n\n\n\n\n\n\nx2 = np.array(list(o.values()))\n\n\no2 = {}\nfor i in range(N-3):\n    o2[i] = x2[:i+2].std()\n\n\npd.Series(o2).plot()"
  },
  {
    "objectID": "posts/strassen.html",
    "href": "posts/strassen.html",
    "title": "Naive implementation of Strassen’s algorithm",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np \nimport time\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Retina display\n%config InlineBackend.figure_format = 'retina'\n\n\nlog_size = 8\nsize = 2**log_size\n\ndef create_data(size=2**10, random_seed=0):\n    np.random.seed(random_seed)\n    A = np.random.rand(size,size)\n    B = np.random.rand(size,size)\n    return A, B\n\n\nA, B = create_data(size=size)\n\n\n# Naive implementation\ndef naive_multiply(A, B):\n    C = np.zeros_like(A)\n    for i in range(A.shape[0]):\n        for j in range(A.shape[1]):\n            for k in range(A.shape[0]):\n                C[i,j] += A[i,k] * B[k,j]\n    return C\n\n\n# Modify the Timer class to handle exceptions during the timing\nclass Timer:\n    def __enter__(self):\n        self.start_time = time.time()\n        return self\n\n    def __exit__(self, *args):\n        self.end_time = time.time()\n        self.elapsed = self.end_time - self.start_time\n\n# Define a function to run and time different matrix multiplications\ndef run_and_time_multiplication(function, n_times, *args, **kwargs):\n    elapsed_times = []\n    for _ in range(n_times):\n        with Timer() as timer:\n            result = function(*args, **kwargs)\n        elapsed_times.append(timer.elapsed)\n    return np.array(elapsed_times), result\n\n\n# Number of times to run the timing code\nn_times = 10\n\n# Time Naive multiplication\nnaive_times, C_naive = run_and_time_multiplication(naive_multiply, n_times, A, B)\nprint(f\"Naive Multiplication Times: {naive_times.mean():0.3f} +/- {naive_times.std():0.3f}\")\n\nNaive Multiplication Times: 8.541 +/- 0.016\n\n\n\ndef divide_matrix_four_parts(A):\n    n = A.shape[0]//2\n    A11 = A[:n,:n]\n    A12 = A[:n,n:]\n    A21 = A[n:,:n]\n    A22 = A[n:,n:]\n    return A11, A12, A21, A22\n\n\nA11, A12, A21, A22 = divide_matrix_four_parts(A)\n\n\nA.shape\n\n(256, 256)\n\n\n\nA11.shape\n\n(128, 128)\n\n\n\ndef strassen_multiply(A, B, threshold=32):\n    # if A and B are threshold X threshold matrices directly multiply them\n    if A.shape[0] &lt;= threshold:\n        return naive_multiply(A, B)\n    else:\n        A11, A12, A21, A22 = divide_matrix_four_parts(A)\n        B11, B12, B21, B22 = divide_matrix_four_parts(B)\n        M1 = strassen_multiply(A11 + A22, B11 + B22)\n        M2 = strassen_multiply(A21 + A22, B11)\n        M3 = strassen_multiply(A11, B12 - B22)\n        M4 = strassen_multiply(A22, B21 - B11)\n        M5 = strassen_multiply(A11 + A12, B22)\n        M6 = strassen_multiply(A21 - A11, B11 + B12)\n        M7 = strassen_multiply(A12 - A22, B21 + B22)\n        C11 = M1 + M4 - M5 + M7\n        C12 = M3 + M5\n        C21 = M2 + M4\n        C22 = M1 - M2 + M3 + M6\n        C = np.vstack((np.hstack((C11, C12)), np.hstack((C21, C22))))\n        return C\n\n\n# Time Strassen multiplication with thresholds 8, 16, 32\nthresholds = [8, 16, 32]\n\nstrassen_times = {}\nstrassen_results = {}\nfor threshold in thresholds:\n    strassen_times[threshold], strassen_results[threshold] = run_and_time_multiplication(strassen_multiply, n_times, A, B, threshold=threshold)\n    print(f\"Strassen Multiplication Times (threshold={threshold}): {strassen_times[threshold].mean():0.3f} +/- {strassen_times[threshold].std():0.3f}\")   \n\nStrassen Multiplication Times (threshold=8): 5.716 +/- 0.082\nStrassen Multiplication Times (threshold=16): 5.767 +/- 0.016\nStrassen Multiplication Times (threshold=32): 5.774 +/- 0.005\n\n\n\n# Plot the results of the timing experiments as bar plot with mean and standard deviation\nplt.figure(figsize=(10,5))\ndf = {}\ndf[\"naive\"] = {\"mean\": naive_times.mean(), \"std\": naive_times.std()}\nfor threshold in thresholds:\n    df[f\"strassen \\n(threshold={threshold})\"] = {\"mean\": strassen_times[threshold].mean(), \"std\": strassen_times[threshold].std()}\ndf = pd.DataFrame(df).T\n\ndf[\"mean\"].plot(kind=\"bar\", yerr=df[\"std\"], capsize=5, rot=0)\nplt.ylabel(\"Time (s)\")\n\nText(0, 0.5, 'Time (s)')\n\n\n\n\n\n\n\n\n\n\n# Directly multiply A and B usung numpy\nnumpy_times, C_numpy = run_and_time_multiplication(np.matmul, n_times, A, B)\nprint(f\"NumPy Multiplication Times: {numpy_times.mean():0.3f} +/- {numpy_times.std():0.3f}\")\n\nNumPy Multiplication Times: 0.001 +/- 0.000"
  },
  {
    "objectID": "posts/2022-02-24-audio-filtering.html",
    "href": "posts/2022-02-24-audio-filtering.html",
    "title": "Audio Filtering",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nfrom functools import partial\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nimport librosa\ny, sr = librosa.load(\"/Users/nipun/Downloads/external-sensors_data_audio_audacity_recorded-mask-tidal-breathing.wav\")\n\n\nplt.plot(y), sr\n\n\n\n\n\n\n\n\n\nfrom scipy import signal\n\n\nfrom scipy.fft import fft, fftfreq\n\n\nyf = fft(y)\nxf = fftfreq(len(y), 1 / sr)\n\nplt.plot(xf, np.abs(yf), lw=0.1)\nplt.xlim((0, 1000))\n\n\n\n\n\n\n\n\n\nplt.specgram(x = y,Fs=sr);\n#plt.ylim((0, 100))\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nsos = signal.butter(10, 20, 'lp', fs=sr, output='sos')\nfiltered = signal.sosfilt(sos, y)\nplt.plot(y)\nplt.plot(filtered)\n\n\n\n\n\n\n\n\n\nplt.plot(filtered)\n\n\n\n\n\n\n\n\n\nplt.specgram(x = filtered,Fs=sr);\n#plt.ylim((0, 100))\nplt.colorbar()"
  },
  {
    "objectID": "posts/mv-taylor.html",
    "href": "posts/mv-taylor.html",
    "title": "Multivariate Taylor Series",
    "section": "",
    "text": "import numpy as np\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport jax\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# Use 64 bit precision for JAX\njax.config.update(\"jax_enable_x64\", True)\n\n\n# Create a 2d function\ndef f(x):\n    return jnp.sin(x[0]*x[1])\n\n\nx_range=(-2, 2)\ny_range=(-2, 2)\nn=100\nx = jnp.linspace(x_range[0], x_range[1], n)\ny = jnp.linspace(y_range[0], y_range[1], n)\nX, Y = jnp.meshgrid(x, y)\n\n\n# Evaluate the function at a grid of points using vmap\ndef eval_grid(f, x_range=(-2, 2), y_range=(-2, 2), n=100):\n    x = jnp.linspace(x_range[0], x_range[1], n)\n    y = jnp.linspace(y_range[0], y_range[1], n)\n    X, Y = jnp.meshgrid(x, y)\n    return X, Y, jax.vmap(jax.vmap(f, in_axes=0), in_axes=0)(jnp.stack([X, Y], axis=-1))\n\n\n# Plot the contour of the function\ndef plot_contour(f, x_range=(-2, 2), y_range=(-2, 2), n=100, ax = None, **kwargs):\n    X, Y, Z = eval_grid(f, x_range, y_range, n)\n    if ax is None:\n        fig, ax = plt.subplots()\n        \n    levels = jnp.linspace(-1.0, int(jnp.max(Z))+0.5, 11)\n    contours = ax.contour(X, Y,Z, levels=levels, **kwargs)\n    ax.clabel(contours, inline=True, fontsize=8)\n\n    #ax.imshow(Z, extent= [X.min(), X.max(), Y.min(), Y.max()], origin='lower', cmap='viridis', alpha=0.5)\n    return ax\n\n\nplot_contour(f, colors='k')\n\n\n\n\n\n\n\n\n\n# Plot surface of the function\ndef plot_surface(f, x_range=(-2, 2), y_range=(-2, 2), n=100, ax = None, **kwargs):\n    X, Y, Z = eval_grid(f, x_range, y_range, n)\n\n    if ax is None:\n        fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n        \n    ax.plot_surface(X, Y, Z, **kwargs)\n    return ax\n\n\n# Plot surface in Plotly\nimport plotly.graph_objects as go\n\ndef plot_surface_plotly(f, x_range=(-2, 2), y_range=(-2, 2), n=100, **kwargs):\n    X, Y, Z = eval_grid(f, x_range, y_range, n)\n    fig = go.Figure(data=[go.Surface(z=Z, x=X, y=Y, **kwargs)])\n    fig.update_layout(scene = dict(\n                    xaxis_title='x',\n                    yaxis_title='y',\n                    zaxis_title='z'))\n    \n\n    \n    fig.show()\n\n\nplot_surface(f, cmap='viridis')\n\n\n\n\n\n\n\n\n\nplot_surface_plotly(f)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ng = jax.grad(f)\nH = jax.hessian(f)\n\n\njnp.array(g([1.0, 1.0]))\n\nArray([0.54030231, 0.54030231], dtype=float64)\n\n\n\njnp.array(H([1.0, 1.0]))\n\nArray([[-0.84147098, -0.30116868],\n       [-0.30116868, -0.84147098]], dtype=float64)\n\n\n\nprint(type(f([1.0, 1.0])), type(jnp.array(g([1.0, 1.0]))), type(H([1.0, 1.0])))\n\n&lt;class 'jaxlib.xla_extension.Array'&gt; &lt;class 'jaxlib.xla_extension.Array'&gt; &lt;class 'list'&gt;\n\n\n\n# First order Taylor approximation around x0\ndef taylor1(f, x0):\n    g = jax.grad(f)\n    t = lambda x: f(x0) + jnp.array(g(x0)) @ (x - x0)\n    # Print the Taylor approximation\n    print(\"f(x) = {:.2f} + {:.2f} (x1 - {:.2f}) + {:.2f} (x2 - {:.2f})\".format(f(x0), g(x0)[0], x0[0], g(x0)[1], x0[1]))\n    \n    return t\n\n\ntaylor1(f, jnp.array([1.0, 1.0]))(jnp.array([0.0, 1.0]))\n\nf(x) = 0.84 + 0.54 (x1 - 1.00) + 0.54 (x2 - 1.00)\n\n\nArray(0.30116868, dtype=float64)\n\n\n\n# Second order Taylor approximation around x0\ndef taylor2(f, x0):\n    g = jax.grad(f)\n    H = jax.hessian(f)\n    t = lambda x: f(x0) + jnp.array(g(x0)) @ (x - x0) + 0.5*(x - x0) @ jnp.array(H(x0)) @ (x - x0)\n    # Print the Taylor approximation\n    print(\"f(x) = {:.2f} + {:.2f} (x1 - {:.2f}) + {:.2f} (x2 - {:.2f}) + {:.2f} (x1 - {:.2f})^2 + {:.2f} (x2 - {:.2f})^2 + {:.2f} (x1 - {:.2f})(x2 - {:.2f})\".format(f(x0), g(x0)[0], x0[0], g(x0)[1], x0[1], H(x0)[0, 0], x0[0], H(x0)[1, 1], x0[1], H(x0)[0, 1], x0[0], x0[1]))\n    \n    return t\n\n\ntaylor2(f, jnp.array([1.0, 1.0]))(jnp.array([0.0, 1.0]))\n\nf(x) = 0.84 + 0.54 (x1 - 1.00) + 0.54 (x2 - 1.00) + -0.84 (x1 - 1.00)^2 + -0.84 (x2 - 1.00)^2 + -0.30 (x1 - 1.00)(x2 - 1.00)\n\n\nArray(-0.11956681, dtype=float64)\n\n\n\nH(jnp.array([1.0, 1.0]))\n\nArray([[-0.84147098, -0.30116868],\n       [-0.30116868, -0.84147098]], dtype=float64)\n\n\n\ng(jnp.array([1.0, 1.0]))\n\nArray([0.54030231, 0.54030231], dtype=float64)\n\n\n\n# Plot contour of the Taylor approximation around x0 for both first and second order in comparison with the original function\n# 3 subplots\ndef plot_taylor(f, x0, x_range=(-2, 2), y_range=(-2, 2), n=100, ax = None):\n    t1 = taylor1(f, x0)\n    t2 = taylor2(f, x0)\n    \n    if ax is None:\n        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n    \n    # Mark the point x0\n    ax[0].scatter(x0[0], x0[1], marker='x', color='red', s=100)\n\n    # Plot the contour of the function\n    plot_contour(f, x_range, y_range, n, ax=ax[0], colors='black')\n\n    # Plot the contour of the first order Taylor approximation\n    plot_contour(t1, x_range, y_range, n, ax=ax[1], colors='black')\n    ax[1].scatter(x0[0], x0[1], marker='x', color='red', s=100)\n\n    # Plot the contour of the second order Taylor approximation\n    plot_contour(t2, x_range, y_range, n, ax=ax[2], colors='black')\n    ax[2].scatter(x0[0], x0[1], marker='x', color='red', s=100)\n\n\nplot_taylor(f, jnp.array([1.0, 1.0]))\n\nf(x) = 0.84 + 0.54 (x1 - 1.00) + 0.54 (x2 - 1.00)\nf(x) = 0.84 + 0.54 (x1 - 1.00) + 0.54 (x2 - 1.00) + -0.84 (x1 - 1.00)^2 + -0.84 (x2 - 1.00)^2 + -0.30 (x1 - 1.00)(x2 - 1.00)\n\n\n\n\n\n\n\n\n\n\n# Plot surface of the Taylor approximation around x0 for both first and second order in comparison with the original function\n# 3 subplots\n\ndef plot_taylor_surface(f, x0, x_range=(-2, 2), y_range=(-2, 2), n=100, ax = None):\n    t1 = taylor1(f, x0)\n    t2 = taylor2(f, x0)\n    \n    if ax is None:\n        fig, ax = plt.subplots(1, 3, figsize=(15, 5), subplot_kw={\"projection\": \"3d\"})\n    \n    # Mark the point x0\n    ax[0].scatter(x0[0], x0[1], f(x0), marker='x', color='red', s=100)\n\n    # Plot the surface of the function\n    plot_surface(f, x_range, y_range, n, ax=ax[0])\n\n    # Plot the surface of the first order Taylor approximation\n    plot_surface(t1, x_range, y_range, n, ax=ax[1])\n    ax[1].scatter(x0[0], x0[1], f(x0), marker='x', color='red', s=100)\n\n    # Plot the surface of the second order Taylor approximation\n    plot_surface(t2, x_range, y_range, n, ax=ax[2])\n    ax[2].scatter(x0[0], x0[1], f(x0), marker='x', color='red', s=100)\n\n\nplot_taylor_surface(f, jnp.array([1.0, 1.0]))\n\nf(x) = 0.84 + 0.54 (x1 - 1.00) + 0.54 (x2 - 1.00)\nf(x) = 0.84 + 0.54 (x1 - 1.00) + 0.54 (x2 - 1.00) + -0.84 (x1 - 1.00)^2 + -0.84 (x2 - 1.00)^2 + -0.30 (x1 - 1.00)(x2 - 1.00)\n\n\n\n\n\n\n\n\n\nSecond order Taylor series expansion of a function f around a point (x0, y0) is given by (when using the vector notation)\n\\[f(x,y) = f(x_0,y_0) + \\frac{\\partial f}{\\partial x}(x_0,y_0)(x-x_0) + \\frac{\\partial f}{\\partial y}(x_0,y_0)(y-y_0) + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2}(x_0,y_0)(x-x_0)^2 + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial y^2}(x_0,y_0)(y-y_0)^2 + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x \\partial y}(x_0,y_0)(x-x_0)(y-y_0)\\]"
  },
  {
    "objectID": "posts/2021-06-18-audio-filters.html",
    "href": "posts/2021-06-18-audio-filters.html",
    "title": "Audio filters",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- signal-processing- audio- filtering- digital-signal-processing- python- scipydate: ’2021-06-18’description: Audio filtering techniques and applicationsoutput-file: 2021-06-18-audio-filters.htmltitle: Audio filterstoc: true—"
  },
  {
    "objectID": "posts/2021-06-18-audio-filters.html#introduction",
    "href": "posts/2021-06-18-audio-filters.html#introduction",
    "title": "Audio filters",
    "section": "Introduction",
    "text": "Introduction\nIn this post I will look into some filters for audio processing in ffmpeg, sox, and Python. I have recorded a small 6 second audio clip where for the first couple of seconds I was not speaking, but background noise is present.\nI had recorded the audio on my Apple device and it was default recorded in .m4a format. I convert it to the wav format. I use ffmpeg for the same. In addition, I am using two flags: -v quiet to reduce the amount of information printed on the console. Second, I am using -y to overwrite an existing file with the same name.\n\n!ffmpeg -i Test.m4a Test.wav -v quiet -y\n\n\nfrom IPython.display import Audio\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nAudio(\"Test.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n!ffmpeg -i Test.wav -lavfi showspectrumpic=s=720x540:color='magma' ../images/input-spectogram.png -y -v quiet\n\n\nAs can be seen in the above image, I am speaking somewhere close to 3.70 seconds onwards. However, the audio is pretty noisy before this even though I am not speaking. This is due to the background noise coming in from the fans and the air conditioning system.\n\n!sox Test.wav -n spectrogram -o ../images/sox-sg.png\n\n\n\n!sox Test.wav -n rate 32k spectrogram  -o ../images/sox-sg-trimmed.png \n\n\nI’ll now get some attributes of the post that are required for processing, such as the recording rate. ## Getting attributes of the recorded file\n\n!ffmpeg -i Test.wav\n\n\nffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n\n  built with Apple clang version 12.0.5 (clang-1205.0.22.9)\n\n  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-avresample --enable-videotoolbox\n\n  libavutil      56. 70.100 / 56. 70.100\n\n  libavcodec     58.134.100 / 58.134.100\n\n  libavformat    58. 76.100 / 58. 76.100\n\n  libavdevice    58. 13.100 / 58. 13.100\n\n  libavfilter     7.110.100 /  7.110.100\n\n  libavresample   4.  0.  0 /  4.  0.  0\n\n  libswscale      5.  9.100 /  5.  9.100\n\n  libswresample   3.  9.100 /  3.  9.100\n\n  libpostproc    55.  9.100 / 55.  9.100\n\nGuessed Channel Layout for Input Stream #0.0 : mono\n\nInput #0, wav, from 'Test.wav':\n\n  Metadata:\n\n    title           : Test\n\n    encoder         : Lavf58.76.100\n\n  Duration: 00:00:06.63, bitrate: 768 kb/s\n\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s\n\nAt least one output file must be specified\n\n\n\n\n\nAs can be seen from the cell above, the recording rate is 48 kHz. We will need this when we do some processing in Python.\nBuilding a noise profile from first 3 second\n\n!ffmpeg -i Test.wav -ss 0 -to 3.5 -c copy Noise-Test.wav -v quiet -y\n\n\nAudio('Noise-Test.wav')\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n!sox Noise-Test.wav -n rate 32k spectrogram  -o ../images/sox-noise.png \n\n\n\n!sox Noise-Test.wav -n noiseprof noise.prof\n\n\n!sox Noise-Test.wav Noise-Test-cleaned.wav noisered noise.prof 0.21\n\n\nAudio(\"Noise-Test-cleaned.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n!sox Test.wav Test-cleaned-05.wav noisered noise.prof 0.05\n\n\n!sox Test.wav Test-cleaned-18.wav noisered noise.prof 0.18\n!sox Test.wav Test-cleaned-21.wav noisered noise.prof 0.21\n\n\nAudio(\"Test-cleaned-05.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nAudio(\"Test-cleaned-18.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nAudio(\"Test-cleaned-21.wav\")\n\n\n!sox Test-cleaned-21.wav -n rate 32k spectrogram  -o ../images/sox-cleaned-21.png \n\n\n\n!sox Test-cleaned-05.wav -n rate 32k spectrogram  -o ../images/sox-cleaned-05.png \n\n\n\nAudio(\"Test-audacity.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n!sox Test-audacity.wav -n rate 32k spectrogram  -o ../images/sg-audacity.png \n\n\n\n!ffmpeg -i Test.wav -filter:a \"highpass=f=300\" high-passed.wav -y -v quiet\n\n\n\nAudio(\"high-passed.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n!sox high-passed.wav -n rate 32k spectrogram  -o ../images/highpass.png \n\n\n\nAudio(\"test-imovie.wav\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\n!sox test-imovie.wav -n remix 1 rate 32k spectrogram  -o ../images/imovie.png \n\n\nimport mediapy\n\norig  = mediapy.read_image('../images/sox-sg-trimmed.png')\naudacity = mediapy.read_image('../images/sg-audacity.png')\nsox_21 = mediapy.read_image('../images/sox-cleaned-21.png')\nsox_05 = mediapy.read_image('../images/sox-cleaned-05.png')\nhigh_pass_300 = mediapy.read_image('../images/highpass.png')\nimovie = mediapy.read_image('../images/imovie.png')\n\n\n\n\nmediapy.show_images({'Original':orig, \n                     'Audacity':audacity,\n                     'Sox:0.21':sox_21,\n                    'Sox:0.05':sox_05,\n                    'HPF:300': high_pass_300,\n                    'imovie':imovie},\n                    cmap='magma', columns=4, height=200 )\n\n\n\n\n\n\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\n\n\n\n\nAudacity\n\n\n\n\n\n\n\n\n\nSox:0.21\n\n\n\n\n\n\n\n\n\nSox:0.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHPF:300\n\n\n\n\n\n\n\n\n\nimovie\n\n\n\n\n\n\n\n\n\n\n\n\n!sox test-audacity.wav output.dat\n\n\nimport pandas as pd\ndf = pd.read_csv(\"output.dat\", skiprows=2, index_col=0, names=['values'],delim_whitespace=True)\ndf = df.astype('float64')\n\n\ndf.plot()"
  },
  {
    "objectID": "posts/2020-03-08-keras-neural-non-linear.html",
    "href": "posts/2020-03-08-keras-neural-non-linear.html",
    "title": "Some Neural Network Classification",
    "section": "",
    "text": "from sklearn.datasets import make_moons\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\n\nX, y = make_moons()\n\n\nplt.scatter(X[:, 0], X[:, 1], c= y)\n\n\n\n\n\n\n\n\n\nfrom keras.models import Sequential\nfrom sklearn.metrics import accuracy_score\nimport os\n\n\nfrom keras.layers import Dense, Activation\nfrom keras.utils import to_categorical\nmodel_simple = Sequential([\n    Dense(1, input_shape=(2,)),\n    Activation('relu'),\n    Dense(2),\n    Activation('softmax'),\n])\n\n\n\nmodel_complex = Sequential([\n    Dense(6, input_shape=(2,)),\n    Activation('relu'),\n    Dense(4),\n    Activation('relu'),\n    Dense(3),\n    Activation('relu'),\n    Dense(2),\n    Activation('softmax'),\n])\n\nmodel_complex_2 = Sequential([\n    Dense(10, input_shape=(2,)),\n    Activation('relu'),\n    Dense(8, ),\n    Activation('relu'),\n    Dense(8),\n    Activation('relu'),\n    Dense(2),\n    Activation('softmax'),\n])\n\n\nmodel_simple.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel_complex.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nmodel_complex_2.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\ndef make_plot(X, y, model, dataset, model_type, noise, n_iter=80,cmap='PRGn'):\n\n    h=200\n    if dataset==\"moon\":\n        X, y = make_moons(noise=noise)\n    if dataset==\"iris\":\n        X, y = load_iris()['data'][:, :2], load_iris()['target']\n    print(X.shape, y.shape)\n    y_binary = to_categorical(y)\n\n    xx, yy = np.meshgrid(np.linspace(X[:, 0].min()-0.2, X[:, 0].max()+0.2, h),\n                             np.linspace(X[:, 1].min()-0.2, X[:, 1].max()+0.2, h))\n    XX = np.c_[xx.ravel(), yy.ravel()]\n\n    for i in range(n_iter):\n        model.fit(X, y_binary, epochs=1, verbose=0)\n        Z = np.argmax(model.predict(XX), axis=1).reshape(xx.shape)\n        y_hat = np.argmax(model.predict(X), axis=1)\n        train_accuracy = accuracy_score(y, y_hat)\n        contours = plt.contourf(xx, yy, Z, h , cmap=cmap, alpha=0.4)\n        plt.title(\"Iteration: \"+str(i)+\"\\n Accuracy:\"+str(train_accuracy))\n        plt.colorbar()\n        plt.scatter(X[:, 0], X[:, 1], c= y, cmap=cmap)\n        if not os.path.exists(f\"/Users/nipun/Desktop/animation-keras/{dataset}/{model_type}/{noise}/\"):\n            os.makedirs(f\"/Users/nipun/Desktop/animation-keras/{dataset}/{model_type}/{noise}/\")\n        plt.savefig(f\"/Users/nipun/Desktop/animation-keras/{dataset}/{model_type}/{noise}/{i:03}.png\")\n        plt.clf()\n    \n\n\nmake_plot(X, y, model_simple, \"moon\", \"simple\", None)\n\n(100, 2) (100,)\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n!convert -delay 20 -loop 0 /Users/nipun/Desktop/animation-keras/moon/simple/None/*.png moon-simple-none.gif\n\n\n\nmake_plot(X, y, model_complex, \"moon\", \"complex\", None, 500)\n\n(100, 2) (100,)\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n!convert -delay 20 -loop 0 /Users/nipun/Desktop/animation-keras/moon/complex/None/*.png moon-complex-none.gif\n\n\n\nmake_plot(X, y, model_complex_2, \"moon\", \"complex\", 0.3, 700)\n\n(100, 2) (100,)\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n!convert -delay 20 -loop 0 /Users/nipun/Desktop/animation-keras/moon/complex/0.3/*.png moon-complex-03.gif\n\n\n\nmodel_simple_2 = Sequential([\n    Dense(1, input_shape=(2,)),\n    Activation('relu'),\n    Dense(3),\n    Activation('softmax'),\n])\n\nmodel_simple_2.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nmake_plot(X, y, model_simple_2, \"iris\", \"simple\", None, 500)\n\n(150, 2) (150,)\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n!convert -delay 20 -loop 0 /Users/nipun/Desktop/animation-keras/iris/simple/None/*.png iris-simple.gif\n\n\n\nmodel_complex_iris = Sequential([\n    Dense(12, input_shape=(2,)),\n    Activation('relu'),\n    Dense(6),\n    Activation('relu'),\n    Dense(4),\n    Activation('relu'),\n    Dense(3),\n    Activation('softmax'),\n])\n\nmodel_complex_iris.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nmake_plot(X, y, model_complex_iris, \"iris\", \"complex\", None, 500)\n\n(150, 2) (150,)\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n!convert -delay 20 -loop 0 /Users/nipun/Desktop/animation-keras/iris/complex/None/*.png iris-complex.gif"
  },
  {
    "objectID": "posts/2022-02-20-condition-pyro.html",
    "href": "posts/2022-02-20-condition-pyro.html",
    "title": "Pyro Conditioning",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\nimport pyro\n\ndist =pyro.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nX = dist.MultivariateNormal(loc = torch.tensor([0., 0.]), covariance_matrix=torch.eye(2))\n\n\npyro.condition()\n\ntensor([-0.0687,  0.7461])\n\n\n\ndata_dim = 2\nlatent_dim = 1\nnum_datapoints = 100\nz = dist.Normal(\n    loc=torch.zeros([latent_dim, num_datapoints]),\n    scale=torch.ones([latent_dim, num_datapoints]),)\n\nw = dist.Normal(\n    loc=torch.zeros([data_dim, latent_dim]),\n    scale=5.0 * torch.ones([data_dim, latent_dim]),\n)\n\n\nw_sample= w.sample()\nz_sample = z.sample()\n\n\nx = dist.Normal(loc = w_sample@z_sample, scale=1)\nx_sample = x.sample([100])\nplt.scatter(x_sample[:, 0], x_sample[:, 1], alpha=0.2, s=30)\n\n\n\n\n\n\n\n\n\n\nGenerative model for PPCA in Pyro\n\nimport pyro.distributions as dist\nimport pyro.distributions.constraints as constraints\nimport pyro\n\npyro.clear_param_store()\n\n\ndef ppca_model(data, latent_dim):\n    N, data_dim = data.shape\n    W = pyro.sample(\n        \"W\",\n        dist.Normal(\n            loc=torch.zeros([latent_dim, data_dim]),\n            scale=5.0 * torch.ones([latent_dim, data_dim]),\n        ),\n    )\n    Z = pyro.sample(\n        \"Z\",\n        dist.Normal(\n            loc=torch.zeros([N, latent_dim]),\n            scale=torch.ones([N, latent_dim]),\n        ),\n    )\n\n    mean = Z @ W\n\n    return pyro.sample(\"obs\", pyro.distributions.Normal(mean, 1.0), obs=data)\n\n\npyro.render_model(\n    ppca_model, model_args=(torch.randn(150, 2), 1), render_distributions=True\n)\n\n\n\n\n\n\n\n\n\nppca_model(x_sample[0], 3).shape\n\ntorch.Size([2, 100])\n\n\n\nfrom pyro import poutine\nwith pyro.plate(\"samples\", 10, dim=-3):\n    trace = poutine.trace(ppca_model).get_trace(x_sample[0], 1)\n\n\ntrace.nodes['W']['value'].squeeze()\n\ntorch.Size([10, 100])\n\n\n\ndata_dim = 3\nlatent_dim = 2\n\nW = pyro.sample(\n        \"W\",\n        dist.Normal(\n            loc=torch.zeros([latent_dim, data_dim]),\n            scale=5.0 * torch.ones([latent_dim, data_dim]),\n        ),\n    )\n\n\nN = 150\nZ = pyro.sample(\n        \"Z\",\n        dist.Normal(\n            loc=torch.zeros([N, latent_dim]),\n            scale=torch.ones([N, latent_dim]),\n        ),\n    )\n\n\nZ.shape, W.shape\n\n(torch.Size([150, 2]), torch.Size([2, 3]))\n\n\n\n(Z@W).shape\n\ntorch.Size([150, 3])"
  },
  {
    "objectID": "posts/2022-01-28-tfp-linear-regression.html",
    "href": "posts/2022-01-28-tfp-linear-regression.html",
    "title": "Linear Regression in Tensorflow Probability",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\ntfd = tfp.distributions\ntfl = tfp.layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import Callback\nsns.reset_defaults()\nsns.set_context(context='talk',font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nnp.random.seed(42)\nx = np.linspace(-0.5, 1, 100)\ny = 5*x + 4 + 2*np.multiply(x, np.random.randn(100))\n\n\nplt.scatter(x, y, s=20, alpha=0.6)\nsns.despine()\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\n\nText(0, 0.5, 'y')\n\n\n\n\n\n\n\n\n\n\nModel 1: Vanilla Linear Regression\n\nmodel = Sequential([\n    Dense(input_shape=(1,), units=1, name='D1')])\n\n2022-02-01 09:37:25.292936: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n D1 (Dense)                  (None, 1)                 2         \n                                                                 \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nmodel.compile(loss='mse', optimizer='adam')\nmodel.fit(x, y, epochs=4000, verbose=0)\n\n&lt;keras.callbacks.History at 0x1a36573a0&gt;\n\n\n\nmodel.get_layer('D1').weights\n\n[&lt;tf.Variable 'D1/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[4.929521]], dtype=float32)&gt;,\n &lt;tf.Variable 'D1/bias:0' shape=(1,) dtype=float32, numpy=array([3.997371], dtype=float32)&gt;]\n\n\n\nplt.scatter(x, y, s=20, alpha=0.6)\nsns.despine()\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\npred_m1 = model.predict(x)\nplt.plot(x, pred_m1)\n\n\n\n\n\n\n\n\n\n\nModel 2\n\nmodel_2 = Sequential([\n    Dense(input_shape=(1,), units=1, name='M2_D1'),\n    tfl.DistributionLambda(lambda loc: tfd.Normal(loc=loc, scale=1.), name='M2_Likelihood')])\n\n2022-02-01 09:37:33.529583: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n\n\n\nmodel_2.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n M2_D1 (Dense)               (None, 1)                 2         \n                                                                 \n M2_Likelihood (Distribution  ((None, 1),              0         \n Lambda)                      (None, 1))                         \n                                                                 \n=================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nm2_untrained_weight = model_2.get_layer('M2_D1').weights\n\n\nplt.scatter(x, y, s=20, alpha=0.6)\nsns.despine()\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nm_2 = model_2(x)\nplt.plot(x, m_2.sample(40).numpy()[:, :, 0].T, color='k', alpha=0.05);\nplt.plot(x, m_2.mean().numpy().flatten(), color='k')\n\n\n\n\n\n\n\n\n\ndef plot(model):\n    plt.scatter(x, y, s=20, alpha=0.6)\n    sns.despine()\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    m = model(x)\n    m_s = m.stddev().numpy().flatten()\n    m_m = m.mean().numpy().flatten()\n\n    plt.plot(x, m_m , color='k')\n    plt.fill_between(x, m_m-m_s, m_m+m_s, color='k', alpha=0.4)\n\n\nplot(model_2)\n\n\n\n\n\n\n\n\n\ndef nll(y_true, y_pred):\n    # y_pred is distribution\n    return -y_pred.log_prob(y_true)\n\n\nmodel_2.compile(loss=nll, optimizer='adam')\nmodel_2.fit(x, y, epochs=4000, verbose=0)\n\n&lt;keras.callbacks.History at 0x1a3b96880&gt;\n\n\n\nplot(model_2)\n\n\n\n\n\n\n\n\n\n\nModel 3\n\nmodel_3 = Sequential([\n    Dense(input_shape=(1,), units=2, name='M3_D1'),\n    tfl.DistributionLambda(lambda t: tfd.Normal(loc=t[..., 0], scale=tf.exp(t[..., 1])), name='M3_Likelihood')])\n\n\nmodel_3.get_layer('M3_D1').weights\n\n[&lt;tf.Variable 'M3_D1/kernel:0' shape=(1, 2) dtype=float32, numpy=array([[0.04476571, 0.55212975]], dtype=float32)&gt;,\n &lt;tf.Variable 'M3_D1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)&gt;]\n\n\n\nmodel_3.compile(loss=nll, optimizer='adam')\nmodel_3.fit(x, y, epochs=4000, verbose=0)\n\n&lt;keras.callbacks.History at 0x1a3d20190&gt;\n\n\n\nplot(model_3)\n\n\n\n\n\n\n\n\nGood reference https://tensorchiefs.github.io/bbs/files/21052019-bbs-Beate-uncertainty.pdf\nAt this point, we see that scale or sigma is a linear function of input x.\n\n#### Model 4\n\n\nmodel_4 = Sequential([\n    Dense(input_shape=(1,), units=2, name='M4_D1', activation='relu'),\n    Dense(units=2, name='M4_D2',  activation='relu'),\n    Dense(units=2, name='M4_D3'),\n    tfl.DistributionLambda(lambda t: tfd.Normal(loc=t[..., 0], scale=tf.math.softplus(t[..., 1])), name='M4_Likelihood')])\n\n\nmodel_4.compile(loss=nll, optimizer='adam')\nmodel_4.fit(x, y, epochs=4000, verbose=0)\n\n&lt;keras.callbacks.History at 0x1a3cd0a60&gt;\n\n\n\nplot(model_4)\n\n\n\n\n\n\n\n\n\n\nModel 5\nFollow: https://juanitorduz.github.io/tfp_lm/\n\n\nModel 6\nDense Variational\n\ndef prior(kernel_size, bias_size, dtype=None):\n    n = kernel_size + bias_size\n    # Independent Normal Distribution\n    return lambda t: tfd.Independent(tfd.Normal(loc=tf.zeros(n, dtype=dtype),\n                                                scale=1),\n                                     reinterpreted_batch_ndims=1)\n\ndef posterior(kernel_size, bias_size, dtype=None):\n    n = kernel_size + bias_size\n    return Sequential([\n        tfl.VariableLayer(tfl.IndependentNormal.params_size(n), dtype=dtype),\n        tfl.IndependentNormal(n)\n    ])\n\n\nN = len(x)\nmodel_6 = Sequential([\n    # Requires posterior and prior distribution\n    # Add kl_weight for weight regularization\n    #tfl.DenseVariational(16, posterior, prior, kl_weight=1/N, activation='relu', input_shape=(1, )),\n    tfl.DenseVariational(2, posterior, prior, kl_weight=1/N, input_shape=(1,)),\n    tfl.IndependentNormal(1)\n])\n\n\nmodel_6.compile(loss=nll, optimizer='adam')\n\n\nmodel_6.fit(x, y, epochs=5000, verbose=0)\n\n&lt;keras.callbacks.History at 0x1a61a9ee0&gt;\n\n\n\nplot(model_6)\n\n\n\n\n\n\n\n\n\nN = len(x)\nmodel_7 = Sequential([\n    # Requires posterior and prior distribution\n    # Add kl_weight for weight regularization\n    tfl.DenseVariational(16, posterior, prior, kl_weight=1/N, activation='relu', input_shape=(1, )),\n    tfl.DenseVariational(2, posterior, prior, kl_weight=1/N),\n    tfl.IndependentNormal(1)\n])\n\nmodel_7.compile(loss=nll, optimizer='adam')\n\n\nmodel_7.fit(x, y, epochs=5000, verbose=0)\n\n&lt;keras.callbacks.History at 0x1a669da90&gt;\n\n\n\nplot(model_7)\n\n\n\n\n\n\n\n\nhttps://livebook.manning.com/book/probabilistic-deep-learning-with-python/chapter-8/123"
  },
  {
    "objectID": "posts/2022-02-12-variational-inference.html",
    "href": "posts/2022-02-12-variational-inference.html",
    "title": "Variational inference",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- variational-inference- bayesian- approximate-inference- probabilistic-models- optimizationdate: ’2022-02-12’output-file: 2022-02-12-variational-inference.htmltitle: Variational inferencetoc: true—\n\nGoals:\n\nG1: Given probability distributions \\(p\\) and \\(q\\), find the divergence (measure of similarity) between them\nLet us first look at G1. Look at the illustration below. We have a normal distribution \\(p\\) and two other normal distributions \\(q_1\\) and \\(q_2\\). Which of \\(q_1\\) and \\(q_2\\), would we consider closer to \\(p\\)? \\(q_2\\), right?\n\nTo understand the notion of similarity, we use a metric called the KL-divergence given as \\(D_{KL}(a || b)\\) where \\(a\\) and \\(b\\) are the two distributions.\nFor G1, we can say \\(q_2\\) is closer to \\(p\\) compared to \\(q_1\\) as:\n\\(D_{KL}(q_2 || p) \\lt D_{KL}(q_1 || p)\\)\nFor the above example, we have the values as \\(D_{KL}(q_2|| p) = 0.07\\) and \\(D_{KL}(q_1|| p)= 0.35\\)\n\n\nG2: assuming \\(p\\) to be fixed, can we find optimum parameters of \\(q\\) to make it as close as possible to \\(p\\)\nThe following GIF shows the process of finding the optimum set of parameters for a normal distribution \\(q\\) so that it becomes as close as possible to \\(p\\). This is equivalent of minimizing \\(D_{KL}(q || p)\\)\n\nThe following GIF shows the above but for a two-dimensional distribution.\n\n\n\nG3: finding the “distance” between two distributions of different families\nThe below image shows the KL-divergence between distribution 1 (mixture of Gaussians) and distribution 2 (Gaussian)\n\n\n\nG4: optimizing the “distance” between two distributions of different families\nThe below GIF shows the optimization of the KL-divergence between distribution 1 (mixture of Gaussians) and distribution 2 (Gaussian)\n\n\n\nG5: Approximating the KL-divergence\n\n\nG6: Implementing variational inference for linear regression\n\n\n\nBasic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\n\ndist =torch.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n\nCreating distributions\n\nCreating \\(p\\sim\\mathcal{N}(1.00, 4.00)\\)\n\np = dist.Normal(1, 4)\n\n\nz_values = torch.linspace(-5, 15, 200)\nprob_values_p = torch.exp(p.log_prob(z_values))\nplt.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\")\nsns.despine()\nplt.legend()\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\n\nText(0, 0.5, 'PDF')\n\n\n\n\n\n\n\n\n\n\n\nCreating \\(q\\sim\\mathcal{N}(loc, scale)\\)\n\ndef create_q(loc, scale):\n    return dist.Normal(loc, scale)\n\n\n\nGenerating a few qs for different location and scale value\n\nq = {}\nq[(0, 1)] = create_q(0.0, 1.0)\n\nfor loc in [0, 1]:\n    for scale in [1, 2]:\n        q[(loc, scale)] = create_q(float(loc), float(scale))\n\n\nplt.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\", lw=3)\nplt.plot(\n    z_values,\n    torch.exp(create_q(0.0, 2.0).log_prob(z_values)),\n    label=r\"$q_1\\sim\\mathcal{N}(0.00, 2.00)$\",\n    lw=2,\n    linestyle=\"--\",\n)\nplt.plot(\n    z_values,\n    torch.exp(create_q(1.0, 3.0).log_prob(z_values)),\n    label=r\"$q_2\\sim\\mathcal{N}(1.00, 3.00)$\",\n    lw=2,\n    linestyle=\"-.\",\n)\n\nplt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\nsns.despine()\nplt.tight_layout()\nplt.savefig(\n    \"dkl.png\",\n    dpi=150,\n)\n\n\n\n\n\n\n\n\n\n#### Computing KL-divergence\n\nq_0_2_dkl = dist.kl_divergence(create_q(0.0, 2.0), p)\nq_1_3_dkl = dist.kl_divergence(create_q(1.0, 3.0), p)\n\nprint(f\"D_KL (q(0, 2)||p) = {q_0_2_dkl:0.2f}\")\nprint(f\"D_KL (q(1, 3)||p) = {q_1_3_dkl:0.2f}\")\n\nD_KL (q(0, 2)||p) = 0.35\nD_KL (q(1, 3)||p) = 0.07\n\n\nAs mentioned earlier, clearly, \\(q_2\\sim\\mathcal{N}(1.00, 3.00)\\) seems closer to \\(p\\)\n\n\n\nOptimizing the KL-divergence between q and p\nWe could create a grid of (loc, scale) pairs and find the best, as shown below.\n\nplt.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\", lw=5)\n\n\nfor loc in [0, 1]:\n    for scale in [1, 2]:\n        q_d = q[(loc, scale)]\n        kl_d = dist.kl_divergence(q[(loc, scale)], p)\n        plt.plot(\n            z_values,\n            torch.exp(q_d.log_prob(z_values)),\n            label=rf\"$q\\sim\\mathcal{{N}}({loc}, {scale})$\"\n            + \"\\n\"\n            + rf\"$D_{{KL}}(q||p)$ = {kl_d:0.2f}\",\n        )\nplt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\nsns.despine()\n\n\n\n\n\n\n\n\nOr, we could use continuous optimization to find the best loc and scale parameters for q.\n\nloc = torch.tensor(8.0, requires_grad=True)\nscale = torch.tensor(0.1, requires_grad=True)\n\n\nloc_array = []\nscale_array = []\nloss_array = []\nopt = torch.optim.Adam([loc, scale], lr=0.05)\nfor i in range(401):\n    scale_softplus = torch.functional.F.softplus(scale)\n\n    to_learn = dist.Normal(loc=loc, scale=scale_softplus)\n    loss = dist.kl_divergence(to_learn, p)\n    loss_array.append(loss.item())\n    loc_array.append(to_learn.loc.item())\n    scale_array.append(to_learn.scale.item())\n\n    loss.backward()\n    if i % 100 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss.item():0.2f}, Loc: {loc.item():0.2f}, Scale: {scale_softplus.item():0.2f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 2.73, Loc: 8.00, Scale: 0.74\nIteration: 100, Loss: 0.26, Loc: 3.75, Scale: 3.46\nIteration: 200, Loss: 0.01, Loc: 1.68, Scale: 3.98\nIteration: 300, Loss: 0.00, Loc: 1.10, Scale: 4.00\nIteration: 400, Loss: 0.00, Loc: 1.01, Scale: 4.00\n\n\n\nplt.plot(torch.tensor(scale_array))\nplt.plot(torch.tensor(loc_array))\nplt.plot(torch.tensor(loss_array))\n\n\n\n\n\n\n\n\nAfter training, we are able to recover the scale and loc very close to that of \\(p\\)\n\n\nAnimation!\n\nfrom matplotlib import animation\n\nfig = plt.figure(tight_layout=True, figsize=(8, 4))\nax = fig.gca()    \n\n\ndef animate(i):\n    ax.clear()\n    ax.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\", lw=5)\n    to_learn_q = dist.Normal(loc = loc_array[i], scale=scale_array[i])\n    loss = loss_array[i]\n    ax.plot(\n        z_values,\n        torch.exp(to_learn_q.log_prob(z_values)),\n        label=rf\"$q\\sim \\mathcal{{N}}({loc:0.2f}, {scale:0.2f})$\",\n    )\n\n    ax.set_title(rf\"Iteration: {i}, $D_{{KL}}(q||p)$: {loss:0.2f}\")\n    ax.legend(bbox_to_anchor=(1.1, 1), borderaxespad=0)\n    ax.set_ylim((0, 1))\n    ax.set_xlim((-5, 15))\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"PDF\")\n    sns.despine()\n\n\nani = animation.FuncAnimation(fig, animate, frames=350)\nplt.close()\n\n\nani.save(\"kl_qp.gif\", writer=\"imagemagick\", fps=60)\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n\n\nFinding the KL divergence for two distributions from different families\nLet us rework our example with p coming from a mixture of Gaussian distribution and q being Normal.\n\np_s = dist.MixtureSameFamily(\n    mixture_distribution=dist.Categorical(probs=torch.tensor([0.5, 0.5])),\n    component_distribution=dist.Normal(\n        loc=torch.tensor([-0.2, 1]), scale=torch.tensor([0.4, 0.5])  # One for each component.\n    ),\n)  \n\np_s\n\nMixtureSameFamily(\n  Categorical(probs: torch.Size([2]), logits: torch.Size([2])),\n  Normal(loc: torch.Size([2]), scale: torch.Size([2])))\n\n\n\nplt.plot(z_values, torch.exp(p_s.log_prob(z_values)))\nsns.despine()\n\n\n\n\n\n\n\n\nLet us create two Normal distributions q_1 and q_2 and plot them to see which looks closer to p_s.\n\nq_1 = create_q(3, 1)\nq_2 = create_q(3, 4.5)\n\n\nprob_values_p_s = torch.exp(p_s.log_prob(z_values))\nprob_values_q_1 = torch.exp(q_1.log_prob(z_values))\nprob_values_q_2 = torch.exp(q_2.log_prob(z_values))\n\nplt.plot(z_values, prob_values_p_s, label=r\"MOG\")\nplt.plot(z_values, prob_values_q_1, label=r\"$q_1\\sim\\mathcal{N} (3, 1.0)$\")\nplt.plot(z_values, prob_values_q_2, label=r\"$q_2\\sim\\mathcal{N} (3, 4.5)$\")\n\nsns.despine()\nplt.legend()\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\nplt.tight_layout()\nplt.savefig(\n    \"dkl-different.png\",\n    dpi=150,\n)\n\n\n\n\n\n\n\n\n\ntry:\n    dist.kl_divergence(q_1, p_s)\nexcept NotImplementedError:\n    print(f\"KL divergence not implemented between {q_1.__class__} and {p_s.__class__}\")\n\nKL divergence not implemented between &lt;class 'torch.distributions.normal.Normal'&gt; and &lt;class 'torch.distributions.mixture_same_family.MixtureSameFamily'&gt;\n\n\nAs we see above, we can not compute the KL divergence directly. The core idea would now be to leverage the Monte Carlo sampling and generating the expectation. The following function does that.\n\ndef kl_via_sampling(q, p, n_samples=100000):\n    # Get samples from q\n    sample_set = q.sample([n_samples])\n    # Use the definition of KL-divergence\n    return torch.mean(q.log_prob(sample_set) - p.log_prob(sample_set))\n\n\ndist.kl_divergence(q_1, q_2)\n\ntensor(1.0288)\n\n\n\nkl_via_sampling(q_1, q_2)\n\ntensor(1.0268)\n\n\n\nkl_via_sampling(q_1, p_s), kl_via_sampling(q_2, p_s)\n\n(tensor(9.4963), tensor(45.4601))\n\n\nAs we can see from KL divergence calculations, q_1 is closer to our Gaussian mixture distribution.\n\n\nOptimizing the KL divergence for two distributions from different families\nWe saw that we can calculate the KL divergence between two different distribution families via sampling. But, as we did earlier, will we be able to optimize the parameters of our target surrogate distribution? The answer is No! As we have introduced sampling. However, there is still a way – by reparameterization!\nOur surrogate q in this case is parameterized by loc and scale. The key idea here is to generate samples from a standard normal distribution (loc=0, scale=1) and then apply an affine transformation on the generated samples to get the samples generated from q. See my other post on sampling from normal distribution to understand this better.\nThe loss can now be thought of as a function of loc and scale.\n\nn_samples = 1000\n\n\ndef loss(loc, scale):\n    q = dist.Normal(loc=loc, scale=scale)\n    std_normal = dist.Normal(loc=0.0, scale=1.0)\n    sample_set = std_normal.sample([n_samples])\n    sample_set = loc + scale * sample_set\n    return torch.mean(q.log_prob(sample_set) - p_s.log_prob(sample_set))\n\nHaving defined the loss above, we can now optimize loc and scale to minimize the KL-divergence.\n\noptimizer = tf.optimizers.Adam(learning_rate=0.05)\n\n\nloc = torch.tensor(8.0, requires_grad=True)\nscale = torch.tensor(0.1, requires_grad=True)\n\n\nloc_array = []\nscale_array = []\nloss_array = []\nopt = torch.optim.Adam([loc, scale], lr=0.05)\nfor i in range(401):\n    scale_softplus = torch.functional.F.softplus(scale)\n\n    to_learn = dist.Normal(loc=loc, scale=scale_softplus)\n    loss_value = loss(loc, scale_softplus)\n    loss_array.append(loss_value.item())\n    loc_array.append(to_learn.loc.item())\n    scale_array.append(to_learn.scale.item())\n\n    loss_value.backward()\n    if i % 100 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss_value.item():0.2f}, Loc: {loc.item():0.2f}, Scale: {scale_softplus.item():0.2f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 99.76, Loc: 8.00, Scale: 0.74\nIteration: 100, Loss: 15.53, Loc: 3.75, Scale: 0.49\nIteration: 200, Loss: 1.57, Loc: 1.67, Scale: 0.51\nIteration: 300, Loss: 0.33, Loc: 0.96, Scale: 0.70\nIteration: 400, Loss: 0.08, Loc: 0.62, Scale: 0.74\n\n\n\nq_s = dist.Normal(loc=loc, scale=scale_softplus)\nq_s\n\nNormal(loc: 0.6216101050376892, scale: 0.739622175693512)\n\n\n\nprob_values_p_s = torch.exp(p_s.log_prob(z_values))\nprob_values_q_s = torch.exp(q_s.log_prob(z_values))\n\nplt.plot(z_values, prob_values_p_s.detach(), label=r\"p\")\nplt.plot(z_values, prob_values_q_s.detach(), label=r\"q\")\n\nsns.despine()\nplt.legend()\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\n\nText(0, 0.5, 'PDF')\n\n\n\n\n\n\n\n\n\n\nprob_values_p_s = torch.exp(p_s.log_prob(z_values))\n\nfig = plt.figure(tight_layout=True, figsize=(8, 4))\nax = fig.gca()\nn_iter = 300\n\ndef a(iteration):\n\n    ax.clear()\n    loc = loc_array[iteration]\n    scale = scale_array[iteration]\n    q_s = dist.Normal(loc=loc, scale=scale)\n\n    prob_values_q_s = torch.exp(q_s.log_prob(z_values))\n\n    ax.plot(z_values, prob_values_p_s, label=r\"p\")\n    ax.plot(z_values, prob_values_q_s, label=r\"q\")\n    ax.set_title(f\"Iteration {iteration}, Loss: {loss_array[iteration]:0.2f}\")\n    ax.set_ylim((-0.05, 1.05))\n    ax.legend()\n\nani_mg = animation.FuncAnimation(fig, a, frames=n_iter)\nplt.close()\n\n\nplt.plot(loc_array, label=\"loc\")\nplt.plot(scale_array, label=\"scale\")\nplt.xlabel(\"Iterations\")\nsns.despine()\nplt.legend()\n\n\n\n\n\n\n\n\n\nani_mg.save(\"kl_qp_mg.gif\", writer=\"imagemagick\")\n\n\n\nKL-Divergence and ELBO\nLet us consider linear regression. We have parameters \\(\\theta \\in R^D\\) and we define a prior over them. Let us assume we define prior \\(p(\\theta)\\sim \\mathcal{N_D} (\\mu, \\Sigma)\\). Now, given our dataset \\(D = \\{X, y\\}\\) and a parameter vector \\(\\theta\\), we can deifine our likelihood as \\(p(D|\\theta)\\) or $p(y|X, ) = {i=1}^{n} p(y_i|x_i, ) = {i=1}^{n} (y_i|x_i^T, ^2) $\nAs per Bayes rule, we can obtain the posterior over \\(\\theta\\) as:\n\\(p(\\theta|D) = \\dfrac{p(D|\\theta)p(\\theta)}{p(D)}\\)\nNow, in general \\(p(D)\\) is hard to compute.\nSo, in variational inference, our aim is to use a surrogate distribution \\(q(\\theta)\\) such that it is very close to \\(p(\\theta|D)\\). We do so by minimizing the KL divergence between \\(q(\\theta)\\) and \\(p(\\theta|D)\\).\nAim: \\[q^*(\\theta) = \\underset{q(\\theta) \\in \\mathcal{Q}}{\\mathrm{argmin~}} D_{KL}[q(\\theta)||p(\\theta|D)]\\]\nNow, \\[D_{KL}[q(\\theta)||p(\\theta|D)] = \\mathbb{E}_{q(\\theta)}[\\log\\frac{q(\\theta)}{p(\\theta|D)}]\\] Now, \\[ = \\mathbb{E}_{q(\\theta)}[\\log\\frac{q(\\theta)p(D)}{p(\\theta, D)}]\\] Now, \\[ = \\mathbb{E}_{q(\\theta)}[\\log q(\\theta)]- \\mathbb{E}_{q(\\theta)}[\\log p(\\theta, D)] + \\mathbb{E}_{q(\\theta)}[\\log p(D)] \\] \\[= \\mathbb{E}_{q(\\theta)}[\\log q(\\theta)]- \\mathbb{E}_{q(\\theta)}[\\log p(\\theta, D)] + \\log p(D) \\]\nNow, \\(p(D) \\in \\{0, 1\\}\\). Thus, \\(\\log p(D) \\in \\{-\\infty, 0 \\}\\)\nNow, let us look at the quantities:\n\\[\\underbrace{D_{KL}[q(\\theta)||p(\\theta|D)]}_{\\geq 0} = \\underbrace{\\mathbb{E}_{q(\\theta)}[\\log q(\\theta)]- \\mathbb{E}_{q(\\theta)}[\\log p(\\theta, D)]}_{-\\text{ELBO(q)}} +  \\underbrace{\\log p(D)}_{\\leq 0}\\]\nThus, we know that \\(\\log p(D) \\geq \\text{ELBO(q)}\\)\nThus, finally we can rewrite the optimisation from\n\\[q^*(\\theta) = \\underset{q(\\theta) \\in \\mathcal{Q}}{\\mathrm{argmin~}} D_{KL}[q(\\theta)||p(\\theta|D)]\\]\nto\n\\[q^*(\\theta) = \\underset{q(\\theta) \\in \\mathcal{Q}}{\\mathrm{argmax~}} \\text{ELBO(q)}\\]\nNow, given our linear regression problem setup, we want to maximize the ELBO.\nWe can do so by the following. As a simple example, let us assume \\(\\theta \\in R^2\\)\n\nAssume some q. Say, a Normal distribution. So, \\(q\\sim \\mathcal{N}_2\\)\nDraw samples from q. Say N samples.\nInitilize ELBO = 0.0\nFor each sample:\n\nLet us assume drawn sample is \\([\\theta_1, \\theta_2]^T\\)\nCompute log_prob of prior on \\([\\theta_1, \\theta_2]^T\\) or lp = p.log_prob(θ1, θ2)\nCompute log_prob of likelihood on \\([\\theta_1, \\theta_2]^T\\) or ll = l.log_prob(θ1, θ2)\nCompute log_prob of q on \\([\\theta_1, \\theta_2]^T\\) or lq = q.log_prob(θ1, θ2)\nELBO = ELBO + (ll+lp-q)\n\nReturn ELBO/N\n\n\nprior = dist.Normal(loc = 0., scale = 1.)\np = dist.Normal(loc = 5., scale = 1.)\n\n\nsamples = p.sample([1000])\n\n\nmu = torch.tensor(1.0, requires_grad=True)\n\ndef surrogate_sample(mu):\n    std_normal = dist.Normal(loc = 0., scale=1.)\n    sample_std_normal  = std_normal.sample()\n    return mu + sample_std_normal\n\n\nsamples_from_surrogate = surrogate_sample(mu)\n\n\nsamples_from_surrogate\n\ntensor(2.7988, grad_fn=&lt;AddBackward0&gt;)\n\n\n\ndef logprob_prior(mu):\n    return prior.log_prob(mu)\n\nlp = logprob_prior(samples_from_surrogate)\n\ndef log_likelihood(mu, samples):\n    di = dist.Normal(loc=mu, scale=1)\n    return torch.sum(di.log_prob(samples))\n\nll = log_likelihood(samples_from_surrogate, samples)\n\nls = surrogate.log_prob(samples_from_surrogate)\n\n\n\ndef elbo_loss(mu, data_samples):\n    samples_from_surrogate = surrogate_sample(mu)\n    lp = logprob_prior(samples_from_surrogate)\n    ll = log_likelihood(samples_from_surrogate, data_samples)\n    ls = surrogate.log_prob(samples_from_surrogate)\n\n    return -lp - ll + ls\n\n\nmu = torch.tensor(1.0, requires_grad=True)\n\nloc_array = []\nloss_array = []\n\nopt = torch.optim.Adam([mu], lr=0.02)\nfor i in range(2000):\n    loss_val = elbo_loss(mu, samples)\n    loss_val.backward()\n    loc_array.append(mu.item())\n    loss_array.append(loss_val.item())\n\n    if i % 100 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss_val.item():0.2f}, Loc: {mu.item():0.3f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 11693.85, Loc: 1.000\nIteration: 100, Loss: 2550.90, Loc: 2.744\nIteration: 200, Loss: 2124.30, Loc: 3.871\nIteration: 300, Loss: 2272.48, Loc: 4.582\nIteration: 400, Loss: 2025.17, Loc: 4.829\nIteration: 500, Loss: 1434.45, Loc: 5.079\nIteration: 600, Loss: 1693.33, Loc: 5.007\nIteration: 700, Loss: 1495.89, Loc: 4.957\nIteration: 800, Loss: 2698.28, Loc: 5.149\nIteration: 900, Loss: 2819.85, Loc: 5.117\nIteration: 1000, Loss: 1491.79, Loc: 5.112\nIteration: 1100, Loss: 1767.87, Loc: 4.958\nIteration: 1200, Loss: 1535.30, Loc: 4.988\nIteration: 1300, Loss: 1458.61, Loc: 4.949\nIteration: 1400, Loss: 1400.21, Loc: 4.917\nIteration: 1500, Loss: 2613.42, Loc: 5.073\nIteration: 1600, Loss: 1411.46, Loc: 4.901\nIteration: 1700, Loss: 1587.94, Loc: 5.203\nIteration: 1800, Loss: 1461.40, Loc: 5.011\nIteration: 1900, Loss: 1504.93, Loc: 5.076\n\n\n\nplt.plot(loss_array)\n\n\n\n\n\n\n\n\n\nfrom numpy.lib.stride_tricks import sliding_window_view\nplt.plot(np.average(sliding_window_view(loss_array, window_shape = 10), axis=1))\n\n\n\n\n\n\n\n\n\n\nLinear Regression\n\ntrue_theta_0 = 3.\ntrue_theta_1 = 4.\n\nx = torch.linspace(-5, 5, 100)\ny_true = true_theta_0 + true_theta_1*x\ny_noisy = y_true + torch.normal(mean = torch.zeros_like(x), std = torch.ones_like(x))\n\nplt.plot(x, y_true)\nplt.scatter(x, y_noisy, s=20, alpha=0.5)\n\n\n\n\n\n\n\n\n\ny_pred = x_dash@theta_prior.sample()\nplt.plot(x, y_pred, label=\"Fit\")\nplt.scatter(x, y_noisy, s=20, alpha=0.5, label='Data')\nplt.legend()\n\n\n\n\n\n\n\n\n\ntheta_prior = dist.MultivariateNormal(loc = torch.tensor([0., 0.]), covariance_matrix=torch.eye(2))\n\n\ndef likelihood(theta, x, y):\n    x_dash = torch.vstack((torch.ones_like(x), x)).t()\n    d = dist.Normal(loc=x_dash@theta, scale=torch.ones_like(x))\n    return torch.sum(d.log_prob(y))\n\n\nlikelihood(theta_prior.sample(), x, y_noisy)\n\ntensor(-3558.0769)\n\n\n\nloc = torch.tensor([-1., 1.], requires_grad=True)\nsurrogate_mvn = dist.MultivariateNormal(loc = loc, covariance_matrix=torch.eye(2))\nsurrogate_mvn\n\nMultivariateNormal(loc: torch.Size([2]), covariance_matrix: torch.Size([2, 2]))\n\n\n\nsurrogate_mvn.sample()\n\ntensor([-1.1585,  2.6212])\n\n\n\ndef surrogate_sample_mvn(loc):\n    std_normal_mvn = dist.MultivariateNormal(loc = torch.zeros_like(loc), covariance_matrix=torch.eye(loc.shape[0]))\n    sample_std_normal  = std_normal_mvn.sample()\n    return loc + sample_std_normal\n\n\ndef elbo_loss(loc, x, y):\n    samples_from_surrogate_mvn = surrogate_sample_mvn(loc)\n    lp = theta_prior.log_prob(samples_from_surrogate_mvn)\n    ll = likelihood(samples_from_surrogate_mvn, x, y_noisy)\n    ls = surrogate_mvn.log_prob(samples_from_surrogate_mvn)\n\n    return -lp - ll + ls\n\n\nloc.shape, x.shape, y_noisy.shape\n\n(torch.Size([2]), torch.Size([100]), torch.Size([100]))\n\n\n\nelbo_loss(loc, x, y_noisy)\n\ntensor(2850.3154, grad_fn=&lt;AddBackward0&gt;)\n\n\n\nloc = torch.tensor([-1., 1.], requires_grad=True)\n\n\nloc_array = []\nloss_array = []\n\nopt = torch.optim.Adam([loc], lr=0.02)\nfor i in range(10000):\n    loss_val = elbo_loss(loc, x, y_noisy)\n    loss_val.backward()\n    loc_array.append(mu.item())\n    loss_array.append(loss_val.item())\n\n    if i % 1000 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss_val.item():0.2f}, Loc: {loc}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 5479.97, Loc: tensor([-1.,  1.], requires_grad=True)\nIteration: 1000, Loss: 566.63, Loc: tensor([2.9970, 4.0573], requires_grad=True)\nIteration: 2000, Loss: 362.19, Loc: tensor([2.9283, 3.9778], requires_grad=True)\nIteration: 3000, Loss: 231.23, Loc: tensor([2.8845, 4.1480], requires_grad=True)\nIteration: 4000, Loss: 277.94, Loc: tensor([2.9284, 3.9904], requires_grad=True)\nIteration: 5000, Loss: 1151.51, Loc: tensor([2.9620, 4.0523], requires_grad=True)\nIteration: 6000, Loss: 582.19, Loc: tensor([2.8003, 4.0540], requires_grad=True)\nIteration: 7000, Loss: 178.48, Loc: tensor([2.8916, 3.9968], requires_grad=True)\nIteration: 8000, Loss: 274.76, Loc: tensor([3.0807, 4.1957], requires_grad=True)\nIteration: 9000, Loss: 578.37, Loc: tensor([2.9830, 4.0174], requires_grad=True)\n\n\n\nlearnt_surrogate = dist.MultivariateNormal(loc = loc, covariance_matrix=torch.eye(2))\n\n\ny_samples_surrogate = x_dash@learnt_surrogate.sample([500]).t()\nplt.plot(x, y_samples_surrogate, alpha = 0.02, color='k');\nplt.scatter(x, y_noisy, s=20, alpha=0.5)\n\n\n\n\n\n\n\n\n\nx_dash@learnt_surrogate.loc.detach().t()\ntheta_sd = torch.linalg.cholesky(learnt_surrogate.covariance_matrix)\n\n\n#y_samples_surrogate = x_dash@learnt_surrogate.loc.t()\n#plt.plot(x, y_samples_surrogate, alpha = 0.02, color='k');\n#plt.scatter(x, y_noisy, s=20, alpha=0.5)\n\ntensor([-1.6542e+01, -1.6148e+01, -1.5754e+01, -1.5360e+01, -1.4966e+01,\n        -1.4572e+01, -1.4178e+01, -1.3784e+01, -1.3390e+01, -1.2996e+01,\n        -1.2602e+01, -1.2208e+01, -1.1814e+01, -1.1420e+01, -1.1026e+01,\n        -1.0632e+01, -1.0238e+01, -9.8441e+00, -9.4501e+00, -9.0561e+00,\n        -8.6621e+00, -8.2681e+00, -7.8741e+00, -7.4801e+00, -7.0860e+00,\n        -6.6920e+00, -6.2980e+00, -5.9040e+00, -5.5100e+00, -5.1160e+00,\n        -4.7220e+00, -4.3280e+00, -3.9340e+00, -3.5400e+00, -3.1460e+00,\n        -2.7520e+00, -2.3579e+00, -1.9639e+00, -1.5699e+00, -1.1759e+00,\n        -7.8191e-01, -3.8790e-01,  6.1054e-03,  4.0011e-01,  7.9412e-01,\n         1.1881e+00,  1.5821e+00,  1.9761e+00,  2.3702e+00,  2.7642e+00,\n         3.1582e+00,  3.5522e+00,  3.9462e+00,  4.3402e+00,  4.7342e+00,\n         5.1282e+00,  5.5222e+00,  5.9162e+00,  6.3102e+00,  6.7043e+00,\n         7.0983e+00,  7.4923e+00,  7.8863e+00,  8.2803e+00,  8.6743e+00,\n         9.0683e+00,  9.4623e+00,  9.8563e+00,  1.0250e+01,  1.0644e+01,\n         1.1038e+01,  1.1432e+01,  1.1826e+01,  1.2220e+01,  1.2614e+01,\n         1.3008e+01,  1.3402e+01,  1.3796e+01,  1.4190e+01,  1.4584e+01,\n         1.4978e+01,  1.5372e+01,  1.5766e+01,  1.6160e+01,  1.6554e+01,\n         1.6948e+01,  1.7342e+01,  1.7736e+01,  1.8131e+01,  1.8525e+01,\n         1.8919e+01,  1.9313e+01,  1.9707e+01,  2.0101e+01,  2.0495e+01,\n         2.0889e+01,  2.1283e+01,  2.1677e+01,  2.2071e+01,  2.2465e+01])\n\n\nTODO\n\nPyro for linear regression example\nHandle more samples in ELBO\nReuse some methods\nAdd figure on reparameterization\nLinear regression learn covariance also\nLinear regression posterior compare with analytical posterior (refer Murphy book)\nClean up code and reuse code whwrever possible\nImprove figures and make them consistent\nAdd background maths wherever needed\nplot the Directed graphical model (refer Maths ML book and render in Pyro)\nLook at the TFP post on https://www.tensorflow.org/probability/examples/Probabilistic_Layers_Regression\nShow the effect of data size (less data, solution towards prior, else dominated by likelihood)\nMean Firld (full covariance v/s diagonal) for surrogate\n\nReferences\n\nhttps://www.youtube.com/watch?v=HUsznqt2V5I\nhttps://www.youtube.com/watch?v=x9StQ8RZ0ag&list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ&index=9\nhttps://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2021-09-13-02-Minimizing-KL-Divergence.ipynb#scrollTo=gd_ev8ceII8q\nhttps://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/09/13/02-Minimizing-KL-Divergence.html"
  },
  {
    "objectID": "posts/2024-sample-distribution.html",
    "href": "posts/2024-sample-distribution.html",
    "title": "Sampling Distribution Analysis - Mean vs Standard Deviation",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- MLdate: ’2024-05-07’title: Sampling Distribution Analysis - Mean vs Standard Deviationtoc: true—\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange, reduce, repeat\n\n\nvals_Delhi = np.array([182, 322, 252, 269, 245, 214, 230, 223, 229, 327, 219, 216, 272, 208, 320, 310, 187, 230, 192, 332, 213, 198, 269, 226, 242, 299, 241, 249, 203, 270, 273, 228, 294, 233, 220, 311, 208, 245, 271])\nvals_Kolhapur = np.array([90, 150])\n\n\npop_mean = np.mean(vals_Delhi)\npop_stdev = np.std(vals_Delhi)\n\n# Now, consider different subsets of the data of size K and find the mean and standard deviation of each subset \n# and plot the mean and standard deviation of each subset.\n\nK = 5\n\ndef plot_subsets(vals, K):\n\n    means = []\n    stdevs = []\n\n    num_subset = 100\n    for i in range(num_subset):\n        subset = np.random.choice(vals_Delhi, K)\n        means.append(np.mean(subset))\n        stdevs.append(np.std(subset))\n        \n\n    plt.scatter(means, stdevs, label = 'Subsets')\n    plt.xlabel('Mean')\n    plt.ylabel('Standard Deviation')\n\n    plt.scatter([pop_mean], [pop_stdev], color='red', label = 'Population', s = 100)\n    plt.xlim(180, 360)\n    plt.ylim(-10, 80)\n    plt.legend()\n    plt.title(f'Mean vs Standard Deviation of Subsets for K = {K}')\n\n\nplot_subsets(vals_Delhi, 2)\n\n\n\n\n\n\n\n\n\nplot_subsets(vals_Delhi, 5)\n\n\n\n\n\n\n\n\n\nplot_subsets(vals_Delhi, 30)\n\n\n\n\n\n\n\n\n\ndef plot_distribution(vals, city='Delhi'):\n    # Fit a normal distribution to the data\n    mu, std = np.mean(vals), np.std(vals, ddof=0)\n\n    # Plot the normal distribution\n    xs = np.linspace(0, 400, 1000)\n\n    ys = 1/(std * np.sqrt(2 * np.pi)) * np.exp( - (xs - mu)**2 / (2 * std**2) )\n\n    plt.plot(xs, ys)\n\n    # Mark the mean\n    plt.axvline(mu, color='r', linestyle='--', label = 'Mean')\n\n    # Mark the values via rag plot\n    plt.plot(vals, [0]*len(vals), 'k|', label = 'Values')\n    \n    standard_error_mean = std / np.sqrt(len(vals)-1)\n\n\n    # Mark the 95% confidence interval of SEM with shading \n    fac = 1.96\n    sem_times_fac = standard_error_mean * fac\n    plt.fill_between(xs, 0, ys, where = (xs &gt; mu - sem_times_fac) & (xs &lt; mu + sem_times_fac), color = 'r', alpha = 0.5, label = '95% CI of SEM')\n    plt.legend()\n    plt.title(f'Distribution of values in {city}\\n Mean: {mu:.2f}, Sample STDEV: {std:.2f} Standard Error of Mean: {standard_error_mean:.2f}')\n\n\nplot_distribution(vals_Delhi, city='Delhi')\n\n\n\n\n\n\n\n\n\nplot_distribution(vals_Kolhapur, city='Kolhapur')"
  },
  {
    "objectID": "posts/torch-likelihoods.html",
    "href": "posts/torch-likelihoods.html",
    "title": "Heteroskedastic and Homoskedastic MLPs in PyTorch for regression",
    "section": "",
    "text": "# Imports\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.distributions as dist\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# Set device to GPU if available\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nDataset\n\n### Heteroskedastic Noise Dataset\n                       \n# Fix random seed\ntorch.manual_seed(0)\n\nx = torch.linspace(-1, 1, 100)\nf = lambda x: 3 * x\n\neps = torch.randn(x.size()) * x * 0.5\ny = f(x) + eps\n\nplt.scatter(x.numpy(), y.numpy())\nplt.plot(x.numpy(), 3 * x.numpy(), 'r-', lw=5)\n\n# Move data to device\nx = x.to(device)\ny = y.to(device)\n\n\n\n\n\n\n\n\n\nclass HeteroskedasticMLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(HeteroskedasticMLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, 2)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        z = self.fc3(x)\n        # Get mu and log_sigma from the last layer\n        mu, log_sigma = z[:, 0], z[:, 1]\n        return mu, log_sigma\n\n\n# Create model\n\nmodel = HeteroskedasticMLP(1, 100)\n\n# Move model to device\n\nmodel = model.to(device)\n\n# Define loss function\n\ndef heteroskedastic_loss(y, mu, log_sigma):\n    sigma = torch.exp(log_sigma)\n    ll = dist.Normal(mu.ravel(), sigma.ravel()).log_prob(y.ravel())\n    return -ll.mean()\n\n\nwith torch.no_grad():\n    mu, log_sigma = model(x.unsqueeze(1))\n    loss = heteroskedastic_loss(y, mu, log_sigma)\n    print(loss)\n\ntensor(2.9041, device='cuda:0')\n\n\n\n# Plot initial predictions\n\nwith torch.no_grad():\n    mu, log_sigma = model(x.unsqueeze(1))\n    sigma = torch.exp(log_sigma)\n    plt.scatter(x.cpu().numpy(), y.cpu().numpy())\n    plt.plot(x.cpu().numpy(), mu.cpu().numpy(), 'r-', lw=5)\n    plt.fill_between(x.cpu().numpy(), mu.cpu().numpy() - sigma.cpu().numpy(), mu.cpu().numpy() + sigma.cpu().numpy(), alpha=0.5)\n\n\n\n\n\n\n\n\n\n# Train model with Adam\n\noptimizer = optim.Adam(model.parameters(), lr=0.01)\nevery_i = 10\nouts= {}\nlosses = []\n\nfor epoch in range(1000):\n    # Store model predictions every_i epochs\n    if epoch % every_i == 0:\n        \n        with torch.no_grad():\n            mu, log_sigma = model(x.unsqueeze(1))\n            outs[epoch] = {\"mu\":mu.cpu().numpy(),\n                            \"log_sigma\":log_sigma.cpu().numpy()}\n\n            # Print loss\n            loss = heteroskedastic_loss(y, mu, log_sigma)\n            print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n\n    # Forward pass\n    mu, log_sigma = model(x.unsqueeze(1))\n    loss = heteroskedastic_loss(y, mu, log_sigma)\n    losses.append(loss.item())\n\n    # Backward pass\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n\nEpoch: 0, Loss: 2.904067277908325\nEpoch: 10, Loss: 0.8787063956260681\nEpoch: 20, Loss: 0.21688087284564972\nEpoch: 30, Loss: 0.13268794119358063\nEpoch: 40, Loss: 0.026131045073270798\nEpoch: 50, Loss: -0.04720224440097809\nEpoch: 60, Loss: -0.10559850186109543\nEpoch: 70, Loss: -0.14626550674438477\nEpoch: 80, Loss: -0.18292102217674255\nEpoch: 90, Loss: -0.1582060158252716\nEpoch: 100, Loss: -0.20254844427108765\nEpoch: 110, Loss: -0.21556152403354645\nEpoch: 120, Loss: -0.21742510795593262\nEpoch: 130, Loss: -0.2227230668067932\nEpoch: 140, Loss: -0.22566699981689453\nEpoch: 150, Loss: -0.23224511742591858\nEpoch: 160, Loss: -0.27615076303482056\nEpoch: 170, Loss: -0.239326611161232\nEpoch: 180, Loss: -0.2770726978778839\nEpoch: 190, Loss: -0.3069627285003662\nEpoch: 200, Loss: -0.2779914140701294\nEpoch: 210, Loss: -0.27238503098487854\nEpoch: 220, Loss: -0.3456583023071289\nEpoch: 230, Loss: -0.2058892548084259\nEpoch: 240, Loss: -0.2964232563972473\nEpoch: 250, Loss: -0.306146502494812\nEpoch: 260, Loss: -0.3319600522518158\nEpoch: 270, Loss: -0.3472471833229065\nEpoch: 280, Loss: -0.24077902734279633\nEpoch: 290, Loss: -0.3256893455982208\nEpoch: 300, Loss: -0.31607362627983093\nEpoch: 310, Loss: -0.35320231318473816\nEpoch: 320, Loss: -0.28444549441337585\nEpoch: 330, Loss: -0.3202727437019348\nEpoch: 340, Loss: -0.27290675044059753\nEpoch: 350, Loss: -0.3401243984699249\nEpoch: 360, Loss: -0.3831108808517456\nEpoch: 370, Loss: -0.4019301235675812\nEpoch: 380, Loss: -0.22064653038978577\nEpoch: 390, Loss: -0.3605082631111145\nEpoch: 400, Loss: -0.35815513134002686\nEpoch: 410, Loss: -0.3972603976726532\nEpoch: 420, Loss: -0.4117273688316345\nEpoch: 430, Loss: -0.3907165825366974\nEpoch: 440, Loss: -0.4307834506034851\nEpoch: 450, Loss: -0.3612615466117859\nEpoch: 460, Loss: -0.40269431471824646\nEpoch: 470, Loss: -0.3225415050983429\nEpoch: 480, Loss: -0.41836538910865784\nEpoch: 490, Loss: -0.24793219566345215\nEpoch: 500, Loss: -0.3380727171897888\nEpoch: 510, Loss: -0.41523680090904236\nEpoch: 520, Loss: -0.42837637662887573\nEpoch: 530, Loss: -0.3614443242549896\nEpoch: 540, Loss: -0.45410436391830444\nEpoch: 550, Loss: -0.45134565234184265\nEpoch: 560, Loss: -0.4771314263343811\nEpoch: 570, Loss: -0.37739044427871704\nEpoch: 580, Loss: -0.4571133255958557\nEpoch: 590, Loss: -0.3359305262565613\nEpoch: 600, Loss: -0.4643993377685547\nEpoch: 610, Loss: -0.4199213981628418\nEpoch: 620, Loss: -0.48145925998687744\nEpoch: 630, Loss: -0.39580008387565613\nEpoch: 640, Loss: -0.1910054236650467\nEpoch: 650, Loss: -0.4236544072628021\nEpoch: 660, Loss: -0.5013049840927124\nEpoch: 670, Loss: -0.4683534502983093\nEpoch: 680, Loss: -0.46403956413269043\nEpoch: 690, Loss: -0.40134137868881226\nEpoch: 700, Loss: -0.4733808934688568\nEpoch: 710, Loss: -0.49756529927253723\nEpoch: 720, Loss: -0.5301379561424255\nEpoch: 730, Loss: -0.4607459604740143\nEpoch: 740, Loss: -0.39366793632507324\nEpoch: 750, Loss: -0.5319433212280273\nEpoch: 760, Loss: -0.5354660153388977\nEpoch: 770, Loss: -0.058051079511642456\nEpoch: 780, Loss: -0.3275614082813263\nEpoch: 790, Loss: 0.18349406123161316\nEpoch: 800, Loss: -0.22516368329524994\nEpoch: 810, Loss: -0.3372257649898529\nEpoch: 820, Loss: -0.46307849884033203\nEpoch: 830, Loss: -0.49147552251815796\nEpoch: 840, Loss: -0.4938444495201111\nEpoch: 850, Loss: 0.0712403729557991\nEpoch: 860, Loss: -0.3009780943393707\nEpoch: 870, Loss: -0.4817323088645935\nEpoch: 880, Loss: -0.5302295088768005\nEpoch: 890, Loss: -0.31002792716026306\nEpoch: 900, Loss: -0.4778610169887543\nEpoch: 910, Loss: -0.473131388425827\nEpoch: 920, Loss: -0.4545957148075104\nEpoch: 930, Loss: -0.5534473061561584\nEpoch: 940, Loss: -0.42977163195610046\nEpoch: 950, Loss: -0.5166257619857788\nEpoch: 960, Loss: -0.10863237082958221\nEpoch: 970, Loss: -0.4224903881549835\nEpoch: 980, Loss: -0.5379492044448853\nEpoch: 990, Loss: -0.5719044804573059\n\n\n\n# Plot loss\n\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\n# Plot final predictions\n\nwith torch.no_grad():\n    mu, log_sigma = model(x.unsqueeze(1))\n    sigma = torch.exp(log_sigma)\n    plt.scatter(x.cpu().numpy(), y.cpu().numpy())\n    plt.plot(x.cpu().numpy(), mu.cpu().numpy(), 'r-', lw=5)\n    plt.fill_between(x.cpu().numpy(), mu.cpu().numpy() - sigma.cpu().numpy(), mu.cpu().numpy() + sigma.cpu().numpy(), alpha=0.5)\n\n\n\n\n\n\n\n\n\n# Save predictions and use ffmpeg to create a video\n\nimport imageio\nimport os\nimport numpy as np\n\n# Filter out warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimages = []\nfor i in range(0, 40, every_i):\n    plt.clf()\n    plt.scatter(x.cpu().numpy(), y.cpu().numpy())\n    plt.plot(x.cpu().numpy(), outs[i][\"mu\"], 'r-', lw=5)\n    plt.fill_between(x.cpu().numpy(), outs[i][\"mu\"] - np.exp(outs[i][\"log_sigma\"]), \n            outs[i][\"mu\"] + np.exp(outs[i][\"log_sigma\"]), alpha=0.5)\n    plt.savefig(\"tmp.png\")\n    images.append(imageio.imread(\"tmp.png\"))\n    os.remove(\"tmp.png\")\n\nimageio.mimsave('heteroskedastic.gif', images, duration=0.1)\n\n\n\n\n\n\n\n\n\n # Plot gif\nfrom IPython.display import Image\nImage(url='heteroskedastic.gif')\n\n\n\n\n\n# Homoskedastic model\n\nclass HomoskedasticMLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(HomoskedasticMLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, 1)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        z = self.fc3(x)\n        return z\n\n# Create model\n\nmodel = HomoskedasticMLP(1, 100)\n\n# Move model to device\n\nmodel = model.to(device)\n\n# Learn sigma with a parameter\nlog_sigma = nn.Parameter(torch.tensor(-1.0).to(device))\n\n\n# Evaluate loss function on homoskedastic model\n\nm = HomoskedasticMLP(1, 100)\nm = m.to(device)\n\nwith torch.no_grad():\n    mu = m(x.unsqueeze(1))\n    loss = heteroskedastic_loss(y, mu.ravel(), log_sigma)\n    print(loss)\n\ntensor(10.7744, device='cuda:0')\n\n\n\n\n\n\n# Train\n\noptimizer = optim.Adam(list(model.parameters()) + [log_sigma], lr=0.01)\nevery_i = 10\nouts= {}\nlosses = []\n\nfor epoch in range(1000):\n    # Store model predictions every_i epochs\n    if epoch % every_i == 0:\n        \n        with torch.no_grad():\n            mu = model(x.unsqueeze(1))\n            outs[epoch] = {\"mu\":mu.cpu().numpy(),\n                            \"log_sigma\":log_sigma.cpu().numpy()}\n\n            # Print loss, sigma\n            loss = heteroskedastic_loss(y, mu, log_sigma)\n            print(\"Epoch: {}, Loss: {}, Sigma: {}\".format(epoch, loss.item(), torch.exp(log_sigma).item()))\n            \n\n    # Forward pass\n    mu = model(x.unsqueeze(1))\n    loss = heteroskedastic_loss(y, mu, log_sigma)\n    losses.append(loss.item())\n\n    # Backward pass\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\nEpoch: 0, Loss: 11.295394897460938, Sigma: 0.3678794801235199\nEpoch: 10, Loss: 0.25705787539482117, Sigma: 0.39439815282821655\nEpoch: 20, Loss: 0.2636868357658386, Sigma: 0.40588462352752686\nEpoch: 30, Loss: 0.29097408056259155, Sigma: 0.40923401713371277\nEpoch: 40, Loss: 0.2588760554790497, Sigma: 0.40765181183815\nEpoch: 50, Loss: 0.21829169988632202, Sigma: 0.40334761142730713\nEpoch: 60, Loss: 0.20873460173606873, Sigma: 0.3975759744644165\nEpoch: 70, Loss: 0.19598166644573212, Sigma: 0.3910154104232788\nEpoch: 80, Loss: 0.18514487147331238, Sigma: 0.38402578234672546\nEpoch: 90, Loss: 0.17355667054653168, Sigma: 0.3768104016780853\nEpoch: 100, Loss: 0.16240520775318146, Sigma: 0.36949458718299866\nEpoch: 110, Loss: 0.151631698012352, Sigma: 0.36216607689857483\nEpoch: 120, Loss: 0.14121828973293304, Sigma: 0.3548945188522339\nEpoch: 130, Loss: 0.13112765550613403, Sigma: 0.3477365970611572\nEpoch: 140, Loss: 0.12154199182987213, Sigma: 0.3407391607761383\nEpoch: 150, Loss: 0.11244719475507736, Sigma: 0.33394208550453186\nEpoch: 160, Loss: 0.10387172549962997, Sigma: 0.327378511428833\nEpoch: 170, Loss: 0.09589903801679611, Sigma: 0.32107508182525635\nEpoch: 180, Loss: 0.08854608237743378, Sigma: 0.3150540590286255\nEpoch: 190, Loss: 0.08189988881349564, Sigma: 0.3093332350254059\nEpoch: 200, Loss: 0.07573989033699036, Sigma: 0.30392542481422424\nEpoch: 210, Loss: 0.07032809406518936, Sigma: 0.29883837699890137\nEpoch: 220, Loss: 0.06527172774076462, Sigma: 0.294076144695282\nEpoch: 230, Loss: 0.060850128531455994, Sigma: 0.28963765501976013\nEpoch: 240, Loss: 0.05669783428311348, Sigma: 0.2855187654495239\nEpoch: 250, Loss: 0.05313286557793617, Sigma: 0.2817113697528839\nEpoch: 260, Loss: 0.04971342161297798, Sigma: 0.2782053053379059\nEpoch: 270, Loss: 0.04643983766436577, Sigma: 0.2749860882759094\nEpoch: 280, Loss: 0.04914667457342148, Sigma: 0.27207323908805847\nEpoch: 290, Loss: 0.04101118817925453, Sigma: 0.26953327655792236\nEpoch: 300, Loss: 0.038715146481990814, Sigma: 0.2671847343444824\nEpoch: 310, Loss: 0.03739570453763008, Sigma: 0.2649960517883301\nEpoch: 320, Loss: 0.03401820734143257, Sigma: 0.26296529173851013\nEpoch: 330, Loss: 0.040461644530296326, Sigma: 0.26111650466918945\nEpoch: 340, Loss: 0.03497060015797615, Sigma: 0.2595013380050659\nEpoch: 350, Loss: 0.02781158685684204, Sigma: 0.25808778405189514\nEpoch: 360, Loss: 0.025791816413402557, Sigma: 0.25677621364593506\nEpoch: 370, Loss: 0.027708368375897408, Sigma: 0.25549817085266113\nEpoch: 380, Loss: 0.034673772752285004, Sigma: 0.25454577803611755\nEpoch: 390, Loss: 0.01713133230805397, Sigma: 0.25372540950775146\nEpoch: 400, Loss: 0.016848329454660416, Sigma: 0.2527487576007843\nEpoch: 410, Loss: 0.012192592024803162, Sigma: 0.2516818642616272\nEpoch: 420, Loss: 0.01921256259083748, Sigma: 0.25061044096946716\nEpoch: 430, Loss: 0.023222172632813454, Sigma: 0.25001898407936096\nEpoch: 440, Loss: 0.007255341857671738, Sigma: 0.24958008527755737\nEpoch: 450, Loss: 0.0056707593612372875, Sigma: 0.24894456565380096\nEpoch: 460, Loss: 0.0030113577377051115, Sigma: 0.24814389646053314\nEpoch: 470, Loss: 2.707242856558878e-05, Sigma: 0.24727357923984528\nEpoch: 480, Loss: 0.03657829388976097, Sigma: 0.24644359946250916\nEpoch: 490, Loss: 0.006805286277085543, Sigma: 0.2461744099855423\nEpoch: 500, Loss: -0.00197244412265718, Sigma: 0.2457384169101715\nEpoch: 510, Loss: -0.0030348419677466154, Sigma: 0.2451060265302658\nEpoch: 520, Loss: -0.009371060878038406, Sigma: 0.2443939745426178\nEpoch: 530, Loss: 0.02710571512579918, Sigma: 0.24379168450832367\nEpoch: 540, Loss: -0.012330576777458191, Sigma: 0.24365800619125366\nEpoch: 550, Loss: -0.007400104776024818, Sigma: 0.2433018535375595\nEpoch: 560, Loss: -0.011339571326971054, Sigma: 0.24270297586917877\nEpoch: 570, Loss: -0.01660667359828949, Sigma: 0.24198408424854279\nEpoch: 580, Loss: 0.021730687469244003, Sigma: 0.2414063662290573\nEpoch: 590, Loss: -0.018733227625489235, Sigma: 0.2413862645626068\nEpoch: 600, Loss: -0.013013801537454128, Sigma: 0.24117600917816162\nEpoch: 610, Loss: -0.022421661764383316, Sigma: 0.24065044522285461\nEpoch: 620, Loss: -0.02372388355433941, Sigma: 0.23987528681755066\nEpoch: 630, Loss: -0.01686267741024494, Sigma: 0.23911306262016296\nEpoch: 640, Loss: -0.03131835535168648, Sigma: 0.2387116551399231\nEpoch: 650, Loss: -0.003353776875883341, Sigma: 0.2382737398147583\nEpoch: 660, Loss: -0.018221279606223106, Sigma: 0.23798178136348724\nEpoch: 670, Loss: -0.02976962924003601, Sigma: 0.23750412464141846\nEpoch: 680, Loss: -0.04258110001683235, Sigma: 0.2370409518480301\nEpoch: 690, Loss: -0.01051234733313322, Sigma: 0.23640307784080505\nEpoch: 700, Loss: -0.03791022673249245, Sigma: 0.23605792224407196\nEpoch: 710, Loss: -0.0460396483540535, Sigma: 0.23555223643779755\nEpoch: 720, Loss: -0.03509620949625969, Sigma: 0.23478062450885773\nEpoch: 730, Loss: 0.03369412198662758, Sigma: 0.23536834120750427\nEpoch: 740, Loss: -0.052086129784584045, Sigma: 0.2364046573638916\nEpoch: 750, Loss: -0.04687647894024849, Sigma: 0.23619304597377777\nEpoch: 760, Loss: -0.05750618875026703, Sigma: 0.23515582084655762\nEpoch: 770, Loss: -0.060779087245464325, Sigma: 0.2337678074836731\nEpoch: 780, Loss: -0.06353538483381271, Sigma: 0.23233218491077423\nEpoch: 790, Loss: -0.06269311159849167, Sigma: 0.23100987076759338\nEpoch: 800, Loss: 0.04665428027510643, Sigma: 0.2304842472076416\nEpoch: 810, Loss: -0.03871075063943863, Sigma: 0.23162372410297394\nEpoch: 820, Loss: -0.058183226734399796, Sigma: 0.23170208930969238\nEpoch: 830, Loss: -0.06906687468290329, Sigma: 0.2309386432170868\nEpoch: 840, Loss: -0.07344689220190048, Sigma: 0.2297821193933487\nEpoch: 850, Loss: -0.06889341026544571, Sigma: 0.2285580188035965\nEpoch: 860, Loss: -0.02580447681248188, Sigma: 0.22790952026844025\nEpoch: 870, Loss: -0.05484987795352936, Sigma: 0.22809277474880219\nEpoch: 880, Loss: -0.06924512982368469, Sigma: 0.2277873456478119\nEpoch: 890, Loss: -0.08295488357543945, Sigma: 0.22713424265384674\nEpoch: 900, Loss: -0.07165029644966125, Sigma: 0.2261764407157898\nEpoch: 910, Loss: 0.10657352209091187, Sigma: 0.22907805442810059\nEpoch: 920, Loss: -0.0770278126001358, Sigma: 0.23380540311336517\nEpoch: 930, Loss: -0.07862641662359238, Sigma: 0.23497235774993896\nEpoch: 940, Loss: -0.07769864052534103, Sigma: 0.23367847502231598\nEpoch: 950, Loss: -0.08631709963083267, Sigma: 0.23134003579616547\nEpoch: 960, Loss: -0.08885804563760757, Sigma: 0.22882986068725586\nEpoch: 970, Loss: -0.09149400144815445, Sigma: 0.2265719324350357\nEpoch: 980, Loss: -0.09441927075386047, Sigma: 0.2247086465358734\nEpoch: 990, Loss: -0.09578744322061539, Sigma: 0.22321872413158417\n\n\n\n# Plot final predictions\n\nwith torch.no_grad():\n    mu = model(x.unsqueeze(1))\n    sigma = torch.exp(log_sigma)\n\n    # Move to cpu\n    mu = mu.cpu().numpy()\n    sigma = sigma.cpu().numpy()\n\n    plt.scatter(x.cpu().numpy(), y.cpu().numpy())\n    plt.plot(x.cpu().numpy(), mu, 'r-', lw=5)\n\n    plt.fill_between(x.cpu().numpy(), (mu - sigma).flatten(), (mu + sigma).flatten(), alpha=0.5)"
  },
  {
    "objectID": "posts/2024-06-10-shortcuts-mac.html",
    "href": "posts/2024-06-10-shortcuts-mac.html",
    "title": "Keyboard shortcuts on Mac",
    "section": "",
    "text": "Safari Tab Shortcuts\n\n\n\nAction\nShortcut\n\n\n\n\nGo to first tab\nCommand (⌘) + 1\n\n\nGo to second tab\nCommand (⌘) + 2\n\n\nGo to third tab\nCommand (⌘) + 3\n\n\nGo to fourth tab\nCommand (⌘) + 4\n\n\nGo to fifth tab\nCommand (⌘) + 5\n\n\nGo to sixth tab\nCommand (⌘) + 6\n\n\nGo to seventh tab\nCommand (⌘) + 7\n\n\nGo to eighth tab\nCommand (⌘) + 8\n\n\nGo to last tab\nCommand (⌘) + 9\n\n\nMove to the next tab\nControl (⌃) + Tab\n\n\nMove to the previous tab\nControl (⌃) + Shift (⇧) + Tab"
  },
  {
    "objectID": "posts/2020-06-26-gp-understand.html",
    "href": "posts/2020-06-26-gp-understand.html",
    "title": "Understanding Kernels in Gaussian Processes Regression",
    "section": "",
    "text": "Disclaimer\nThis blog post is forked from GPSS 2019 Lab 1. This is produced only for educational purposes. All credit goes to the GPSS organisers.\n\n# Support for maths\nimport numpy as np\n# Plotting tools\nfrom matplotlib import pyplot as plt\n# we use the following for plotting figures in jupyter\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# GPy: Gaussian processes library\nimport GPy\nfrom IPython.display import display\n\n\n\nCovariance functions, aka kernels\nWe will define a covariance function, from hereon referred to as a kernel, using GPy. The most commonly used kernel in machine learning is the Gaussian-form radial basis function (RBF) kernel. It is also commonly referred to as the exponentiated quadratic or squared exponential kernel – all are equivalent.\nThe definition of the (1-dimensional) RBF kernel has a Gaussian-form, defined as:\n\\[\n    \\kappa_\\mathrm{rbf}(x,x') = \\sigma^2\\exp\\left(-\\frac{(x-x')^2}{2\\mathscr{l}^2}\\right)\n\\]\nIt has two parameters, described as the variance, \\(\\sigma^2\\) and the lengthscale \\(\\mathscr{l}\\).\nIn GPy, we define our kernels using the input dimension as the first argument, in the simplest case input_dim=1 for 1-dimensional regression. We can also explicitly define the parameters, but for now we will use the default values:\n\n# Create a 1-D RBF kernel with default parameters\nk = GPy.kern.RBF(lengthscale=0.5, input_dim=1, variance=4)\n# Preview the kernel's parameters\nk\n\n\n\n\n\n\nrbf.\nvalue\nconstraints\npriors\n\n\nvariance\n4.0\n+ve\n\n\n\nlengthscale\n0.5\n+ve\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib import rc\nls = [0.0005, 0.05, 0.25, 0.5, 1., 2., 4.]\n\nX = np.linspace(0.,1.,500)# 500 points evenly spaced over [0,1]\nX = X[:,None]\nmu = np.zeros((500))\n\ndef update(iteration):\n    ax.cla()\n    k = GPy.kern.RBF(1)\n    k.lengthscale = ls[iteration]\n    # Calculate the new covariance function at k(x,0)\n    C = k.K(X,X)\n    Z = np.random.multivariate_normal(mu,C,40)\n    for i in range(40):\n        ax.plot(X[:],Z[i,:],color='k',alpha=0.2)\n    ax.set_title(\"$\\kappa_{rbf}(x,x')$\\nLength scale = %s\" %k.lengthscale[0]);\n    ax.set_ylim((-4, 4))\n\n\n\nnum_iterations = len(ls)\nanim = FuncAnimation(fig, update, frames=np.arange(0, num_iterations-1, 1), interval=500)\nplt.close()\n\nrc('animation', html='jshtml')\nanim\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nIn the animation above, as you increase the length scale, the learnt functions keep getting smoother.\n\nfig, ax = plt.subplots()\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib import rc\nvar = [0.0005, 0.05, 0.25, 0.5, 1., 2., 4., 9.]\n\nX = np.linspace(0.,1.,500)# 500 points evenly spaced over [0,1]\nX = X[:,None]\nmu = np.zeros((500))\n\ndef update(iteration):\n    ax.cla()\n    k = GPy.kern.RBF(1)\n    k.variance = var[iteration]\n    # Calculate the new covariance function at k(x,0)\n    C = k.K(X,X)\n    Z = np.random.multivariate_normal(mu,C,40)\n    for i in range(40):\n        ax.plot(X[:],Z[i,:],color='k',alpha=0.2)\n    ax.set_title(\"$\\kappa_{rbf}(x,x')$\\nVariance = %s\" %k.variance[0]);\n    ax.set_ylim((-4, 4))\n\n\n\nnum_iterations = len(ls)\nanim = FuncAnimation(fig, update, frames=np.arange(0, num_iterations-1, 1), interval=500)\nplt.close()\n\nrc('animation', html='jshtml')\nanim\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nIn the animation above, as you increase the variance, the scale of values increases.\n\nX1 = np.array([1, 2, 3]).reshape(-1, 1)\n\ny1 = np.array([0, 1, 0]).reshape(-1, 1)\ny2 = np.array([0, -1, 0]).reshape(-1, 1)\ny3 = np.array([0, 10, 0]).reshape(-1, 1)\ny4 = np.array([0, 0.3, 0]).reshape(-1, 1)\n\n\nk = GPy.kern.RBF(lengthscale=0.5, input_dim=1, variance=4)\n\nm = GPy.models.GPRegression(X1, y1, k)\n#m.Gaussian_noise = 0.0\nm.optimize()\nprint(k)\nm.plot();\n\n\n  rbf.         |                value  |  constraints  |  priors\n\n  variance     |    0.262031485550043  |      +ve      |        \n\n  lengthscale  |  0.24277532672486218  |      +ve      |        \n\n\n\n\n\n\n\n\n\n\n\n\nk = GPy.kern.RBF(lengthscale=0.5, input_dim=1, variance=4)\n\nm = GPy.models.GPRegression(X1, y2, k)\n#m.Gaussian_noise = 0.0\nm.optimize()\nprint(k)\nm.plot();\n\n\n  rbf.         |                value  |  constraints  |  priors\n\n  variance     |    0.262031485550043  |      +ve      |        \n\n  lengthscale  |  0.24277532672486218  |      +ve      |        \n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the above two examples, the y values are: 0, 1, 0 and 0, -1, 0. This shows smoothness. Thus, length scale can be big (0.24)\n\nk = GPy.kern.RBF(lengthscale=0.5, input_dim=1, variance=4)\n\nm = GPy.models.GPRegression(X1, y3, k)\n#m.Gaussian_noise = 0.0\nm.optimize()\nprint(k)\nm.plot();\n\n\n  rbf.         |                value  |  constraints  |  priors\n\n  variance     |   16.918792970578004  |      +ve      |        \n\n  lengthscale  |  0.07805339389352635  |      +ve      |        \n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the above example, the y values are: 0, 10, 0. The data set is not smooth. Thus, length scale learnt uis very small (0.24). Noise variance of RBF kernel also increased to accomodate the 10.\n\nk = GPy.kern.RBF(lengthscale=0.5, input_dim=1, variance=4)\n\nm = GPy.models.GPRegression(X1, y4, k)\n#m.Gaussian_noise = 0.0\nm.optimize()\nprint(k)\nm.plot();\n\n\n  rbf.         |                 value  |  constraints  |  priors\n\n  variance     |  5.90821963086592e-06  |      +ve      |        \n\n  lengthscale  |     2.163452641925496  |      +ve      |        \n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the above examples, the y values are: 0, 0.3, 0. The data set is the smoothest amongst the four. Thus, length scale learnt is large (2.1). Noise variance of RBF kernel is also small."
  },
  {
    "objectID": "posts/2022-02-07-coin-toss.html",
    "href": "posts/2022-02-07-coin-toss.html",
    "title": "Coin Toss (MLE, MAP, Fully Bayesian) in TF Probability",
    "section": "",
    "text": "Goals\nWe will be studying the problem of coin tosses. I will not go into derivations but mostly deal with automatic gradient computation in TF Probability.\nWe have the following goals in this tutorial.\n\nGoal 1: Maximum Likelihood Estimate (MLE)\nGiven a set of N observations, estimate the probability of H (denoted as \\(\\theta = p(H)\\))\n\n\nGoal 2: Maximum A-Posteriori (MAP)\nGiven a set of N observations and some prior knowledge on the distribution of \\(\\theta\\), estimate the best point estimate of \\(\\theta\\) once we have observed the dataset.\n\n\nGoal 3: Fully Bayesian\nGiven a set of N observations and some prior knowledge on the distribution of \\(\\theta\\), estimate the distribution of \\(\\theta\\) once we have observed the dataset.\nWhile I mention all the references below, I acknowledge Felix and his excellent repo and video playlist (Playlist 1, Playlist 2). They inspired me to create this post.\n\n\n\nBasic Imports\n\nfrom silence_tensorflow import silence_tensorflow\n\nsilence_tensorflow()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport functools\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\n\ntfd = tfp.distributions\ntfl = tfp.layers\ntfb = tfp.bijectors\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nCreating a dataset\nLet us create a dataset. We will assume the coin toss to be given as per the Bernoulli distribution. We will assume that \\(\\theta = p(H) = 0.75\\) and generate 10 samples. We will fix the random seeds for reproducibility.\nWe will be encoding Heads as 1 and Tails as 0.\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\n\ndistribution = tfd.Bernoulli(probs=0.75)\n\ndataset_10 = distribution.sample(10)\nprint(dataset_10.numpy())\nmle_estimate_10 = tf.reduce_mean(tf.cast(dataset_10, tf.float32))\ntf.print(mle_estimate_10)\n\n[0 0 0 1 1 1 1 1 0 1]\n0.6\n\n\n\n\n\nMLE\n\nObtaining MLE analytically\nFrom the above 10 samples, we obtain 6 Heads (1) and 4 Tails. As per the principal of MLE, the best estimate for \\(\\theta = p(H) = \\dfrac{n_h}{n_h+n_t} = 0.6\\)\nWe may also notice that the value of 0.6 is far from the 0.75 value we had initially set. This is possible as our dataset is small.\nWe will now verify if we get the same result using TFP. But, first, we can create a graphical model for our problem.\n\n\nGraphical model\n\nimport daft\n\npgm = daft.PGM([4, 3], origin=[0, 0])\npgm.add_node(daft.Node(\"theta\", r\"$\\theta$\", 1, 2.5, aspect=1.8))\n\npgm.add_node(daft.Node(\"obs\", r\"$obs_i$\", 1, 1, aspect=1.2, observed=True))\n\npgm.add_edge(\"theta\", \"obs\")\npgm.add_plate([0, 0.5, 2, 1.0], label=r\"$N$\", shift=-0.1)\npgm.render()\n\n\n\n\n\n\n\n\n\n\nObtaining MLE analytically for different dataset sizes\n\ndataset_large = distribution.sample(100000)\n\nmle_estimate = {}\nfor dataset_size in [10, 50, 100, 500, 1000, 10000, 100000]:\n    mle_estimate[dataset_size] = tf.reduce_mean(\n        tf.cast(dataset_large[:dataset_size], tf.float32)\n    )\ntf.print(mle_estimate)\n\n{10: 0.9,\n 50: 0.76,\n 100: 0.71,\n 500: 0.746,\n 1000: 0.749,\n 10000: 0.749,\n 100000: 0.75144}\n\n\nAs we can see above, when we use larger dataset sizes, our estimate matches the value we set (0.75).\n\n\nUsing TFP for MLE\n\nModel setup\n\ntheta = tf.Variable(0.1)\nfit = tfd.Bernoulli(probs=theta)\n\nfit.log_prob(dataset_10)\n\n&lt;tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([-0.10536052, -0.10536052, -0.10536052, -2.3025851 , -2.3025851 ,\n       -2.3025851 , -2.3025851 , -2.3025851 , -0.10536052, -2.3025851 ],\n      dtype=float32)&gt;\n\n\n\n\nDefining loss\nWe now define the negative log likelihood as our loss function and work towards minimizing it.\n\ndataset = dataset_10\n\n\ndef loss():\n    return -tf.reduce_sum(fit.log_prob(dataset))\n\n\n\nTracing variables over training\n\ntrace_fn = lambda traceable_quantities: {\n    \"loss\": traceable_quantities.loss,\n    \"theta\": theta,\n}\n\nnum_steps = 150\n\n\n\nMinimizing the loss function\n\ntrace = tfp.math.minimize(\n    loss_fn=loss,\n    num_steps=num_steps,\n    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n    trace_fn=trace_fn,\n)\n\n\ntheta\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5981374&gt;\n\n\n\nfig, ax = plt.subplots(nrows=2, sharex=True, figsize=(6, 4))\nax[0].plot(range(num_steps), trace[\"loss\"])\nax[1].plot(range(num_steps), trace[\"theta\"])\nsns.despine()\nax[1].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Loss\")\nax[1].set_ylabel(r\"$\\theta$\")\nfig.tight_layout()\n\n\n\n\n\n\n\n\nFrom the above calculations, we can see that we have obtained the same estimate of ~0.6 using TFP.\n\n\nAlternate way to minimize\nPreviously, we used the tf.math.minimize, but we can also use tf.GradientTape() for the same purpose.\n\n@tf.function\ndef loss_and_grads(fit):\n    with tf.GradientTape() as tape:\n        loss = -tf.reduce_sum(fit.log_prob(dataset))\n    return loss, tape.gradient(loss, fit.trainable_variables)\n\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\n\ntheta = tf.Variable(0.1)\nfit = tfd.Bernoulli(probs=theta)\n\n\nfor i in range(num_steps):\n    loss, grads = loss_and_grads(fit)\n    optimizer.apply_gradients(zip(grads, fit.trainable_variables))\n\n\nfit.trainable_variables\n\n(&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5981374&gt;,)\n\n\nWe can see that we obtain the same estimate.\n\n\n\n\nMAP\nWe will now be setting a prior over \\(\\theta\\). A general graphical model is shown below.\n\npgm = daft.PGM([4, 4], origin=[0, 0])\npgm.add_node(daft.Node(\"alpha\", r\"$\\alpha$\", 0.5, 3.5, aspect=1.8))\npgm.add_node(daft.Node(\"beta\", r\"$\\beta$\", 1.5, 3.5, aspect=1.8))\n\n\npgm.add_node(daft.Node(\"theta\", r\"$\\theta$\", 1, 2.5, aspect=2))\n# pgm.add_node(daft.Node(\"theta\", r\"$\\theta\\sim Beta (\\alpha, \\beta)$\", 1, 2.5, aspect=4))\n\npgm.add_node(daft.Node(\"obs\", r\"$obs_i$\", 1, 1, aspect=1.2, observed=True))\n\npgm.add_edge(\"theta\", \"obs\")\npgm.add_edge(\"alpha\", \"theta\")\npgm.add_edge(\"beta\", \"theta\")\n\n\npgm.add_plate([0, 0.5, 2, 1.0], label=r\"$N$\", shift=-0.1)\npgm.render()\n\n\n\n\n\n\n\n\n\nMAP with uniform prior\nFirst, we see the estimate for \\(\\theta\\) if we use the uniform prior. We should obtain the MLE answer.\n\ndef coin_toss_uniform_model():\n    theta = yield tfp.distributions.Uniform(low=0.0, high=1.0, name=\"Theta\")\n    coin = yield tfp.distributions.Bernoulli(probs=tf.ones(100) * theta, name=\"Coin\")\n\n\ncoin_toss_uniform_model\n\n&lt;function __main__.coin_toss_uniform_model()&gt;\n\n\n\nmodel_joint_uniform = tfp.distributions.JointDistributionCoroutineAutoBatched(\n    lambda: coin_toss_uniform_model(), name=\"Original\"\n)\n\n\nmodel_joint_uniform\n\n&lt;tfp.distributions.JointDistributionCoroutineAutoBatched 'Original' batch_shape=[] event_shape=StructTuple(\n  Theta=[],\n  Coin=[100]\n) dtype=StructTuple(\n  Theta=float32,\n  Coin=int32\n)&gt;\n\n\n\ndef uniform_model(dataset):\n    num_datapoints = len(dataset)\n    theta = yield tfp.distributions.Uniform(low=0.0, high=1.0, name=\"Theta\")\n\n    coin = yield tfp.distributions.Bernoulli(\n        probs=tf.ones(num_datapoints) * theta, name=\"Coin\"\n    )\n\n\nconcrete_uniform_model = functools.partial(uniform_model, dataset=dataset_10)\n\nmodel = tfd.JointDistributionCoroutineAutoBatched(concrete_uniform_model)\n\n\nmodel.sample()\n\nStructTuple(\n  Theta=&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.5930122&gt;,\n  Coin=&lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 0, 1, 0, 1, 1, 1, 0, 1, 1], dtype=int32)&gt;\n)\n\n\n\nth = tf.Variable(0.4)\n\ntarget_log_prob_fn = lambda th: model.log_prob((th, dataset_10))\n\n\nx_s = tf.linspace(0.0, 1.0, 1000)\ny_s = -target_log_prob_fn(x_s)\nplt.plot(x_s, y_s)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"- Joint Log Prob \\n(Unnormalized)\")\n\nsns.despine()\n\n\n\n\n\n\n\n\n\ntrace = tfp.math.minimize(\n    lambda: -target_log_prob_fn(th),\n    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n    # trace_fn=trace_fn,\n    num_steps=200,\n)\n\n\nth\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.59999406&gt;\n\n\n\nmle_estimate_10\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.6&gt;\n\n\nWe see above that our MAP estimate is fairly close to the MLE when we used the uniform prior.\n\n\nMAP with Beta prior\nWe will now use a much more informative prior – the Beta prior. We will be setting \\(\\alpha=40\\) and \\(\\beta=10\\) indicating that we have a prior belief that Tails is much more likely than Heads. This is a bad assumption and in the limited data regime will lead to poor estimates.\n\ndef beta_prior_model(dataset, alpha, beta):\n    num_datapoints = len(dataset)\n    theta = yield tfp.distributions.Beta(\n        concentration0=alpha, concentration1=beta, name=\"Theta\"\n    )\n\n    coin = yield tfp.distributions.Bernoulli(\n        probs=tf.ones(num_datapoints) * theta, name=\"Coin\"\n    )\n\n\nconcrete_beta_prior_model_40_10 = functools.partial(\n    beta_prior_model, dataset=dataset_10, alpha=40, beta=10\n)\n\n\nmodel_2_40_10 = tfd.JointDistributionCoroutineAutoBatched(\n    concrete_beta_prior_model_40_10\n)\n\n\nmodel_2_40_10.sample()\n\nStructTuple(\n  Theta=&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.16982338&gt;,\n  Coin=&lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)&gt;\n)\n\n\n\nmodel_2_40_10.prob(Theta=0.1, Coin=[0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.005809709&gt;\n\n\n\nth = tf.Variable(0.2)\n\ntarget_log_prob_fn = lambda th: model_2_40_10.log_prob(Theta=th, Coin=dataset_10)\n\n\nx_s = tf.linspace(0.0, 1.0, 1000)\ny_s = -target_log_prob_fn(x_s)\nplt.plot(x_s, y_s)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"- Joint Log Prob \\n(Unnormalized)\")\n\nsns.despine()\n\n\n\n\n\n\n\n\n\ntrace = tfp.math.minimize(\n    lambda: -target_log_prob_fn(th),\n    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n    # trace_fn=trace_fn,\n    num_steps=200,\n)\n\n\nth\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.25861916&gt;\n\n\nWe now see that our MAP estimate for \\(\\theta\\) is 0.25, which is very far from the MLE. Choosing a better prior would have led to better estimates. Or, if we had more data, the likelihood would have dominated over the prior resulting in better estimates.\n\nconcrete_beta_prior_model_1_1 = functools.partial(\n    beta_prior_model, dataset=dataset_10, alpha=1, beta=1\n)\n\nmodel_2_1_1 = tfd.JointDistributionCoroutineAutoBatched(concrete_beta_prior_model_1_1)\n\nth = tf.Variable(0.2)\n\ntarget_log_prob_fn = lambda th: model_2_1_1.log_prob(Theta=th, Coin=dataset_10)\n\ntrace = tfp.math.minimize(\n    lambda: -target_log_prob_fn(th),\n    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n    # trace_fn=trace_fn,\n    num_steps=200,\n)\n\nth\n\n&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.6000196&gt;\n\n\nOur estimate for \\(\\theta\\) is more reasonable now.\n\n\n\nFully Bayesian\nWe now need to define a model \\(q(\\theta)\\) to act as the surrogate for our posterior \\(p(\\theta|D)\\). Let us use a Beta distribution.\n\nq_alpha = tf.Variable(1.0)\nq_beta = tf.Variable(1.0)\n\n\nsurrogate_posterior = tfd.Beta(concentration0=q_alpha, concentration1=q_beta, name=\"q\")\n\n\nsurrogate_posterior.sample()\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.7745516&gt;\n\n\n\nlosses = tfp.vi.fit_surrogate_posterior(\n    target_log_prob_fn,\n    surrogate_posterior=surrogate_posterior,\n    optimizer=tf.optimizers.Adam(learning_rate=0.005),\n    num_steps=400,\n)\n\n\nplt.plot(losses)\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nsns.despine()\n\n\n\n\n\n\n\n\n\nq_alpha, q_beta\n\n(&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.1893775&gt;,\n &lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.5093094&gt;)\n\n\n\nsns.kdeplot(surrogate_posterior.sample(500).numpy(), bw_adjust=2)\nsns.despine()\nplt.xlabel(r\"$\\theta$\")\n\nText(0.5, 0, '$\\\\theta$')\n\n\n\n\n\n\n\n\n\n\nGenerating samples on coin tosses conditioning on theta\nFirst, let us look at the syntax and then generate 1000 samples.\n\nmodel_2_1_1.sample(Theta=0.1)\n\nStructTuple(\n  Theta=&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.1&gt;,\n  Coin=&lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int32)&gt;\n)\n\n\n\nmodel_2_1_1.sample(Theta=0.9)\n\nStructTuple(\n  Theta=&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.9&gt;,\n  Coin=&lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)&gt;\n)\n\n\nWe can clearly see that conditioning on r\\(\\theta\\) changes the number of heads.\n\n\nFun check: What if we fix the dataset and sample on theta?\n\nmodel_2_1_1.sample(Coin=[0, 1, 1, 0, 1, 1, 1, 0])\n\nStructTuple(\n  Theta=&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.34792978&gt;,\n  Coin=&lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 1, 1, 0, 1, 1, 1, 0], dtype=int32)&gt;\n)\n\n\n\nmodel_2_1_1.sample(Coin=[0, 1, 1, 0, 1, 1, 1, 0])\n\nStructTuple(\n  Theta=&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.74594486&gt;,\n  Coin=&lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 1, 1, 0, 1, 1, 1, 0], dtype=int32)&gt;\n)\n\n\nAs we see above, we can get different \\(\\theta\\). If our dataset was large, this effect would be less pronounced.\n\nc = model_2_1_1.sample(Theta=surrogate_posterior.sample(1000)).Coin\n\n\npd.DataFrame(c)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n2\n1\n1\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n3\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n\n\n4\n1\n1\n1\n0\n0\n1\n1\n1\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n\n\n996\n1\n0\n1\n1\n1\n1\n1\n1\n0\n0\n\n\n997\n0\n0\n0\n0\n1\n1\n1\n1\n1\n0\n\n\n998\n1\n1\n1\n1\n1\n0\n1\n1\n1\n0\n\n\n999\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\n\n1000 rows × 10 columns\n\n\n\n\nsns.histplot(tf.reduce_sum(tf.cast(c, tf.float32), axis=1), bins=11)\nsns.despine()\n\n\n\n\n\n\n\n\nWe can see the count of number of heads in 1000 samples generated from the posterior.\n\n\nReferences (incomplete as of now)\n\nExcellent repo and video playlist (Playlist 1, Playlist 2) by Felix\nProbabilistic PCA tutorial on TFP\nDiscussion on joint log prob on TFP"
  },
  {
    "objectID": "posts/2022-02-14-logistic-regression.html",
    "href": "posts/2022-02-14-logistic-regression.html",
    "title": "Logistic Regression using PyTorch distributions",
    "section": "",
    "text": "Basic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport seaborn as sns\nimport pandas as pd\n\ndist =torch.distributions\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n\nGenerative model for logistic regression\n\nx = dist.Normal(loc = torch.tensor([0., 0.]), scale=torch.tensor([1., 2.]))\nx_sample = x.sample([100])\nx_sample.shape\n\nx_dash = torch.concat((torch.ones(x_sample.shape[0], 1), x_sample), axis=1)\n\n\ntheta = dist.MultivariateNormal(loc = torch.tensor([0., 0., 0.]), covariance_matrix=0.5*torch.eye(3))\ntheta_sample = theta.sample()\n\np = torch.sigmoid(x_dash@theta_sample)\n\ny = dist.Bernoulli(probs=p)\ny_sample = y.sample()\n\n\nplt.scatter(x_sample[:, 0], x_sample[:, 1], c = y_sample, s=40, alpha=0.5)\nsns.despine()\n\n\n\n\n\n\n\n\n\ntheta_sample\n\ntensor([ 0.6368, -0.7526,  1.4652])\n\n\n\nfrom sklearn.linear_model import LogisticRegression\nlr_l2 = LogisticRegression()\nlr_none = LogisticRegression(penalty='none')\n\n\nlr_l2.fit(x_sample, y_sample)\nlr_none.fit(x_sample, y_sample)\n\nLogisticRegression(penalty='none')\n\n\n\ndef plot_fit(x_sample, y_sample, theta, model_name):\n\n    \n    # Retrieve the model parameters.\n    b = theta[0]\n    w1, w2 = theta[1], theta[2]\n    # Calculate the intercept and gradient of the decision boundary.\n    c = -b/w2\n    m = -w1/w2\n\n    # Plot the data and the classification with the decision boundary.\n    xmin, xmax = x_sample[:, 0].min()-0.2, x_sample[:, 0].max()+0.2\n    ymin, ymax =  x_sample[:, 1].min()-0.2, x_sample[:, 1].max()+0.2\n    xd = np.array([xmin, xmax])\n    yd = m*xd + c\n    plt.plot(xd, yd, 'k', lw=1, ls='--')\n    plt.fill_between(xd, yd, ymin, color='tab:blue', alpha=0.2)\n    plt.fill_between(xd, yd, ymax, color='tab:orange', alpha=0.2)\n\n    plt.scatter(*x_sample[y_sample==0].T, s=20, alpha=0.5)\n    plt.scatter(*x_sample[y_sample==1].T, s=20, alpha=0.5)\n    plt.xlim(xmin, xmax)\n    plt.ylim(ymin, ymax)\n    plt.ylabel(r'$x_2$')\n    plt.xlabel(r'$x_1$')\n    theta_print = np.round(theta, 1)\n    plt.title(f\"{model_name}\\n{theta_print}\")\n    sns.despine()\n\n\nplot_fit(\n    x_sample,\n    y_sample,\n    theta_sample,\n    r\"Generating $\\theta$\",\n)\n\n\n\n\n\n\n\n\n\nplot_fit(\n    x_sample,\n    y_sample,\n    np.concatenate((lr_l2.intercept_.reshape(-1, 1), lr_l2.coef_), axis=1).flatten(),\n    r\"Sklearn $\\ell_2$ penalty \",\n)\n\n\n\n\n\n\n\n\n\nplot_fit(\n    x_sample,\n    y_sample,\n    np.concatenate((lr_none.intercept_.reshape(-1, 1), lr_none.coef_), axis=1).flatten(),\n    r\"Sklearn No penalty \",\n)\n\n\n\n\n\n\n\n\n\n\nMLE estimate PyTorch\n\ndef neg_log_likelihood(theta, x, y):\n    x_dash = torch.concat((torch.ones(x.shape[0], 1), x), axis=1)\n    p = torch.sigmoid(x_dash@theta)\n    y_dist = dist.Bernoulli(probs=p)\n\n    return -torch.sum(y_dist.log_prob(y))\n\n\nneg_log_likelihood(theta_sample, x_sample, y_sample)\n\ntensor(33.1907)\n\n\n\ntheta_learn_loc = torch.tensor([1., 1., 1.], requires_grad=True)\nneg_log_likelihood(theta_learn_loc, x_sample, y_sample)\n\nplot_fit(\n    x_sample,\n    y_sample,\n    theta_learn_loc.detach(),\n    r\"Torch without training\",\n)\n\n\n\n\n\n\n\n\n\ntheta_learn_loc = torch.tensor([0., 0., 0.], requires_grad=True)\nloss_array = []\nloc_array = []\n\nopt = torch.optim.Adam([theta_learn_loc], lr=0.05)\nfor i in range(101):\n    loss_val = neg_log_likelihood(theta_learn_loc, x_sample, y_sample)\n    loss_val.backward()\n    loc_array.append(theta_learn_loc)\n    loss_array.append(loss_val.item())\n\n    if i % 10 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss_val.item():0.2f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 69.31\nIteration: 10, Loss: 44.14\nIteration: 20, Loss: 35.79\nIteration: 30, Loss: 32.73\nIteration: 40, Loss: 31.67\nIteration: 50, Loss: 31.25\nIteration: 60, Loss: 31.08\nIteration: 70, Loss: 31.00\nIteration: 80, Loss: 30.97\nIteration: 90, Loss: 30.95\nIteration: 100, Loss: 30.94\n\n\n\nplot_fit(\n    x_sample,\n    y_sample,\n    theta_learn_loc.detach(),\n    r\"Torch MLE\",\n)\n\n\n\n\n\n\n\n\n\n\nMAP estimate PyTorch\n\nprior_theta = dist.MultivariateNormal(loc = torch.tensor([0., 0., 0.]), covariance_matrix=2*torch.eye(3))\n\nlogprob = lambda theta: -prior_theta.log_prob(theta)\n\n\ntheta_learn_loc = torch.tensor([0., 0., 0.], requires_grad=True)\nloss_array = []\nloc_array = []\n\nopt = torch.optim.Adam([theta_learn_loc], lr=0.05)\nfor i in range(101):\n    loss_val = neg_log_likelihood(theta_learn_loc, x_sample, y_sample) + logprob(theta_learn_loc)\n    loss_val.backward()\n    loc_array.append(theta_learn_loc)\n    loss_array.append(loss_val.item())\n\n    if i % 10 == 0:\n        print(\n            f\"Iteration: {i}, Loss: {loss_val.item():0.2f}\"\n        )\n    opt.step()\n    opt.zero_grad()\n\nIteration: 0, Loss: 73.11\nIteration: 10, Loss: 48.06\nIteration: 20, Loss: 39.89\nIteration: 30, Loss: 37.01\nIteration: 40, Loss: 36.10\nIteration: 50, Loss: 35.78\nIteration: 60, Loss: 35.67\nIteration: 70, Loss: 35.64\nIteration: 80, Loss: 35.62\nIteration: 90, Loss: 35.62\nIteration: 100, Loss: 35.62\n\n\n\nplot_fit(\n    x_sample,\n    y_sample,\n    theta_learn_loc.detach(),\n    r\"Torch MAP\",\n)\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\nPlotting code borrwed from here: https://scipython.com/blog/plotting-the-decision-boundary-of-a-logistic-regression-model/"
  },
  {
    "objectID": "posts/2017-04-21-constrained-nmf-cvx.html",
    "href": "posts/2017-04-21-constrained-nmf-cvx.html",
    "title": "Constrained Non-negative matrix factorisation using CVXPY",
    "section": "",
    "text": "In a previous post, we saw how we can use CVXPY to perform non-negative matrix factorisation. In this post, I’ll show how to add additional constraints that may arise from the problem domain. As a trivial example, I’ll take constraints of the form when there is a less-than relationship among members of the matrix. For example, we may want to enforce certain movies to be always rated more than others? We’ll create a matrix of 30 users and 12 items. We will enforce the contraint that the rating of the first 6 items be atleast twice that of the last 6 items.\n\nCreating a ratings matrix\nWe will now create a matrix where the relationship among items exists.\n\nimport numpy as np\nimport pandas as pd\n\n\nK, N, M = 2, 12, 30\nY_gen = np.random.rand(M, K)\nX_1 = np.random.rand(K, N/2)\n# So that atleast twice as much\nX_2 = 2* X_1 + np.random.rand(K, N/2)\nX_gen = np.hstack([X_2, X_1])\n# Normalizing\nX_gen = X_gen/np.max(X_gen)\n# Creating A (ratings matrix of size M, N)\nA = np.dot(Y_gen, X_gen)\npd.DataFrame(A).head()\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n\n0\n0.732046\n0.613565\n0.961128\n0.920089\n0.244323\n0.506472\n0.280477\n0.251049\n0.324418\n0.378219\n0.075556\n0.131750\n\n\n1\n0.903630\n0.340956\n0.784109\n0.919741\n0.190856\n0.433635\n0.321932\n0.135134\n0.290862\n0.394680\n0.052976\n0.081148\n\n\n2\n0.972145\n0.576558\n1.046197\n1.098279\n0.261103\n0.562996\n0.358574\n0.233405\n0.368118\n0.460967\n0.077286\n0.128344\n\n\n3\n0.292231\n0.263864\n0.401968\n0.377116\n0.102567\n0.210890\n0.113070\n0.108163\n0.134489\n0.154266\n0.031993\n0.056299\n\n\n4\n0.694038\n0.803459\n1.125454\n0.987344\n0.290605\n0.582178\n0.278848\n0.331075\n0.365935\n0.397023\n0.093088\n0.168300\n\n\n\n\n\n\n\nWe can see that for each user, the 0th item has higher rating compared to the 5th, 1st more than the 6th and so on. Now, in our alternating least squares implementation, we break down A as Y.X. Here X has dimensions of K, N. To ensure the relationship among the items, we will put contraints on X of the form: X[:, 0] &gt; 2 x X[:, 5] and so on. We will create a simple for loop for the same.\n\ne = \"[\"\nfor a in range(N/2):\n    e+=\"X[:,%d] &gt; 2 * X[:,%d],\" %(a, a+N/2)\ne = e[:-1] + \"]\"\ne\n\n'[X[:,0] &gt; 2 * X[:,6],X[:,1] &gt; 2 * X[:,7],X[:,2] &gt; 2 * X[:,8],X[:,3] &gt; 2 * X[:,9],X[:,4] &gt; 2 * X[:,10],X[:,5] &gt; 2 * X[:,11]]'\n\n\nAs we can see, we now have 6 constraints that we can feed into the optimisation routine. Whenever we learn X in the ALS, we apply these constraint.\n\n\nCVX routine for handling input constraints\n\ndef nmf_features(A, k,  MAX_ITERS=30, input_constraints_X=None, input_constraints_Y = None):\n    import cvxpy as cvx\n    np.random.seed(0)\n\n    # Generate random data matrix A.\n    m, n = A.shape\n    mask = ~np.isnan(A)\n\n    # Initialize Y randomly.\n    Y_init = np.random.rand(m, k)\n    Y = Y_init\n\n    # Perform alternating minimization.\n\n    residual = np.zeros(MAX_ITERS)\n    for iter_num in xrange(1, 1 + MAX_ITERS):\n    \n        # For odd iterations, treat Y constant, optimize over X.\n        if iter_num % 2 == 1:\n            X = cvx.Variable(k, n)\n            constraint = [X &gt;= 0]\n            if input_constraints_X:\n                constraint.extend(eval(input_constraints_X))\n\n        # For even iterations, treat X constant, optimize over Y.\n        else:\n            Y = cvx.Variable(m, k)\n            constraint = [Y &gt;= 0]\n           \n\n        Temp = Y * X\n        error = A[mask] - (Y * X)[mask]\n       \n        \n        obj = cvx.Minimize(cvx.norm(error, 'fro'))\n       \n\n        prob = cvx.Problem(obj, constraint)\n        prob.solve(solver=cvx.SCS)\n\n        if prob.status != cvx.OPTIMAL:\n            pass\n       \n        residual[iter_num - 1] = prob.value\n      \n        if iter_num % 2 == 1:\n            X = X.value\n        else:\n            Y = Y.value\n    return X, Y, residual\n\n\n# Without constraints\nX, Y, r = nmf_features(A, 3, MAX_ITERS=20)\n# With contstraints\nX_c, Y_c, r_c = nmf_features(A, 3, MAX_ITERS=20, input_constraints_X=e)\n\n\npd.DataFrame(X)\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n\n0\n0.749994\n0.112355\n0.485850\n0.674801\n0.113004\n0.281371\n0.257239\n0.04056\n0.196474\n0.297978\n0.02745\n0.033952\n\n\n1\n0.102384\n0.222149\n0.266055\n0.199361\n0.070403\n0.133510\n0.047174\n0.09233\n0.081233\n0.076518\n0.02375\n0.045097\n\n\n2\n0.567213\n0.558638\n0.825066\n0.756059\n0.211427\n0.430690\n0.222174\n0.22944\n0.273260\n0.307475\n0.06659\n0.118371\n\n\n\n\n\n\n\n\npd.DataFrame(X_c)\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n\n0\n0.749882\n0.112384\n0.485923\n0.674778\n0.113027\n0.281399\n0.257206\n0.040566\n0.196489\n0.297960\n0.027461\n0.033971\n\n\n1\n0.102366\n0.222080\n0.266058\n0.199353\n0.070404\n0.133511\n0.047168\n0.092298\n0.081233\n0.076513\n0.023751\n0.045091\n\n\n2\n0.567363\n0.558700\n0.825253\n0.756242\n0.211473\n0.430789\n0.222234\n0.229470\n0.273319\n0.307549\n0.066604\n0.118382\n\n\n\n\n\n\n\nOk. The obtained X matrix looks fairly similar. How about we reverse the constraints.\n\ne_rev = \"[\"\nfor a in range(N/2):\n    e_rev+=\" 2* X[:,%d]  &lt; X[:,%d],\" %(a, a+N/2)\ne_rev = e_rev[:-1] + \"]\"\ne_rev\n\n'[ 2* X[:,0]  &lt; X[:,6], 2* X[:,1]  &lt; X[:,7], 2* X[:,2]  &lt; X[:,8], 2* X[:,3]  &lt; X[:,9], 2* X[:,4]  &lt; X[:,10], 2* X[:,5]  &lt; X[:,11]]'\n\n\n\nX_c_rev, Y_c_rev, r_c_rev = nmf_features(A, 3, MAX_ITERS=20, input_constraints_X=e_rev)\n\n\npd.DataFrame(X_c_rev)\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n\n0\n0.250945\n0.038070\n0.174189\n0.252085\n0.033251\n0.069176\n0.502026\n0.076147\n0.348450\n0.504277\n0.066521\n0.138405\n\n\n1\n0.030757\n0.088033\n0.085947\n0.065135\n0.024395\n0.045976\n0.061398\n0.176002\n0.171773\n0.130146\n0.048760\n0.091882\n\n\n2\n0.220256\n0.183292\n0.269014\n0.282814\n0.065713\n0.128120\n0.440553\n0.366600\n0.538065\n0.565669\n0.131436\n0.256263\n\n\n\n\n\n\n\nThere you go! We now have learnt latent factors that conform to our constraints."
  },
  {
    "objectID": "posts/2022-01-26-tfp-distributions.html",
    "href": "posts/2022-01-26-tfp-distributions.html",
    "title": "Testing out some distributions in Tensorflow Probability",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\ntfd = tfp.distributions\nsns.reset_defaults()\nsns.set_context(context='talk',font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nUnivariate normal\n\nuv_normal = tfd.Normal(loc=0., scale=1.)\n\n\nuv_normal\n\n&lt;tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32&gt;\n\n\n\nsamples = uv_normal.sample(1000)\n\n\nsns.histplot(samples.numpy())\nsns.despine()\n\n\n\n\n\n\n\n\n\nsns.displot(samples.numpy(), kind='kde')\n\n\n\n\n\n\n\n\n\nuv_normal_dict_mean = {x: tfd.Normal(loc=x, scale=1.) for x in [-2, -1, 0, 1, 2]}\n\n\nuv_normal_dict_mean_samples = pd.DataFrame({x:uv_normal_dict_mean[x].sample(10000).numpy() \n                                            for x in uv_normal_dict_mean})\n\n\nsns.displot(uv_normal_dict_mean_samples, kind='kde', fill=True)\n\n\n\n\n\n\n\n\n\nuv_normal_dict_var = {x: tfd.Normal(loc=0, scale=x) for x in [1, 2, 5, 10]}\nuv_normal_dict_var_samples = pd.DataFrame({x:uv_normal_dict_var[x].sample(10000).numpy() \n                                            for x in uv_normal_dict_var})\n\n\nsns.displot(uv_normal_dict_var_samples, kind='kde', fill=True)\n\n\n\n\n\n\n\n\n\n\nUsing batches\n\nvar_dfs = pd.DataFrame(\n    tfd.Normal(loc=[0., 0., 0., 0.],\n               scale=[1., 2., 5., 10.]).sample(10000).numpy())\nvar_dfs.columns = [1, 2, 5, 10]\nsns.displot(var_dfs, kind='kde', fill=True)\n\n\n\n\n\n\n\n\n\ntfd.Normal(loc=[0., 0., 0., 0.],\n               scale=[1., 2., 5., 10.])\n\n&lt;tfp.distributions.Normal 'Normal' batch_shape=[4] event_shape=[] dtype=float32&gt;\n\n\n\nsamples = uv_normal.sample(10000)\nsns.displot(samples.numpy(), kind='kde')\nplt.axvline(0.5, color='k', linestyle='--')\npdf_05 = uv_normal.prob(0.5).numpy()\nlog_pdf_05 = uv_normal.log_prob(0.5).numpy()\n\n\nplt.title(\"Density at x = 0.5 is {:.2f}\\n Logprob at x = 0.5 is {:.2f}\".format(pdf_05, log_pdf_05))\n\nText(0.5, 1.0, 'Density at x = 0.5 is 0.35\\n Logprob at x = 0.5 is -1.04')\n\n\n\n\n\n\n\n\n\n\n\nLearning parameters\nLet us generate some normally distributed data and see if we can learn the mean.\n\ntrain_data = uv_normal.sample(10000)\n\n\nuv_normal.loc, uv_normal.scale\n\n(&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.0&gt;,\n &lt;tf.Tensor: shape=(), dtype=float32, numpy=1.0&gt;)\n\n\nLet us create a new TFP trainable distribution where we wish to learn the mean.\n\nto_train = tfd.Normal(loc = tf.Variable(-1., name='loc'), scale = 1.)\n\n\nto_train\n\n&lt;tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32&gt;\n\n\n\nto_train.trainable_variables\n\n(&lt;tf.Variable 'loc:0' shape=() dtype=float32, numpy=-1.0&gt;,)\n\n\n\ntf.reduce_mean(train_data), tf.math.reduce_variance(train_data)\n\n(&lt;tf.Tensor: shape=(), dtype=float32, numpy=-0.024403999&gt;,\n &lt;tf.Tensor: shape=(), dtype=float32, numpy=0.9995617&gt;)\n\n\n\ndef nll(train):\n    return -tf.reduce_mean(to_train.log_prob(train))\n\n\nnll(train_data)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=1.8946133&gt;\n\n\n\ndef get_loss_and_grads(train):\n    with tf.GradientTape() as tape:\n        tape.watch(to_train.trainable_variables)\n        loss = nll(train)\n    grads = tape.gradient(loss, to_train.trainable_variables)\n    return loss, grads\n\n\nget_loss_and_grads(train_data)\n\n(&lt;tf.Tensor: shape=(), dtype=float32, numpy=1.8946133&gt;,\n (&lt;tf.Tensor: shape=(), dtype=float32, numpy=-0.97559595&gt;,))\n\n\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\n\noptimizer\n\n&lt;keras.optimizer_v2.adam.Adam at 0x7f94c97ae490&gt;\n\n\n\niterations = 500\nlosses = np.empty(iterations)\nvals = np.empty(iterations)\nfor i in range(iterations):\n    loss, grads = get_loss_and_grads(train_data)\n    losses[i] = loss\n    vals[i] = to_train.trainable_variables[0].numpy()\n    optimizer.apply_gradients(zip(grads, to_train.trainable_variables))\n    if i%50 == 0:\n        print(i, loss.numpy())\n\n0 1.8946133\n50 1.5505791\n100 1.4401271\n150 1.4205703\n200 1.4187955\n250 1.4187206\n300 1.4187194\n350 1.4187193\n400 1.4187193\n450 1.4187194\n\n\n\nplt.plot(losses)\nsns.despine()\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n\nText(0, 0.5, 'Loss')\n\n\n\n\n\n\n\n\n\n\nplt.plot(vals)\nsns.despine()\nplt.xlabel(\"Iterations\")\nplt.ylabel(r\"Value of $\\hat{\\mu}$\")\n\nText(0, 0.5, 'Value of $\\\\hat{\\\\mu}$')\n\n\n\n\n\n\n\n\n\n\nto_train_mean_var = tfd.Normal(loc = tf.Variable(-1., name='loc'), scale = tf.Variable(10., name='scale'))\n\ndef nll(train):\n    return -tf.reduce_mean(to_train_mean_var.log_prob(train))\n\ndef get_loss_and_grads(train):\n    with tf.GradientTape() as tape:\n        tape.watch(to_train_mean_var.trainable_variables)\n        loss = nll(train)\n    grads = tape.gradient(loss, to_train_mean_var.trainable_variables)\n    return loss, grads\n\nto_train_mean_var.trainable_variables\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\niterations = 1000\nlosses = np.empty(iterations)\nvals_scale = np.empty(iterations)\nvals_means = np.empty(iterations)\nfor i in range(iterations):\n    loss, grads = get_loss_and_grads(train_data)\n    losses[i] = loss\n    vals_means[i] = to_train_mean_var.trainable_variables[0].numpy()\n    vals_scale[i] = to_train_mean_var.trainable_variables[1].numpy()\n\n\n    optimizer.apply_gradients(zip(grads, to_train_mean_var.trainable_variables))\n    if i%50 == 0:\n        print(i, loss.numpy())\n\n0 3.2312806\n50 3.1768403\n100 3.1204312\n150 3.0602157\n200 2.9945102\n250 2.9219644\n300 2.8410006\n350 2.749461\n400 2.6442661\n450 2.5208094\n500 2.3718355\n550 2.1852348\n600 1.9403238\n650 1.6161448\n700 1.4188237\n750 1.4187355\n800 1.4187193\n850 1.4187193\n900 1.4187193\n950 1.4187193\n\n\n\nplt.plot(losses)\nsns.despine()\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n\nText(0, 0.5, 'Loss')\n\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame({\"Mean\":vals_means, \"Scale\":vals_scale}, index=range(iterations))\ndf.index.name = 'Iteration'\n\n\ndf.plot(alpha=1)\nsns.despine()\nplt.axhline(0, linestyle='--', lw = 4, label = 'True mean', alpha=0.5, color='purple')\nplt.axhline(1, linestyle='--', lw = 4, label = 'True scale', alpha=0.5, color='red')\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nMultivariate Normal\n\nmv_normal = tfd.MultivariateNormalFullCovariance(loc=[0, 0], covariance_matrix=[[1, 0.5], [0.5, 2]])\n\n\nmv_data = pd.DataFrame(mv_normal.sample(10000).numpy())\nmv_data.columns = [r'$x_1$', r'$x_2$']\n\n\nmv_normal.prob([0, 0])\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.120309845&gt;\n\n\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\n\n\ndef make_pdf_2d_gaussian(mu, sigma):\n    N = 60\n    X = np.linspace(-3, 3, N)\n    Y = np.linspace(-3, 4, N)\n    X, Y = np.meshgrid(X, Y)\n\n    # Pack X and Y into a single 3-dimensional array\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n\n    F = tfd.MultivariateNormalFullCovariance(loc=mu, covariance_matrix=sigma)\n    Z = F.prob(pos)\n\n    plt.contourf(X, Y, Z, cmap=cm.Purples)\n    sns.despine() \n    plt.xlabel(r\"$x_1$\")\n    plt.ylabel(r\"$x_2$\")\n    plt.gca().set_aspect('equal')\n    plt.title(f'$\\mu$ = {mu}\\n $\\Sigma$ = {np.array(sigma)}')\n\n\nmake_pdf_2d_gaussian([0, 0,], [[1, 0.5,], [0.5, 1]])\n\n\n\n\n\n\n\n\n\nmake_pdf_2d_gaussian([0, 0,], [[3, 0.,], [0., 1]])\n\n\n\n\n\n\n\n\n\nsns.jointplot(data=mv_data,\n              x=r'$x_1$',y=r'$x_2$',\n              alpha=0.1)\n\n\n\n\n\n\n\n\n\nmv_data\n\n\n\n\n\n\n\n\n$x_1$\n$x_2$\n\n\n\n\n0\n2.155621\n-0.343866\n\n\n1\n-0.731184\n0.378393\n\n\n2\n0.832593\n-0.459740\n\n\n3\n-0.701200\n-0.249675\n\n\n4\n-0.430790\n-1.694002\n\n\n...\n...\n...\n\n\n9995\n-0.165910\n-0.171243\n\n\n9996\n0.208389\n-1.698432\n\n\n9997\n-0.030418\n0.353905\n\n\n9998\n1.342328\n1.127457\n\n\n9999\n-0.145741\n0.830713\n\n\n\n\n10000 rows × 2 columns"
  },
  {
    "objectID": "posts/moe.html",
    "href": "posts/moe.html",
    "title": "Mixture of Experts",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange, reduce, repeat\n\n\n# Create \"S\" shaped data\nx_region1 = torch.linspace(0, 2, 150)\nx_region2 = torch.linspace(1, 3, 150)\nx_region3 = torch.linspace(2, 4, 150)\n\nf1 = lambda x: 2*x - 1\nf2 = lambda x: -2*x + 6\nf3 = lambda x: torch.tensor([0.5]*len(x))\n\nf1_x = f1(x_region1)\nf2_x = f2(x_region2)\nf3_x = f3(x_region3)\n\nx_total = torch.cat([x_region1, x_region2, x_region3])\nf_total = torch.cat([f1_x, f2_x, f3_x])\n\ny_total = f_total + torch.randn_like(f_total)*0.2\n\n\nplt.plot(x_total, y_total, 'o', ms=10, c='k', alpha=0.2)\n\n\n\n\n\n\n\n\n\nclass Linear(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        return self.linear(x)\n\n\ne1 = Linear(1, 1)\ne2 = Linear(1, 1)\ne3 = Linear(1, 1)\n\n\nclass Gating(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.linear = torch.nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        pred = F.softmax(self.linear(x), dim=1)\n        return pred\n        \n\n\ng = Gating(1, 3)\n\n\nx_test = torch.linspace(0, 4, 100).view(-1, 1)\nweights = g(x_test)\nprint(weights.shape)\n\ntorch.Size([100, 3])\n\n\n\npredictions = torch.cat([e1(x_test), e2(x_test), e3(x_test)], dim=1)\nprint(predictions.shape)\n\ntorch.Size([100, 3])\n\n\n\noverall_prediction = torch.sum(weights*predictions, dim=1)\nprint(overall_prediction.shape)\n\ntorch.Size([100])\n\n\n\ndef predict(g, e1, e2, e3, x):\n    weights = g(x)\n    predictions = torch.cat([e1(x),\n                            e2(x),\n                            e3(x)], dim=1)\n    overall_prediction = torch.sum(weights*predictions, dim=1)\n    return overall_prediction\n\n\ndef plot(g, e1, e2, e3, x_test):\n    y_hat = predict(g, e1, e2, e3, x_test).detach().numpy()\n    plt.plot(x_region1, f1_x,  lw=3, label='f1')\n    plt.plot(x_region2, f2_x,  lw=3, label='f2')\n    plt.plot(x_region3, f3_x,  lw=3, label='f3')\n    plt.plot(x_total, y_total, 'o', ms=5, c='k', alpha=0.1, label='data')\n    plt.plot(x_test, y_hat, 'r', lw=3, label='Overall prediction')\n    # prediction of each expert\n    y_hat_e1 = e1(x_test).detach().numpy()\n    y_hat_e2 = e2(x_test).detach().numpy()\n    y_hat_e3 = e3(x_test).detach().numpy()\n    plt.plot(x_test, y_hat_e1, '--', lw=2, label='Expert 1')\n    plt.plot(x_test, y_hat_e2, '--', lw=2, label='Expert 2')\n    plt.plot(x_test, y_hat_e3, '--', lw=2, label='Expert 3')\n    # legend outside the plot\n    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n\n\nplot(g, e1, e2, e3, x_test)\n\n\n\n\n\n\n\n\n\noptimizer = torch.optim.Adam(list(e1.parameters()) + \n                             list(e2.parameters()) + \n                             list(e3.parameters()) + \n                             list(g.parameters()), lr=0.01)\n\nfor i in range(5000):\n    optimizer.zero_grad()\n    loss = torch.mean((y_total - predict(g, e1, e2, e3, x_total.view(-1, 1)))**2)\n    loss.backward()\n    optimizer.step()\n    if i % 500 == 0:\n        print(loss.item())\n\n2.34350848197937\n0.3760591149330139\n0.34844234585762024\n0.3476337492465973\n0.34751665592193604\n0.34749242663383484\n0.34747281670570374\n0.34743985533714294\n0.347318172454834\n0.33742383122444153\n\n\n\nplot(g, e1, e2, e3, x_test)\n\n\n\n\n\n\n\n\n\nweights = g(x_test).detach().numpy()\nfor i in range(3):\n    plt.plot(x_test, weights[:, i], label=f'Weight {i}')\nplt.legend()"
  },
  {
    "objectID": "posts/2013-09-01-denoising.html",
    "href": "posts/2013-09-01-denoising.html",
    "title": "Denoising",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- signal-processing- denoising- image-processing- feature-extractiondate: ’2013-09-01’output-file: 2013-09-01-denoising.htmltitle: Denoisingtoc: true—\nI took the Linear and Integer Programming course on coursera last year. It was a very well paced and structured course. In one of the modules, the instructors discussed least squares and unlike the conventional line fitting, they demonstrated the concept via signal denoising. Matlab code for the same was also provided. This is an attempt to do the same thing in an IPython notebook and leverage static widgets for a better understanding.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn\n%matplotlib inline\n\n\nTrue data\nLet us create the true data, i.e. if there were no noise and the measuring system was perfect, how would our data look like. This is a modified sinusoid signal.\n\nn=400\nt=np.array(xrange(n))\nex=0.5*np.sin(np.dot(2*np.pi/n,t))*np.sin(0.01*t)\n\n\nplt.plot(ex);\n\n\n\n\n\n\n\n\n\n\nNoisy data\nNow, let us add some Gaussian noise about the true data\n\ncorr=ex+0.05*np.random.normal(0,1,n)\n\nThis is how the corrupted signal looks like.\n\nplt.plot(corr);\n\n\n\n\n\n\n\n\n\n\nThe optimization problem\nConstraints\n\nWe want the cleaned data to be as close to the corrupted data\nWe want the successive entries in the cleaned data to be as close as possible\n\nMathematically, we can write this as follows:\n\n$ $\n\nHere, \\(||(x-x_{corr})||^2\\) corresponds to the first constraint and ${k=1}^{n-1} (x{k+1}-x_{k})^{2} $ corresponds to the second constraint.\n\n\nFormulation as least squares problem\nFor the least squares problem, we would like a form of \\(Ax=b\\)\n\nFirst constraint\nLooking at the first constraint, \\(||(x-x_{corr})||^2\\), this can be expanded as follows:\n$ (x_1 -x_{corr}(1))^2 + (x_2 -x_{corr}(2))^2 + ..(x_n -x_{corr}(n))^2$\nwhich we can rewrite as :\n$ ([1,0,0 ..0][x_1, x_2,..x_n]^T - x_{corr}(1))^2 + ([0,1,0 ..0][x_1, x_2,..x_n]^T - x_{corr}(2))^2 + …([0,0,0 ..n][x_1, x_2,..x_n]^T - x_{corr}(n))^2$\nComparing with the standard least squares, we get\n\\(A_{first} = I^{nxn}\\) and \\(b_{first} = x_{corr}\\)\n\n\nSecond constraint\nFor the second constraint, \\(\\mu\\sum_{k=1}^{n-1} (x_{k+1}-x_{k})^{2}\\)\nThis can be written as: \\((\\sqrt{\\mu}(x_2-x_1))^2 + (\\sqrt{\\mu}(x_3-x_2))^2 + .. (\\sqrt{\\mu}(x_n-x_{n-1}))^2\\) which we can write as:\n\\((\\sqrt{\\mu}[-1,1,0,0,0,0..][x_1,x_2,..x_n]^T - 0)^2 + ...(\\sqrt{\\mu}[0,0,0,..,-1,1][x_1,x_2,..x_n]^T - 0)^2\\)\nFrom this formulation, we get for this constraint, \\(A_{second}\\) as follows (we ignore \\(\\sqrt{\\mu}\\) for now)\n[-1, 1, 0, ...., 0]\n\n[0, -1, 1, ......0]\n\n..\n\n[0, 0, ..... -1, 1]\nand \\(b_{second}\\) as a zeros matrix of size (n-1, n)\n\n\nCombining both constraints\nSo, we combine the two sets of As and bs in a bigger matrix to get \\(A_{combined}\\) and \\(b_{combined}\\) as follows:\n\\(A_{combined}\\)\n[A_first\nA_second]\nand \\(b_{combined}\\) as :\n[b_first\nb_second]\n\n\n\nConstructing \\(A_{second}\\) matrix with parameter \\(n\\) and \\(\\mu\\)\n\nroot_mu=10\n\n\nd1=np.eye(n-1,n)\n\n\nd1\n\narray([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])\n\n\n\nd1=np.roll(d1,1)\n\n\nd1\n\narray([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])\n\n\n\nd2=-np.eye(n-1,n)\n\n\na_second=  root_mu*(d1+d2)\n\n\na_second\n\narray([[-10.,  10.,   0., ...,   0.,   0.,   0.],\n       [  0., -10.,  10., ...,   0.,   0.,   0.],\n       [  0.,   0., -10., ...,   0.,   0.,   0.],\n       ..., \n       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n       [  0.,   0.,   0., ..., -10.,  10.,   0.],\n       [  0.,   0.,   0., ...,   0., -10.,  10.]])\n\n\n\n\nConstructing \\(A_{first}\\) matrix with parameter \\(n\\)\n\na_first=np.eye(n)\n\n\na_first\n\narray([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n       ..., \n       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])\n\n\n\n\nConstructing \\(A\\) matrix\n\nA=np.vstack((a_first,a_second))\n\n\nA\n\narray([[  1.,   0.,   0., ...,   0.,   0.,   0.],\n       [  0.,   1.,   0., ...,   0.,   0.,   0.],\n       [  0.,   0.,   1., ...,   0.,   0.,   0.],\n       ..., \n       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n       [  0.,   0.,   0., ..., -10.,  10.,   0.],\n       [  0.,   0.,   0., ...,   0., -10.,  10.]])\n\n\nSimilarly, we construct \\(b\\) matrix\n\ncorr=corr.reshape((n,1))\n\n\nb_2=np.zeros((n-1,1))\n\n\nb=np.vstack((corr,b_2))\n\nLet us use least squares for our denoising for \\(\\mu=100\\)\n\nimport numpy.linalg.linalg as LA\n\n\nans = LA.lstsq(A,b)\n\n\n\nComparing original, noisy and denoised signal\n\nplt.plot(corr,label='noisy',alpha=0.4)\nplt.plot(ans[0],'r',linewidth=2, label='denoised')\nplt.plot(ex,'g',linewidth=2, label='original')\nplt.legend();\n\n\n\n\n\n\n\n\n\n\nObserving the variation with \\(\\mu\\)\nLet us quickly create an interactive widget to see how denoising would be affected by different values of \\(\\mu\\). We will view this on a log scale.\n\ndef create_A(n, mu):\n    \"\"\"\n    Create the A matrix\n    \"\"\"\n    d1=np.eye(n-1,n)\n    d1=np.roll(d1,1)\n    a_second=  np.sqrt(mu)*(d1+d2)\n    a_first=np.eye(n)\n    A=np.vstack((a_first,a_second))\n    return A\n\ndef create_b(n):\n    b_2=np.zeros((n-1,1))\n    b=np.vstack((corr,b_2))\n    \n    return b\n\ndef denoise(mu):\n    \"\"\"\n    Return denoised signal\n    \"\"\"\n    n =  len(corr)\n    A = create_A(n, mu)\n    b = create_b(n)\n    return LA.lstsq(A,b)[0]\n\ndef comparison_plot(mu):\n    fig, ax = plt.subplots(figsize=(4,3))  \n    ax.plot(corr,label='noisy',alpha=0.4)\n    ax.plot(denoise(np.power(10,mu)),'r',linewidth=2, label='denoised')\n    ax.plot(ex,'g',linewidth=2, label='original')\n    plt.title(r\"$\\mu=%d$\" % np.power(10,mu))\n    plt.legend()\n    return fig\n\nfrom ipywidgets import StaticInteract, RangeWidget\nStaticInteract(comparison_plot, mu = RangeWidget(0,5,1))    \n\n\n    \n    \n    \n      \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n    \n      \n    \n    \n      mu: \n    \n    \n\n\nFor smaller values of \\(\\mu\\), the first constraints is the dominant one and tries to keep the denoised signal close to the noisy one. For higher values of \\(\\mu\\), the second constraint dominates."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2018-01-07-cs-phd-lessons.html",
    "href": "posts/2018-01-07-cs-phd-lessons.html",
    "title": "CS Ph.D. lessons to my younger self",
    "section": "",
    "text": "I completed my CS Ph.D. from IIIT Delhi (Note the three Is) in March 2017. My Ph.D. was a lesson filled journey. Here’s a letter from me to my younger self for CS Ph.D. lessons.\nDear younger self,\nAs you embark this Ph.D. journey, I wanted to share some lessons and experiences. While I do not claim to be able to follow this 100 %, I am more aware than I was before. I think I might have done a better job at my Ph.D. if I’d taken note of the points I am going to mention now (in no particular order).\n\nTake care of your health\nYou’re joining fresh after completing your undergraduate studies. You are full of energy. But, your body won’t remain the same. You’ll realise that there is a difference between the early and late 20s. You’ll be debugging your code, and will feel it’ll take only 5 minutes more, and after three hours realise you’re well past your routine, your neck may hurt! Very soon, your body might hunch forward because of long sitting hours staring at your screen, and you may start gaining weight. Remember that when optimising for a happy life, you can’t neglect your health for long. As one of my mentors would say, take time off. Set it on your calendar! Ensure that you get some form of exercise routinely.\nBy health, I mean not only your physical health but also your mental health. There’ll be times that you’d be exhausted and dejected. No matter what you do, you don’t seem to make any progress. You’ll start developing doubts about your abilities. You’ll start questioning your decision to pursue a Ph.D. Remember that you’re not alone! Taking time off would help. It would also greatly help to have friends to talk and share. Don’t keep all your anxieties and worries to yourself!\n\n\nMeet well!\nYou’d be participating in a lot of meetings over the tenure of your Ph.D. Most often you’d be meeting your research advisor. You’d be very excited to discuss every possible detail of your work with your advisor. But, remember, that your advisor probably has some courses to take. They might have a group of students working under them, and have multiple projects running simultaneously. So, you’d need to plan and strategise to make the best use of the meeting time you get with your advisor. Here’s a template that I tried to follow. First, set the context by giving a summary of previous meeting discussion. Setting the context will ensure that you both are on the same page. Present a brief agenda. Then, present the main findings. Have some thoughts on why your method works or does not work. Over the course of your Ph.D., you’ll realise that your advisor is an expert in deducing why something works, and why something doesn’t. It’ll be precious for you to observe your advisor and learn and apply this yourself. In my earlier years, I’d often just go and show all my results to my advisor. You really shouldn’t stop there. Think about what you should conclude from your findings. Come up with specific questions for your advisor. Ensure that you make the best use of the limited meeting time you get with your advisor.\n\n\nPaper rejection is tough, but not the end of the world\nIt’s likely that you’ll have a few papers rejected during your Ph.D. I couldn’t believe when I got my first paper rejected. How could it be! In anguish, I felt the reviewer didn’t do a good job. I took it very personally! With more rejections, I got somewhat better at it. I also learned lessons along the way. One of the lessons that stuck with me was to not ponder too much on the reviews for 1-2 days after the paper was rejected. I wasn’t able to take the reviews with an unbiased attitude anyway. After 1-2 days, I would often appreciate the points made by the reviewers. Sometimes, I wouldn’t, but, then reviewing is complex, anyway! It should also be noted that of all my total submissions, only about one-third or so got accepted. Top CS conferences are very competitive, so paper rejections are likely to be more common than not!\n\n\nBetter emails go a long way\nYou’d be writing a ton of emails during your Ph.D., way more often than meeting in person. It’s important that you learn the art and science of writing better emails. Poorly written emails are less likely to get a response. At the beginning of my Ph.D., I wrote poor emails. The subject line wasn’t indicative of what to expect in the post, which made it incredibly hard to find relevant threads later! I often jumbled up multiple projects/topics in one email. I often wrote very long emails. Many of my emails were a brain dump and not organised well. Eventually, by observing how my advisor and other senior people wrote emails, I improved in this important skill. I think that many of the points about meetings are also applicable to emails. You need to set the context, discuss how you proceeded, and why you did so, summarise the observation, form some conclusions and questions, and if possible be specific on what inputs you need.\n\n\nEmbrace the scientific method\nI was an engineer by training before I started my Ph.D. So, I’d be thinking like - “this seems cool. Let’s try this approach. Should be fun to solve”. I went this way for some time, till I had a meeting with a senior faculty. The first question he asked me was - “what’s your hypothesis?”. I stood dumbfounded. I realised that thus far I’d been a solution-first researcher without doing so in a scientific way. I’d try and pick up approaches, if they didn’t work, move on. After a bit of rewiring, I improved my understanding and application of the scientific method. So, my work would now be more structured. I’d be wasting less time on random trails or unimportant problems. The key lesson is to have a checklist (mental or physical) of common pitfalls - like, improving the accuracy of a system from 95% to 99% on an unimportant or extremely contrived problem; or, starting data collection without much thought to the final experiments and analysis you’d plan to conduct to prove your hypothesis; or, the worst of all, having no hypothesis to start off with!\n\n\nMid-PhD. crisis time: you’re not alone\nI’d heard that every Ph.D. student goes through some crisis period. I thought I’d be an exception. How wrong I was. This period occurred after I’d been academically weaned. My coursework had finished. There was little barring research to keep me busy. Paper rejections stopped surprising me. Ideas not working stopped surprising me. I started questioning if I should quit Ph.D. midway. I started looking at forums on this topic and realised that this problem was common. During this period, I kept in touch with folks who’d completed their PhDs. Everyone suggested that this is normal, and a Ph.D. wouldn’t be so valuable if it weren’t this difficult! I feel that staying in touch with people who could relate to me was important. It was also helpful that despite the so-called inputs not converting to output, my advisors continued encouraging me, meeting regularly, and discussing scientifically correct ways of finding solutions to the Ph.D. problem. Miraculously this phase ended and led to the most successful phase of my Ph.D. where I was able to submit and get accepted a few top-tier conference papers. The key lesson is to stick it out, don’t feel alone or worthless, keep talking to cheerful people and keep reporting progress to your advisor on a regular basis.\n\n\nIt all boils down to addition and subtraction: Blog posts\nI won’t lie, I often get intimidated by research papers and the huge amount of techniques in our field. Yes, I still do. One of best teachers at my university spoke - “it all boils down to addition and subtraction.” This has stuck with me. I took a programming and visualisation approach to understanding concepts in my field. At a higher level, I’d be thinking that if I had to teach this concept to someone, how would I go about it. For example, if say, I wanted to study dynamic time warping, I started with some trivial problems where I’d use the concept. On such trivial problems, it would be easy to understand what the algorithm would be doing. I’d often end up writing detailed Jupyter/IPython notebooks showing how the algorithm works, programming and visualsing the various steps. All these formed a part of my technical blog, which I would update on a regular basis. The learning in writing these blog posts was immense. While these blog posts are public, I think I am the biggest beneficiary. Not only does one gain a good understanding of the concept involved, but one also gains confidence about the subject and one’s ability to understand! The key lesson is to document your learnings, understandings, and try to abstract out your specific problem and think of teaching the concept to someone who doesn’t know much about your problem.\n\n\nTeaching is learning\nA teaching assistantship is often dreaded. Why waste my valuable time on it? It turns out, I learned a lot from my TA experiences. I realised that learning with an intention to share the learning ensured that I learned well. I didn’t cut corners. Moreover, with an emphasis on teaching well, I often had to think hard about making concepts relatable. This exercise helped me a lot! In my first semester, I was a TA for an introduction to programming course. Before the course, I thought I knew Python reasonably well. After the course, I realised that now I knew it way better than earlier. Since Python turned out to be the language I did most of my research coding in, it turned out to be a great learning experience. Besides, I made a lot of friends with my students in the course! The key lesson here is somewhat related to the lesson on blog posts. Thinking how to explain stuff usually always helped me get a better understanding!\n\n\nGood research is only half done!\nTalks are a great way to advertise your research and get some good feedback. It’s easy to go very excited and fit everything from the paper into a few slides in a 15-20 minute presentation. This is a great recipe for disaster! Good presentations often leave the audience feeling thankful that they attended the talk. Bad talks ensure that people open their laptops and start answering emails they’ve not replied for ages! A good talk requires preparation. I repeat. A good talk requires preparation. Even if you’re a pro. Over the course of the years, I developed my style learning from my advisors, other faculties, other presenters. There were a lot of lessons involved! One of the key lessons for me was to jot down a script for my slides. While I felt I could mostly do a good job speaking without speaker notes, I think I was better with them! Of course, it took a lot of effort! Another important lesson was to deliver a talk in terms of things the audience could relate with, and thus keeping them engaged. I also maintained that the slides are there to support me and not replace me. Thus, I would never put much text into them! I’d put a lot of efforts in maintaining consistency across slides, using similar figures, conventions. All of this to ensure that the viewer doesn’t lose interest!\nOf course, despite all these efforts, I would usually always deliver a pathetic first talk. I was lucky that most of these first pathetic talks came in front of colleagues and not the main audience. So, “Practice! Practice! And practice!” is the mantra.\n\n\nVolunteer to review papers\nYour advisor would likely be reviewing a lot of papers throughout the year. Many of these would probably be in your sub-area of CS. It was an excellent exercise for me when I’d help my advisor review some of the papers. Taking part in the review process makes you appreciate the time and effort put in by the TPC and the conference management team! No one is paid for all this effort! I particularly remember excitedly telling my advisor that I’d champion one of the papers he gave me to review. He smiled and said that paper wouldn’t probably go through. The discussion that followed helped me learn the traits of a good and a bad paper from a reviewer’s perspective. Once you get the hang of it and do the same critical analysis of your paper, you’d be able to improve your paper!\n\n\nOpen source is the right way\nCS research often involves writing code for our approach, some baselines, data management and analysis. This set of code leads to the generation of results and analysis in our papers. Now, when I started my Ph.D. and started working on a problem, I thought that it should be trivial to compare our work to previous literature. It turns out; I was wrong. Reproducibility or the act of generating results from previous literature is a huge challenge. Making your code reproducible, such that others can use it for their analysis and paper takes a lot of effort. I felt that it was the right thing to make my code open source and easy for others to use. One of my most cited paper came as a result of introducing more transparency, comparability, and reproducibility. I’m also not surprised that I’m the biggest benefactor by making my code good enough to be made public. The steps I took to make the code more readable, and reproducible, helped me a lot going back to my code to tweak or re-run some experiments. In the age of Github, there aren’t really many excuses for not putting efforts towards - “Let’s make scientific articles comparable again.”\n\n\nFunding for conferences/PhD scholarships\nWhile we may crib about our stipends not being comparable to industry folks, let’s not forget that a Ph.D. can be very expensive. Coming from India, the travel costs to conferences would be high! Yes, very few of the international conferences I attended happened in India. However, some research labs like MSR and Google and some government agencies provide funding for “good” conferences. Many conferences also provide economic support. I was lucky that I could cut some of the costs for my advisor and department by getting travel fundings. Various organisations also offer Ph.D. fellowships. I was fortunate to receive one from TCS. These fellowships not only allow for some industry mentors but also include financial support. It’s one less thing to worry if we can get some of the finances worked out. The key lesson isn’t a particularly surprising one - apply for fellowship and grants whenever you can!\n\n\nGood paper writing takes time and practice\nBefore joining grad school, I was a great writer. After completing it, I could manage some writing. Confused? When I entered grad school did I realise how pathetic my scientific writing skills were. While I’d been speaking and writing English since I was four or so, it wasn’t my first language. The red coloured paper returned by my advisor on my first draft was an eye opener (technically, it was \\color in LaTeX and not a hard copy!). For someone like me who loves to learn by observation, the process of taking my first draft and seeing it turn into a well-written document courtesy my advisor was wonderful. The key lesson is to observe what makes a good draft. I came up with a structure that I would follow in almost all of my papers:\n\nWhat is the general problem?\nHow can we convert it to a CS problem?\nWhat’s the related work and where does it fail to address the problem?\nWhy would our approach work? and what’s the gist of it?\nWhat’s the experimental setup I’ve used for evaluation?\nHow well does our approach perform?\nIn light of above, what can be conclude about the problem given our approach?\n\nI’d write using such a structure in the abstract and just expand it into different sections in the paper.\nOh, and yes, don’t forget Grammarly and some scripts from Matt Might! Something that really helped me was to run my drafts, even before the final version with my colleagues to get some reviews.\n\n\nAccept limitations of your work and be honest about them\nWe’ve all seen those few points on the graph that make our algorithm look bad. Only if we didn’t have those points, our technique would look so amazing! There may be a tendency to “avoid” the limitations. My key learning on this front has been to accept the limitations of my work and be very honest about them. Science loses if we “hide” facts. Rather, it’s the limitations which make things interesting. They force us to go back and review everything. Is this an issue with our approach, or implementation, or dataset, or something more fundamental? Maintaining this integrity was always a top priority! There’ve been instances where paper reviewers have shown appreciation for us being clear and honest about the limitations.\n\n\nSometimes it helps to disconnect\nWe live in an age of data deluge. There are so many forums to network and brand your work. There are so many forums like Reddit and HackerNews to remain on top of the latest in the field. While I tried to remain up to date with the latest, it helped when I would sometimes disconnect. This used to be the way I studied in primary and secondary school. So, if any idea or interesting problem comes to mind, I would sometimes try and think it through before googling it. Similarly, if the code gives some error, I found that my programming and understanding improved if I would spend some time thinking before googling! The key lesson is to think before you search.\n\n\nIs the grass really greener on the other side\nAs a Ph.D. student sitting in India, I’d often think how great it would have been to be a Ph.D. student at say MIT, Stanford, or some other top CS university! Maybe, I would have a “better” publication record. Procrastinating in such situations is easy. My key learning in this aspect came from a discussion I had about 15 years back in my high school when my teacher told me that it’s the students who make the school. So, the key lesson was to accept that I may not be from the most well-known school in the world, but nothing stops me from doing world-class research. So, accepting what I had, and trying to change what I could was the main learning. Of course, research is highly collaborative these days. Eventually, by the time I had graduated, I had worked with people from Imperial London, Univ. of Southampton, University of Virginia, UCLA and CMU.\n\n\nInvest in good hardware\nI get it. Our Ph.D. stipends aren’t super amazing. I chose to buy the “best” laptop I could in a reasonable budget. Why bother with Apple-like expensive laptops. I could do with a regular laptop and just install Linux on it. It turns out, I was wrong. Within two years, my laptop had a broken hinge, I had driver issues (on Linux), the laptop wasn’t super light, the battery wasn’t all that great. Then, it took me a hard time to move to a superior laptop. It was expensive. But, it more than made up in terms of the increased productivity. The battery would often last a work day; my back pain got better due to a lighter laptop. I was no longer afraid of updating my system. So, while I am talking about a laptop here, the lesson is more general. The cost of a “good” piece of hardware can be easily recovered many times over in terms of increased productivity.\nTake care!\n\nMore to come\n\nNetworking at conferences, discussion buddy, elevator pitch, attending thesis and faculty job talks.."
  },
  {
    "objectID": "posts/2014-05-01-dtw.html",
    "href": "posts/2014-05-01-dtw.html",
    "title": "DTW",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- ML- time-series- dynamic-time-warping- sequence-alignment- algorithms- distance-metricsdate: ’2014-05-01’output-file: 2014-05-01-dtw.htmltitle: DTWtoc: true—\nSo you just recorded yourself saying a word and try to match it against another instance. The signals look similar, but have varying lengths and different activations for different features. So, how do you decide the similarity. Dynamic time warping (DTW) is probably something which can come to your rescue. Quoting wikipedia:\n“In time series analysis, dynamic time warping (DTW) is an algorithm for measuring similarity between two temporal sequences which may vary in time or speed. For instance, similarities in walking patterns could be detected using DTW, even if one person was walking faster than the other, or if there were accelerations and decelerations during the course of an observation.”\nIn this post I will try and put forward a naive implementation of DTW and also explain the different pieces of the problem.\n\nCustomary imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n\nCreating two signals\n\nx = np.array([1, 1, 2, 3, 2, 0])\ny = np.array([0, 1, 1, 2, 3, 2, 1])\n\n\n\nPlotting the two signals\n\nplt.plot(x,'r', label='x')\nplt.plot(y, 'g', label='y')\nplt.legend();\n\n\n\n\n\n\n\n\nSo, it appears that both the signals show similar behaviour: they both have a peak and around the peak they slop downwards. They vary in their speed and total duration. So, all set for DTW.\n\n\nAim\nOur aim is to find a mapping between all points of x and y. For instance, x(3) may be mapped to y(4) and so on.\n\n\nMaking a 2d matrix to compute distances between all pairs of x and y\nIn this initial step, we will find out the distance between all pair of points in the two signals. Lesser distances implies that these points may be candidates to be matched together.\n\ndistances = np.zeros((len(y), len(x)))\n\n\ndistances\n\narray([[ 0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.]])\n\n\nWe will use euclidean distance between the pairs of points.\n\nfor i in range(len(y)):\n    for j in range(len(x)):\n        distances[i,j] = (x[j]-y[i])**2  \n\n\ndistances\n\narray([[ 1.,  1.,  4.,  9.,  4.,  0.],\n       [ 0.,  0.,  1.,  4.,  1.,  1.],\n       [ 0.,  0.,  1.,  4.,  1.,  1.],\n       [ 1.,  1.,  0.,  1.,  0.,  4.],\n       [ 4.,  4.,  1.,  0.,  1.,  9.],\n       [ 1.,  1.,  0.,  1.,  0.,  4.],\n       [ 0.,  0.,  1.,  4.,  1.,  1.]])\n\n\n\n\nVisualizing the distance matrix\nWe will write a small function to visualize the distance matrix we just created.\n\ndef distance_cost_plot(distances):\n    im = plt.imshow(distances, interpolation='nearest', cmap='Reds') \n    plt.gca().invert_yaxis()\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.grid()\n    plt.colorbar();\n\n\ndistance_cost_plot(distances)\n\n\n\n\n\n\n\n\nFrom the plot above, it seems like the diagonal entries have low distances, which means that the distance between similar index points in x and y is low.\n\n\nWarping path\nIn order to create a mapping between the two signals, we need to create a path in the above plot. The path should start at (0,0) and want to reach (M,N) where (M, N) are the lengths of the two signals. Our aim is to find the path of minimum distance. To do this, we thus build a matrix similar to the distances matrix. This matrix would contain the minimum distances to reach a specific point when starting from (0,0). We impose some restrictions on the paths which we would explore: 1. The path must start at (0,0) and end at (M,N) 2. We cannot go back in time, so the path only flows forwards, which means that from a point (i, j), we can only right (i+1, j) or upwards (i, j+1) or diagonal (i+1, j+1).\nThese restrictions would prevent the combinatorial explosion and convert the problem to a Dynamic Programming problem which can be solved in O(MN) time.\n\naccumulated_cost = np.zeros((len(y), len(x)))\n\n\n\nLet us now build up the accumulated cost\n\nSince we start from (0,0), the accumulated cost at this point is distance(0,0)\n\n\naccumulated_cost[0,0] = distances[0,0]\n\nLets see how accumulated cost looks at this point.\n\ndistance_cost_plot(accumulated_cost)\n\n\n\n\n\n\n\n\n\nIf we were to move along the first row, i.e. from (0,0) in the right direction only, one step at a time\n\n\nfor i in range(1, len(x)):\n    accumulated_cost[0,i] = distances[0,i] + accumulated_cost[0, i-1]    \n\n\ndistance_cost_plot(accumulated_cost)\n\n\n\n\n\n\n\n\n\nIf we were to move along the first column, i.e. from (0,0) in the upwards direction only, one step at a time\n\n\nfor i in range(1, len(y)):\n    accumulated_cost[i,0] = distances[i, 0] + accumulated_cost[i-1, 0]    \n\n\ndistance_cost_plot(accumulated_cost)\n\n\n\n\n\n\n\n\nFor all other elements, we have\n\n\nfor i in range(1, len(y)):\n    for j in range(1, len(x)):\n        accumulated_cost[i, j] = min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]) + distances[i, j]\n\n\ndistance_cost_plot(accumulated_cost)\n\n\n\n\n\n\n\n\nSo, now we have obtained the matrix containing cost of all paths starting from (0,0). We now need to find the path minimizing the distance which we do by backtracking.\n\n\nBacktracking and finding the optimal warp path\nBacktracking procedure is fairly simple and involves trying to move back from the last point (M, N) and finding which place we would reached there from (by minimizing the cost) and do this in a repetitive fashion.\n\npath = [[len(x)-1, len(y)-1]]\ni = len(y)-1\nj = len(x)-1\nwhile i&gt;0 and j&gt;0:\n    if i==0:\n        j = j - 1\n    elif j==0:\n        i = i - 1\n    else:\n        if accumulated_cost[i-1, j] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n            i = i - 1\n        elif accumulated_cost[i, j-1] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n            j = j-1\n        else:\n            i = i - 1\n            j= j- 1\n    path.append([j, i])\npath.append([0,0])\n\n\npath\n\n[[5, 6], [4, 5], [3, 4], [2, 3], [1, 2], [1, 1], [0, 1], [0, 0]]\n\n\n\npath_x = [point[0] for point in path]\npath_y = [point[1] for point in path]\n\n\ndistance_cost_plot(accumulated_cost)\nplt.plot(path_x, path_y);\n\n\n\n\n\n\n\n\nThe above plot shows the optimum warping path which minimizes the sum of distance (DTW distance) along the path. Let us wrap up the function by also incorporating the DTW distance between the two signals as well.\n\ndef path_cost(x, y, accumulated_cost, distances):\n    path = [[len(x)-1, len(y)-1]]\n    cost = 0\n    i = len(y)-1\n    j = len(x)-1\n    while i&gt;0 and j&gt;0:\n        if i==0:\n            j = j - 1\n        elif j==0:\n            i = i - 1\n        else:\n            if accumulated_cost[i-1, j] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n                i = i - 1\n            elif accumulated_cost[i, j-1] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n                j = j-1\n            else:\n                i = i - 1\n                j= j- 1\n        path.append([j, i])\n    path.append([0,0])\n    for [y, x] in path:\n        cost = cost +distances[x, y]\n    return path, cost    \n\n\npath, cost = path_cost(x, y, accumulated_cost, distances)\nprint path\nprint cost\n\n[[5, 6], [4, 5], [3, 4], [2, 3], [1, 2], [1, 1], [0, 1], [0, 0]]\n2.0\n\n\nLet us compare our naive implementation with that of mlpy which also provides a DTW implementation.\n\nimport mlpy\n\n\ndist, cost, path = mlpy.dtw_std(x, y, dist_only=False)\n\n\nimport matplotlib.cm as cm\nfig = plt.figure(1)\nax = fig.add_subplot(111)\nplot1 = plt.imshow(cost.T, origin='lower', cmap=cm.gray, interpolation='nearest')\nplot2 = plt.plot(path[0], path[1], 'w')\nxlim = ax.set_xlim((-0.5, cost.shape[0]-0.5))\nylim = ax.set_ylim((-0.5, cost.shape[1]-0.5))\n\n\n\n\n\n\n\n\nThe path looks almost identical to the one we got. The slight difference is due to the fact that the path chosen by our implementation and the one chosen by DTW have the same distance and thus we woulc choose either.\n\ndist\n\n2.0\n\n\nNot bad! Our implementation gets the same distance between x and y.\nLet us look at another interesting way to visualize the warp. We will place the two signals on the same axis and\n\nplt.plot(x, 'bo-' ,label='x')\nplt.plot(y, 'g^-', label = 'y')\nplt.legend();\npaths = path_cost(x, y, accumulated_cost, distances)[0]\nfor [map_x, map_y] in paths:\n    print map_x, x[map_x], \":\", map_y, y[map_y]\n    \n    plt.plot([map_x, map_y], [x[map_x], y[map_y]], 'r')\n\n5 0 : 6 1\n4 2 : 5 2\n3 3 : 4 3\n2 2 : 3 2\n1 1 : 2 1\n1 1 : 1 1\n0 1 : 1 1\n0 1 : 0 0\n\n\n\n\n\n\n\n\n\nThe above plot shows the mapping between the two signal. The red lines connect the matched points which are given by the DTW algorithm Looks neat isn’t it? Now, let us try this for some known signal. This example is inspired from the example used in R’s dtw implementation. We will see the DTW path between a sine and cosine on the same angles.\n\nidx = np.linspace(0, 6.28, 100)\n\n\nx = np.sin(idx)\n\n\ny = np.cos(idx)\n\n\ndistances = np.zeros((len(y), len(x)))\n\n\nfor i in range(len(y)):\n    for j in range(len(x)):\n        distances[i,j] = (x[j]-y[i])**2  \n\n\ndistance_cost_plot(distances)\n\n\n\n\n\n\n\n\n\naccumulated_cost = np.zeros((len(y), len(x)))\naccumulated_cost[0,0] = distances[0,0]\nfor i in range(1, len(y)):\n    accumulated_cost[i,0] = distances[i, 0] + accumulated_cost[i-1, 0]\nfor i in range(1, len(x)):\n    accumulated_cost[0,i] = distances[0,i] + accumulated_cost[0, i-1] \nfor i in range(1, len(y)):\n    for j in range(1, len(x)):\n        accumulated_cost[i, j] = min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]) + distances[i, j]\n\n\nplt.plot(x, 'bo-' ,label='x')\nplt.plot(y, 'g^-', label = 'y')\nplt.legend();\npaths = path_cost(x, y, accumulated_cost, distances)[0]\nfor [map_x, map_y] in paths:\n    #print map_x, x[map_x], \":\", map_y, y[map_y]\n    \n    plt.plot([map_x, map_y], [x[map_x], y[map_y]], 'r')\n\n\n\n\n\n\n\n\nOk, this does look nice. I am impressed!\n\n\nConclusions\nWe worked out a naive DTW implementation pretty much from scratch. It seems to do reasonably well on artificial data.\n\n\nReferences\n\nWikipedia page on dtw\nR’s dtw package\nmlpy page on dtw\nDTW review paper\n\nFeel free to comment!"
  },
  {
    "objectID": "posts/2023-01-19-conformal-intro.html",
    "href": "posts/2023-01-19-conformal-intro.html",
    "title": "Conformal Prediction",
    "section": "",
    "text": "This is a work in progress. I will be adding more content to this post in the coming days.\nReference: https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_multiclass.html#sphx-glr-auto-examples-calibration-plot-calibration-multiclass-py\n\nimport sklearn\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\nimport numpy as np\nfrom sklearn.datasets import make_blobs\n\nnp.random.seed(0)\n\nX, y = make_blobs(\n    n_samples=2000, n_features=2, centers=3, random_state=42, cluster_std=5.0\n)\nX_train, y_train = X[:600], y[:600]\nX_valid, y_valid = X[600:1000], y[600:1000]\nX_train_valid, y_train_valid = X[:1000], y[:1000]\nX_test, y_test = X[1000:], y[1000:]\n\n\n# Scater plot showing different classes in different colors\nplt.scatter(X[:, 0], X[:, 1], c=y ,alpha=0.7)\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\nprob_df = pd.DataFrame(lr.predict_proba(X_valid))\nprob_df.columns = lr.classes_\nprob_df.head()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n0.014323\n0.959135\n0.026542\n\n\n1\n0.000326\n0.004617\n0.995057\n\n\n2\n0.667887\n0.322486\n0.009627\n\n\n3\n0.953779\n0.043703\n0.002518\n\n\n4\n0.000029\n0.000130\n0.999841\n\n\n\n\n\n\n\n\npd.Series(prob_df.values[np.arange(400), y_valid]).quantile(0.1)\n\n0.3934260593598625\n\n\n\n# Get the predicted probability for the correct class for each sample\ny_valid\n\narray([1, 2, 0, 0, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 1, 2,\n       1, 0, 0, 2, 0, 0, 1, 2, 0, 1, 2, 0, 0, 2, 1, 2, 0, 1, 1, 0, 0, 1,\n       0, 0, 2, 2, 1, 1, 0, 0, 0, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 0, 1, 1,\n       0, 1, 1, 2, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1,\n       0, 1, 0, 1, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 1, 0, 0, 1,\n       2, 2, 2, 1, 0, 2, 2, 0, 0, 2, 0, 1, 2, 0, 1, 1, 2, 2, 1, 1, 2, 2,\n       0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 2, 0, 2, 0, 1, 1, 0, 2, 0, 1, 0,\n       1, 0, 2, 2, 0, 0, 2, 1, 0, 2, 0, 2, 0, 0, 0, 1, 2, 0, 1, 2, 0, 2,\n       1, 0, 0, 0, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 0, 0,\n       2, 0, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 0, 2,\n       0, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 0, 2, 0, 1, 0, 2, 2, 2, 1, 0, 1,\n       1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 2, 1,\n       0, 1, 0, 1, 2, 0, 1, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 0,\n       1, 0, 1, 2, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 2, 2, 1, 2, 0, 1, 1, 2,\n       1, 2, 2, 0, 2, 2, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 2, 1, 0, 1, 1, 2,\n       0, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 1, 2, 0, 1,\n       0, 1, 0, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 0, 0, 2, 2,\n       0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0,\n       2, 2, 2, 2])\n\n\n\n# Get the predicted probability for the correct class for each sample\n\n\n\n\n\n\n\n\n1\n2\n0\n0\n2\n2\n2\n1\n1\n2\n...\n2\n0\n0\n1\n0\n0\n2\n2\n2\n2\n\n\n\n\n0\n0.959135\n0.026542\n0.014323\n0.014323\n0.026542\n0.026542\n0.026542\n0.959135\n0.959135\n0.026542\n...\n0.026542\n0.014323\n0.014323\n0.959135\n0.014323\n0.014323\n0.026542\n0.026542\n0.026542\n0.026542\n\n\n1\n0.004617\n0.995057\n0.000326\n0.000326\n0.995057\n0.995057\n0.995057\n0.004617\n0.004617\n0.995057\n...\n0.995057\n0.000326\n0.000326\n0.004617\n0.000326\n0.000326\n0.995057\n0.995057\n0.995057\n0.995057\n\n\n2\n0.322486\n0.009627\n0.667887\n0.667887\n0.009627\n0.009627\n0.009627\n0.322486\n0.322486\n0.009627\n...\n0.009627\n0.667887\n0.667887\n0.322486\n0.667887\n0.667887\n0.009627\n0.009627\n0.009627\n0.009627\n\n\n3\n0.043703\n0.002518\n0.953779\n0.953779\n0.002518\n0.002518\n0.002518\n0.043703\n0.043703\n0.002518\n...\n0.002518\n0.953779\n0.953779\n0.043703\n0.953779\n0.953779\n0.002518\n0.002518\n0.002518\n0.002518\n\n\n4\n0.000130\n0.999841\n0.000029\n0.000029\n0.999841\n0.999841\n0.999841\n0.000130\n0.000130\n0.999841\n...\n0.999841\n0.000029\n0.000029\n0.000130\n0.000029\n0.000029\n0.999841\n0.999841\n0.999841\n0.999841\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n395\n0.253215\n0.038669\n0.708116\n0.708116\n0.038669\n0.038669\n0.038669\n0.253215\n0.253215\n0.038669\n...\n0.038669\n0.708116\n0.708116\n0.253215\n0.708116\n0.708116\n0.038669\n0.038669\n0.038669\n0.038669\n\n\n396\n0.000339\n0.999576\n0.000086\n0.000086\n0.999576\n0.999576\n0.999576\n0.000339\n0.000339\n0.999576\n...\n0.999576\n0.000086\n0.000086\n0.000339\n0.000086\n0.000086\n0.999576\n0.999576\n0.999576\n0.999576\n\n\n397\n0.019843\n0.980018\n0.000139\n0.000139\n0.980018\n0.980018\n0.980018\n0.019843\n0.019843\n0.980018\n...\n0.980018\n0.000139\n0.000139\n0.019843\n0.000139\n0.000139\n0.980018\n0.980018\n0.980018\n0.980018\n\n\n398\n0.000094\n0.999780\n0.000126\n0.000126\n0.999780\n0.999780\n0.999780\n0.000094\n0.000094\n0.999780\n...\n0.999780\n0.000126\n0.000126\n0.000094\n0.000126\n0.000126\n0.999780\n0.999780\n0.999780\n0.999780\n\n\n399\n0.000133\n0.999776\n0.000092\n0.000092\n0.999776\n0.999776\n0.999776\n0.000133\n0.000133\n0.999776\n...\n0.999776\n0.000092\n0.000092\n0.000133\n0.000092\n0.000092\n0.999776\n0.999776\n0.999776\n0.999776\n\n\n\n\n400 rows × 400 columns"
  },
  {
    "objectID": "posts/autoencoder.html",
    "href": "posts/autoencoder.html",
    "title": "Autoencoders in JAX",
    "section": "",
    "text": "Imports\n\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\nimport optax\n\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nimport jax.random as random\nimport tensorflow_probability.substrates.jax as tfp\n\nfrom flax import linen as nn\nfrom typing import Any, Callable, Sequence\n\nimport seaborn as sns\nimport pandas as pd\n\nfrom bayes_opt import BayesianOptimization\n\n\n\n\nCreate a simple 2d dataset\n\nX = random.multivariate_normal(\n    key=random.PRNGKey(0),\n    shape=(100,),\n    mean=jnp.array([1, 3]),\n    cov=jnp.array([[1.0, -0.5], [-0.5, 2.0]]),\n)\n\n\nX.shape\n\n(100, 2)\n\n\n\nplt.scatter(X[:, 0], X[:, 1])\n# plt.gca().set_aspect(\"equal\")\n\n\n\n\n\n\n\n\n\nclass Encoder(nn.Module):\n    bottleneck: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(5)(x)\n        x = nn.selu(x)\n        x = nn.Dense(features=self.bottleneck)(x)\n        return x\n\n\nclass Decoder(nn.Module):\n    out: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(5)(x)\n        x = nn.selu(x)\n        x = nn.Dense(features=self.out)(x)\n        return x\n\n\nenc = Encoder(bottleneck=1)\n\ndec = Decoder(out=2)\n\n\nparams_enc = enc.init(random.PRNGKey(0), X)\nX_bottlenecked = enc.apply(params_enc, X)\nX_bottlenecked.shape\n\n(100, 1)\n\n\n\nprint(enc.tabulate(random.PRNGKey(0), X))\n\nprint(dec.tabulate(random.PRNGKey(0), X_bottlenecked))\n\n\n                               Encoder Summary                                \n\n┏━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n\n┃ path    ┃ module  ┃ inputs         ┃ outputs        ┃ params               ┃\n\n┡━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n\n│         │ Encoder │ float32[100,2] │ float32[100,1] │                      │\n\n├─────────┼─────────┼────────────────┼────────────────┼──────────────────────┤\n\n│ Dense_0 │ Dense   │ float32[100,2] │ float32[100,5] │ bias: float32[5]     │\n\n│         │         │                │                │ kernel: float32[2,5] │\n\n│         │         │                │                │                      │\n\n│         │         │                │                │ 15 (60 B)            │\n\n├─────────┼─────────┼────────────────┼────────────────┼──────────────────────┤\n\n│ Dense_1 │ Dense   │ float32[100,5] │ float32[100,1] │ bias: float32[1]     │\n\n│         │         │                │                │ kernel: float32[5,1] │\n\n│         │         │                │                │                      │\n\n│         │         │                │                │ 6 (24 B)             │\n\n├─────────┼─────────┼────────────────┼────────────────┼──────────────────────┤\n\n│         │         │                │          Total │ 21 (84 B)            │\n\n└─────────┴─────────┴────────────────┴────────────────┴──────────────────────┘\n\n                                                                              \n\n                         Total Parameters: 21 (84 B)                          \n\n\n\n\n\n\n\n                               Decoder Summary                                \n\n┏━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n\n┃ path    ┃ module  ┃ inputs         ┃ outputs        ┃ params               ┃\n\n┡━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n\n│         │ Decoder │ float32[100,1] │ float32[100,2] │                      │\n\n├─────────┼─────────┼────────────────┼────────────────┼──────────────────────┤\n\n│ Dense_0 │ Dense   │ float32[100,1] │ float32[100,5] │ bias: float32[5]     │\n\n│         │         │                │                │ kernel: float32[1,5] │\n\n│         │         │                │                │                      │\n\n│         │         │                │                │ 10 (40 B)            │\n\n├─────────┼─────────┼────────────────┼────────────────┼──────────────────────┤\n\n│ Dense_1 │ Dense   │ float32[100,5] │ float32[100,2] │ bias: float32[2]     │\n\n│         │         │                │                │ kernel: float32[5,2] │\n\n│         │         │                │                │                      │\n\n│         │         │                │                │ 12 (48 B)            │\n\n├─────────┼─────────┼────────────────┼────────────────┼──────────────────────┤\n\n│         │         │                │          Total │ 22 (88 B)            │\n\n└─────────┴─────────┴────────────────┴────────────────┴──────────────────────┘\n\n                                                                              \n\n                         Total Parameters: 22 (88 B)                          \n\n\n\n\n\n\n\n\n\nclass AE(nn.Module):\n    bottleneck: int\n    out: int\n    def setup(self):\n        # Alternative to @nn.compact -&gt; explicitly define modules\n        # Better for later when we want to access the encoder and decoder explicitly\n        self.encoder = Encoder(bottleneck=self.bottleneck)\n        self.decoder = Decoder(out=self.out)\n\n    def __call__(self, x):\n\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        return x_hat\n\n\nbottleneck_size = 1\nout_size = X.shape[1]\nae = AE(bottleneck_size, out_size)\n\n\nae\n\nAE(\n    # attributes\n    bottleneck = 1\n    out = 2\n)\n\n\n\nprint(ae.tabulate(random.PRNGKey(0), X))\n\n\n                                   AE Summary                                   \n\n┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n\n┃ path            ┃ module  ┃ inputs         ┃ outputs        ┃ params         ┃\n\n┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n\n│                 │ AE      │ float32[100,2] │ float32[100,2] │                │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│ encoder         │ Encoder │ float32[100,2] │ float32[100,1] │                │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│ encoder/Dense_0 │ Dense   │ float32[100,2] │ float32[100,5] │ bias:          │\n\n│                 │         │                │                │ float32[5]     │\n\n│                 │         │                │                │ kernel:        │\n\n│                 │         │                │                │ float32[2,5]   │\n\n│                 │         │                │                │                │\n\n│                 │         │                │                │ 15 (60 B)      │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│ encoder/Dense_1 │ Dense   │ float32[100,5] │ float32[100,1] │ bias:          │\n\n│                 │         │                │                │ float32[1]     │\n\n│                 │         │                │                │ kernel:        │\n\n│                 │         │                │                │ float32[5,1]   │\n\n│                 │         │                │                │                │\n\n│                 │         │                │                │ 6 (24 B)       │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│ decoder         │ Decoder │ float32[100,1] │ float32[100,2] │                │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│ decoder/Dense_0 │ Dense   │ float32[100,1] │ float32[100,5] │ bias:          │\n\n│                 │         │                │                │ float32[5]     │\n\n│                 │         │                │                │ kernel:        │\n\n│                 │         │                │                │ float32[1,5]   │\n\n│                 │         │                │                │                │\n\n│                 │         │                │                │ 10 (40 B)      │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│ decoder/Dense_1 │ Dense   │ float32[100,5] │ float32[100,2] │ bias:          │\n\n│                 │         │                │                │ float32[2]     │\n\n│                 │         │                │                │ kernel:        │\n\n│                 │         │                │                │ float32[5,2]   │\n\n│                 │         │                │                │                │\n\n│                 │         │                │                │ 12 (48 B)      │\n\n├─────────────────┼─────────┼────────────────┼────────────────┼────────────────┤\n\n│                 │         │                │          Total │ 43 (172 B)     │\n\n└─────────────────┴─────────┴────────────────┴────────────────┴────────────────┘\n\n                                                                                \n\n                          Total Parameters: 43 (172 B)                          \n\n\n\n\n\n\n\n\n\nparams = ae.init(random.PRNGKey(0), X)\nparams\n\nFrozenDict({\n    params: {\n        encoder: {\n            Dense_0: {\n                kernel: DeviceArray([[ 0.17535934, -1.0953957 ,  0.69273657, -0.26352578,\n                               0.63077825],\n                             [ 0.36360174, -0.73782593, -0.5395247 , -0.41536337,\n                              -0.30090812]], dtype=float32),\n                bias: DeviceArray([0., 0., 0., 0., 0.], dtype=float32),\n            },\n            Dense_1: {\n                kernel: DeviceArray([[-0.64744544],\n                             [ 0.4855265 ],\n                             [-0.82133824],\n                             [ 0.62454295],\n                             [ 0.6013553 ]], dtype=float32),\n                bias: DeviceArray([0.], dtype=float32),\n            },\n        },\n        decoder: {\n            Dense_0: {\n                kernel: DeviceArray([[-0.5305567 ,  1.1100855 , -0.31129056,  0.43152457,\n                              -0.09589562]], dtype=float32),\n                bias: DeviceArray([0., 0., 0., 0., 0.], dtype=float32),\n            },\n            Dense_1: {\n                kernel: DeviceArray([[-0.76956064,  0.13031492],\n                             [ 0.11736098,  0.47368795],\n                             [-0.12549445, -0.31066778],\n                             [-0.4392067 , -0.9067152 ],\n                             [-0.86761785,  0.42325035]], dtype=float32),\n                bias: DeviceArray([0., 0.], dtype=float32),\n            },\n        },\n    },\n})\n\n\n\nX_hat = ae.apply(params, X)\nX_hat.shape\n\n(100, 2)\n\n\n\ntry:\n    ae.encoder\nexcept:\n    pass\n    # Trying to figure this out\n    # https://github.com/google/flax/discussions/2602\n\n\n# Encoded values/latent representation\nencoded_1d = Encoder(1).apply({\"params\": params[\"params\"][\"encoder\"]}, X).flatten()\nencoded_1d\n\nDeviceArray([-2.4718695, -2.1964364, -2.6823573, -2.4936147, -1.7122931,\n             -1.8346143, -2.0767107, -1.8570523, -1.7632042, -2.067935 ,\n             -2.2317708, -2.14561  , -1.0023856, -2.1458383, -2.3645976,\n             -1.9418356, -2.7020268, -1.6407721, -1.8281609, -2.2202983,\n             -2.517499 , -2.5888596, -2.0095935, -2.4470625, -2.18571  ,\n             -1.9742887, -1.8921608, -2.245328 , -0.8897901, -2.5329056,\n             -2.2861118, -1.5862433, -2.2295656, -2.496296 , -2.404385 ,\n             -2.0180435, -1.8416756, -1.858724 , -2.0980945, -1.777173 ,\n             -2.0027544, -2.1870096, -2.44952  , -1.7563678, -1.5761943,\n             -2.3097022, -2.0295165, -2.9528203, -2.2042174, -1.9090188,\n             -1.8868417, -2.4206855, -2.143362 , -1.880422 , -2.5127397,\n             -2.1454868, -2.0043788, -2.570388 , -2.5082102, -2.3339696,\n             -1.8621875, -2.4201612, -2.561397 , -2.0498512, -1.6772006,\n             -1.6392376, -2.3855271, -1.8138398, -3.3776197, -2.3745804,\n             -2.6683671, -1.8609927, -1.4205931, -1.8123009, -2.236284 ,\n             -2.2161927, -2.5204146, -2.0504622, -2.1548996, -1.6896895,\n             -1.3192847, -2.2909331, -2.1295016, -2.0703764, -1.9394028,\n             -2.041992 , -1.8279521, -1.690125 , -2.7230937, -2.3157165,\n             -1.7527001, -2.2544892, -2.6310122, -2.0703619, -2.2476096,\n             -1.8941168, -1.5398859, -1.5742403, -2.375471 , -1.9361446],            dtype=float32)\n\n\n\ndef plot_2d_reconstruction(X, params, model, trained = False):\n    X_hat = model.apply(params, X)\n    plt.scatter(X[:, 0], X[:, 1], label=\"Original Data\")\n    plt.scatter(X_hat[:, 0], X_hat[:, 1], label=\"Reconstructed Data\")\n    if trained:\n        plt.title(\"Trained\")\n    else:\n        plt.title(\"Untrained\")\n\n\nplot_2d_reconstruction(X, params, ae, False)\n\n\n\n\n\n\n\n\n\n\nDefine the Loss function\n\\(\\ell_2\\) penalty\n\ndiff = X - X_hat\n\n\ndiff.shape\n\n(100, 2)\n\n\n\ndiff[:5]\n\nDeviceArray([[-0.46981597,  5.271835  ],\n             [ 1.6502905 ,  3.6781619 ],\n             [ 1.8507848 ,  5.0589485 ],\n             [ 2.8690844 ,  4.5646677 ],\n             [ 0.4905889 ,  2.8893166 ]], dtype=float32)\n\n\n\n(diff**2).sum(axis=1).mean() / 2\n\nDeviceArray(7.9555416, dtype=float32)\n\n\n\n(diff**2).sum(axis=1)[:5]\n\nDeviceArray([28.01297 , 16.252333, 29.018364, 29.067837,  8.588828], dtype=float32)\n\n\n\n(jnp.linalg.norm(diff, ord=2, axis=1) ** 2).mean() / 2\n\nDeviceArray(7.955541, dtype=float32)\n\n\n\nfrom sklearn.metrics import mean_squared_error\n\n\nmean_squared_error(X, X_hat)\n\n7.9555407\n\n\n\nprint(2 * optax.l2_loss(X_hat, X).mean())\n\n\"\"\"\n\nMultplying by two\nDocstring says:\nCalculates the L2 loss for a set of predictions.\n\nNote: the 0.5 term is standard in \"Pattern Recognition and Machine Learning\"\nby Bishop, but not \"The Elements of Statistical Learning\" by Tibshirani.\n\"\"\"\n\n7.9555416\n\n\n'\\n\\nMultplying by two\\nDocstring says:\\nCalculates the L2 loss for a set of predictions.\\n\\nNote: the 0.5 term is standard in \"Pattern Recognition and Machine Learning\"\\nby Bishop, but not \"The Elements of Statistical Learning\" by Tibshirani.\\n'\n\n\n\n@jax.jit\ndef loss(params, X):\n    X_hat = ae.apply(params, X)\n    return 2 * optax.l2_loss(X_hat, X).mean()\n\n\nloss(params, X)\n\nDeviceArray(7.9555416, dtype=float32)\n\n\n\n\nDefining the train function\n\ndef train(\n    X: jnp.array,\n    optimizer: optax._src.base.GradientTransformation,\n    model: nn.Module,\n    key_param: jax.random.PRNGKey,\n    n_iter: int=500,\n    print_every: int=10\n):\n    loss_array  = np.zeros(n_iter)\n    def loss(params, X):\n        X_hat = model.apply(params, X)\n        return 2 * optax.l2_loss(X_hat, X).mean()\n\n    params = model.init(key_param, X)\n    opt_state = optimizer.init(params)\n    loss_grad_fn = jax.value_and_grad(loss)\n\n    for i in range(n_iter):\n        loss_val, grads = loss_grad_fn(params, X)\n        loss_array[i] = loss_val.item()\n        updates, opt_state = optimizer.update(grads, opt_state)\n        params = optax.apply_updates(params, updates)\n        if i % print_every == 0:\n            print(\"Loss step {}: \".format(i), loss_val)\n    return params, loss_array\n\n\noptimized_params, loss_array = train(\n    X, optax.adam(learning_rate=0.1), ae, jax.random.PRNGKey(0), n_iter=30\n)\n\nLoss step 0:  7.9555416\nLoss step 10:  1.3104575\nLoss step 20:  0.544944\n\n\n\nplt.plot(loss_array)\nplt.xlabel(\"Iterations\")\n_ = plt.ylabel(\"Reconstruction loss\")\n\n\n\n\n\n\n\n\n\nplot_2d_reconstruction(X, optimized_params, ae, True)\n\n\n\n\n\n\n\n\n\nfrom sklearn import datasets\n\n\ndigits = datasets.load_digits()\n\n\nX = jnp.array(digits[\"data\"])\ny = digits[\"target\"]\n\n\nX.shape\n\n(1797, 64)\n\n\n\nplt.imshow(X[1].reshape(8, 8), cmap=\"Greys\")\ny[1]\n\n1\n\n\n\n\n\n\n\n\n\n\nbn = 2\nae_digits = AE(bn, X.shape[1])\n\nae_digits\n\nAE(\n    # attributes\n    bottleneck = 2\n    out = 64\n)\n\n\n\nprint(ae_digits.tabulate(random.PRNGKey(0), X))\n\n\n                                   AE Summary                                   \n\n┏━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n\n┃ path           ┃ module  ┃ inputs         ┃ outputs         ┃ params         ┃\n\n┡━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n\n│                │ AE      │ float32[1797,… │ float32[1797,6… │                │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│ encoder        │ Encoder │ float32[1797,… │ float32[1797,2] │                │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│ encoder/Dense… │ Dense   │ float32[1797,… │ float32[1797,5] │ bias:          │\n\n│                │         │                │                 │ float32[5]     │\n\n│                │         │                │                 │ kernel:        │\n\n│                │         │                │                 │ float32[64,5]  │\n\n│                │         │                │                 │                │\n\n│                │         │                │                 │ 325 (1.3 KB)   │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│ encoder/Dense… │ Dense   │ float32[1797,… │ float32[1797,2] │ bias:          │\n\n│                │         │                │                 │ float32[2]     │\n\n│                │         │                │                 │ kernel:        │\n\n│                │         │                │                 │ float32[5,2]   │\n\n│                │         │                │                 │                │\n\n│                │         │                │                 │ 12 (48 B)      │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│ decoder        │ Decoder │ float32[1797,… │ float32[1797,6… │                │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│ decoder/Dense… │ Dense   │ float32[1797,… │ float32[1797,5] │ bias:          │\n\n│                │         │                │                 │ float32[5]     │\n\n│                │         │                │                 │ kernel:        │\n\n│                │         │                │                 │ float32[2,5]   │\n\n│                │         │                │                 │                │\n\n│                │         │                │                 │ 15 (60 B)      │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│ decoder/Dense… │ Dense   │ float32[1797,… │ float32[1797,6… │ bias:          │\n\n│                │         │                │                 │ float32[64]    │\n\n│                │         │                │                 │ kernel:        │\n\n│                │         │                │                 │ float32[5,64]  │\n\n│                │         │                │                 │                │\n\n│                │         │                │                 │ 384 (1.5 KB)   │\n\n├────────────────┼─────────┼────────────────┼─────────────────┼────────────────┤\n\n│                │         │                │           Total │ 736 (2.9 KB)   │\n\n└────────────────┴─────────┴────────────────┴─────────────────┴────────────────┘\n\n                                                                                \n\n                         Total Parameters: 736 (2.9 KB)                         \n\n\n\n\n\n\n\n\n\nparams_digits = ae_digits.init(random.PRNGKey(0), X)\n\n\njax.tree_util.tree_map(lambda x: x.shape, params_digits)\n\nFrozenDict({\n    params: {\n        decoder: {\n            Dense_0: {\n                bias: (5,),\n                kernel: (2, 5),\n            },\n            Dense_1: {\n                bias: (64,),\n                kernel: (5, 64),\n            },\n        },\n        encoder: {\n            Dense_0: {\n                bias: (5,),\n                kernel: (64, 5),\n            },\n            Dense_1: {\n                bias: (2,),\n                kernel: (5, 2),\n            },\n        },\n    },\n})\n\n\n\ndef plot_encoding_2dim(encoder, params):\n    assert encoder.bottleneck &gt;= 2\n    X_low = encoder.apply({\"params\": params[\"params\"][\"encoder\"]}, X)\n    df = pd.DataFrame(X_low)\n    df[\"label\"] = y\n    sns.pairplot(df, hue=\"label\", palette=\"bright\")\n\n\n\nUntrained encodings\n\nplot_encoding_2dim(Encoder(bottleneck=bn), params_digits)\n\n\n\n\n\n\n\n\n\nX_recon = ae_digits.apply(params_digits, X)\n\n\ndef plot_orig_recon(index=0):\n    fig, ax = plt.subplots(sharex=True, ncols=2)\n    ax[0].imshow(X[index].reshape(8, 8), cmap=\"Greys\")\n    ax[1].imshow(X_recon[index].reshape(8, 8), cmap=\"Greys\")\n    ax[0].set_title(\"Original\")\n    ax[1].set_title(\"Reconstructed\")\n\n\nplot_orig_recon(5)\n\n\n\n\n\n\n\n\n\noptimized_params_digits, loss_array_digits = train(\n    X, optax.adam(learning_rate=0.01), ae_digits, jax.random.PRNGKey(0), n_iter=1000\n)\n\nLoss step 0:  90.91908\nLoss step 10:  62.609577\nLoss step 20:  58.390884\nLoss step 30:  53.54514\nLoss step 40:  45.062607\nLoss step 50:  33.541103\nLoss step 60:  25.167671\nLoss step 70:  21.107908\nLoss step 80:  19.424128\nLoss step 90:  18.734087\nLoss step 100:  18.47802\nLoss step 110:  18.390646\nLoss step 120:  18.352455\nLoss step 130:  18.333141\nLoss step 140:  18.321236\nLoss step 150:  18.311743\nLoss step 160:  18.3032\nLoss step 170:  18.295115\nLoss step 180:  18.287226\nLoss step 190:  18.279234\nLoss step 200:  18.270723\nLoss step 210:  18.26098\nLoss step 220:  18.2499\nLoss step 230:  18.237106\nLoss step 240:  18.221647\nLoss step 250:  18.20243\nLoss step 260:  18.177717\nLoss step 270:  18.14539\nLoss step 280:  18.105865\nLoss step 290:  18.058249\nLoss step 300:  18.000141\nLoss step 310:  17.931208\nLoss step 320:  17.84967\nLoss step 330:  17.755304\nLoss step 340:  17.65073\nLoss step 350:  17.537819\nLoss step 360:  17.418528\nLoss step 370:  17.293976\nLoss step 380:  17.164043\nLoss step 390:  17.029558\nLoss step 400:  16.89464\nLoss step 410:  16.760334\nLoss step 420:  16.626553\nLoss step 430:  16.493797\nLoss step 440:  16.362513\nLoss step 450:  16.234201\nLoss step 460:  16.11052\nLoss step 470:  15.992949\nLoss step 480:  15.883502\nLoss step 490:  15.783846\nLoss step 500:  15.694724\nLoss step 510:  15.615571\nLoss step 520:  15.54589\nLoss step 530:  15.483993\nLoss step 540:  15.427973\nLoss step 550:  15.376085\nLoss step 560:  15.326871\nLoss step 570:  15.280196\nLoss step 580:  15.23521\nLoss step 590:  15.191253\nLoss step 600:  15.149132\nLoss step 610:  15.109302\nLoss step 620:  15.071858\nLoss step 630:  15.037474\nLoss step 640:  15.005837\nLoss step 650:  14.977009\nLoss step 660:  14.950782\nLoss step 670:  14.927103\nLoss step 680:  14.905551\nLoss step 690:  14.885867\nLoss step 700:  14.867877\nLoss step 710:  14.851396\nLoss step 720:  14.836317\nLoss step 730:  14.8224125\nLoss step 740:  14.809575\nLoss step 750:  14.797547\nLoss step 760:  14.786259\nLoss step 770:  14.775562\nLoss step 780:  14.76545\nLoss step 790:  14.755904\nLoss step 800:  14.746771\nLoss step 810:  14.738021\nLoss step 820:  14.729595\nLoss step 830:  14.721415\nLoss step 840:  14.713423\nLoss step 850:  14.705618\nLoss step 860:  14.697898\nLoss step 870:  14.690201\nLoss step 880:  14.682494\nLoss step 890:  14.674812\nLoss step 900:  14.667133\nLoss step 910:  14.6593275\nLoss step 920:  14.651322\nLoss step 930:  14.643042\nLoss step 940:  14.634569\nLoss step 950:  14.625735\nLoss step 960:  14.616413\nLoss step 970:  14.6066065\nLoss step 980:  14.596094\nLoss step 990:  14.58464\n\n\n\nplt.plot(loss_array_digits)\n\n\n\n\n\n\n\n\n\n\nTrained encodings\n\nplot_encoding_2dim(Encoder(bottleneck=bn), optimized_params_digits)\n\n\n\n\n\n\n\n\n\n\nReconstruction\n\nX_recon = ae_digits.apply(optimized_params_digits, X)\nplot_orig_recon(4)\n\n\n\n\n\n\n\n\n\nX_reconstructed = ae.apply(params, X)\n\n\nerrs = jnp.square(X - X_reconstructed).sum(axis=1)\nerr_df = pd.DataFrame({\"error\": errs, \"label\": y})\nerr_df.groupby(\"label\").mean()\n\n\n\n\n\n\n\n\nerror\n\n\nlabel\n\n\n\n\n\n0\n1067.159668\n\n\n1\n1253.397217\n\n\n2\n1187.446655\n\n\n3\n730.839417\n\n\n4\n919.732239\n\n\n5\n1103.442505\n\n\n6\n913.172607\n\n\n7\n1309.424438\n\n\n8\n892.981750\n\n\n9\n891.891907\n\n\n\n\n\n\n\n\nerr_df = pd.DataFrame({\"error\": errs, \"label\": y})\n\n\nerr_df.groupby(\"label\").mean()\n\n\n\n\n\n\n\n\nerror\n\n\nlabel\n\n\n\n\n\n0\n1067.159668\n\n\n1\n1253.397217\n\n\n2\n1187.446655\n\n\n3\n730.839417\n\n\n4\n919.732239\n\n\n5\n1103.442505\n\n\n6\n913.172607\n\n\n7\n1309.424438\n\n\n8\n892.981750\n\n\n9\n891.891907\n\n\n\n\n\n\n\n\n\nConvoluational AE\n\nclass ConvEncoder(nn.Module):\n    bottleneck: int\n\n    @nn.compact\n    def __call__(self, x):\n        n = x.shape[0]  # x is nx64\n        x = x.reshape(n, 8, 8, 1)\n        x = nn.Conv(features=4, kernel_size=(2, 2), strides=1, padding=0)(\n            x\n        )  # 8X8X1 -&gt; 6x6X4\n        x = nn.selu(x)\n        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))  # 6x6x4 --&gt; 3x3x4\n        x = nn.selu(x)\n        x = x.reshape(n, -1)  # N X 3x3x4 -&gt; N X 36\n        x = nn.Dense(self.bottleneck)(x)\n        return x\n\n\nce = ConvEncoder(2)\n#print(ce.tabulate(random.PRNGKey(0), X))\nprint(ce.tabulate(random.PRNGKey(0), X, console_kwargs={\"width\": 120}))\n\n\n                                      ConvEncoder Summary                                       \n\n┏━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\n┃ path    ┃ module      ┃ inputs              ┃ outputs             ┃ params                   ┃\n\n┡━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\n│         │ ConvEncoder │ float32[1797,64]    │ float32[1797,2]     │                          │\n\n├─────────┼─────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ Conv_0  │ Conv        │ float32[1797,8,8,1] │ float32[1797,7,7,4] │ bias: float32[4]         │\n\n│         │             │                     │                     │ kernel: float32[2,2,1,4] │\n\n│         │             │                     │                     │                          │\n\n│         │             │                     │                     │ 20 (80 B)                │\n\n├─────────┼─────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ Dense_0 │ Dense       │ float32[1797,36]    │ float32[1797,2]     │ bias: float32[2]         │\n\n│         │             │                     │                     │ kernel: float32[36,2]    │\n\n│         │             │                     │                     │                          │\n\n│         │             │                     │                     │ 74 (296 B)               │\n\n├─────────┼─────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│         │             │                     │               Total │ 94 (376 B)               │\n\n└─────────┴─────────────┴─────────────────────┴─────────────────────┴──────────────────────────┘\n\n                                                                                                \n\n                                  Total Parameters: 94 (376 B)                                  \n\n\n\n\n\n\n\n\n\nclass ConvDecoder(nn.Module):\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(36)(x)  # Nx2 --&gt; Nx36\n        x = nn.selu(x)\n        x = x.reshape(-1, 3, 3, 4)  # NX3X3X4\n        x = nn.ConvTranspose(features=4, kernel_size=(2, 2), strides=(2, 2))(\n            x\n        )  # 3x3x4 -&gt; 6x6X4\n        x = nn.selu(x)\n        x = nn.Conv(features=1, kernel_size=(1, 1), strides=1, padding=1)(\n            x\n        )  # 6x6x4 -&gt; 8x8x1\n        x = x.reshape(-1, 64)\n        return x\n\n\ncd = ConvDecoder()\nprint(\n    cd.tabulate(\n        random.PRNGKey(0),\n        jax.random.normal(key=jax.random.PRNGKey(0), shape=(1797, 2)),\n        console_kwargs={\"width\": 120},\n    )\n)\n\n\n                                           ConvDecoder Summary                                            \n\n┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\n┃ path            ┃ module        ┃ inputs              ┃ outputs             ┃ params                   ┃\n\n┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\n│                 │ ConvDecoder   │ float32[1797,2]     │ float32[1797,64]    │                          │\n\n├─────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ Dense_0         │ Dense         │ float32[1797,2]     │ float32[1797,36]    │ bias: float32[36]        │\n\n│                 │               │                     │                     │ kernel: float32[2,36]    │\n\n│                 │               │                     │                     │                          │\n\n│                 │               │                     │                     │ 108 (432 B)              │\n\n├─────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ ConvTranspose_0 │ ConvTranspose │ float32[1797,3,3,4] │ float32[1797,6,6,4] │ bias: float32[4]         │\n\n│                 │               │                     │                     │ kernel: float32[2,2,4,4] │\n\n│                 │               │                     │                     │                          │\n\n│                 │               │                     │                     │ 68 (272 B)               │\n\n├─────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ Conv_0          │ Conv          │ float32[1797,6,6,4] │ float32[1797,8,8,1] │ bias: float32[1]         │\n\n│                 │               │                     │                     │ kernel: float32[1,1,4,1] │\n\n│                 │               │                     │                     │                          │\n\n│                 │               │                     │                     │ 5 (20 B)                 │\n\n├─────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│                 │               │                     │               Total │ 181 (724 B)              │\n\n└─────────────────┴───────────────┴─────────────────────┴─────────────────────┴──────────────────────────┘\n\n                                                                                                          \n\n                                      Total Parameters: 181 (724 B)                                       \n\n\n\n\n\n\n\n\n\nclass ConvAE(nn.Module):\n    bottleneck: int\n\n    def setup(self):\n        # Alternative to @nn.compact -&gt; explicitly define modules\n        # Better for later when we want to access the encoder and decoder explicitly\n        self.encoder = ConvEncoder(bottleneck=self.bottleneck)\n        self.decoder = ConvDecoder()\n\n    def __call__(self, x):\n\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        return x_hat\n\n\ncae = ConvAE(2)\nprint(\n    cae.tabulate(\n        random.PRNGKey(0),\n        X,\n        console_kwargs={\"width\": 120},\n    )\n)\n\n\n                                                  ConvAE Summary                                                  \n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n\n┃ path                    ┃ module        ┃ inputs              ┃ outputs             ┃ params                   ┃\n\n┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n\n│                         │ ConvAE        │ float32[1797,64]    │ float32[1797,64]    │                          │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ encoder                 │ ConvEncoder   │ float32[1797,64]    │ float32[1797,2]     │                          │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ encoder/Conv_0          │ Conv          │ float32[1797,8,8,1] │ float32[1797,7,7,4] │ bias: float32[4]         │\n\n│                         │               │                     │                     │ kernel: float32[2,2,1,4] │\n\n│                         │               │                     │                     │                          │\n\n│                         │               │                     │                     │ 20 (80 B)                │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ encoder/Dense_0         │ Dense         │ float32[1797,36]    │ float32[1797,2]     │ bias: float32[2]         │\n\n│                         │               │                     │                     │ kernel: float32[36,2]    │\n\n│                         │               │                     │                     │                          │\n\n│                         │               │                     │                     │ 74 (296 B)               │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ decoder                 │ ConvDecoder   │ float32[1797,2]     │ float32[1797,64]    │                          │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ decoder/Dense_0         │ Dense         │ float32[1797,2]     │ float32[1797,36]    │ bias: float32[36]        │\n\n│                         │               │                     │                     │ kernel: float32[2,36]    │\n\n│                         │               │                     │                     │                          │\n\n│                         │               │                     │                     │ 108 (432 B)              │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ decoder/ConvTranspose_0 │ ConvTranspose │ float32[1797,3,3,4] │ float32[1797,6,6,4] │ bias: float32[4]         │\n\n│                         │               │                     │                     │ kernel: float32[2,2,4,4] │\n\n│                         │               │                     │                     │                          │\n\n│                         │               │                     │                     │ 68 (272 B)               │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│ decoder/Conv_0          │ Conv          │ float32[1797,6,6,4] │ float32[1797,8,8,1] │ bias: float32[1]         │\n\n│                         │               │                     │                     │ kernel: float32[1,1,4,1] │\n\n│                         │               │                     │                     │                          │\n\n│                         │               │                     │                     │ 5 (20 B)                 │\n\n├─────────────────────────┼───────────────┼─────────────────────┼─────────────────────┼──────────────────────────┤\n\n│                         │               │                     │               Total │ 275 (1.1 KB)             │\n\n└─────────────────────────┴───────────────┴─────────────────────┴─────────────────────┴──────────────────────────┘\n\n                                                                                                                  \n\n                                          Total Parameters: 275 (1.1 KB)                                          \n\n\n\n\n\n\n\n\n\nparams = cae.init(random.PRNGKey(0), X)\n\n\nplot_encoding_2dim(ConvEncoder(bottleneck=2), params)\n\n\n\n\n\n\n\n\n\noptimized_params_digits_cae, loss_array_digits_cae = train(\n    X, optax.adam(learning_rate=0.01), cae, jax.random.PRNGKey(0), n_iter=1000, print_every=50\n)\n\nLoss step 0:  61.916904\nLoss step 50:  30.379993\nLoss step 100:  27.855324\nLoss step 150:  26.851124\nLoss step 200:  25.77603\nLoss step 250:  25.184359\nLoss step 300:  24.772747\nLoss step 350:  24.351847\nLoss step 400:  24.091908\nLoss step 450:  23.887573\nLoss step 500:  23.72832\nLoss step 550:  23.607725\nLoss step 600:  23.514961\nLoss step 650:  23.419945\nLoss step 700:  23.363184\nLoss step 750:  23.30127\nLoss step 800:  23.258532\nLoss step 850:  23.206999\nLoss step 900:  23.162285\nLoss step 950:  23.13027\n\n\n\nplot_encoding_2dim(ConvEncoder(bottleneck=2), optimized_params_digits_cae)\n\n\n\n\n\n\n\n\n\n\nBayesOpt for optimizing the latent dimension\n\ndef black_box_function(x, y):\n    \"\"\"Function with unknown internals we wish to maximize.\n\n    This is just serving as an example, for all intents and\n    purposes think of the internals of this function, i.e.: the process\n    which generates its output values, as unknown.\n    \"\"\"\n    x = int(x)\n    y = int(y)\n    return function_discrete(x, y)\n\n\ndef function_discrete(x, y):\n    assert type(x) ==int\n    return -(x**2) - (y - 1) ** 2 + 1\n\n\npbounds = {\"x\": (2, 4), \"y\": (-3, 3)}\n\n\noptimizer = BayesianOptimization(\n    f=black_box_function,\n    pbounds=pbounds,\n    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n    random_state=1,\n)\n\n\noptimizer.maximize()\n\n\n|   iter    |  target   |     x     |     y     |\n\n-------------------------------------------------\n\n| 1         | -3.0      | 2.834     | 1.322     |\n\n| 2         | -7.0      | 2.0       | -1.186    |\n\n| 3         | -12.0     | 2.294     | -2.446    |\n\n| 4         | -4.0      | 2.373     | -0.9266   |\n\n| 5         | -4.0      | 2.794     | 0.2329    |\n\n| 6         | -15.0     | 4.0       | 1.331     |\n\n| 7         | -4.0      | 2.348     | 0.8879    |\n\n| 8         | -3.0      | 2.797     | 1.257     |\n\n| 9         | -4.0      | 2.064     | 2.229     |\n\n| 10        | -9.0      | 3.657     | -0.9428   |\n\n| 11        | -7.0      | 2.901     | 3.0       |\n\n| 12        | -4.0      | 2.0       | -0.1486   |\n\n| 13        | -31.0     | 4.0       | -3.0      |\n\n| 14        | -7.0      | 2.0       | 3.0       |\n\n| 15        | -3.0      | 2.0       | 1.539     |\n\n| 16        | -3.0      | 2.512     | 1.792     |\n\n| 17        | -19.0     | 4.0       | 3.0       |\n\n| 18        | -4.0      | 2.831     | -0.4655   |\n\n| 19        | -4.0      | 2.402     | -0.3286   |\n\n| 20        | -9.0      | 3.539     | 0.08748   |\n\n| 21        | -7.0      | 2.841     | -1.217    |\n\n| 22        | -4.0      | 2.764     | 2.245     |\n\n| 23        | -4.0      | 2.0       | 0.4436    |\n\n| 24        | -3.0      | 2.469     | 1.423     |\n\n| 25        | -3.0      | 2.0       | 1.16      |\n\n| 26        | -3.0      | 2.787     | 1.714     |\n\n| 27        | -4.0      | 2.932     | 0.7853    |\n\n| 28        | -3.0      | 2.647     | 1.526     |\n\n| 29        | -3.0      | 2.148     | 1.373     |\n\n| 30        | -3.0      | 2.212     | 1.795     |\n\n=================================================\n\n\n\n\n\noptimizer.max\n\n{'target': -3.0, 'params': {'x': 2.8340440094051482, 'y': 1.3219469606529488}}\n\n\n\n{k: int(v) for k, v in optimizer.max[\"params\"].items()}\n\n{'x': 2, 'y': 1}\n\n\n\nfunction_discrete(2, 1)\n\n-3\n\n\nLet us keep a separate validation set\n\ndef loss_model(params, X, model):\n    X_hat = model.apply(params, X)\n    diff = X - X_hat\n    return (diff**2).sum(axis=1).mean() / X.shape[1]\n\n\nfrom functools import partial\n\ne = partial(loss_model, model=cae)\ne(params, X)\n\nDeviceArray(61.916904, dtype=float32)\n\n\n\ndef validation_loss_discrete(bn):\n    assert type(bn) == int\n\n    # Train the model on bn sized bottleneck\n    cae = ConvAE(bn)\n    loss_fn_concrete = jax.jit(partial(loss_model, model=cae))\n    loss_grad_fn = jax.value_and_grad(loss_fn_concrete)\n    tx = optax.adam(learning_rate=1e-2)\n    params = cae.init(random.PRNGKey(0), X_train)\n    opt_state = tx.init(params)\n    print(f\"--------Bottleneck of Size: {bn}-------------\")\n    for i in range(30):\n        loss_val, grads = loss_grad_fn(params, X_train)\n        updates, opt_state = tx.update(grads, opt_state)\n        params = optax.apply_updates(params, updates)\n\n        if i % 5 == 0:\n            print(\"Loss step {}: \".format(i), loss_val)\n    print(f\"--------End-------------\")\n\n    # Evaluate on validation dataset\n    return loss_fn_concrete(params, X_validation)\n\n\nX_train, X_validation = X[:1000], X[1000:]\n\n\nvalidation_loss_discrete(2)\n\n--------Bottleneck of Size: 2-------------\nLoss step 0:  62.27715\nLoss step 5:  58.5037\nLoss step 10:  53.984245\nLoss step 15:  49.513382\nLoss step 20:  43.078316\nLoss step 25:  38.30596\n--------End-------------\n\n\nDeviceArray(36.75615, dtype=float32)\n\n\n\ndef validation_loss_bb(bn):\n    bn_int = int(bn)\n    return -validation_loss_discrete(bn_int)\n\n\nvalidation_loss_bb(2.5)\n\n--------Bottleneck of Size: 2-------------\nLoss step 0:  62.27715\nLoss step 5:  58.5037\nLoss step 10:  53.984245\nLoss step 15:  49.513382\nLoss step 20:  43.078316\nLoss step 25:  38.30596\n--------End-------------\n\n\nDeviceArray(-36.75615, dtype=float32)\n\n\n\npbounds = {\"bn\": (1, 40)}\noptimizer = BayesianOptimization(\n    f=validation_loss_bb,\n    pbounds=pbounds,\n    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n    random_state=1,\n)\n\n\noptimizer.maximize(n_iter=8)\n\n\n|   iter    |  target   |    bn     |\n\n-------------------------------------\n\n--------Bottleneck of Size: 17-------------\n\nLoss step 0:  62.85297\n\nLoss step 5:  52.85449\n\nLoss step 10:  40.903214\n\nLoss step 15:  35.32036\n\nLoss step 20:  35.3193\n\nLoss step 25:  33.33418\n\n--------End-------------\n\n| 1         | -32.36    | 17.26     |\n\n--------Bottleneck of Size: 29-------------\n\nLoss step 0:  64.064514\n\nLoss step 5:  53.85875\n\nLoss step 10:  47.26749\n\nLoss step 15:  43.828564\n\nLoss step 20:  41.847286\n\nLoss step 25:  39.23966\n\n--------End-------------\n\n| 2         | -37.29    | 29.09     |\n\n--------Bottleneck of Size: 1-------------\n\nLoss step 0:  60.969757\n\nLoss step 5:  58.92785\n\nLoss step 10:  53.683678\n\nLoss step 15:  49.58035\n\nLoss step 20:  45.86102\n\nLoss step 25:  44.17104\n\n--------End-------------\n\n| 3         | -42.48    | 1.004     |\n\n--------Bottleneck of Size: 12-------------\n\nLoss step 0:  63.704227\n\nLoss step 5:  57.338806\n\nLoss step 10:  49.537926\n\nLoss step 15:  41.210827\n\nLoss step 20:  38.469257\n\nLoss step 25:  35.276833\n\n--------End-------------\n\n| 4         | -34.07    | 12.79     |\n\n--------Bottleneck of Size: 6-------------\n\nLoss step 0:  61.450924\n\nLoss step 5:  55.82548\n\nLoss step 10:  47.88899\n\nLoss step 15:  40.131763\n\nLoss step 20:  37.62544\n\nLoss step 25:  35.873016\n\n--------End-------------\n\n| 5         | -34.2     | 6.723     |\n\n--------Bottleneck of Size: 20-------------\n\nLoss step 0:  61.81845\n\nLoss step 5:  56.358246\n\nLoss step 10:  51.92751\n\nLoss step 15:  47.312576\n\nLoss step 20:  42.146885\n\nLoss step 25:  37.025486\n\n--------End-------------\n\n| 6         | -33.86    | 20.39     |\n\n--------Bottleneck of Size: 40-------------\n\nLoss step 0:  61.5667\n\nLoss step 5:  49.598972\n\nLoss step 10:  42.639145\n\nLoss step 15:  39.22532\n\nLoss step 20:  36.597954\n\nLoss step 25:  34.528015\n\n--------End-------------\n\n| 7         | -32.67    | 40.0      |\n\n--------Bottleneck of Size: 36-------------\n\nLoss step 0:  62.303535\n\nLoss step 5:  52.075367\n\nLoss step 10:  44.435425\n\nLoss step 15:  40.889286\n\nLoss step 20:  39.280178\n\nLoss step 25:  37.09512\n\n--------End-------------\n\n| 8         | -35.77    | 36.05     |\n\n--------Bottleneck of Size: 9-------------\n\nLoss step 0:  63.35566\n\nLoss step 5:  52.45499\n\nLoss step 10:  43.281902\n\nLoss step 15:  37.028984\n\nLoss step 20:  35.006325\n\nLoss step 25:  33.583298\n\n--------End-------------\n\n| 9         | -33.01    | 9.596     |\n\n--------Bottleneck of Size: 24-------------\n\nLoss step 0:  62.888515\n\nLoss step 5:  52.035835\n\nLoss step 10:  42.154068\n\nLoss step 15:  36.804348\n\nLoss step 20:  34.53549\n\nLoss step 25:  32.37921\n\n--------End-------------\n\n| 10        | -30.08    | 24.26     |\n\n--------Bottleneck of Size: 25-------------\n\nLoss step 0:  63.406757\n\nLoss step 5:  50.291225\n\nLoss step 10:  41.73214\n\nLoss step 15:  38.421593\n\nLoss step 20:  37.0491\n\nLoss step 25:  34.847046\n\n--------End-------------\n\n| 11        | -33.89    | 25.81     |\n\n--------Bottleneck of Size: 22-------------\n\nLoss step 0:  62.303898\n\nLoss step 5:  53.713398\n\nLoss step 10:  47.806355\n\nLoss step 15:  43.550034\n\nLoss step 20:  42.033653\n\nLoss step 25:  39.68766\n\n--------End-------------\n\n| 12        | -38.51    | 22.8      |\n\n--------Bottleneck of Size: 24-------------\n\nLoss step 0:  62.888515\n\nLoss step 5:  52.035835\n\nLoss step 10:  42.154068\n\nLoss step 15:  36.804348\n\nLoss step 20:  34.53549\n\nLoss step 25:  32.37921\n\n--------End-------------\n\n| 13        | -30.08    | 24.3      |\n\n=====================================\n\n\n\n\n\noptimizer.max\n\n{'target': -30.082199096679688, 'params': {'bn': 24.25939633195359}}\n\n\n\n\nVAE\n\nclass VAE_Encoder(nn.Module):\n    bottleneck: int\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(5)(x)\n        x = nn.selu(x)\n        mu = nn.Dense(features=self.bottleneck)(x)\n        log_std = nn.Dense(features=self.bottleneck)(x)\n        return mu, log_std\n\n\ndef reparameterize(mu, log_std, key=random.PRNGKey(0), samples=1):\n    std = jnp.exp(log_std)\n    eps = random.normal(key=key, shape=(samples,))\n    return mu + eps * std\n\n\nsamples = reparameterize(2, jnp.log(1), samples=5000)\nsns.kdeplot(samples)\nplt.title(f\"Mean:{jnp.mean(samples):0.2f}, stddev: {jnp.std(samples):0.2f}\")\n\nText(0.5, 1.0, 'Mean:2.00, stddev: 1.00')\n\n\n\n\n\n\n\n\n\n\nclass VAE(nn.Module):\n    bottleneck: int\n    out: int\n\n    def setup(self):\n        # Alternative to @nn.compact -&gt; explicitly define modules\n        # Better for later when we want to access the encoder and decoder explicitly\n        self.encoder = VAE_Encoder(bottleneck=self.bottleneck)\n        self.decoder = Decoder(out=self.out)\n\n    def __call__(self, x, rng=random.PRNGKey(0)):\n        mu, log_std = self.encoder(x)\n        z = reparameterize(mu, log_std, key=rng)\n        x_hat = self.decoder(z)\n        return x_hat, mu, log_std\n\n\nvae = VAE(bottleneck=2, out=64)\n\n\nparams = vae.init(random.PRNGKey(10), X)\n\n\nplt.imshow(vae.apply(params, X)[0][0].reshape(8, 8))\n\n\n\n\n\n\n\n\n\nvae.apply(params, X, random.PRNGKey(10))[0][0].reshape(8, 8)\n\nDeviceArray([[ -3999.399   ,   6091.6396  ,  -2634.2932  ,    307.47302 ,\n                3932.0298  ,   1823.3352  ,   3852.157   ,   5576.5605  ],\n             [ -8809.304   ,   5299.91    ,    286.5227  ,   1059.3925  ,\n                -951.62537 ,  -6623.4824  ,  -1463.6239  ,  16223.624   ],\n             [ -5279.1323  ,  -7333.815   ,    -71.1485  ,   5679.2773  ,\n                1384.2794  ,   8326.92    ,  -1747.943   ,  -4802.341   ],\n             [   403.3739  ,  13455.688   ,  -7414.195   ,   7299.713   ,\n                1180.7408  ,   -328.49432 ,   6619.1357  ,    363.74713 ],\n             [ -4376.3506  ,  -2045.3063  ,   2618.412   , -10890.402   ,\n               -3035.3848  ,  -3574.7527  ,  -5057.2593  ,  -1859.8529  ],\n             [   -53.99241 ,   2318.109   ,  -1323.9087  ,  -6801.4814  ,\n               -7300.1553  ,    865.4169  ,  13349.937   ,    865.3773  ],\n             [    37.275284,  -3962.8357  ,   1771.9886  ,  -7992.7188  ,\n                4896.562   , -17371.383   ,   4737.3887  ,   7307.3384  ],\n             [  -221.0234  ,  -5475.8447  ,   4189.172   ,  -1095.9471  ,\n               -6452.915   ,   3767.8381  , -10514.758   ,  -2311.0862  ]],            dtype=float32)\n\n\n\nvae_e = VAE_Encoder(2)\nmu, log_sigma = vae_e.apply({\"params\": params[\"params\"][\"encoder\"]}, X)\n\n\ntfd = tfp.distributions\n\n\nq\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nInput In [99], in &lt;cell line: 1&gt;()\n----&gt; 1 q\n\nNameError: name 'q' is not defined\n\n\n\n\ntfd.kl_divergence(q, p).shape\n\n\ntfd.kl_divergence(q, p).mean()\n\n\nq.stddev()\n\n\n\nLoss\n\n@jax.jit\ndef loss_vae(params, X, rng=random.PRNGKey(0)):\n    X_hat, mu, log_sigma = vae.apply(params, X, rng)\n    q = tfd.Normal(loc=mu, scale=jnp.exp(log_sigma))\n    p = tfd.Normal(loc=0.0, scale=1.0)\n    kl_loss = tfd.kl_divergence(q, p).mean()\n\n    diff = X - X_hat\n    recon_loss = (diff**2).sum(axis=1).mean() / X.shape[1]\n\n    return recon_loss + 0.0020 * kl_loss\n\n\nloss_vae(params, X, random.PRNGKey(4))\n\n\nimport optax\n\nlearning_rate = 0.01\ntx = optax.adam(learning_rate=learning_rate)\nopt_state = tx.init(params)\nloss_grad_fn = jax.value_and_grad(loss_vae)\n\n\nfor i in range(2001):\n    rng, key = random.split(rng)\n    loss_val, grads = loss_grad_fn(params, X, rng)\n    updates, opt_state = tx.update(grads, opt_state)\n    params = optax.apply_updates(params, updates)\n    if i % 50 == 0:\n        print(\"Loss step {}: \".format(i), loss_val)\n\n\nX_recon, _, _ = vae.apply(params, X)\n\n\nplot_orig_recon(8)\n\n\ndec = Decoder(out=64)\nN = 10\nx_range = jnp.linspace(-2, 2, N)\nfig, ax = plt.subplots(ncols=N, sharey=True, figsize=(20, 4))\nfor i in range(N):\n    ax[i].imshow(\n        dec.apply(\n            {\"params\": params[\"params\"][\"decoder\"]}, jnp.array([x_range[i], 0.0])\n        ).reshape(8, 8),\n        cmap=\"Greys\",\n    )\n\n\ndef plot_encoding_2dim_vae(encoder, params):\n    assert encoder.bottleneck &gt;= 2\n    mu, log_sigma = encoder.apply({\"params\": params[\"params\"][\"encoder\"]}, X)\n    df = pd.DataFrame(mu)\n    df[\"label\"] = y\n    sns.pairplot(df, hue=\"label\", palette=\"bright\")\n\n\nvae_enc = VAE_Encoder(2)\nmu, log_sigma = vae_enc.apply({\"params\": params[\"params\"][\"encoder\"]}, X)\n# plot_encoding_2dim_vae(VAE_Encoder(2), params)\n\n\nplot_encoding_2dim_vae(vae_enc, params)\n\n\n\nTODO\n\nregular AE: Bayesopt for latent dimension\ngeneration from regular AE\ngraph of reconstruction loss v/s latent dimension for regular AE\nGIF for walking in latent space for VAE\nReconstruction as a factor of Recon + Beta X KL\nGet the Encoder from AE object directly\nImpact of MC samples\nReconstruction v/s Expected Log Likelihood (confirm the trend is same for both)\nCleanup code so that can be reused rather than copy pasting\nSparse VAE\nAdd references\nAdd bib entry\nConsider CNNs for more realistic datasets\n\n\nhttps://lilianweng.github.io/posts/2018-08-12-vae/\nhttps://theaisummer.com/jax-tensorflow-pytorch/\nhttps://dmol.pub/dl/VAE.html"
  },
  {
    "objectID": "posts/fsgm.html",
    "href": "posts/fsgm.html",
    "title": "Gradient wrt input for a simple model for adversarial attacks",
    "section": "",
    "text": "Introduction\nMain idea:\n\nStart with an input image \\(x\\) and a target class \\(y\\).\nCompute the gradient of the loss function (with true target class) with respect to the input image \\(x\\).\nMake a small update \\(\\epsilon\\) to the input image \\(x\\) to slightly change the output of the model.\nUpdate equation: \\(x_{adv} = x + \\epsilon \\cdot sign(\\nabla_x J(\\theta, x, y))\\)\nRepeat step 2-4 until the model is fooled.\n\nReference: https://www.youtube.com/watch?v=5lFiZTSsp40\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# retina display\n%config InlineBackend.figure_format = 'retina'\n\n\nxs = torch.linspace(-3, 3, 1000)\nsigns = torch.sign(xs)\nplt.plot(xs.numpy(), signs.numpy())\nplt.xlabel('x')\nplt.ylabel('sign(x)')\n\nText(0, 0.5, 'sign(x)')\n\n\n\n\n\n\n\n\n\n\n# Load a pretrained model for imagenet classification\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n\nUsing cache found in /home/nipun.batra/.cache/torch/hub/pytorch_vision_v0.6.0\n\n\n\nmodel\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n\n# Put the model in evaluation mode\nmodel.eval()\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n\n# Read in an image and preprocess\nfrom PIL import Image\nfrom torchvision import transforms\n\n\n\nim = Image.open(\"happy-doggy.jpg\")\nplt.imshow(im)\n\n\n\n\n\n\n\n\n\n# Apply transformations\npreprocess_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n])\nimg_tensor = preprocess_transforms(im)\n\n/home/nipun.batra/.cache/torch/hub/pytorch_vision_v0.6.0/torchvision/transforms/functional.py:74: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n\n\n\n# plot transformed image\nplt.imshow(img_tensor.permute(1, 2, 0))\n\n\n\n\n\n\n\n\n\n# Add a batch dimension\nbatched_img_tensor = img_tensor.unsqueeze(0)\nbatched_img_tensor.shape\n\ntorch.Size([1, 3, 224, 224])\n\n\n\n# predict the class of the image\npreds = model(batched_img_tensor)\npreds.argmax()\n\ntensor(273)\n\n\n\n# Download imagenet labels\nimport urllib\nurl, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\ntry: urllib.URLopener().retrieve(url, filename)\nexcept: urllib.request.urlretrieve(url, filename)\n\n# Load ImageNet labels\nwith open(\"imagenet_classes.txt\", \"r\") as f:\n    categories = [s.strip() for s in f.readlines()]\n    \n\n\ncategories[preds.argmax()]\n\n'dingo'\n\n\n\ndef func(inp, model, target):\n    out = model(inp)\n    loss = torch.nn.functional.nll_loss(out, target=torch.LongTensor([target]))\n\n    print(f\"Loss: {loss.item()}\")\n    return loss\n\n\nfunc(batched_img_tensor, model, 258), func(batched_img_tensor, model, 263)\n\nLoss: 1.7196619510650635\nLoss: -5.548308372497559\n\n\n(tensor(1.7197, grad_fn=&lt;NllLossBackward0&gt;),\n tensor(-5.5483, grad_fn=&lt;NllLossBackward0&gt;))\n\n\n\n# Get the gradient of the output with respect to an image\ndef get_gradient(image_tensor, label_idx):\n    # Make sure the image requires a gradient.\n    image_tensor.requires_grad_(True)\n    # Forward pass\n    preds = model(image_tensor)\n    # Get the gradient of the output with respect to the inputs based on NLL\n    loss = torch.nn.functional.nll_loss(preds, target=torch.LongTensor([label_idx]))\n    loss.backward()\n    print(f\"Loss: {loss.item()}\")\n    image_tensor.requires_grad_(False)\n    return image_tensor.grad.data\n\n\ngrads = get_gradient(batched_img_tensor, preds.argmax())\ngrads.shape\n\nLoss: -12.811663627624512\n\n\ntorch.Size([1, 3, 224, 224])\n\n\n\n# Plot the gradient\nplt.imshow(grads[0].permute(1, 2, 0))\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# Get the sign of the gradient\nsigns = torch.sign(grads)\nsigns\n\ntensor([[[[-1., -1.,  1.,  ...,  1., -1.,  1.],\n          [-1., -1., -1.,  ...,  1.,  1.,  1.],\n          [ 1., -1., -1.,  ..., -1.,  1.,  1.],\n          ...,\n          [-1.,  1., -1.,  ...,  1.,  1.,  1.],\n          [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n          [-1., -1., -1.,  ..., -1., -1.,  1.]],\n\n         [[-1., -1.,  1.,  ..., -1., -1.,  1.],\n          [-1., -1.,  1.,  ..., -1., -1., -1.],\n          [ 1., -1., -1.,  ..., -1., -1.,  1.],\n          ...,\n          [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n          [-1., -1.,  1.,  ...,  1.,  1.,  1.],\n          [-1.,  1., -1.,  ..., -1., -1.,  1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1.,  1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [ 1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [ 1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1.,  1.,  ...,  1., -1., -1.],\n          [-1.,  1., -1.,  ..., -1., -1.,  1.]]]])\n\n\n\n# Plot the sign of the gradient\nplt.imshow(signs[0].permute(1, 2, 0))\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n# Add noise to the image\neps = 0.001\nnoisy_img = batched_img_tensor + eps * signs\nnoisy_img = torch.clamp(noisy_img, 0, 1)\n\n\n# Plot the noisy image\nplt.imshow(noisy_img[0].permute(1, 2, 0))\n\n\n\n\n\n\n\n\n\n# view the label for the noisy image\nmodel(noisy_img).argmax()\n\ntensor(434)\n\n\n\n# Now, repeat till the model is fooled\neps = 0.0001\n\nnoisy_img = batched_img_tensor.clone()\nnoisy_img.requires_grad_(True)\ni = 0\nwhile model(noisy_img).argmax() == preds.argmax():\n    grads = get_gradient(noisy_img, preds.argmax())\n    signs = torch.sign(grads)\n    noisy_img = noisy_img + eps * signs\n    noisy_img = torch.clamp(noisy_img, -2, 2)\n    noisy_img = noisy_img.detach().requires_grad_(True)\n    i = i + 1\n    if i % 10 == 0:\n        print(i)\n\n# Detach the image tensor from the computation graph\nnoisy_img.requires_grad_(False)\nnoisy_img = noisy_img.detach()\n\n\n\nLoss: -12.811663627624512\nLoss: -12.379142761230469\nLoss: -11.94972038269043\nLoss: -11.527520179748535\n\n\n\nmodel(noisy_img).argmax()\n\ntensor(173)\n\n\n\ncategories[model(noisy_img).argmax()]\n\n'Ibizan hound'\n\n\n\n# Plot the image\nplt.imshow(noisy_img[0].permute(1, 2, 0))\n\n\n\n\n\n\n\n\n\n# Difference between the original and the adversarial image\ndiff = (noisy_img - batched_img_tensor)[0]\ndiff = diff.mean(dim=0)\ndiff = torch.abs(diff)\ndiff = diff / diff.max()\n\n\ndiff.shape\n\ntorch.Size([224, 224])\n\n\n\nfig, ax = plt.subplots(figsize=(10, 4), ncols=3)\nax[0].imshow(batched_img_tensor[0].permute(1, 2, 0))\nax[0].set_title(\"Original Image\\n Label: \" + categories[preds.argmax()])\n\nax[1].imshow(noisy_img[0].permute(1, 2, 0))\nax[1].set_title(\"Adversarial Image\\n Label: \" + categories[model(noisy_img).argmax()])\n\nax[2].imshow(diff, cmap='gray')\nax[2].set_title(\"Difference\")\n\nText(0.5, 1.0, 'Difference')\n\n\n\n\n\n\n\n\n\n\n# Now, let us create a function to generate adversarial examples for any image\n\ndef generate_adversarial_example(image_tensor, target_label, model, eps=0.001, max_iter=500):\n    # Create a noisy image identical to the input image\n    noisy_img = image_tensor.clone()\n    # Make the noisy image require a gradient\n    noisy_img.requires_grad_(True)\n    for i in range(max_iter):\n        # Get the gradient of the input image\n        grads = get_gradient(noisy_img, target_label)\n        # Get the sign of the gradient\n        signs = torch.sign(grads)\n        # Add noise to the image\n        noisy_img = noisy_img + eps * signs\n        # Clamp the image to make sure it is within the valid pixel range\n        noisy_img = torch.clamp(noisy_img, -2, 2)\n        # Detach the image tensor from the computation graph\n        noisy_img.requires_grad_(False)\n        # Check if the noisy image is misclassified\n        # Print model prediction\n        print(f\"Iteration: {i} \\t Model Prediction: {categories[model(noisy_img).argmax()]}\")\n        # If the noisy image is misclassified, return it\n        if model(noisy_img).argmax() != target_label:\n            return noisy_img\n    # If the noisy image is not misclassified within max_iter iterations, return it\n    return noisy_img\n\ndef plot_image_adversary_difference(image_tensor, noisy_img):\n    # Difference between the original and the adversarial image\n    diff = (noisy_img - image_tensor)[0]\n    diff = diff.mean(dim=0)\n    diff = torch.abs(diff)\n    diff = diff / diff.max()\n    # Plot the image\n    fig, ax = plt.subplots(figsize=(10, 4), ncols=3)\n    ax[0].imshow(image_tensor[0].permute(1, 2, 0))\n    ax[0].set_title(\"Original Image\\n Label: \" + categories[model(image_tensor).argmax()])\n\n    ax[1].imshow(noisy_img[0].permute(1, 2, 0))\n    ax[1].set_title(\"Adversarial Image\\n Label: \" + categories[model(noisy_img).argmax()])\n\n    ax[2].imshow(diff, cmap='gray')\n    ax[2].set_title(\"Difference\")\n\ndef preprocess(img_path):\n    img = Image.open(img_path)\n    img = img.resize((224, 224))\n    img_tensor = preprocess_transforms(img)\n    img_tensor = img_tensor.unsqueeze(0)\n    return img_tensor\n\n\nimg_path = \"lion.jpg\"\nimg_tensor = preprocess(img_path)\n\n/home/nipun.batra/.cache/torch/hub/pytorch_vision_v0.6.0/torchvision/transforms/functional.py:74: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n\n\n\nplt.imshow(img_tensor[0].permute(1, 2, 0))\n\n\n\n\n\n\n\n\n\nmodel(img_tensor).argmax()\n\ntensor(291)\n\n\n\ncategories[model(img_tensor).argmax()]\n\n'lion'\n\n\n\nadv = generate_adversarial_example(img_tensor, model(img_tensor).argmax(), model, eps=0.0001, max_iter=50)\n\nplot_image_adversary_difference(img_tensor, adv)\n\nLoss: -17.654619216918945\nIteration: 0     Model Prediction: lion\nLoss: -17.16172981262207\nIteration: 1     Model Prediction: lion\nLoss: -16.668292999267578\nIteration: 2     Model Prediction: lion\nLoss: -16.1711483001709\nIteration: 3     Model Prediction: lion\nLoss: -15.673859596252441\nIteration: 4     Model Prediction: lion\nLoss: -15.182080268859863\nIteration: 5     Model Prediction: lion\nLoss: -14.688620567321777\nIteration: 6     Model Prediction: lion\nLoss: -14.19030475616455\nIteration: 7     Model Prediction: lion\nLoss: -13.684654235839844\nIteration: 8     Model Prediction: lion\nLoss: -13.176743507385254\nIteration: 9     Model Prediction: lion\nLoss: -12.678997993469238\nIteration: 10    Model Prediction: lion\nLoss: -12.19263744354248\nIteration: 11    Model Prediction: lion\nLoss: -11.708401679992676\nIteration: 12    Model Prediction: lion\nLoss: -11.224825859069824\nIteration: 13    Model Prediction: lion\nLoss: -10.733859062194824\nIteration: 14    Model Prediction: lion\nLoss: -10.247729301452637\nIteration: 15    Model Prediction: lion\nLoss: -9.766221046447754\nIteration: 16    Model Prediction: lion\nLoss: -9.282770156860352\nIteration: 17    Model Prediction: lion\nLoss: -8.798469543457031\nIteration: 18    Model Prediction: lion\nLoss: -8.31735897064209\nIteration: 19    Model Prediction: lion\nLoss: -7.843080043792725\nIteration: 20    Model Prediction: lion\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\nLoss: -7.380602836608887\nIteration: 21    Model Prediction: lion\nLoss: -6.926629066467285\nIteration: 22    Model Prediction: shield\n\n\n\n\n\n\n\n\n\n\nimg_path =\"monkey.jpg\"\nimg_tensor = preprocess(img_path)\n\nplt.imshow(img_tensor[0].permute(1, 2, 0))\n\n/home/nipun.batra/.cache/torch/hub/pytorch_vision_v0.6.0/torchvision/transforms/functional.py:74: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n\n\n\n\n\n\n\n\n\n\nmodel(img_tensor).argmax()\n\ntensor(373)\n\n\n\ncategories[model(img_tensor).argmax()]\n\n'macaque'\n\n\n\nadv = generate_adversarial_example(img_tensor, model(img_tensor).argmax(), model, eps=0.0001, max_iter=50)\n\nplot_image_adversary_difference(img_tensor, adv)\n\nLoss: -10.831324577331543\nIteration: 0     Model Prediction: macaque\nLoss: -10.409868240356445\nIteration: 1     Model Prediction: macaque\nLoss: -9.994575500488281\nIteration: 2     Model Prediction: macaque\nLoss: -9.579815864562988\nIteration: 3     Model Prediction: macaque\nLoss: -9.168878555297852\nIteration: 4     Model Prediction: macaque\nLoss: -8.76225471496582\nIteration: 5     Model Prediction: Chihuahua"
  },
  {
    "objectID": "posts/2021-06-12-setup-mac.html",
    "href": "posts/2021-06-12-setup-mac.html",
    "title": "My Mac Setup",
    "section": "",
    "text": "Setting up a new Mac\nHere is a screenshot.\n\nI will now discuss how I setup a new Mac. I use homebrew. It makes it very easy to maintain all the packages up to date.\n\nInstall homebrew and some pertinent packages\nxcode-select --install\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nInstall git\nbrew install git\nInstall Git-Credential-Manager\nbrew tap microsoft/git\nbrew install --cask git-credential-manager-core\nInstall powerline fonts\ngit clone https://github.com/powerline/fonts\ncd fonts\n./install.sh\nUse powerline fonts in shell\nGo to Terminal -&gt; Preferences Change font to powerline I am using Roboto Mono Light Powerline 18pt\ngit clone git://github.com/stephenway/monokai.terminal.git\n\ncd monokai.terminal\n\nopen monokai.terminal\n\n(set this theme as default)\nInstall Zoom\nbrew install --cask zoom\nInstall Firefox\nbrew install --cask firefox\nInstall VSCode\nbrew install --cask visual-studio-code\nInstall OBSStudio\nbrew install --cask obs\nVLC\nbrew install --cask vlc\nwget\nbrew install wget\nDownload miniconda wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh sh Miniconda3-latest-MacOSX-x86_64.sh\nAnaconda path setup in zsh\nsource ~/miniconda3/bin/activate conda init zsh\nInstall mamba (faster than conda) conda install mamba -n base -c conda-forge\nDownload oh-my-zsh sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\nVSCode configure Python Cmd + Shift + p -&gt; Select Python Interpreter -&gt; Point to the miniconda one \nInstall LaTeX (tinyTeX)\nFirst, install quarto using https://quarto.org/docs/get-started/\nSee https://danmackinlay.name/notebook/latex_installation.html for more\nquarto install tool tinytex\n\ntlmgr install pgfplots psnfss beamertheme-metropolis pgfopts type1cm cm-super underscore dvipng adjustbox collectbox collection-fontsrecommended enumitem logreq ucs xstrin sourcesanspro sourcecodespro                  \n\nln -s ~/Library/TinyTeX/bin/*/dvipng /usr/local/bin/\nSearching for a missing .sty file\n`tlmgr search –global –file “/sourcesanspro.sty”``\nInstalling TexStudio brew install --cask texstudio\nFFMPeg brew install ffmpeg\nImagemagick brew install imagemagick\nGhostscript brew install ghostscript\nInstall pandoc\nbrew install pandoc\n\n\nViewing installed packages\nbrew leaves &gt; brew.txt\nThe content of brew.txt is:\nboost\ncmake\nffmpeg\nfish\ngit\ngraphviz\nilmbase\nimagemagick\npandoc\nr\nrtmpdump\nswig\nvim\nwget\nbrew list --cask &gt; casks.txt\nThe content of casks.txt is:\nanydesk\narduino\naudacity\nfirefox\ngoogle-chrome\ninkscape\nkeycastr\nmactex\nnotion\nobs\npdf-expert\npycharm\nrstudio\nsimplenote\ntexstudio\nvisual-studio-code\nvlc\nzoom\n\n\nInstalling standard Python packages using mamba\nmamba install numpy scipy matplotlib pandas jupyter ipython seaborn rich -c conda-forge\nPeriodically updating all packages mamba update --all -c conda-forge"
  },
  {
    "objectID": "posts/2024-rnn.html",
    "href": "posts/2024-rnn.html",
    "title": "Character-Level RNN for Name Generation",
    "section": "",
    "text": "—author: Nipun Batrabadges: truecategories:- MLdate: ’2024-05-30’title: Character-Level RNN for Name Generationtoc: true—\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange, reduce, repeat\n\n\n!wget https://raw.githubusercontent.com/MASTREX/List-of-Indian-Names/master/2.%20First.txt -O names-indian.txt\n\n--2024-05-30 09:41:48--  https://raw.githubusercontent.com/MASTREX/List-of-Indian-Names/master/2.%20First.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 8752 (8.5K) [text/plain]\nSaving to: ‘names-indian.txt’\n\nnames-indian.txt    100%[===================&gt;]   8.55K  --.-KB/s    in 0s      \n\n2024-05-30 09:41:49 (33.8 MB/s) - ‘names-indian.txt’ saved [8752/8752]\n\n\n\n\nimport pandas as pd\npd.read_csv('names-indian.txt', header=None)\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\nAbhishek\n\n\n1\nAman\n\n\n2\nHarsh\n\n\n3\nAyush\n\n\n4\nAditi\n\n\n...\n...\n\n\n1160\nPrasoon\n\n\n1161\nMadhusudan\n\n\n1162\nPrastuti\n\n\n1163\nRampratap\n\n\n1164\nMadhukar\n\n\n\n\n1165 rows × 1 columns\n\n\n\n\n# convert all names to lowercase\nnames = pd.read_csv('names-indian.txt', header=None)[0].str.lower().values\n\n\nnames\n\narray(['abhishek', 'aman', 'harsh', ..., 'prastuti', 'rampratap',\n       'madhukar'], dtype=object)\n\n\n\n# KDE plot of name lengths\nplt.figure(figsize=(8, 4))\nplt.hist([len(name) for name in names], bins=range(1, 20), density=True, alpha=0.7)\nplt.xlabel('Name length')\nplt.ylabel('Density')\n\nText(0, 0.5, 'Density')\n\n\n\n\n\n\n\n\n\n\n# Attach START and END tokens to each name. Need to add these two to the vocabulary.\nstart_symbol = '^'\nend_symbol = '$'\n\nnames = [start_symbol + name + end_symbol for name in names]\nnames[:5]\n\n['^abhishek$', '^aman$', '^harsh$', '^ayush$', '^aditi$']\n\n\n\n# Find unique characters in the dataset\nvocab = set(''.join(names))\nvocab = sorted(vocab)\nprint(vocab, len(vocab))\n\n['$', '^', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] 28\n\n\n\n# Create a d dimensional lookup table for each character in the vocabulary\nclass CharTable:\n    def __init__(self, vocab):\n        self.vocab = vocab\n        self.char2index = {c: i for i, c in enumerate(vocab)}\n        self.index2char = {i: c for i, c in enumerate(vocab)}\n        self.vocab_size = len(vocab)\n    \n    def encode(self, name):\n        return torch.tensor([self.char2index[c] for c in name])\n    \n    def decode(self, tensor):\n        if type(tensor) == torch.Tensor:\n            tensor = tensor.cpu().numpy()\n        return ''.join([self.index2char[i] for i in tensor])\n\n\nct = CharTable(vocab)\n\n\nct.encode('^'), ct.encode('$'), ct.encode('a'), ct.encode('z'), ct.encode('ab'), ct.encode('za')\n\n(tensor([1]),\n tensor([0]),\n tensor([2]),\n tensor([27]),\n tensor([2, 3]),\n tensor([27,  2]))\n\n\n\nct.decode([1]), ct.decode(torch.tensor([1])), ct.decode(torch.tensor([1, 2, 3]))\n\n('^', '^', '^ab')\n\n\n\n# create embedding layer\nclass CharEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_size):\n        super(CharEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        \n    def forward(self, x):\n        return self.embedding(x)\n\n\nchar_embedding = CharEmbedding(ct.vocab_size, 2)\n\n\ndef plot_2d_embeddings(embedding, vocab):\n    plt.figure(figsize=(4, 4))\n    for i, char in enumerate(vocab):\n        tensor = ct.encode(char)\n        embedding = char_embedding(tensor)\n        plt.scatter(embedding[0, 0].item(), embedding[0, 1].item())\n        plt.text(embedding[0, 0].item(), embedding[0, 1].item(), char)\n    plt.xlabel('Dimension 1')\n    plt.ylabel('Dimension 2')\n\nplot_2d_embeddings(char_embedding, vocab)\n\n\n\n\n\n\n\n\n\nimport torch.nn.functional as F\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(input_size, hidden_size)\n        self.h2h = nn.Linear(hidden_size, hidden_size)\n        self.h2o = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n        output = self.h2o(hidden)\n        output = self.softmax(output)\n        return output, hidden\n\n    def init_hidden(self):\n        return torch.zeros(1, self.hidden_size)\n\n\nrnn = RNN(2, 128, ct.vocab_size)\n\n\n# Predict the next character given the current character\ncurrent_char = \"a\"\nprint(\"Current character:\", current_char)\n# convert to tensor\ncurrent_tensor = ct.encode(current_char)\nprint(\"Curent tensor:\", current_tensor)\n# Look up the embedding\ncurrent_embedding = char_embedding(current_tensor)\nprint(\"Current embedding:\", current_embedding)\n# Initialize the hidden state\nhidden = rnn.init_hidden()\n#print(hidden)\n# Pass the embedding and hidden state through the RNN\noutput, hidden = rnn(current_embedding, hidden)\nprint(output)\n\n# Print the predicted character (most probable)\n_, predicted_index = output.topk(1)\n# flatten the tensor\npredicted_index = predicted_index.squeeze().item()\n# convert to character\npredicted_char = ct.decode([predicted_index])\nprint(\"Predicted character:\", predicted_char)\n\nCurrent character: a\nCurent tensor: tensor([2])\nCurrent embedding: tensor([[-1.4545,  0.9880]], grad_fn=&lt;EmbeddingBackward0&gt;)\ntensor([[-2.5902, -3.3533, -3.8653, -3.9548, -3.5940, -2.8801, -3.4821, -3.0470,\n         -3.5943, -3.5595, -3.6062, -3.5047, -3.6877, -3.3012, -3.7079, -4.4289,\n         -2.9308, -3.6200, -3.3797, -3.7172, -2.8883, -2.6247, -3.7265, -3.3239,\n         -3.7247, -2.9247, -3.4027, -3.2497]], grad_fn=&lt;LogSoftmaxBackward0&gt;)\nPredicted character: $\n\n\n\n# Create a function to generate a word (sequence of characters) given a \n# starting sequence of characters (stops when END token is predicted) \n# or if the length of the generated word exceeds a certain limit of 10 characters\ndef create_name(start_string, rnn, char_embedding, ct):\n    with torch.no_grad():\n        # start with the last character in the start_string\n        current_char = start_string[-1]\n        current_tensor = ct.encode(current_char)\n        current_embedding = char_embedding(current_tensor)\n        hidden = rnn.init_hidden()\n        name = start_string\n        while current_char != end_symbol and len(name) &lt; 10:\n            output, hidden = rnn(current_embedding, hidden)\n            # Find the next character by sampling from the output distribution\n            predicted_index = torch.multinomial(torch.exp(output), 1).item()\n            current_char = ct.decode([predicted_index])\n            _, predicted_index = output.topk(1)\n            predicted_index = predicted_index.squeeze().item()\n            current_char = ct.decode([predicted_index])\n            name += current_char\n            current_tensor = ct.encode(current_char)\n            current_embedding = char_embedding(current_tensor)\n        return name\n    \n\n\ncreate_name('^a', rnn, char_embedding, ct)\n\n'^anm$'\n\n\n\ncreate_name('^c', rnn, char_embedding, ct)\n\n'^c$'\n\n\n\n# Generate dataset for training\ndef generate_data(names, ct):\n    X = []\n    Y = []\n    for name in names:\n        for i in range(1, len(name)):\n            X.append(name[i-1])\n            Y.append(name[i])\n    X = [ct.encode(x) for x in X]\n    Y = [ct.encode(y) for y in Y]\n    return X, Y\n\nX, Y = generate_data(names, ct)\n\n\nX[0], Y[0], X[1], Y[1], X[2], Y[2]\n\n(tensor([1]), tensor([2]))\n\n\n\nprint(names[0])\nprint(ct.decode(X[0]), ct.decode(Y[0]))\nprint(ct.decode(X[1]), ct.decode(Y[1]))\nprint(ct.decode(X[2]), ct.decode(Y[2]))\n\n^abhishek$\n^ a\na b\nb h\n\n\n\n# Training loop\nnum_epochs = 12\nlearning_rate = 3e-4\nembedding_size = 8\nhidden_size = 32\nrnn = RNN(embedding_size, hidden_size, ct.vocab_size)\nembedding = CharEmbedding(ct.vocab_size, embedding_size)\n\noptimizer = torch.optim.Adam(list(rnn.parameters()) + list(embedding.parameters()), lr=learning_rate)\n\ncriterion = nn.NLLLoss()\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for i in range(len(X)):\n        optimizer.zero_grad()\n        hidden = rnn.init_hidden()\n        input_tensor = X[i]\n        target_tensor = Y[i].squeeze()\n        input_embedding = embedding(input_tensor)\n        target_tensor = target_tensor.unsqueeze(0)\n        output, hidden = rnn(input_embedding, hidden)\n        \n        predicted_next_char = output.argmax().item()\n        \n        loss = criterion(output, target_tensor)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        \n        #print(i, loss.item())\n    if (epoch+1) % 1 == 0:\n        print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {total_loss/len(X)}')\n\nEpoch: 1/12, Loss: 2.684675631081001\nEpoch: 2/12, Loss: 2.4274482760898484\nEpoch: 3/12, Loss: 2.3604175581492934\nEpoch: 4/12, Loss: 2.3314669918697972\nEpoch: 5/12, Loss: 2.3155676853116023\nEpoch: 6/12, Loss: 2.3054449003057\nEpoch: 7/12, Loss: 2.2983417296262845\nEpoch: 8/12, Loss: 2.2929774504282614\nEpoch: 9/12, Loss: 2.2887099773854604\nEpoch: 10/12, Loss: 2.2851798680263626\nEpoch: 11/12, Loss: 2.2821793051528485\nEpoch: 12/12, Loss: 2.2795761335450453\n\n\n\nplot_2d_embeddings(embedding, vocab)\n\n\n\n\n\n\n\n\n\ncreate_name('^a', rnn, embedding, ct)\n\n'^an$'\n\n\n\ncreate_name('^b', rnn, embedding, ct)\n\n'^bhan$'\n\n\n\ncreate_name('^c', rnn, embedding, ct)\n\n'^chan$'\n\n\n\ncreate_name('^d', rnn, embedding, ct)\n\n'^dan$'\n\n\n\ncreate_name('^n', rnn, embedding, ct)\n\n'^n$'"
  },
  {
    "objectID": "posts/vscode-tips/index.html",
    "href": "posts/vscode-tips/index.html",
    "title": "VSCode Settings and Tips",
    "section": "",
    "text": "Most used keyboard shortcuts\n\n\n\nShortcut\nAction\n\n\n\n\nCmd + Shift + P\nOpen command palette\n\n\nCtrl + `\nToggle terminal\n\n\nCmd + B\nToggle sidebar\n\n\nCmd + Ctrl + F\nToggle full screen"
  },
  {
    "objectID": "posts/residual-torch.html",
    "href": "posts/residual-torch.html",
    "title": "Residual Connections in PyTorch",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader, TensorDataset\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\n# Regression dataset from sklearn diabetes dataset\n\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_diabetes(return_X_y=True)\n\n# Train, validation, test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Convert to torch tensors\nX_train = torch.from_numpy(X_train).float()\nX_val = torch.from_numpy(X_val).float()\nX_test = torch.from_numpy(X_test).float()\n\ny_train = torch.from_numpy(y_train).float().view(-1, 1)\ny_val = torch.from_numpy(y_val).float().view(-1, 1)\ny_test = torch.from_numpy(y_test).float().view(-1, 1)\n\n# Create dataloaders\ntrain_loader = DataLoader(list(zip(X_train, y_train)), batch_size=32, shuffle=True)\nval_loader = DataLoader(list(zip(X_val, y_val)), batch_size=32, shuffle=False)\ntest_loader = DataLoader(list(zip(X_test, y_test)), batch_size=32, shuffle=False)\n\n\n# Model 1: Linear regression\n\nclass LinearRegression(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.linear = nn.Linear(input_dim, 1)\n        \n    def forward(self, x):\n        return self.linear(x)\n\n\ndef train(model, optimizer, criterion = nn.MSELoss(), train_loader=None, val_loader=None, epochs=1000):\n    train_losses = []\n    val_losses = []\n    for e in range(epochs):\n        train_loss = 0\n        val_loss = 0\n        model.train()\n        for batch_x, batch_y in train_loader:\n            optimizer.zero_grad()\n            output = model(batch_x)\n            loss = criterion(output, batch_y)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * batch_x.size(0)\n        train_loss /= len(train_loader.dataset)\n        train_losses.append(train_loss)\n\n        model.eval()\n        with torch.no_grad():\n            for batch_x, batch_y in val_loader:\n                output = model(batch_x)\n                loss = criterion(output, batch_y)\n                val_loss += loss.item() * batch_x.size(0)\n            val_loss /= len(val_loader.dataset)\n            val_losses.append(val_loss)\n\n        if (e+1) % 100 == 0:\n            print(f'Epoch {e+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n    \n    return train_losses, val_losses\n\n\ncriterion = nn.MSELoss()\n\nmodel = LinearRegression(X_train.shape[1])\noptimizer = optim.Adam(model.parameters(), lr=0.1)\n\ntrain_losses, val_losses = train(model, optimizer, criterion, train_loader, val_loader, epochs=1000)\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\n\nEpoch 100/1000, Train Loss: 10315.2895, Validation Loss: 12724.1896\nEpoch 200/1000, Train Loss: 4804.3067, Validation Loss: 5319.9323\nEpoch 300/1000, Train Loss: 3715.5066, Validation Loss: 3480.5550\nEpoch 400/1000, Train Loss: 3388.3811, Validation Loss: 3083.5462\nEpoch 500/1000, Train Loss: 3194.2672, Validation Loss: 2970.7406\nEpoch 600/1000, Train Loss: 3075.9221, Validation Loss: 2929.4660\nEpoch 700/1000, Train Loss: 3007.6152, Validation Loss: 2911.9031\nEpoch 800/1000, Train Loss: 2970.0181, Validation Loss: 2906.4726\nEpoch 900/1000, Train Loss: 2948.9850, Validation Loss: 2904.5393\nEpoch 1000/1000, Train Loss: 2937.7591, Validation Loss: 2901.6748\n\n\n\n\n\n\n\n\n\n\n# RMSE on test set\n\ndef rmse(model, test_loader):\n    model.eval()\n    with torch.no_grad():\n        test_loss = 0\n        for batch_x, batch_y in test_loader:\n            output = model(batch_x)\n            loss = criterion(output, batch_y)\n            test_loss += loss.item() * batch_x.size(0)\n        test_loss /= len(test_loader.dataset)\n    return np.sqrt(test_loss)\n\n\nerrors = {}\n\nerrors[\"linreg\"] = rmse(model, test_loader)\n\n\n# Model 2: MLP\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 32)\n        self.fc2 = nn.Linear(32, 16)\n        self.fc3 = nn.Linear(16, 10)\n        self.fc4 = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        return self.fc4(x)\n\n\nmlp = MLP(X_train.shape[1])\noptimizer = optim.Adam(mlp.parameters(), lr=0.001)\n\ntrain_losses, val_losses = train(mlp, optimizer, criterion, train_loader, val_loader, epochs=1500)\n\nEpoch 100/1500, Train Loss: 3663.8245, Validation Loss: 3086.0981\nEpoch 200/1500, Train Loss: 3077.9123, Validation Loss: 2912.6680\nEpoch 300/1500, Train Loss: 2952.4684, Validation Loss: 2906.0980\nEpoch 400/1500, Train Loss: 2920.8557, Validation Loss: 2916.5231\nEpoch 500/1500, Train Loss: 2908.5543, Validation Loss: 2903.3417\nEpoch 600/1500, Train Loss: 2898.7857, Validation Loss: 2920.6625\nEpoch 700/1500, Train Loss: 2888.3550, Validation Loss: 2886.4415\nEpoch 800/1500, Train Loss: 2874.1253, Validation Loss: 2905.2355\nEpoch 900/1500, Train Loss: 2866.0193, Validation Loss: 2915.6193\nEpoch 1000/1500, Train Loss: 2858.1495, Validation Loss: 2914.3357\nEpoch 1100/1500, Train Loss: 2849.0639, Validation Loss: 2919.2359\nEpoch 1200/1500, Train Loss: 2835.6841, Validation Loss: 2927.5912\nEpoch 1300/1500, Train Loss: 2814.3485, Validation Loss: 2942.1452\nEpoch 1400/1500, Train Loss: 2802.6443, Validation Loss: 2928.9871\nEpoch 1500/1500, Train Loss: 2789.4206, Validation Loss: 2943.3993\n\n\n\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\n\n\n\n\n\n\n\n\n\nerrors[\"MLP\"]= rmse(mlp, test_loader)\nerrors\n\n{'linreg': 53.8179193310273, 'MLP': 51.32108141562702}\n\n\n\n# Model 3: Residual MLP\n\n# Adding a skip connection from input to output\n\nclass ResMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 32)\n        self.fc2 = nn.Linear(32 + input_dim, 16)\n        self.fc3 = nn.Linear(16 + input_dim, 10)\n        self.fc4 = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        x_inp = x\n        x = F.relu(self.fc1(x)) \n        # Concatenate input to output of first layer\n        x = torch.cat((x, x_inp), dim=1)\n        x = F.relu(self.fc2(x))\n\n        # Concatenate input to output of second layer\n        x = torch.cat((x, x_inp), dim=1)\n        x = F.relu(self.fc3(x))\n\n        return self.fc4(x)\n\n\nres_mlp = ResMLP(X_train.shape[1])\nres_mlp(X_train).shape\n\ntorch.Size([282, 1])\n\n\n\nres_mlp = ResMLP(X_train.shape[1])\noptimizer = optim.Adam(res_mlp.parameters(), lr=0.001)\n\ntrain_losses, val_losses = train(res_mlp, optimizer, criterion, train_loader, val_loader, epochs=1500)\n\nEpoch 100/1500, Train Loss: 3298.6719, Validation Loss: 2937.0046\nEpoch 200/1500, Train Loss: 2958.9598, Validation Loss: 2908.0027\nEpoch 300/1500, Train Loss: 2933.4946, Validation Loss: 2915.9148\nEpoch 400/1500, Train Loss: 2924.1275, Validation Loss: 2885.2503\nEpoch 500/1500, Train Loss: 2918.3424, Validation Loss: 2883.3218\nEpoch 600/1500, Train Loss: 2913.7633, Validation Loss: 2891.1281\nEpoch 700/1500, Train Loss: 2909.4774, Validation Loss: 2875.5787\nEpoch 800/1500, Train Loss: 2906.8811, Validation Loss: 2885.1002\nEpoch 900/1500, Train Loss: 2896.1299, Validation Loss: 2894.3401\nEpoch 1000/1500, Train Loss: 2881.0517, Validation Loss: 2883.1614\nEpoch 1100/1500, Train Loss: 2859.3730, Validation Loss: 2900.0346\nEpoch 1200/1500, Train Loss: 2843.1591, Validation Loss: 2892.0867\nEpoch 1300/1500, Train Loss: 2825.5589, Validation Loss: 2935.1988\nEpoch 1400/1500, Train Loss: 2807.9256, Validation Loss: 2898.6540\nEpoch 1500/1500, Train Loss: 2798.3861, Validation Loss: 2901.6544\n\n\n\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\n\n\n\n\n\n\n\n\n\nerrors[\"resnet\"] = rmse(res_mlp, test_loader)\nerrors\n\n{'linreg': 53.8179193310273,\n 'MLP': 51.32108141562702,\n 'resnet': 51.87944353261233}\n\n\n\n# Adding LR scheduler\ndef train(model, optimizer, criterion=nn.MSELoss(), epochs=1000, lr_scheduler=None):\n    train_losses = []\n    val_losses = []\n\n    for e in range(epochs):\n        # Training loop\n        train_loss = 0\n        model.train()  # set the model to training mode\n        for X_train_batch, y_train_batch in train_loader:\n            optimizer.zero_grad()\n            y_train_pred = model(X_train_batch)\n            loss = criterion(y_train_pred, y_train_batch)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        train_losses.append(train_loss / len(train_loader))\n\n        # Validation loop\n        val_loss = 0\n        model.eval()  # set the model to evaluation mode\n        with torch.no_grad():\n            for X_val_batch, y_val_batch in val_loader:\n                y_val_pred = model(X_val_batch)\n                loss = criterion(y_val_pred, y_val_batch)\n                val_loss += loss.item()\n            val_losses.append(val_loss / len(val_loader))\n\n        # Update learning rate\n        if lr_scheduler is not None:\n            lr_scheduler.step(val_losses[-1])\n\n        # Print progress\n        if e % 100 == 0:\n            print(f\"Epoch {e}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n\n    return train_losses, val_losses\n\n\n# Use a LRPlateau scheduler to reduce the learning rate when the validation loss stops improving\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nres_mlp = ResMLP(X_train.shape[1])\n\noptimizer = optim.Adam(res_mlp.parameters(), lr=0.01)\n\nlr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, verbose=True)\n\ntrain_losses, val_losses = train(res_mlp, optimizer, criterion, epochs=1500, lr_scheduler=lr_scheduler)\n\nEpoch 0, Train Loss: 28639.6855, Val Loss: 33158.0742\nEpoch 100, Train Loss: 2911.0527, Val Loss: 2420.7449\nEpoch 00141: reducing learning rate of group 0 to 5.0000e-03.\nEpoch 00192: reducing learning rate of group 0 to 2.5000e-03.\nEpoch 200, Train Loss: 2815.0154, Val Loss: 2422.1171\nEpoch 00243: reducing learning rate of group 0 to 1.2500e-03.\nEpoch 00294: reducing learning rate of group 0 to 6.2500e-04.\nEpoch 300, Train Loss: 2783.4652, Val Loss: 2429.3894\nEpoch 00345: reducing learning rate of group 0 to 3.1250e-04.\nEpoch 00396: reducing learning rate of group 0 to 1.5625e-04.\nEpoch 400, Train Loss: 2794.7555, Val Loss: 2432.0923\nEpoch 00447: reducing learning rate of group 0 to 7.8125e-05.\nEpoch 00498: reducing learning rate of group 0 to 3.9063e-05.\nEpoch 500, Train Loss: 2799.6670, Val Loss: 2432.4159\nEpoch 00549: reducing learning rate of group 0 to 1.9531e-05.\nEpoch 00600: reducing learning rate of group 0 to 9.7656e-06.\nEpoch 600, Train Loss: 2773.7532, Val Loss: 2431.9507\nEpoch 00651: reducing learning rate of group 0 to 4.8828e-06.\nEpoch 700, Train Loss: 2789.9358, Val Loss: 2431.6210\nEpoch 00702: reducing learning rate of group 0 to 2.4414e-06.\nEpoch 00753: reducing learning rate of group 0 to 1.2207e-06.\nEpoch 800, Train Loss: 2809.1560, Val Loss: 2431.6233\nEpoch 00804: reducing learning rate of group 0 to 6.1035e-07.\nEpoch 00855: reducing learning rate of group 0 to 3.0518e-07.\nEpoch 900, Train Loss: 2825.4572, Val Loss: 2431.6108\nEpoch 00906: reducing learning rate of group 0 to 1.5259e-07.\nEpoch 00957: reducing learning rate of group 0 to 7.6294e-08.\nEpoch 1000, Train Loss: 2780.1241, Val Loss: 2431.6187\nEpoch 01008: reducing learning rate of group 0 to 3.8147e-08.\nEpoch 01059: reducing learning rate of group 0 to 1.9073e-08.\nEpoch 1100, Train Loss: 2789.0557, Val Loss: 2431.6189\nEpoch 1200, Train Loss: 2816.7811, Val Loss: 2431.6187\nEpoch 1300, Train Loss: 2810.0122, Val Loss: 2431.6189\nEpoch 1400, Train Loss: 2782.1095, Val Loss: 2431.6191\n\n\n\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\n\n\n\n\n\n\n\n\n\nerrors[\"resnet-lr\"] = rmse(res_mlp, test_loader)\n\n\nimport pandas as pd\npd.Series(errors).plot.barh()"
  },
  {
    "objectID": "posts/sympy.html",
    "href": "posts/sympy.html",
    "title": "Some useful tidibts in sympy",
    "section": "",
    "text": "from sympy import *\ninit_printing(use_unicode=True)\n\n\nn, k = symbols(\"n k\")\n\n\nexpr = Limit((1 + k/n)**n, n, oo)\n\n\nexpr\n\n\\(\\displaystyle \\lim_{n \\to \\infty} \\left(\\frac{k}{n} + 1\\right)^{n}\\)\n\n\n\nexpr.doit()\n\n\\(\\displaystyle e^{k}\\)\n\n\n\nx, mu, sigma = symbols(\"x \\mu \\sigma\")\n\n\nnorm  = exp(-(x-mu)**2/(2*sigma**2))\n\n\nnorm\n\n\\(\\displaystyle e^{- \\frac{\\left(- \\mu + x\\right)^{2}}{2 \\sigma^{2}}}\\)\n\n\n\nexpr = integrate(norm, x)\n\n\nnorm\n\n\\(\\displaystyle e^{- \\frac{\\left(- \\mu + x\\right)^{2}}{2 \\sigma^{2}}}\\)\n\n\n\nsimplify(expr)\n\n\\(\\displaystyle - \\frac{\\sqrt{2} \\sqrt{\\pi} \\sigma \\operatorname{erf}{\\left(\\frac{\\sqrt{2} \\left(\\mu - x\\right)}{2 \\sigma} \\right)}}{2}\\)"
  },
  {
    "objectID": "posts/2017-08-13-mf-autograd-adagrad.html",
    "href": "posts/2017-08-13-mf-autograd-adagrad.html",
    "title": "Adagrad based matrix factorization",
    "section": "",
    "text": "In a previous post, we had seen how to perfom non-negative matrix factorization (NNMF) using Tensorflow. In another previous post, I had shown how to use Adagrad for linear regression. This current post can be considered an extension of the linear regression using Adagrad post. Just for the purpose of education, I’ll poorly initialise the estimate of one of the decomposed matrix, to see how well Adagrad can adjust weights!\n\nCustomary imports\n\nimport autograd.numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib import gridspec\n\n%matplotlib inline\n\n\n\nCreating the matrix to be decomposed\n\nA = np.array([[3, 4, 5, 2],\n                   [4, 4, 3, 3],\n                   [5, 5, 4, 3]], dtype=np.float32).T\n\n\n\nMasking one entry\n\nA[0, 0] = np.NAN\n\n\nA\n\narray([[ nan,   4.,   5.],\n       [  4.,   4.,   5.],\n       [  5.,   3.,   4.],\n       [  2.,   3.,   3.]], dtype=float32)\n\n\n\n\nDefining the cost function\n\ndef cost(param_list):\n    W, H = param_list\n    pred = np.dot(W, H)\n    mask = ~np.isnan(A)\n    return np.sqrt(((pred - A)[mask].flatten() ** 2).mean(axis=None))\n\n\n\nDecomposition params\n\nrank = 2\nlearning_rate=0.01\nn_steps = 10000\n\n\n\nAdagrad routine\n\ndef adagrad_gd(param_init, cost, niter=5, lr=1e-2, eps=1e-8, random_seed=0):\n    \"\"\"\n    param_init: List of initial values of parameters\n    cost: cost function\n    niter: Number of iterations to run\n    lr: Learning rate\n    eps: Fudge factor, to avoid division by zero\n    \"\"\"\n    from copy import deepcopy\n    from autograd import grad\n    # Fixing the random_seed\n    np.random.seed(random_seed)\n    \n    # Function to compute the gradient of the cost function\n    grad_cost = grad(cost)\n    params = deepcopy(param_init)\n    param_array, grad_array, lr_array, cost_array = [params], [], [[lr*np.ones_like(_) for _ in params]], [cost(params)]\n    # Initialising sum of squares of gradients for each param as 0\n    sum_squares_gradients = [np.zeros_like(param) for param in params]\n    for i in range(niter):\n        out_params = []\n        gradients = grad_cost(params)\n        # At each iteration, we add the square of the gradients to `sum_squares_gradients`\n        sum_squares_gradients= [eps + sum_prev + np.square(g) for sum_prev, g in zip(sum_squares_gradients, gradients)]\n        # Adapted learning rate for parameter list\n        lrs = [np.divide(lr, np.sqrt(sg)) for sg in sum_squares_gradients]\n        # Paramter update\n        params = [param-(adapted_lr*grad_param) for param, adapted_lr, grad_param in zip(params, lrs, gradients)]\n        param_array.append(params)\n        lr_array.append(lrs)\n        grad_array.append(gradients)\n        cost_array.append(cost(params))\n        \n    return params, param_array, grad_array, lr_array, cost_array\n\n\n\nRunning Adagrad\n\nFixing initial parameters\nI’m poorly initialising H here to see how the learning rates vary for W and H.\n\nnp.random.seed(0)\nshape = A.shape\nH_init =  -5*np.abs(np.random.randn(rank, shape[1]))\nW_init =  np.abs(np.random.randn(shape[0], rank))\nparam_init = [W_init, H_init]\n\n\nH_init\n\narray([[ -8.82026173,  -2.00078604,  -4.89368992],\n       [-11.204466  ,  -9.33778995,  -4.8863894 ]])\n\n\n\nW_init\n\narray([[ 0.95008842,  0.15135721],\n       [ 0.10321885,  0.4105985 ],\n       [ 0.14404357,  1.45427351],\n       [ 0.76103773,  0.12167502]])\n\n\n\n# Cost for initial set of parameters\ncost(param_init)\n\n11.651268820608442\n\n\n\nlr = 0.1\neps=1e-8\nniter=2000\nada_params, ada_param_array, ada_grad_array, ada_lr_array, ada_cost_array = adagrad_gd(param_init, cost, niter=niter, lr=lr, eps=eps)\n\n\n\nCost v/s # iterations\n\npd.Series(ada_cost_array).plot(logy=True)\nplt.ylabel(\"Cost (log scale)\")\nplt.xlabel(\"# Iterations\")\n\n\n\n\n\n\n\n\n\n\nFinal set of parameters and recovered matrix\n\nW_final, H_final = ada_params\npred = np.dot(W_final, H_final)\npred_df = pd.DataFrame(pred).round()\npred_df\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n5.0\n4.0\n5.0\n\n\n1\n4.0\n4.0\n5.0\n\n\n2\n5.0\n3.0\n4.0\n\n\n3\n2.0\n3.0\n3.0\n\n\n\n\n\n\n\n\n\nLearning rate evolution for W\n\nW_lrs = np.array(ada_lr_array)[:, 0]\n\n\nW_lrs = np.array(ada_lr_array)[:, 0]\nfig= plt.figure(figsize=(4, 2))\ngs = gridspec.GridSpec(1, 2, width_ratios=[8, 1]) \nax = plt.subplot(gs[0]),  plt.subplot(gs[1])\nmax_W, min_W = np.max([np.max(x) for x in W_lrs]), np.min([np.min(x) for x in W_lrs])\n\ndef update(iteration):\n    ax[0].cla()\n    ax[1].cla()\n    sns.heatmap(W_lrs[iteration], vmin=min_W, vmax=max_W, ax=ax[0], annot=True, fmt='.4f', cbar_ax=ax[1])\n    ax[0].set_title(\"Learning rate update for W\\nIteration: {}\".format(iteration))\n    fig.tight_layout()\n\nanim = FuncAnimation(fig, update, frames=np.arange(0, 200, 10), interval=500)\nanim.save('W_update.gif', dpi=80, writer='imagemagick')\nplt.close()\n\n\n\n\nLearning rate evolution for H\n\nH_lrs = np.array(ada_lr_array)[:, 1]\n\nfig= plt.figure(figsize=(4, 2))\ngs = gridspec.GridSpec(1, 2, width_ratios=[10, 1]) \nax = plt.subplot(gs[0]),  plt.subplot(gs[1])\nmax_H, min_H = np.max([np.max(x) for x in H_lrs]), np.min([np.min(x) for x in H_lrs])\n\ndef update(iteration):\n    ax[0].cla()\n    ax[1].cla()\n    sns.heatmap(H_lrs[iteration], vmin=min_H, vmax=max_H, ax=ax[0], annot=True, fmt='.2f', cbar_ax=ax[1])\n    ax[0].set_title(\"Learning rate update for H\\nIteration: {}\".format(iteration))\n    fig.tight_layout()\n\nanim = FuncAnimation(fig, update, frames=np.arange(0, 200, 10), interval=500)\nanim.save('H_update.gif', dpi=80, writer='imagemagick')\nplt.close()"
  },
  {
    "objectID": "posts/2013-04-01-download_weather.html",
    "href": "posts/2013-04-01-download_weather.html",
    "title": "Downloading weather data",
    "section": "",
    "text": "In this notebook, I’ll write a small illustration on downloading historical weather data using forceast.io. I’ll also illustrate handling timezone issues when using such time series data. I am going to use python-forecastio, which is a Python wrapper around forecast.io service. I’ll be downloading hourly weather data for Austin, Texas.\n\nimport datetime\nimport pandas as pd\nimport forecastio\nimport getpass\n\n\n# Enter your API here\napi_key = getpass.getpass()\n\n········\n\n\n\nlen(api_key)\n\n32\n\n\nAustin’s Latitude and longitude\n\nlat = 30.25\nlng = -97.25\n\nLet us see the forecast for 1 Jan 2015\n\ndate = datetime.datetime(2015,1,1)\n\n\nforecast = forecastio.load_forecast(api_key, lat, lng, time=date, units=\"us\")\n\n\nforecast\n\n&lt;forecastio.models.Forecast at 0x10319ce50&gt;\n\n\n\nhourly = forecast.hourly()\n\n\nhourly.data\n\n[&lt;forecastio.models.ForecastioDataPoint at 0x1068643d0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x106864bd0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x106864ad0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x106864cd0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x106864fd0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x106864d10&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x100734e10&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1061e3450&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1061e3350&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3250&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3110&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3150&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3190&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b31d0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3210&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3fd0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3dd0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3e10&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3e50&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068b3f50&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068c84d0&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068c8390&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068c8510&gt;,\n &lt;forecastio.models.ForecastioDataPoint at 0x1068c8550&gt;]\n\n\nExtracting data for a single hour.\n\nhourly.data[0].d\n\n{u'apparentTemperature': 32.57,\n u'dewPoint': 33.39,\n u'humidity': 0.79,\n u'icon': u'clear-night',\n u'precipIntensity': 0,\n u'precipProbability': 0,\n u'pressure': 1032.61,\n u'summary': u'Clear',\n u'temperature': 39.46,\n u'time': 1420005600,\n u'visibility': 10,\n u'windBearing': 21,\n u'windSpeed': 10.95}\n\n\nLet us say that we want to use the temperature and humidity only.\n\nattributes = [\"temperature\", \"humidity\"]\n\n\ntimes = []\ndata = {}\nfor attr in attributes:\n    data[attr] = []\n\nNow, let us download hourly data for 30 days staring January 1 this year.\n\nstart = datetime.datetime(2015, 1, 1)\nfor offset in range(1, 60):\n    forecast = forecastio.load_forecast(api_key, lat, lng, time=start+datetime.timedelta(offset), units=\"us\")\n    h = forecast.hourly()\n    d = h.data\n    for p in d:\n        times.append(p.time)\n        for attr in attributes:\n            data[attr].append(p.d[attr])\n\nNow, let us create a Pandas data frame for this time series data.\n\ndf = pd.DataFrame(data, index=times)\n\n\ndf.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\n\n\n\n\n2015-01-01 11:30:00\n0.73\n38.74\n\n\n2015-01-01 12:30:00\n0.74\n38.56\n\n\n2015-01-01 13:30:00\n0.75\n38.56\n\n\n2015-01-01 14:30:00\n0.79\n37.97\n\n\n2015-01-01 15:30:00\n0.80\n37.78\n\n\n\n\n\n\n\nNow, we need to fix the timezone.\n\ndf = df.tz_localize(\"Asia/Kolkata\").tz_convert(\"US/Central\")\n\n\ndf.head()\n\n\n\n\n\n\n\nhumidity\ntemperature\n\n\n\n\n2015-01-01 00:00:00-06:00\n0.73\n38.74\n\n\n2015-01-01 01:00:00-06:00\n0.74\n38.56\n\n\n2015-01-01 02:00:00-06:00\n0.75\n38.56\n\n\n2015-01-01 03:00:00-06:00\n0.79\n37.97\n\n\n2015-01-01 04:00:00-06:00\n0.80\n37.78\n\n\n\n\n\n\n\nI’ll now export this file to a CSV to use it for following demonstrations on aggregations on time series.\n\ndf.to_csv(\"weather.csv\")\n\nA quick validation of our downloaded data.\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\ndf.plot(subplots=True);"
  },
  {
    "objectID": "posts/2025-06-30-slack-tips.html",
    "href": "posts/2025-06-30-slack-tips.html",
    "title": "Slack Tips for Better Team Management",
    "section": "",
    "text": "Here are some useful Slack tips to improve your team communication and channel management."
  },
  {
    "objectID": "posts/2025-06-30-slack-tips.html#adding-members-from-source-to-destination-channel",
    "href": "posts/2025-06-30-slack-tips.html#adding-members-from-source-to-destination-channel",
    "title": "Slack Tips for Better Team Management",
    "section": "Adding Members from Source to Destination Channel",
    "text": "Adding Members from Source to Destination Channel\nWhen you need to move or copy members from one channel to another, here’s a quick way to do it:\n\nIn the source channel: Use /who command to get a list of all members\nCopy the member list from the output\nIn the destination channel: Use /invite followed by pasting the member list\n\nThis saves you from manually typing each username and ensures you don’t miss anyone when setting up new channels or reorganizing your workspace.\nExample:\n# In source channel\n/who\n\n# Copy the usernames from the output, then in destination channel\n/invite @user1 @user2 @user3 @user4\nThis tip is especially useful when: - Creating project-specific channels from larger teams - Setting up temporary channels for events or sprints - Reorganizing team structures - Onboarding new team members to multiple relevant channels\nMore Slack tips coming soon…"
  },
  {
    "objectID": "posts/2022-01-29-kl-divergence.html",
    "href": "posts/2022-01-29-kl-divergence.html",
    "title": "Understanding KL-Divergence",
    "section": "",
    "text": "Goals:\n\nG1: Given probability distributions \\(p\\) and \\(q\\), find the divergence (measure of similarity) between them\nLet us first look at G1. Look at the illustration below. We have a normal distribution \\(p\\) and two other normal distributions \\(q_1\\) and \\(q_2\\). Which of \\(q_1\\) and \\(q_2\\), would we consider closer to \\(p\\)? \\(q_2\\), right?\n\nTo understand the notion of similarity, we use a metric called the KL-divergence given as \\(D_{KL}(a || b)\\) where \\(a\\) and \\(b\\) are the two distributions.\nFor G1, we can say \\(q_2\\) is closer to \\(p\\) compared to \\(q_1\\) as:\n\\(D_{KL}(q_2 || p) \\lt D_{KL}(q_1 || p)\\)\nFor the above example, we have the values as \\(D_{KL}(q_2|| p) = 0.07\\) and \\(D_{KL}(q_1|| p)= 0.35\\)\n\n\nG2: assuming \\(p\\) to be fixed, can we find optimum parameters of \\(q\\) to make it as close as possible to \\(p\\)\nThe following GIF shows the process of finding the optimum set of parameters for a normal distribution \\(q\\) so that it becomes as close as possible to \\(p\\). This is equivalent of minimizing \\(D_{KL}(q || p)\\)\n\nThe following GIF shows the above but for a two-dimensional distribution.\n\n\n\nG3: finding the “distance” between two distributions of different families\nThe below image shows the KL-divergence between distribution 1 (mixture of Gaussians) and distribution 2 (Gaussian)\n\n\n\nG4: optimizing the “distance” between two distributions of different families\nThe below GIF shows the optimization of the KL-divergence between distribution 1 (mixture of Gaussians) and distribution 2 (Gaussian)\n\n\n\nG5: Approximating the KL-divergence\n\n\nG6: Implementing variational inference for linear regression\n\n\n\nBasic Imports\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport pandas as pd\n\ntfd = tfp.distributions\ntfl = tfp.layers\ntfb = tfp.bijectors\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import Callback\n\nsns.reset_defaults()\nsns.set_context(context=\"talk\", font_scale=1)\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n\n\nCreating distributions\n\nCreating \\(p\\sim\\mathcal{N}(1.00, 4.00)\\)\n\np = tfd.Normal(1, 4)\n\n2022-02-04 14:55:14.596076: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n\nz_values = tf.linspace(-5, 15, 200)\nz_values = tf.cast(z_values, tf.float32)\nprob_values_p = p.prob(z_values)\nplt.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\")\nsns.despine()\nplt.legend()\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\n\n\n\n\n\n\n\n\n\n\nCreating \\(q\\sim\\mathcal{N}(loc, scale)\\)\n\ndef create_q(loc, scale):\n    return tfd.Normal(loc, scale)\n\n\n\nGenerating a few qs for different location and scale value\n\nq = {}\nq[(0, 1)] = create_q(0.0, 1.0)\n\nfor loc in [0, 1]:\n    for scale in [1, 2]:\n        q[(loc, scale)] = create_q(float(loc), float(scale))\n\n\nplt.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\", lw=3)\nplt.plot(\n    z_values,\n    create_q(0.0, 2.0).prob(z_values),\n    label=r\"$q_1\\sim\\mathcal{N}(0.00, 2.00)$\",\n    lw=2,\n    linestyle=\"--\",\n)\nplt.plot(\n    z_values,\n    create_q(1.0, 3.0).prob(z_values),\n    label=r\"$q_2\\sim\\mathcal{N}(1.00, 3.00)$\",\n    lw=2,\n    linestyle=\"-.\",\n)\n\nplt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\nsns.despine()\nplt.tight_layout()\nplt.savefig(\n    \"dkl.png\",\n    dpi=150,\n)\n\n\n\n\n\n\n\n\n\n#### Computing KL-divergence\n\nq_0_2_dkl = tfd.kl_divergence(create_q(0.0, 2.0), p)\nq_1_3_dkl = tfd.kl_divergence(create_q(1.0, 3.0), p)\n\nprint(f\"D_KL (q(0, 2)||p) = {q_0_2_dkl:0.2f}\")\nprint(f\"D_KL (q(1, 3)||p) = {q_1_3_dkl:0.2f}\")\n\nD_KL (q(0, 2)||p) = 0.35\nD_KL (q(1, 3)||p) = 0.07\n\n\nAs mentioned earlier, clearly, \\(q_2\\sim\\mathcal{N}(1.00, 3.00)\\) seems closer to \\(p\\)\n\n\n\nOptimizing the KL-divergence between q and p\nWe could create a grid of (loc, scale) pairs and find the best, as shown below.\n\nplt.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\", lw=5)\n\n\nfor loc in [0, 1]:\n    for scale in [1, 2]:\n        q_d = q[(loc, scale)]\n        kl_d = tfd.kl_divergence(q[(loc, scale)], p)\n        plt.plot(\n            z_values,\n            q_d.prob(z_values),\n            label=rf\"$q\\sim\\mathcal{{N}}({loc}, {scale})$\"\n            + \"\\n\"\n            + rf\"$D_{{KL}}(q||p)$ = {kl_d:0.2f}\",\n        )\nplt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\nsns.despine()\n\n\n\n\n\n\n\n\nOr, we could use continuous optimization to find the best loc and scale parameters for q.\n\nto_train_q = tfd.Normal(\n    loc=tf.Variable(-1.0, name=\"loc\"),\n    scale=tfp.util.TransformedVariable(1.0, bijector=tfb.Exp(), name=\"scale\"),\n)\n\n\nto_train_q.trainable_variables\n\n2022-02-04 14:55:19.564807: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n\n\n(&lt;tf.Variable 'loc:0' shape=() dtype=float32, numpy=-1.0&gt;,\n &lt;tf.Variable 'scale:0' shape=() dtype=float32, numpy=0.0&gt;)\n\n\n\n@tf.function\ndef loss_and_grads(q_dist):\n    with tf.GradientTape() as tape:\n        loss = tfd.kl_divergence(q_dist, p)\n    return loss, tape.gradient(loss, q_dist.trainable_variables)\n\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nfor i in range(500):\n    loss, grads = loss_and_grads(to_train_q)\n    optimizer.apply_gradients(zip(grads, to_train_q.trainable_variables))\n\n\nto_train_q.loc, to_train_q.scale\n\n(&lt;tf.Variable 'loc:0' shape=() dtype=float32, numpy=0.98873746&gt;,\n &lt;TransformedVariable: name=scale, dtype=float32, shape=[], fn=\"exp\", numpy=3.9999995&gt;)\n\n\nAfter training, we are able to recover the scale and loc very close to that of \\(p\\)\n\n\nAnimation!\n\nfrom matplotlib import animation\n\nfig = plt.figure(tight_layout=True, figsize=(8, 4))\nax = fig.gca()\n\nto_train_q = tfd.Normal(\n    loc=tf.Variable(5.0, name=\"loc\"),\n    scale=tfp.util.TransformedVariable(0.1, bijector=tfb.Exp(), name=\"scale\"),\n)\n\n\ndef animate(i):\n    ax.clear()\n    ax.plot(z_values, prob_values_p, label=r\"$p\\sim\\mathcal{N}(1.00, 4.00)$\", lw=5)\n    loss, grads = loss_and_grads(to_train_q)\n    optimizer.apply_gradients(zip(grads, to_train_q.trainable_variables))\n    loc = to_train_q.loc.numpy()\n    scale = to_train_q.scale.numpy()\n\n    ax.plot(\n        z_values,\n        to_train_q.prob(z_values),\n        label=rf\"$q\\sim \\mathcal{{N}}({loc:0.2f}, {scale:0.2f})$\",\n    )\n    d_kl = tfd.kl_divergence(to_train_q, p)\n\n    ax.set_title(rf\"Iteration: {i}, $D_{{KL}}(q||p)$: {d_kl:0.2f}\")\n    ax.legend(bbox_to_anchor=(1.1, 1), borderaxespad=0)\n    ax.set_ylim((0, 1))\n    ax.set_xlim((-5, 15))\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"PDF\")\n    sns.despine()\n\n\nani = animation.FuncAnimation(fig, animate, frames=150)\nplt.close()\n\n\nani.save(\"kl_qp.gif\", writer=\"imagemagick\", fps=15, dpi=100)\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n\n\nFinding the KL divergence for two distributions from different families\nLet us rework our example with p coming from a mixture of Gaussian distribution and q being Normal.\n\np_s = tfd.MixtureSameFamily(\n    mixture_distribution=tfd.Categorical(probs=[0.5, 0.5]),\n    components_distribution=tfd.Normal(\n        loc=[-0.2, 1], scale=[0.1, 0.5]  # One for each component.\n    ),\n)  # And same here.\n\np_s\n\n&lt;tfp.distributions.MixtureSameFamily 'MixtureSameFamily' batch_shape=[] event_shape=[] dtype=float32&gt;\n\n\n\nplt.plot(z_values, p_s.prob(z_values))\nsns.despine()\n\n\n\n\n\n\n\n\nLet us create two Normal distributions q_1 and q_2 and plot them to see which looks closer to p_s.\n\nq_1 = create_q(3, 1)\nq_2 = create_q(3, 4.5)\n\n\nprob_values_p_s = p_s.prob(z_values)\nprob_values_q_1 = q_1.prob(z_values)\nprob_values_q_2 = q_2.prob(z_values)\n\nplt.plot(z_values, prob_values_p_s, label=r\"MOG\")\nplt.plot(z_values, prob_values_q_1, label=r\"$q_1\\sim\\mathcal{N} (3, 1.0)$\")\nplt.plot(z_values, prob_values_q_2, label=r\"$q_2\\sim\\mathcal{N} (3, 4.5)$\")\n\nsns.despine()\nplt.legend()\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\nplt.tight_layout()\nplt.savefig(\n    \"dkl-different.png\",\n    dpi=150,\n)\n\n\n\n\n\n\n\n\n\ntry:\n    tfd.kl_divergence(q_1, p_s)\nexcept Exception as e:\n    print(e)\n\nNo KL(distribution_a || distribution_b) registered for distribution_a type Normal and distribution_b type MixtureSameFamily\n\n\nAs we see above, we can not compute the KL divergence directly. The core idea would now be to leverage the Monte Carlo sampling and generating the expectation. The following function does that.\n\ndef kl_via_sampling(q, p, n_samples=100000):\n    # Get samples from q\n    sample_set = q.sample(n_samples)\n    # Use the definition of KL-divergence\n    return tf.reduce_mean(q.log_prob(sample_set) - p.log_prob(sample_set))\n\n\nkl_via_sampling(q_1, p_s), kl_via_sampling(q_2, p_s)\n\n(&lt;tf.Tensor: shape=(), dtype=float32, numpy=9.465648&gt;,\n &lt;tf.Tensor: shape=(), dtype=float32, numpy=46.48004&gt;)\n\n\nAs we can see from KL divergence calculations, q_1 is closer to our Gaussian mixture distribution.\n\n\nOptimizing the KL divergence for two distributions from different families\nWe saw that we can calculate the KL divergence between two different distribution families via sampling. But, as we did earlier, will we be able to optimize the parameters of our target surrogate distribution? The answer is No! As we have introduced sampling. However, there is still a way – by reparameterization!\nOur surrogate q in this case is parameterized by loc and scale. The key idea here is to generate samples from a standard normal distribution (loc=0, scale=1) and then apply an affine transformation on the generated samples to get the samples generated from q. See my other post on sampling from normal distribution to understand this better.\nThe loss can now be thought of as a function of loc and scale.\n\nn_samples = 1000\n\n\ndef loss(loc, scale):\n    q = tfd.Normal(loc=loc, scale=scale)\n    q_1 = tfd.Normal(loc=0.0, scale=1.0)\n    sample_set = q_1.sample(n_samples)\n    sample_set = loc + scale * sample_set\n    return tf.reduce_mean(q.log_prob(sample_set) - p_s.log_prob(sample_set))\n\nHaving defined the loss above, we can now optimize loc and scale to minimize the KL-divergence.\n\noptimizer = tf.optimizers.Adam(learning_rate=0.05)\n\n\nn_iter = 150\nlocation_array = np.empty(n_iter, dtype=np.float32)\nscale_array = np.empty(n_iter, dtype=np.float32)\nloss_array = np.empty(n_iter, dtype=np.float32)\n\n\nloc = tf.Variable(3.0, dtype=tf.float32)\nscale = tf.Variable(4.0, dtype=tf.float32)\nfor i in range(n_iter):\n    with tf.GradientTape(persistent=True) as tape:\n        tape.watch(loc)\n        tape.watch(scale)\n        lo = loss(loc, scale)\n    [dl_loc, dl_scale] = tape.gradient(lo, [loc, scale])\n    if i % 50 == 0:\n        tf.print(lo, loc, scale)\n    location_array[i] = loc.numpy()\n    scale_array[i] = scale.numpy()\n    loss_array[i] = lo.numpy()\n    optimizer.apply_gradients(zip([dl_loc, dl_scale], [loc, scale]))\n\n38.7589951 3 4\n0.4969607 0.736858189 0.680736303\n0.528585315 0.774057031 0.617758751\n\n\n\nq_s = tfd.Normal(loc=loc, scale=scale)\nq_s\n\n&lt;tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32&gt;\n\n\n\nprob_values_p_s = p_s.prob(z_values)\nprob_values_q_s = q_s.prob(z_values)\n\nplt.plot(z_values, prob_values_p_s, label=r\"p\")\nplt.plot(z_values, prob_values_q_s, label=r\"q\")\n\nsns.despine()\nplt.legend()\nplt.xlabel(\"x\")\nplt.ylabel(\"PDF\")\n\n\n\n\n\n\n\n\n\nprob_values_p_s = p_s.prob(z_values)\n\nfig = plt.figure(tight_layout=True, figsize=(8, 4))\nax = fig.gca()\n\n\ndef a(iteration):\n\n    ax.clear()\n    loc = location_array[iteration]\n    scale = scale_array[iteration]\n    q_s = tfd.Normal(loc=loc, scale=scale)\n\n    prob_values_q_s = q_s.prob(z_values)\n\n    ax.plot(z_values, prob_values_p_s, label=r\"p\")\n    ax.plot(z_values, prob_values_q_s, label=r\"q\")\n    ax.set_title(f\"Iteration {iteration}, Loss: {loss_array[iteration]:0.2f}\")\n\n\nani_mg = animation.FuncAnimation(fig, a, frames=n_iter)\nplt.close()\n\n\nplt.plot(location_array, label=\"loc\")\nplt.plot(scale_array, label=\"scale\")\nplt.xlabel(\"Iterations\")\nsns.despine()\nplt.legend()\n\n\n\n\n\n\n\n\n\nani_mg.save(\"kl_qp_mg.gif\", writer=\"imagemagick\")\n\n\n\n\nOptimizing the KL-divergence between two 2d distributions\nLet us now repeat the same procedure but for two 2d Normal distributions.\n\np_2d = tfd.MultivariateNormalFullCovariance(\n    loc=[0.0, 0.0], covariance_matrix=[[1.0, 0.5], [0.5, 2]]\n)\n\nto_train_q_2d_2 = tfd.MultivariateNormalDiag(\n    loc=tf.Variable([2.0, -2.0], name=\"loc\"),\n    scale_diag=tfp.util.TransformedVariable(\n        [1.0, 2.0], bijector=tfb.Exp(), name=\"scale\"\n    ),\n)\n\nWARNING:tensorflow:From /Users/nipun/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:342: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\nInstructions for updating:\n`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n\n\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\n\n\ndef make_pdf_2d_gaussian(mu, sigma, ax, title):\n    N = 60\n    X = np.linspace(-3, 3, N)\n    Y = np.linspace(-3, 4, N)\n    X, Y = np.meshgrid(X, Y)\n\n    # Pack X and Y into a single 3-dimensional array\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n\n    F = tfd.MultivariateNormalFullCovariance(loc=mu, covariance_matrix=sigma)\n    Z = F.prob(pos)\n\n    sns.despine()\n    ax.set_xlabel(r\"$x_1$\")\n    ax.set_ylabel(r\"$x_2$\")\n    ax.set_aspect(\"equal\")\n    if title:\n        ax.set_title(f\"$\\mu$ = {mu}\\n $\\Sigma$ = {np.array(sigma)}\")\n        ax.contour(X, Y, Z, cmap=\"viridis\", alpha=1, zorder=2)\n    else:\n        ax.contourf(X, Y, Z, cmap=\"plasma\", alpha=0.1)\n\n\nfig, ax = plt.subplots()\nmake_pdf_2d_gaussian([0.0, 1.0], [[1.0, 0.5], [0.5, 2]], ax, False)\nmake_pdf_2d_gaussian(\n    to_train_q_2d_2.loc.numpy(), to_train_q_2d_2.covariance().numpy(), ax, True\n)\n\n\n\n\n\n\n\n\nAs we can see above, the two distributions look very different. We can calculate the KL-divergence as before.\n\ntfd.kl_divergence(to_train_q_2d_2, p_2d)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=4.8723755&gt;\n\n\n\nfig = plt.figure(tight_layout=True, figsize=(8, 4))\nax = fig.gca()\n\n\ndef animate(i):\n    ax.clear()\n    with tf.GradientTape() as tape:\n        loss = tfd.kl_divergence(to_train_q_2d_2, p_2d)\n        grads = tape.gradient(loss, to_train_q_2d_2.trainable_variables)\n        optimizer.apply_gradients(zip(grads, to_train_q_2d_2.trainable_variables))\n    loc = np.round(to_train_q_2d_2.loc.numpy(), 1)\n    scale = np.round(to_train_q_2d_2.covariance().numpy(), 1)\n\n    make_pdf_2d_gaussian(loc, scale, ax, True)\n    make_pdf_2d_gaussian([0.0, 1.0], [[1.0, 0.5], [0.5, 2]], ax, False)\n\n    ax.set_xlabel(r\"$x_1$\")\n    ax.set_ylabel(r\"$x_2$\")\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n\n    # Only show ticks on the left and bottom spines\n    ax.yaxis.set_ticks_position(\"left\")\n    ax.xaxis.set_ticks_position(\"bottom\")\n\n\nani2 = animation.FuncAnimation(fig, animate, frames=100)\nplt.close()\n\n\nani2.save(\"kl_qp_2.gif\", writer=\"imagemagick\", fps=15, dpi=100)\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\n\nto_train_q_2d_2.loc, to_train_q_2d_2.covariance()\n\n(&lt;tf.Variable 'loc:0' shape=(2,) dtype=float32, numpy=array([ 0.01590762, -0.01590773], dtype=float32)&gt;,\n &lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[0.87550056, 0.        ],\n        [0.        , 1.7570419 ]], dtype=float32)&gt;)\n\n\n\ntfd.kl_divergence(to_train_q_2d_2, p_2d)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.0670591&gt;\n\n\nWe can now see that the KL-divergence has reduced significantly from where we started, but it will unlikely improve as ou r q distribution is a multivariate diagonal normal distribution, meaning there is no correlation between the two dimensions.\n\n\nTo-FIX\nEverything below here needs to be fixed\n\nKL-Divergence and ELBO\nLet us consider linear regression. We have parameters \\(\\theta \\in R^D\\) and we define a prior over them. Let us assume we define prior \\(p(\\theta)\\sim \\mathcal{N_D} (\\mu, \\Sigma)\\). Now, given our dataset \\(D = \\{X, y\\}\\) and a parameter vector \\(\\theta\\), we can deifine our likelihood as \\(p(D|\\theta)\\) or $p(y|X, ) = {i=1}^{n} p(y_i|x_i, ) = {i=1}^{n} (y_i|x_i^T, ^2) $\nAs per Bayes rule, we can obtain the posterior over \\(\\theta\\) as:\n\\(p(\\theta|D) = \\dfrac{p(D|\\theta)p(\\theta)}{p(D)}\\)\nNow, in general \\(p(D)\\) is hard to compute.\nSo, in variational inference, our aim is to use a surrogate distribution \\(q(\\theta)\\) such that it is very close to \\(p(\\theta|D)\\). We do so by minimizing the KL divergence between \\(q(\\theta)\\) and \\(p(\\theta|D)\\).\nAim: \\[q^*(\\theta) = \\underset{q(\\theta) \\in \\mathcal{Q}}{\\mathrm{argmin~}} D_{KL}[q(\\theta)||p(\\theta|D)]\\]\nNow, \\[D_{KL}[q(\\theta)||p(\\theta|D)] = \\mathbb{E}_{q(\\theta)}[\\log\\frac{q(\\theta)}{p(\\theta|D)}]\\] Now, \\[ = \\mathbb{E}_{q(\\theta)}[\\log\\frac{q(\\theta)p(D)}{p(\\theta, D)}]\\] Now, \\[ = \\mathbb{E}_{q(\\theta)}[\\log q(\\theta)]- \\mathbb{E}_{q(\\theta)}[\\log p(\\theta, D)] + \\mathbb{E}_{q(\\theta)}[\\log p(D)] \\] \\[= \\mathbb{E}_{q(\\theta)}[\\log q(\\theta)]- \\mathbb{E}_{q(\\theta)}[\\log p(\\theta, D)] + \\log p(D) \\]\nNow, \\(p(D) \\in \\{0, 1\\}\\). Thus, \\(\\log p(D) \\in \\{-\\infty, 0 \\}\\)\nNow, let us look at the quantities:\n\\[\\underbrace{D_{KL}[q(\\theta)||p(\\theta|D)]}_{\\geq 0} = \\underbrace{\\mathbb{E}_{q(\\theta)}[\\log q(\\theta)]- \\mathbb{E}_{q(\\theta)}[\\log p(\\theta, D)]}_{-\\text{ELBO(q)}} +  \\underbrace{\\log p(D)}_{\\leq 0}\\]\nThus, we know that \\(\\log p(D) \\geq \\text{ELBO(q)}\\)\nThus, finally we can rewrite the optimisation from\n\\[q^*(\\theta) = \\underset{q(\\theta) \\in \\mathcal{Q}}{\\mathrm{argmin~}} D_{KL}[q(\\theta)||p(\\theta|D)]\\]\nto\n\\[q^*(\\theta) = \\underset{q(\\theta) \\in \\mathcal{Q}}{\\mathrm{argmax~}} \\text{ELBO(q)}\\]\nNow, given our linear regression problem setup, we want to maximize the ELBO.\nWe can do so by the following. As a simple example, let us assume \\(\\theta \\in R^2\\)\n\nAssume some q. Say, a Normal distribution. So, \\(q\\sim \\mathcal{N}_2\\)\nDraw samples from q. Say N samples.\nInitilize ELBO = 0.0\nFor each sample:\n\nLet us assume drawn sample is \\([\\theta_1, \\theta_2]^T\\)\nCompute log_prob of prior on \\([\\theta_1, \\theta_2]^T\\) or lp = p.log_prob(θ1, θ2)\nCompute log_prob of likelihood on \\([\\theta_1, \\theta_2]^T\\) or ll = l.log_prob(θ1, θ2)\nCompute log_prob of q on \\([\\theta_1, \\theta_2]^T\\) or lq = q.log_prob(θ1, θ2)\nELBO = ELBO + (ll+lp-q)\n\nReturn ELBO/N\n\n\ndef lr(x, stddv_datapoints):\n    num_datapoints, data_dim = x.shape\n    th = yield tfd.Normal(\n        loc=tf.zeros([data_dim + 1]), scale=tf.ones([data_dim + 1]), name=\"theta\"\n    )\n\n    x_dash = tf.concat([tf.ones_like(x), x], 1)\n    y = yield tfd.Normal(\n        loc=tf.linalg.matvec(x_dash, th), scale=stddv_datapoints, name=\"y\"\n    )\n\n\nx = tf.linspace(-5.0, 5.0, 100)\nx = tf.expand_dims(x, 1)\n\n\nimport functools\n\nstddv_datapoints = 1\n\nconcrete_lr_model = functools.partial(lr_2, x=x, stddv_datapoints=stddv_datapoints)\n\nmodel = tfd.JointDistributionCoroutineAutoBatched(concrete_lr_model)\n\n\ntf.random.set_seed(0)\nth_sample, data_sample = model.sample()\n\nplt.scatter(x[:, 0], data_sample, s=10)\nplt.plot(x[:, 0], tf.reshape(x*th_sample[1] + th_sample[0], [-1]))\nprint(th_sample)\n\ntf.Tensor([1.5110626  0.42292204], shape=(2,), dtype=float32)\n\n\n\n\n\n\n\n\n\n\nmodel.log_prob(th_sample, data_sample)\n\n&lt;tf.Tensor: shape=(), dtype=float32, numpy=-150.26591&gt;\n\n\n\nloc = tf.Variable([1.0, 1.0], dtype=tf.float32)\nscale = tf.Variable([1.0, 1.0])\n\nq_to_learn = tfd.Normal(loc=loc, scale=scale, name=\"q_theta_learn\")\n\n\nn_samples = 1000\n\n\nloc = tf.Variable([1.0, 0.4], dtype=tf.float32)\nscale = tfp.util.TransformedVariable([.7, .6], bijector=tfb.SoftClip(0.5, 1.0))\ndef loss():\n    q_to_learn = tfd.Normal(loc=loc, scale=scale, name=\"q_theta_learn\")\n    q_1 = tfd.Normal(loc=[0.0,0.0], scale=[1.0, 1.0])\n    sample_set = q_1.sample(n_samples)\n    log_joint = tf.reduce_sum(model.log_prob(sample_set, data_sample))\n    log_q = tf.reduce_sum(q_to_learn.log_prob(sample_set))\n    return log_q - log_joint\n\n\ntrace6000 = tfp.math.minimize(loss_fn=loss, num_steps=6000, \n                  optimizer=tf.optimizers.Adam(0.0001))\n\n\nloc\n\n&lt;tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1.4298061 , 0.84917635], dtype=float32)&gt;\n\n\n\nscale\n\n&lt;TransformedVariable: name=soft_clip, dtype=float32, shape=[2], fn=\"soft_clip\", numpy=array([0.6512191, 0.5705266], dtype=float32)&gt;\n\n\n\nplt.plot(trace)\n\n\n\n\n\n\n\n\n\nloc, th_sample, scale\n#scale =  tfp.util.TransformedVariable([1., 1.], bijector=tfb.Exp())\n\n(&lt;tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2.0690155, 1.496477 ], dtype=float32)&gt;,\n &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.5110626 , 0.42292204], dtype=float32)&gt;,\n &lt;TransformedVariable: name=soft_clip, dtype=float32, shape=[2], fn=\"soft_clip\", numpy=array([0.5936036, 0.5403929], dtype=float32)&gt;)\n\n\n\nplt.scatter(x[:, 0], data_sample, s=10)\nplt.plot(x[:, 0], tf.reshape(x*loc[1] + loc[0], [-1]))\n\n\n\n\n\n\n\n\n\nloss_mc\n\n&lt;function __main__.loss_mc(loc, scale)&gt;\n\n\n\nloc = tf.Variable([1.0, 0.4], dtype=tf.float32)\nscale = tfp.util.TransformedVariable([.7, .6], bijector=tfb.SoftClip(0.5, 1.0))\n\ndef loss_mc(loc, scale):\n    q_to_learn = tfd.Normal(loc=loc, scale=scale, name=\"q_theta_learn\")\n    q_1 = tfd.Normal(loc=[0.0,0.0], scale=[1.0, 1.0])\n    sample_set = q_1.sample(n_samples)\n    log_joint = tf.reduce_sum(model.log_prob(sample_set, data_sample))\n    log_q = tf.reduce_sum(q_to_learn.log_prob(sample_set))\n    return log_q - log_joint\n\ntarget_log_prob_fn = lambda th: model.log_prob((th, data_sample))\n\n\n\n\ndata_dim=2\nqt_mean = tf.Variable(tf.random.normal([data_dim]))\nqt_stddv = tfp.util.TransformedVariable(\n    1e-4 * tf.ones([data_dim]), bijector=tfb.Softplus()\n)\n\n\ndef factored_normal_variational_model():\n    qt = yield tfd.Normal(loc=qt_mean, scale=qt_stddv, name=\"qt\")\n\n\nsurrogate_posterior = tfd.JointDistributionCoroutineAutoBatched(\n    factored_normal_variational_model\n)\n\nlosses = tfp.vi.fit_surrogate_posterior(\n    target_log_prob_fn=target_log_prob_fn,\n    surrogate_posterior=surrogate_posterior,\n    optimizer=tf.optimizers.Adam(learning_rate=0.05),\n    num_steps=100,\n)\n\n/Users/nipun/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/vectorization_util.py:87: UserWarning: Saw Tensor seed Tensor(\"seed:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n  warnings.warn(\n/Users/nipun/miniforge3/lib/python3.9/site-packages/tensorflow_probability/python/internal/vectorization_util.py:87: UserWarning: Saw Tensor seed Tensor(\"seed:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n  warnings.warn(\n\n\n\nplt.plot(losses)\n\n\n\n\n\n\n\n\n\n\n\nStructTuple(\n  qt=&lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.5720905, 0.4626296], dtype=float32)&gt;\n)\n\n\n\nqt_mean, qt_stddv\n\n(&lt;tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1.5777218 , 0.46246716], dtype=float32)&gt;,\n &lt;TransformedVariable: name=softplus, dtype=float32, shape=[2], fn=\"softplus\", numpy=array([0.01456336, 0.01367522], dtype=float32)&gt;)\n\n\n\nplt.scatter(x[:, 0], data_sample, s=10)\nplt.plot(x[:, 0], tf.reshape(x*qt_mean[1] + qt_mean[0], [-1]))\n\n\n\n\n\n\n\n\n\npost_samples = surrogate_posterior.sample(200)\n\npost_samples.qt[0:5]\n\nWARNING:tensorflow:Note that RandomStandardNormal inside pfor op may not give same output as inside a sequential loop.\n\n\n&lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=\narray([[1.5795265 , 0.500741  ],\n       [1.5515635 , 0.46671686],\n       [1.5585055 , 0.4617632 ],\n       [1.5856469 , 0.44141397],\n       [1.5763292 , 0.45420292]], dtype=float32)&gt;\n\n\n\nplt.scatter(x[:, 0], data_sample, s=10)\n\nplt.plot(x[:, 0], tf.reshape(x*qt_mean[1] + qt_mean[0], [-1]))\n\n\n\n\n\n\n\n\nReferences\n\nhttps://www.youtube.com/watch?v=HUsznqt2V5I\nhttps://www.youtube.com/watch?v=x9StQ8RZ0ag&list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ&index=9\nhttps://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2021-09-13-02-Minimizing-KL-Divergence.ipynb#scrollTo=gd_ev8ceII8q\nhttps://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/09/13/02-Minimizing-KL-Divergence.html"
  },
  {
    "objectID": "posts/2013-07-01-hmm_continuous.html",
    "href": "posts/2013-07-01-hmm_continuous.html",
    "title": "HMM Simulation for Continuous HMM",
    "section": "",
    "text": "In this notebook we shall create a continuous Hidden Markov Model [1] for an electrical appliance. Problem description:\nIn all it matches the description of a continuous Hidden Markov Model. The different components of the Discrete HMM are as follows:\nNext, we import the basic set of libraries used for matrix manipulation and for plotting.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\n#Setting Font Size as 20\nmatplotlib.rcParams.update({'font.size': 20})\nNext, we define the different components of HMM which were described above.\npi=np.array([.9,.1])\nA=np.array([[.99,.01],[.1,.9]])\nB=np.array([{'mean':0,'variance':1},{'mean':170,'variance':4}])\nNow based on these probability we need to produce a sequence of observed and hidden states. We use the notion of weighted sampling, which basically means that terms/states with higher probabilies assigned to them are more likely to be selected/sampled. For example,let us consider the starting state. For this we need to use the pi matrix, since that encodes the likiliness of starting in a particular state. We observe that for starting in Fair state the probability is .667 and twice that of starting in Biased state. Thus, it is much more likely that we start in Fair state. We use Fitness Proportionate Selection [3] to sample states based on weights (probability). For selection of starting state we would proceed as follows:\n'''\nReturns next state according to weigted probability array. Code based on Weighted random generation in Python [4]\n'''\ndef next_state(weights):\n    choice = random.random() * sum(weights)\n    for i, w in enumerate(weights):\n        choice -= w\n        if choice &lt; 0:\n            return i\nWe test the above function by making a call to it 1000 times and then we try to see how many times do we get a 0 (Fair) wrt 1 (Biased), given the pi vector.\ncount=0\nfor i in range(1000):\n    count+=next_state(pi)\nprint \"Expected number of Fair states:\",1000-count\nprint \"Expected number of Biased states:\",count\n\nExpected number of Fair states: 890\nExpected number of Biased states: 110\nThus, we can see that we get approximately twice the number of Fair states as Biased states which is as expected.\nNext, we write the following functions:\ndef create_hidden_sequence(pi,A,length):\n    out=[None]*length\n    out[0]=next_state(pi)\n    for i in range(1,length):\n        out[i]=next_state(A[out[i-1]])\n    return out\n\n   \ndef create_observation_sequence_continuous(hidden_sequence,B):\n    length=len(hidden_sequence)\n    out=[None]*length\n    for i in range(length):\n        out[i]=np.random.normal(B[hidden_sequence[i]]['mean'],B[hidden_sequence[i]]['variance'],1)\n    return out\nThus, using these functions and the HMM paramters we decided earlier, we create length 1000 sequence for hidden and observed states.\nhidden=np.array(create_hidden_sequence(pi,A,1000))\nobserved=np.array(create_observation_sequence_continuous(hidden,B))\nNow, we create helper functions to plot the two sequence in a way we can intuitively understand the HMM.\nplt.figsize(16,10);\nplt.subplot(2,1,1)\nplt.title('Observed Power draw')\nplt.ylabel('Power (W)');\nplt.xlabel('Sample #');\nplt.plot(observed)\nplt.subplot(2,1,2);\nplt.fill_between(range(len(hidden)),hidden,0,alpha=0.5)\nplt.plot(hidden,linewidth=3);\nplt.ylabel('State');\nplt.xlabel('Sample #');\nplt.title('0- Compressor Off, 1- Compressor On');\nplt.tight_layout()"
  },
  {
    "objectID": "posts/2013-07-01-hmm_continuous.html#references",
    "href": "posts/2013-07-01-hmm_continuous.html#references",
    "title": "HMM Simulation for Continuous HMM",
    "section": "References",
    "text": "References\n\nhttp://en.wikipedia.org/wiki/Hidden_Markov_model\nhttp://www.stanford.edu/class/stats366/hmmR2.html\nhttp://en.wikipedia.org/wiki/Fitness_proportionate_selection\nhttp://eli.thegreenplace.net/2010/01/22/weighted-random-generation-in-python/\nhttp://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list"
  },
  {
    "objectID": "posts/2018-08-18-placement-preparation-2018-1-hashmap.html",
    "href": "posts/2018-08-18-placement-preparation-2018-1-hashmap.html",
    "title": "Placement-Preparation-2018-1-HashMap",
    "section": "",
    "text": "In this blogpost, we will take a question from Cracking the Coding Interview. I discussed this question with Masters students at IITGN. We came up with some great answers. I’ll show how we increasingly went towards better solutions starting from naive ones.\nProblem statement\nFind all integer solutions to the problem \\(a^3 + b^3 = c^3 + d^3\\)\nwhere \\(1&lt;=a&lt;=n,\n1&lt;=b&lt;=n,\n1&lt;=c&lt;=n,\n1&lt;=d&lt;=n\\)\n\nFirst attempt : Naive bruteforce \\(O(n^4)\\)\nLet’s write a very simple first attempt. We will write four nested loops. This will be \\(O(n^4)\\) solution.\n\ndef f1(n):\n    out = []\n    for a in range(1, n+1):\n        for b in range(1, n+1):\n            for c in range(1, n+1):\n                for d in range(1, n+1):\n                    if a**3 + b**3 == c**3 + d**3:\n                        out.append((a, b, c, d))\n    return out \n\n\nf1_time = %timeit -o f1(50)\n\n6.65 s ± 203 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nf1_time.average\n\n6.646897936570895\n\n\n\n\nSecond attempt : Reduce computations in brute force method\nLet’s now try to optimise f1. We will still use a solution of \\(O(n^4)\\) solution. However, we add one small optimisation fo f1. We break from the innermost loop once we find a match. This will hopefull save us some computations.\n\ndef f2(n):\n    out = []\n    for a in range(1, n+1):\n        for b in range(1, n+1):\n            for c in range(1, n+1):\n                for d in range(1, n+1):\n                    if a**3 + b**3 == c**3 + d**3:\n                        out.append((a, b, c, d))\n                        break\n    return out \n\n\nf2_time = %timeit -o f2(50)\n\n6.29 s ± 26.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\nOk. We’re little better than f1. Every reduced computation is time saved!\n\n\nThird attempt : Reduce repeated computations by saving cubes of numbers\nOne of the student came up with an excellent observation. Why should we keep on computing cubes of numbers? This is a repeated operation. Let’s instead store them in a dictionary.\n\ndef f3(n):\n    cubes = {}\n    for x in range(1, n+1):\n        cubes[x] = x**3\n    out = []\n    for a in range(1, n+1):\n        for b in range(1, n+1):\n            for c in range(1, n+1):\n                for d in range(1, n+1):\n                    if cubes[a] + cubes[b] == cubes[c] + cubes[d]:\n                        out.append((a, b, c, d))\n                        break\n    return out \n\n\nf3_time = %timeit -o f3(50)\n\n1.05 s ± 4.11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\nOk. We now mean business! This is about 6 times quicker than our previous version.\n\n\nFourth attempt : Reduce one loop \\(O(n^3)\\)\nIn this solution, we will reduce one loop. We can solve for \\(d^3 = a^3 + b^3 - c^3\\) and find all the integer solutions. Now, there’s another clever optimisation that I have added. We can precompute the cubes and the cuberoots corresponding to numbers from 1 to N and perfect cubes from 1 to \\(N^3\\) respectively.\n\ndef f4(n):\n    cubes = {}\n    cuberoots = {}\n    for x in range(1, n+1):\n        x3 = x**3\n        cubes[x] = x3\n        cuberoots[x3] = x\n    out = []\n    for a in range(1, n+1):\n        for b in range(1, n+1):\n            for c in range(1, n+1):\n                d3 = (cubes[a] + cubes[b] - cubes[c])\n                if d3 in cuberoots:\n                    out.append((a, b, c, cuberoots[d3]))\n    return out \n\n\nf4_time = %timeit -o f4(50)\n\n21.7 ms ± 1.99 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nThis is seriously fast now!\n\n\nFifth attempt : Reduce another loop \\(O(n^2)\\)\nIn this solution, we will reduce one more loop. We can compute \\(a^3 + b^3\\) for all a, b. And then find c and d where \\(c^3 + d^3\\) is the same as \\(a^3 + b^3\\). This has a few Python tricks inside! One of the special cases to handle is of the type \\(1^3 + 2^3 = 2^3 + 1^3\\)\n\ndef f5(n):\n    out = []\n    cubes = {}\n    for x in range(1, n+1):\n        cubes[x] = x**3\n    \n    sum_a3_b3 = {}\n    for a in range(1, n+1):\n        for b in range(1, n+1):\n            temp = cubes[a]+cubes[b]\n            if temp in sum_a3_b3:    \n                sum_a3_b3[temp].append((a, b))\n            else:\n                sum_a3_b3[temp] = [(a, b)]\n\n    for c in range(1, n+1):\n        for d in range(1, n+1):\n            sum_c3_d3 = cubes[c] + cubes[d]\n            if sum_c3_d3 in sum_a3_b3:\n                for (a, b) in sum_a3_b3[sum_c3_d3]:\n                    out.append((a, b, c, d))\n\n    return out\n\n\nf5_time = %timeit -o f5(50)\n\n1.97 ms ± 235 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nPlain Wow! Going from 6 seconds to about 2 ms! Let’s plot the timings on a log scale to learn more.\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\ns = pd.Series({'Naive (O(N^4))':f1_time.average,\n              'Naive (O(N^4)) with break':f2_time.average,\n              'Naive (O(N^4)) with break and precomputing cubes':f3_time.average,\n              '(O(N^3))':f4_time.average,\n              '(O(N^2))':f5_time.average})\n\n\ns.plot(kind='bar', logy=True)\nplt.ylabel(\"Time\");\n\n\n\n\n\n\n\n\nHope this was fun!"
  },
  {
    "objectID": "posts/tensorboard.html",
    "href": "posts/tensorboard.html",
    "title": "Tensorboard",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader, TensorDataset\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\n# MNIST dataset\n\nfrom torchvision import datasets, transforms\nimport torchvision\n\n# Split MNIST into train, validation, and test sets\ntrain_data = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor())\n\n# Split train_data into train and validation sets\nval_data = torch.utils.data.Subset(train_data, range(50000, 60000))\ntrain_data = torch.utils.data.Subset(train_data, range(0, 50000))\n\n# Create data loaders\nbatch_size = 64\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n\n\n# Add images to tensorboard\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Clear the log directory\n!rm -rf runs\n\n# Default `log_dir` is \"runs\" - we'll be more specific here\nwriter = SummaryWriter('runs/mnist_experiment_1')\n\n\n\n# Add images to tensorboard in the form of a grid in batches of 64\ndataiter = iter(DataLoader(train_data, batch_size=64, shuffle=True))\n\n# Add a slider in tensorboard to iterate through the batches\nfor i in range(10):\n    images, labels = next(dataiter)\n    images = torchvision.utils.make_grid(images)\n    writer.add_image(f'mnist_images', images)\n\n\n# Define model for 10-class MNIST classification\n\nclass MNISTClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 64)\n        self.fc2 = nn.Linear(64, 64)\n        self.fc3 = nn.Linear(64, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        logits = self.fc3(x)\n        return logits\n\n\nimages.shape\n\ntorch.Size([64, 1, 28, 28])\n\n\n\nlearning_rate = 0.001\nmodel = MNISTClassifier()\n\nopt  = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Define loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Define training loop\nfor epoch in range(2):\n    for i, (images, labels) in enumerate(train_loader):\n        # Flatten images\n        images = images.view(-1, 28*28)\n        \n        # Forward pass\n        logits = model(images)\n        loss = criterion(logits, labels)\n        \n        # Backward pass\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n        # Add loss to tensorboard\n        writer.add_scalar('training loss',\n                          loss.item(),\n                          epoch * len(train_loader) + i)\n        \n        # Add images and labels to tensorboard\n        if i % 100 == 0:\n            images = images.view(-1, 1, 28, 28)\n            img_grid = torchvision.utils.make_grid(images)\n            writer.add_image('mnist_images', img_grid)\n            #writer.add_graph(model, images)\n            #writer.add_embedding(logits,\n            #                     metadata=labels,\n            #                     label_img=images)\n            \n            # Log a histogram of the model parameters\n            for name, param in model.named_parameters():\n                writer.add_histogram(name, param, i)\n            \n            # Evaluate validation accuracy\n            val_loss = 0\n            val_accuracy = 0\n            for images, labels in val_loader:\n                images = images.view(-1, 28*28)\n                logits = model(images)\n                val_loss += criterion(logits, labels)\n                ps = torch.exp(logits)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                val_accuracy += torch.mean(equals.type(torch.FloatTensor))\n            \n            # Log validation accuracy\n            writer.add_scalar('validation loss',\n                                val_loss/len(val_loader),\n            )\n            writer.add_scalar('validation accuracy',\n                                val_accuracy/len(val_loader),\n            )\n\n\n                \n            # Log model parameters\n            writer.add_hparams({'lr': learning_rate, 'bsize': batch_size},\n                               {'hparam/accuracy': val_accuracy/len(val_loader), 'hparam/loss': loss.item()})\n\n\n# Model 1: Linear regression\n\nclass LinearRegression(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.linear = nn.Linear(input_dim, 1)\n        \n    def forward(self, x):\n        return self.linear(x)\n\n\ndef train(model, optimizer, criterion = nn.MSELoss(), train_loader=None, val_loader=None, epochs=1000):\n    train_losses = []\n    val_losses = []\n    for e in range(epochs):\n        train_loss = 0\n        val_loss = 0\n        model.train()\n        for batch_x, batch_y in train_loader:\n            optimizer.zero_grad()\n            output = model(batch_x)\n            loss = criterion(output, batch_y)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * batch_x.size(0)\n        train_loss /= len(train_loader.dataset)\n        train_losses.append(train_loss)\n\n        model.eval()\n        with torch.no_grad():\n            for batch_x, batch_y in val_loader:\n                output = model(batch_x)\n                loss = criterion(output, batch_y)\n                val_loss += loss.item() * batch_x.size(0)\n            val_loss /= len(val_loader.dataset)\n            val_losses.append(val_loss)\n\n        if (e+1) % 100 == 0:\n            print(f'Epoch {e+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n    \n    return train_losses, val_losses\n\n\ncriterion = nn.MSELoss()\n\nmodel = LinearRegression(X_train.shape[1])\noptimizer = optim.Adam(model.parameters(), lr=0.1)\n\ntrain_losses, val_losses = train(model, optimizer, criterion, train_loader, val_loader, epochs=1000)\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\n\nEpoch 100/1000, Train Loss: 10315.2895, Validation Loss: 12724.1896\nEpoch 200/1000, Train Loss: 4804.3067, Validation Loss: 5319.9323\nEpoch 300/1000, Train Loss: 3715.5066, Validation Loss: 3480.5550\nEpoch 400/1000, Train Loss: 3388.3811, Validation Loss: 3083.5462\nEpoch 500/1000, Train Loss: 3194.2672, Validation Loss: 2970.7406\nEpoch 600/1000, Train Loss: 3075.9221, Validation Loss: 2929.4660\nEpoch 700/1000, Train Loss: 3007.6152, Validation Loss: 2911.9031\nEpoch 800/1000, Train Loss: 2970.0181, Validation Loss: 2906.4726\nEpoch 900/1000, Train Loss: 2948.9850, Validation Loss: 2904.5393\nEpoch 1000/1000, Train Loss: 2937.7591, Validation Loss: 2901.6748\n\n\n\n\n\n\n\n\n\n\n# RMSE on test set\n\ndef rmse(model, test_loader):\n    model.eval()\n    with torch.no_grad():\n        test_loss = 0\n        for batch_x, batch_y in test_loader:\n            output = model(batch_x)\n            loss = criterion(output, batch_y)\n            test_loss += loss.item() * batch_x.size(0)\n        test_loss /= len(test_loader.dataset)\n    return np.sqrt(test_loss)\n\n\nerrors = {}\n\nerrors[\"linreg\"] = rmse(model, test_loader)\n\n\n# Model 2: MLP\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 32)\n        self.fc2 = nn.Linear(32, 16)\n        self.fc3 = nn.Linear(16, 10)\n        self.fc4 = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        return self.fc4(x)\n\n\nmlp = MLP(X_train.shape[1])\noptimizer = optim.Adam(mlp.parameters(), lr=0.001)\n\ntrain_losses, val_losses = train(mlp, optimizer, criterion, train_loader, val_loader, epochs=1500)\n\nEpoch 100/1500, Train Loss: 3663.8245, Validation Loss: 3086.0981\nEpoch 200/1500, Train Loss: 3077.9123, Validation Loss: 2912.6680\nEpoch 300/1500, Train Loss: 2952.4684, Validation Loss: 2906.0980\nEpoch 400/1500, Train Loss: 2920.8557, Validation Loss: 2916.5231\nEpoch 500/1500, Train Loss: 2908.5543, Validation Loss: 2903.3417\nEpoch 600/1500, Train Loss: 2898.7857, Validation Loss: 2920.6625\nEpoch 700/1500, Train Loss: 2888.3550, Validation Loss: 2886.4415\nEpoch 800/1500, Train Loss: 2874.1253, Validation Loss: 2905.2355\nEpoch 900/1500, Train Loss: 2866.0193, Validation Loss: 2915.6193\nEpoch 1000/1500, Train Loss: 2858.1495, Validation Loss: 2914.3357\nEpoch 1100/1500, Train Loss: 2849.0639, Validation Loss: 2919.2359\nEpoch 1200/1500, Train Loss: 2835.6841, Validation Loss: 2927.5912\nEpoch 1300/1500, Train Loss: 2814.3485, Validation Loss: 2942.1452\nEpoch 1400/1500, Train Loss: 2802.6443, Validation Loss: 2928.9871\nEpoch 1500/1500, Train Loss: 2789.4206, Validation Loss: 2943.3993\n\n\n\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\n\n\n\n\n\n\n\n\n\nerrors[\"MLP\"]= rmse(mlp, test_loader)\nerrors\n\n{'linreg': 53.8179193310273, 'MLP': 51.32108141562702}\n\n\n\n# Model 3: Residual MLP\n\n# Adding a skip connection from input to output\n\nclass ResMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 32)\n        self.fc2 = nn.Linear(32 + input_dim, 16)\n        self.fc3 = nn.Linear(16 + input_dim, 10)\n        self.fc4 = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        x_inp = x\n        x = F.relu(self.fc1(x)) \n        # Concatenate input to output of first layer\n        x = torch.cat((x, x_inp), dim=1)\n        x = F.relu(self.fc2(x))\n\n        # Concatenate input to output of second layer\n        x = torch.cat((x, x_inp), dim=1)\n        x = F.relu(self.fc3(x))\n\n        return self.fc4(x)\n\n\nres_mlp = ResMLP(X_train.shape[1])\nres_mlp(X_train).shape\n\ntorch.Size([282, 1])\n\n\n\nres_mlp = ResMLP(X_train.shape[1])\noptimizer = optim.Adam(res_mlp.parameters(), lr=0.001)\n\ntrain_losses, val_losses = train(res_mlp, optimizer, criterion, train_loader, val_loader, epochs=1500)\n\nEpoch 100/1500, Train Loss: 3298.6719, Validation Loss: 2937.0046\nEpoch 200/1500, Train Loss: 2958.9598, Validation Loss: 2908.0027\nEpoch 300/1500, Train Loss: 2933.4946, Validation Loss: 2915.9148\nEpoch 400/1500, Train Loss: 2924.1275, Validation Loss: 2885.2503\nEpoch 500/1500, Train Loss: 2918.3424, Validation Loss: 2883.3218\nEpoch 600/1500, Train Loss: 2913.7633, Validation Loss: 2891.1281\nEpoch 700/1500, Train Loss: 2909.4774, Validation Loss: 2875.5787\nEpoch 800/1500, Train Loss: 2906.8811, Validation Loss: 2885.1002\nEpoch 900/1500, Train Loss: 2896.1299, Validation Loss: 2894.3401\nEpoch 1000/1500, Train Loss: 2881.0517, Validation Loss: 2883.1614\nEpoch 1100/1500, Train Loss: 2859.3730, Validation Loss: 2900.0346\nEpoch 1200/1500, Train Loss: 2843.1591, Validation Loss: 2892.0867\nEpoch 1300/1500, Train Loss: 2825.5589, Validation Loss: 2935.1988\nEpoch 1400/1500, Train Loss: 2807.9256, Validation Loss: 2898.6540\nEpoch 1500/1500, Train Loss: 2798.3861, Validation Loss: 2901.6544\n\n\n\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\n\n\n\n\n\n\n\n\n\nerrors[\"resnet\"] = rmse(res_mlp, test_loader)\nerrors\n\n{'linreg': 53.8179193310273,\n 'MLP': 51.32108141562702,\n 'resnet': 51.87944353261233}\n\n\n\n# Adding LR scheduler\ndef train(model, optimizer, criterion=nn.MSELoss(), epochs=1000, lr_scheduler=None):\n    train_losses = []\n    val_losses = []\n\n    for e in range(epochs):\n        # Training loop\n        train_loss = 0\n        model.train()  # set the model to training mode\n        for X_train_batch, y_train_batch in train_loader:\n            optimizer.zero_grad()\n            y_train_pred = model(X_train_batch)\n            loss = criterion(y_train_pred, y_train_batch)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        train_losses.append(train_loss / len(train_loader))\n\n        # Validation loop\n        val_loss = 0\n        model.eval()  # set the model to evaluation mode\n        with torch.no_grad():\n            for X_val_batch, y_val_batch in val_loader:\n                y_val_pred = model(X_val_batch)\n                loss = criterion(y_val_pred, y_val_batch)\n                val_loss += loss.item()\n            val_losses.append(val_loss / len(val_loader))\n\n        # Update learning rate\n        if lr_scheduler is not None:\n            lr_scheduler.step(val_losses[-1])\n\n        # Print progress\n        if e % 100 == 0:\n            print(f\"Epoch {e}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n\n    return train_losses, val_losses\n\n\n# Use a LRPlateau scheduler to reduce the learning rate when the validation loss stops improving\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nres_mlp = ResMLP(X_train.shape[1])\n\noptimizer = optim.Adam(res_mlp.parameters(), lr=0.01)\n\nlr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, verbose=True)\n\ntrain_losses, val_losses = train(res_mlp, optimizer, criterion, epochs=1500, lr_scheduler=lr_scheduler)\n\nEpoch 0, Train Loss: 28639.6855, Val Loss: 33158.0742\nEpoch 100, Train Loss: 2911.0527, Val Loss: 2420.7449\nEpoch 00141: reducing learning rate of group 0 to 5.0000e-03.\nEpoch 00192: reducing learning rate of group 0 to 2.5000e-03.\nEpoch 200, Train Loss: 2815.0154, Val Loss: 2422.1171\nEpoch 00243: reducing learning rate of group 0 to 1.2500e-03.\nEpoch 00294: reducing learning rate of group 0 to 6.2500e-04.\nEpoch 300, Train Loss: 2783.4652, Val Loss: 2429.3894\nEpoch 00345: reducing learning rate of group 0 to 3.1250e-04.\nEpoch 00396: reducing learning rate of group 0 to 1.5625e-04.\nEpoch 400, Train Loss: 2794.7555, Val Loss: 2432.0923\nEpoch 00447: reducing learning rate of group 0 to 7.8125e-05.\nEpoch 00498: reducing learning rate of group 0 to 3.9063e-05.\nEpoch 500, Train Loss: 2799.6670, Val Loss: 2432.4159\nEpoch 00549: reducing learning rate of group 0 to 1.9531e-05.\nEpoch 00600: reducing learning rate of group 0 to 9.7656e-06.\nEpoch 600, Train Loss: 2773.7532, Val Loss: 2431.9507\nEpoch 00651: reducing learning rate of group 0 to 4.8828e-06.\nEpoch 700, Train Loss: 2789.9358, Val Loss: 2431.6210\nEpoch 00702: reducing learning rate of group 0 to 2.4414e-06.\nEpoch 00753: reducing learning rate of group 0 to 1.2207e-06.\nEpoch 800, Train Loss: 2809.1560, Val Loss: 2431.6233\nEpoch 00804: reducing learning rate of group 0 to 6.1035e-07.\nEpoch 00855: reducing learning rate of group 0 to 3.0518e-07.\nEpoch 900, Train Loss: 2825.4572, Val Loss: 2431.6108\nEpoch 00906: reducing learning rate of group 0 to 1.5259e-07.\nEpoch 00957: reducing learning rate of group 0 to 7.6294e-08.\nEpoch 1000, Train Loss: 2780.1241, Val Loss: 2431.6187\nEpoch 01008: reducing learning rate of group 0 to 3.8147e-08.\nEpoch 01059: reducing learning rate of group 0 to 1.9073e-08.\nEpoch 1100, Train Loss: 2789.0557, Val Loss: 2431.6189\nEpoch 1200, Train Loss: 2816.7811, Val Loss: 2431.6187\nEpoch 1300, Train Loss: 2810.0122, Val Loss: 2431.6189\nEpoch 1400, Train Loss: 2782.1095, Val Loss: 2431.6191\n\n\n\nplt.plot(train_losses, label='Train')\nplt.plot(val_losses, label='Validation')\n\n\n\n\n\n\n\n\n\nerrors[\"resnet-lr\"] = rmse(res_mlp, test_loader)\n\n\nimport pandas as pd\npd.Series(errors).plot.barh()"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html",
    "href": "posts/2020-01-14-test-markdown-post.html",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Jekyll requires blog post files to be named according to the following format:\nYEAR-MONTH-DAY-filename.md\nWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files.\nThe first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above.\n\n\n\nYou can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule:\n\n\n\n\nHere’s a list:\n\nitem 1\nitem 2\n\nAnd a numbered list:\n\nitem 1\nitem 2\n\n\n\n\n\nThis is a quotation\n\n{% include alert.html text=“You can include alert boxes” %}\n…and…\n{% include info.html text=“You can include info boxes” %}\n\n\n\n\n\n\n\nYou can format text and code per usual\nGeneral preformatted text:\n# Do a thing\ndo_thing()\nPython code and output:\n# Prints '2'\nprint(1+1)\n2\nFormatting text as shell commands:\necho \"hello world\"\n./some_script.sh --option \"value\"\nwget https://example.com/cat_photo1.png\nFormatting text as YAML:\nkey: value\n- another_key: \"another value\"\n\n\n\n\n\n\nColumn 1\nColumn 2\n\n\n\n\nA thing\nAnother thing\n\n\n\n\n\n\n{% twitter https://twitter.com/jakevdp/status/1204765621767901185?s=20 %}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#basic-setup",
    "href": "posts/2020-01-14-test-markdown-post.html#basic-setup",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Jekyll requires blog post files to be named according to the following format:\nYEAR-MONTH-DAY-filename.md\nWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files.\nThe first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above."
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#basic-formatting",
    "href": "posts/2020-01-14-test-markdown-post.html#basic-formatting",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule:"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#lists",
    "href": "posts/2020-01-14-test-markdown-post.html#lists",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Here’s a list:\n\nitem 1\nitem 2\n\nAnd a numbered list:\n\nitem 1\nitem 2"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#boxes-and-stuff",
    "href": "posts/2020-01-14-test-markdown-post.html#boxes-and-stuff",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "This is a quotation\n\n{% include alert.html text=“You can include alert boxes” %}\n…and…\n{% include info.html text=“You can include info boxes” %}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#code",
    "href": "posts/2020-01-14-test-markdown-post.html#code",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "You can format text and code per usual\nGeneral preformatted text:\n# Do a thing\ndo_thing()\nPython code and output:\n# Prints '2'\nprint(1+1)\n2\nFormatting text as shell commands:\necho \"hello world\"\n./some_script.sh --option \"value\"\nwget https://example.com/cat_photo1.png\nFormatting text as YAML:\nkey: value\n- another_key: \"another value\""
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#tables",
    "href": "posts/2020-01-14-test-markdown-post.html#tables",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Column 1\nColumn 2\n\n\n\n\nA thing\nAnother thing"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#tweetcards",
    "href": "posts/2020-01-14-test-markdown-post.html#tweetcards",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "{% twitter https://twitter.com/jakevdp/status/1204765621767901185?s=20 %}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#footnotes",
    "href": "posts/2020-01-14-test-markdown-post.html#footnotes",
    "title": "An Example Markdown Post",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is the footnote.↩︎"
  }
]
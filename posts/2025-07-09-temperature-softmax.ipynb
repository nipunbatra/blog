{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Temperature Scaling in Softmax: Controlling Randomness in Language Models\"\n",
    "date: \"2025-07-09\"\n",
    "categories: [deep learning, natural language processing, softmax, temperature scaling, text generation]\n",
    "description: \"Exploring how temperature scaling affects the randomness and diversity of language model outputs through mathematical analysis and interactive visualizations\"\n",
    "author: \"Nipun Batra\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Scaling in Softmax: The Mathematics\n",
    "\n",
    "Temperature scaling modifies the softmax function to control the \"sharpness\" of the probability distribution. The standard softmax function is:\n",
    "\n",
    "$$\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}$$\n",
    "\n",
    "With temperature scaling, we introduce a temperature parameter $T$:\n",
    "\n",
    "$$\\text{softmax}_T(x_i) = \\frac{e^{x_i/T}}{\\sum_{j=1}^{n} e^{x_j/T}}$$\n",
    "\n",
    "## Effects of Temperature:\n",
    "\n",
    "- **T = 1**: Standard softmax (no scaling)\n",
    "- **T > 1**: Higher temperature → More uniform distribution → More randomness\n",
    "- **T < 1**: Lower temperature → Sharper distribution → More deterministic\n",
    "- **T → 0**: Distribution becomes one-hot (argmax)\n",
    "- **T → ∞**: Distribution becomes uniform\n",
    "\n",
    "## Entropy and Diversity:\n",
    "The entropy of a probability distribution measures its randomness:\n",
    "$$H(p) = -\\sum_{i=1}^{n} p_i \\log p_i$$\n",
    "\n",
    "Higher temperature typically leads to higher entropy and more diverse outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "Let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Rich imports for better formatting\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "from rich import print as rprint\n",
    "\n",
    "# Initialize rich console\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All necessary libraries loaded for language modeling, visualization, and rich formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Demonstration\n",
    "\n",
    "Let's create a visual diagram showing how temperature affects probability distributions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Set up prettier matplotlib styling\nplt.rcParams.update({\n    'font.size': 12,\n    'axes.labelsize': 14,\n    'axes.titlesize': 16,\n    'xtick.labelsize': 12,\n    'ytick.labelsize': 12,\n    'legend.fontsize': 12,\n    'figure.titlesize': 18\n})\n\n# Create sample logits and temperature ranges\nlogits = np.array([2.0, 1.0, 0.5, 0.2, 0.1])\ntemperatures = [0.1, 0.5, 1.0, 2.0, 5.0]\n\n# Create subplots with better styling\nfig, axes = plt.subplots(1, len(temperatures), figsize=(20, 5))\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\n\nfor i, temp in enumerate(temperatures):\n    # Calculate probabilities for this temperature\n    scaled_logits = logits / temp\n    probs = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits))\n    \n    # Create DataFrame for this temperature\n    df_temp = pd.DataFrame({\n        'Token': [f'Token_{j}' for j in range(len(logits))],\n        'Probability': probs\n    })\n    \n    # Plot distribution with better styling\n    bars = axes[i].bar(df_temp['Token'], df_temp['Probability'], \n                      color=colors[i], alpha=0.8, edgecolor='white', linewidth=1.5)\n    \n    # Bold T=1.0\n    title_weight = 'bold' if temp == 1.0 else 'normal'\n    title_size = 16 if temp == 1.0 else 14\n    axes[i].set_title(f'Temperature = {temp}', fontweight=title_weight, fontsize=title_size)\n    \n    axes[i].set_ylabel('Probability', fontweight='bold')\n    axes[i].set_ylim(0, 1.1)\n    axes[i].tick_params(axis='x', rotation=45)\n    axes[i].grid(True, alpha=0.3, linestyle='--')\n    axes[i].set_facecolor('#F8F9FA')\n    \n    # Add probability values on top of bars\n    for bar, prob in zip(bars, probs):\n        axes[i].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n                    f'{prob:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n\nplt.suptitle('Temperature Scaling Effects: Distribution Shape Changes', \n            fontsize=20, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diagram clearly shows how temperature reshapes probability distributions - low temperatures create peaked distributions while high temperatures flatten them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Load a language model to explore temperature effects in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token to avoid warnings\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilGPT2 loaded with proper tokenizer configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Prompt\n",
    "\n",
    "Let's start with a simple prompt to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[ 818,  262, 2003,   11, 9552,  481]])\n",
      "Vocabulary size: 50257\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In the future, AI will\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Vocabulary size:\", model.config.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model converts text to token IDs and works with a vocabulary of 50,257 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation with Low Temperature\n",
    "\n",
    "Generate text with very low temperature to see deterministic behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: In the future, AI will be able to do things like make people smarter, more intelligent, more intelligent, more intelligent, more\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.01,\n",
    "    max_new_tokens=20,\n",
    "    top_k=50,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    attention_mask=torch.ones_like(input_ids)\n",
    ")\n",
    "\n",
    "decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low temperature produces repetitive, deterministic text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logits Analysis\n",
    "\n",
    "Let's examine the raw logits and probabilities for next token prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">           Top 10 Token Predictions            </span>\n",
       "┏━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Rank </span>┃<span style=\"font-weight: bold\"> Token       </span>┃<span style=\"font-weight: bold\"> Logit    </span>┃<span style=\"font-weight: bold\"> Probability </span>┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' be'       </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -63.5934 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.5269      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' have'     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -64.7306 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.1690      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' need'     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -65.5254 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0763      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' become'   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -65.8555 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0549      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' not'      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -66.0847 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0436      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' also'     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -66.4207 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0312      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' take'     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -66.5617 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0271      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' continue' </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -66.5808 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0266      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9    </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' make'     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -66.6369 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0251      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10   </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> ' only'     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> -66.8984 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 0.0193      </span>│\n",
       "└──────┴─────────────┴──────────┴─────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m           Top 10 Token Predictions            \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mRank\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mToken      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLogit   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mProbability\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m1   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' be'      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-63.5934\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.5269     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' have'    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-64.7306\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.1690     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' need'    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-65.5254\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0763     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' become'  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-65.8555\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0549     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' not'     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-66.0847\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0436     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m6   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' also'    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-66.4207\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0312     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m7   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' take'    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-66.5617\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0271     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m8   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' continue'\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-66.5808\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0266     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m9   \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' make'    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-66.6369\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0251     \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m10  \u001b[0m\u001b[2m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m' only'    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m-66.8984\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m0.0193     \u001b[0m\u001b[32m \u001b[0m│\n",
       "└──────┴─────────────┴──────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the logits for prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    # Show logits and probabilities for top 10 tokens\n",
    "    top_logits, top_indices = torch.topk(logits[0, -1], k=10)\n",
    "    top_probs = torch.softmax(top_logits, dim=0)\n",
    "    top_tokens = [tokenizer.decode([idx]) for idx in top_indices]\n",
    "    \n",
    "    # Create a clean table\n",
    "    table = Table(title=\"Top 10 Token Predictions\")\n",
    "    table.add_column(\"Rank\", style=\"dim\")\n",
    "    table.add_column(\"Token\", style=\"cyan\")\n",
    "    table.add_column(\"Logit\", style=\"magenta\")\n",
    "    table.add_column(\"Probability\", style=\"green\")\n",
    "    \n",
    "    for i, (token, logit, prob) in enumerate(zip(top_tokens, top_logits, top_probs)):\n",
    "        table.add_row(\n",
    "            str(i + 1),\n",
    "            repr(token),\n",
    "            f\"{logit.item():.4f}\",\n",
    "            f\"{prob.item():.4f}\"\n",
    "        )\n",
    "    \n",
    "    console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows clear preference for certain tokens, with \"be\" having the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Sampling\n",
    "\n",
    "Sample tokens from the probability distribution to see randomness in action:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Sample tokens from the distribution\nsampled_indices = torch.multinomial(top_probs, num_samples=100, replacement=True)\nsampled_tokens = [top_tokens[idx] for idx in sampled_indices]\n\n# Display sample using Rich\nrprint(\"Sample of tokens:\")\nrprint(\" \".join([f\"[cyan]{token}[/cyan]\" for token in sampled_tokens[:20]]))\n\n# Count occurrences and display in Rich table\ntoken_counts = Counter(sampled_tokens)\n\n# Create Rich table for token counts\ntable = Table(title=\"Token Counts from 100 Samples\")\ntable.add_column(\"Token\", style=\"cyan\")\ntable.add_column(\"Count\", style=\"green\")\ntable.add_column(\"Percentage\", style=\"yellow\")\n\nfor token, count in token_counts.most_common():\n    percentage = (count / 100) * 100\n    table.add_row(token, str(count), f\"{percentage:.1f}%\")\n\nconsole.print(table)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token counts from 100 samples reflect the underlying probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Scaling Comparison\n",
    "\n",
    "Compare extreme temperature values to see dramatic differences:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Temperature scaling comparison across multiple temperatures\ntemperature_values = [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 100.0]\n\n# Calculate probabilities for each temperature\ntemp_results = {}\nfor temp in temperature_values:\n    scaled_logits = logits / temp\n    top_logits_temp, top_indices_temp = torch.topk(scaled_logits[0, -1], k=10)\n    top_probs_temp = torch.softmax(top_logits_temp, dim=0)\n    temp_results[temp] = {\n        'probs': top_probs_temp,\n        'tokens': [tokenizer.decode([idx]) for idx in top_indices_temp]\n    }\n\n# Create comprehensive comparison table\ntable = Table(title=\"Temperature Scaling: Full Spectrum Comparison\")\ntable.add_column(\"Rank\", style=\"dim\")\ntable.add_column(\"Token\", style=\"cyan\")\n\nfor temp in temperature_values:\n    if temp == 1.0:\n        table.add_column(f\"**T={temp}**\", style=\"bold green\")  # Bold T=1\n    else:\n        table.add_column(f\"T={temp}\", style=\"green\" if temp > 1.0 else \"red\")\n\nfor i in range(10):\n    row_data = [str(i + 1), repr(temp_results[temperature_values[0]]['tokens'][i])]\n    \n    for temp in temperature_values:\n        prob = temp_results[temp]['probs'][i].item()\n        row_data.append(f\"{prob:.4f}\")\n    \n    table.add_row(*row_data)\n\nconsole.print(table)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High temperature creates uniform distribution while low temperature creates deterministic selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Analysis\n",
    "\n",
    "Analyze how different temperatures affect probability distributions and entropy:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Function to analyze temperature effects\ndef analyze_temperature_effects(logits, temperatures, top_k=10):\n    results = []\n    for temp in temperatures:\n        scaled_logits = logits / temp\n        probs = torch.softmax(scaled_logits, dim=-1)\n        \n        # Get top-k tokens\n        top_probs, top_indices = torch.topk(probs[0, -1], k=top_k)\n        top_tokens = [tokenizer.decode([idx]) for idx in top_indices]\n        \n        # Calculate entropy\n        prob_dist = probs[0, -1].cpu().numpy()\n        entropy_value = entropy(prob_dist)\n        \n        for i, (token, prob) in enumerate(zip(top_tokens, top_probs)):\n            results.append({\n                'temperature': temp,\n                'token': token,\n                'probability': prob.item(),\n                'rank': i + 1,\n                'entropy': entropy_value\n            })\n    \n    return results\n\n# Test with different temperature values\ntemperatures = [0.1, 0.5, 1.0, 2.0, 5.0]\nresults = analyze_temperature_effects(logits, temperatures)\n\n# Create prettier visualizations\nplt.rcParams.update({\n    'font.size': 12,\n    'axes.labelsize': 14,\n    'axes.titlesize': 16,\n    'xtick.labelsize': 12,\n    'ytick.labelsize': 12,\n    'legend.fontsize': 12,\n    'figure.titlesize': 18\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Plot 1: Top-k probabilities with better styling\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\nfor i, temp in enumerate(temperatures):\n    temp_data = [r for r in results if r['temperature'] == temp]\n    ranks = [r['rank'] for r in temp_data]\n    probs = [r['probability'] for r in temp_data]\n    \n    linewidth = 3 if temp == 1.0 else 2\n    axes[0].plot(ranks, probs, 'o-', label=f'T={temp}', \n                color=colors[i], linewidth=linewidth, markersize=8, alpha=0.8)\n\naxes[0].set_xlabel('Token Rank', fontweight='bold')\naxes[0].set_ylabel('Probability', fontweight='bold')\naxes[0].set_title('Top-k Token Probabilities vs Temperature', fontweight='bold')\naxes[0].legend(frameon=True, fancybox=True, shadow=True)\naxes[0].grid(True, alpha=0.3, linestyle='--')\naxes[0].set_facecolor('#F8F9FA')\n\n# Plot 2: Entropy vs Temperature with better styling\nentropies = []\nfor temp in temperatures:\n    temp_entropy = [r['entropy'] for r in results if r['temperature'] == temp][0]\n    entropies.append(temp_entropy)\n\naxes[1].plot(temperatures, entropies, 'o-', color='#E74C3C', \n            linewidth=3, markersize=10, alpha=0.8)\naxes[1].set_xlabel('Temperature', fontweight='bold')\naxes[1].set_ylabel('Entropy', fontweight='bold')\naxes[1].set_title('Entropy vs Temperature', fontweight='bold')\naxes[1].grid(True, alpha=0.3, linestyle='--')\naxes[1].set_facecolor('#F8F9FA')\n\n# Highlight T=1.0 on entropy plot\nidx_1 = temperatures.index(1.0)\naxes[1].scatter(1.0, entropies[idx_1], color='#2ECC71', s=150, \n               zorder=5, edgecolors='white', linewidth=2)\naxes[1].annotate('T=1.0\\n(Standard)', xy=(1.0, entropies[idx_1]), \n                xytext=(1.5, entropies[idx_1] + 0.5),\n                arrowprops=dict(arrowstyle='->', color='#2ECC71', lw=2),\n                fontsize=11, ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher temperatures lead to flatter distributions and higher entropy, confirming the mathematical relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diverse Examples Across Domains\n",
    "\n",
    "Test temperature effects on different types of content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">SCIENCE</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mSCIENCE\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt: <span style=\"color: #008000; text-decoration-color: #008000\">'The scientific method involves'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt: \u001b[32m'The scientific method involves'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: a series of experiments that have been performed in the past. The results are\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: a series of experiments that have been performed in the past. The results are\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: a series of mathematical formulas, which are used to calculate the number of points\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: a series of mathematical formulas, which are used to calculate the number of points\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: a series of steps that are performed by the computer and the computer to determine\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: a series of steps that are performed by the computer and the computer to determine\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: studying individual data that they may have accumulated from such collections, such as those\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: studying individual data that they may have accumulated from such collections, such as those\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: an average of about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> degrees on each curve <span style=\"font-weight: bold\">(</span>the average curve<span style=\"font-weight: bold\">)</span>. There\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: an average of about \u001b[1;36m10\u001b[0m degrees on each curve \u001b[1m(\u001b[0mthe average curve\u001b[1m)\u001b[0m. There\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: the elimination of the presence of any known and unknown substance and the replacement of\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: the elimination of the presence of any known and unknown substance and the replacement of\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: conducting research and evaluation by establishing two, high value values <span style=\"font-weight: bold\">(</span>M-T\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: conducting research and evaluation by establishing two, high value values \u001b[1m(\u001b[0mM-T\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: a series of steps used and combined to bring together a high quality of particle\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: a series of steps used and combined to bring together a high quality of particle\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: two simultaneous experiments.\n",
       "\n",
       "If he is a participant this method could provide\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: two simultaneous experiments.\n",
       "\n",
       "If he is a participant this method could provide\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">MATHEMATICS</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mMATHEMATICS\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt: <span style=\"color: #008000; text-decoration-color: #008000\">'To solve the equation x^2 - 4x + 3 = 0,'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt: \u001b[32m'To solve the equation x^2 - 4x + 3 = 0,'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>×<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>×<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> = a + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: \u001b[1;36m1\u001b[0m×\u001b[1;36m3\u001b[0m = \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m×\u001b[1;36m4\u001b[0m = a + \u001b[1;36m3\u001b[0m = \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: * <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, &lt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, * <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: * \u001b[1;36m10\u001b[0m, < \u001b[1;36m1\u001b[0m, * \u001b[1;36m9\u001b[0m, + \u001b[1;36m5\u001b[0m, + \u001b[1;36m7\u001b[0m,\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"font-weight: bold\">(</span>k x + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span> &amp; k , <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> = \\frac<span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: \u001b[1m(\u001b[0mk x + \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m & k , \u001b[1;36m0\u001b[0m = \\frac\u001b[1m{\u001b[0m\u001b[1;36m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: d = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> + t , * r^<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> <span style=\"font-weight: bold\">]</span> -&gt; <span style=\"font-weight: bold\">(</span>R <span style=\"color: #800080; text-decoration-color: #800080\">/</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: d = \u001b[1;36m0\u001b[0m + t , * r^\u001b[1;36m2\u001b[0m \u001b[1m]\u001b[0m -> \u001b[1m(\u001b[0mR \u001b[35m/\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, x <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> x^<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> = 35x\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: \u001b[1;36m1\u001b[0m = \u001b[1;36m15\u001b[0m, x \u001b[35m/\u001b[0m \u001b[1;36m6\u001b[0m x^\u001b[1;36m3\u001b[0m - \u001b[1;36m2\u001b[0m = 35x\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> ,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> a = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: \u001b[1;36m2\u001b[0m ,\u001b[1;36m3\u001b[0m a = \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">LITERATURE/ENGLISH</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mLITERATURE/ENGLISH\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt: <span style=\"color: #008000; text-decoration-color: #008000\">'In Shakespeare'</span>s time, the theater'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt: \u001b[32m'In Shakespeare'\u001b[0ms time, the theater'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: was a place of great entertainment and entertainment. Shakespeare was a great actor,\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: was a place of great entertainment and entertainment. Shakespeare was a great actor,\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: was a place where the audience could see the world, and they could see\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: was a place where the audience could see the world, and they could see\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: was a place where people could play Shakespeare. Shakespeare was a place where people\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: was a place where people could play Shakespeare. Shakespeare was a place where people\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: had to be filled with characters who took part, like Shakespeare's or Shakespeare\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: had to be filled with characters who took part, like Shakespeare's or Shakespeare\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: was in its infancy and, with its most prolific theatre — from its late\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: was in its infancy and, with its most prolific theatre — from its late\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: theater was a small entertainment industry that had no market share. Most people on\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: theater was a small entertainment industry that had no market share. Most people on\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Temperature </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span><span style=\"color: #008080; text-decoration-color: #008080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mTemperature \u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[36m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: critic at Rethinkers of America calls them: 'Is Shakespeare in\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m1\u001b[0m: critic at Rethinkers of America calls them: 'Is Shakespeare in\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: will be one way <span style=\"font-weight: bold\">(</span>and another<span style=\"font-weight: bold\">)</span>. Shakespeare made Shakespeare popular with readers of\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m2\u001b[0m: will be one way \u001b[1m(\u001b[0mand another\u001b[1m)\u001b[0m. Shakespeare made Shakespeare popular with readers of\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Sample <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: company that created Shakespeare the Musical with Daniel Sedaris and James Batson,\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Sample \u001b[1;36m3\u001b[0m: company that created Shakespeare the Musical with Daniel Sedaris and James Batson,\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_comparison_examples():\n",
    "    \"\"\"Generate examples across different domains to show temperature effects\"\"\"\n",
    "    \n",
    "    examples = [\n",
    "        (\"The scientific method involves\", \"Science\"),\n",
    "        (\"To solve the equation x^2 - 4x + 3 = 0,\", \"Mathematics\"),\n",
    "        (\"In Shakespeare's time, the theater\", \"Literature/English\")\n",
    "    ]\n",
    "    \n",
    "    temperatures = [0.3, 1.0, 2.0]\n",
    "    \n",
    "    for prompt, domain in examples:\n",
    "        rprint(f\"\\n[bold]{domain.upper()}[/bold]\")\n",
    "        rprint(f\"Prompt: '{prompt}'\")\n",
    "        rprint(\"-\" * 50)\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            rprint(f\"\\n[cyan]Temperature {temp}:[/cyan]\")\n",
    "            for i in range(3):  # Generate 3 samples per temperature\n",
    "                output = model.generate(\n",
    "                    input_ids,\n",
    "                    do_sample=True,\n",
    "                    temperature=temp,\n",
    "                    max_new_tokens=15,\n",
    "                    top_k=50,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                    attention_mask=torch.ones_like(input_ids)\n",
    "                )\n",
    "                \n",
    "                generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "                new_text = generated_text[len(prompt):].strip()\n",
    "                rprint(f\"  Sample {i+1}: {new_text}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "generate_comparison_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple samples reveal consistency patterns at low temperatures and diversity at high temperatures across all domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Applications\n",
    "\n",
    "## Use Cases\n",
    "- **Low Temperature (0.1-0.5)**: Code generation, technical docs, factual content\n",
    "- **Medium Temperature (0.7-1.2)**: Creative writing, chatbots, general text\n",
    "- **High Temperature (1.5-3.0)**: Brainstorming, fiction, diverse idea generation\n",
    "\n",
    "## Quick Guidelines\n",
    "- Start with T=1.0 as baseline\n",
    "- Lower temperature for consistency and accuracy\n",
    "- Higher temperature for creativity and diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Temperature scaling is a simple yet powerful technique for controlling language model randomness:\n",
    "\n",
    "- **T < 1**: More deterministic, consistent outputs\n",
    "- **T = 1**: Standard softmax behavior  \n",
    "- **T > 1**: More random, diverse outputs\n",
    "\n",
    "Monitor entropy to quantify diversity. Temperature remains one of the most practical tools for controlling LLM behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "## Code and Implementation\n",
    "- Temperature Scaling Repository: https://github.com/gpleiss/temperature_scaling\n",
    "- Twitter Discussion: https://x.com/akshay_pachaar/status/1942201076767412307\n",
    "\n",
    "## Academic Sources\n",
    "- Hinton, G. et al. (2015): \"Distilling the Knowledge in a Neural Network\" - Original paper introducing temperature in knowledge distillation\n",
    "- Guo, C. et al. (2017): \"On Calibration of Modern Neural Networks\" - ICML paper on temperature scaling for calibration\n",
    "- Goodfellow, I. et al. (2016): \"Deep Learning\" - Chapter 6 covers softmax and temperature scaling\n",
    "- Bishop, C. (2006): \"Pattern Recognition and Machine Learning\" - Chapter 4 discusses softmax temperature\n",
    "\n",
    "## Textbooks\n",
    "- \"Deep Learning\" by Goodfellow, Bengio, and Courville - Comprehensive coverage of softmax and sampling techniques\n",
    "- \"Pattern Recognition and Machine Learning\" by Christopher Bishop - Mathematical foundations of probability distributions\n",
    "- \"The Elements of Statistical Learning\" by Hastie, Tibshirani, and Friedman - Statistical perspective on temperature scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}